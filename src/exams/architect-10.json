{"data":{"createNewExamAttempt":{"attempt":{"id":"311d1765-ceb6-4b59-b815-02c72b9f6f29"},"exam":{"id":"0e6b5a9a-afa5-471e-9e64-335d400510c5","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"e9205ab6-d7ce-4708-b92d-e6814f79c6d4","domain":"ResilientDesign","question":"The dashboard application for multiple company contact centers requires fast update response times for a large number of concurrent users. Call center metric data is stored in an Oracle version 11 database. Which architecture will provide high-availability and the low response times needed for this mission-critical data?","explanation":"Since the dashboard updates are needed across multiple contact centers, leveraging read-only replicated databases will provide fast response times. Amazon RDS doesn’t support read replicas for Oracle version 11, so hosting the database on EC2 and replicating the data with Oracle Data Guard is the only viable solution. AWS Database Replication Service is not an offered service, and using EBS snapshots won't provide real-time replication.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/oracle-database/overview.html","title":"Oracle Database on AWS"}],"answers":[{"id":"0129ed97e5c2ec017bdc05d836f10049","text":"Oracle hosted on Amazon EC2 in multiple Availability Zones with Oracle Data Guard replication","correct":true},{"id":"5ee29b50026caa8c20c9e469f93b5a2a","text":"Oracle hosted on Amazon EC2 in Multiple Availability Zones with EBS snapshots","correct":false},{"id":"de5ad68debdabd478d7d4f66542b9ca8","text":"An Amazon RDS Oracle Instance with AWS Database Replication Service","correct":false},{"id":"c1e824f46134bc6696eba635f30df032","text":"An Amazon RDS Oracle instance with Multi-AZ and Read Replicas","correct":false}]},{"id":"a42f6119-13ea-4da2-b000-6d83c8d05d43","domain":"Performant","question":"Your company will be importing to AWS 150TB of data to AWS using AWS Snowball. This data will be used at the database layer, and this database should be able to be queried from a business intelligence application. Each item to be stored in the database is roughly 500KB in size. Which of the following is an ideal storage system for this data?","explanation":"Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud. You can start with just a few hundred gigabytes of data and scale to a petabyte or more.  Know the general size limits of the different DB services.","links":[{"url":"https://docs.aws.amazon.com/redshift/latest/mgmt/welcome.html","title":"What is Amazon Redshift?"}],"answers":[{"id":"978477d5f5134ae77209d11e2ed888cc","text":"AWS DynamoDB","correct":false},{"id":"bb19142594bf36abf39924ce5b3810c2","text":"AWS Aurora","correct":false},{"id":"20ee05108093daf420f5c776f43cf4a2","text":"AWS Redshift","correct":true},{"id":"6e11595bc7ccdbf672fefaababf72939","text":"AWS RDS","correct":false}]},{"id":"22b1c6a0-1e15-4a38-8a17-4a90fa381ffa","domain":"ResilientDesign","question":"Your business is evaluating several database technologies from AWS - one of the major requirements is the ability to withstand an Availability Zone outage within a single database cluster. Which of the following AWS Database services does NOT meet this requirement?","explanation":"A RedShift DB cluster can only be deployed in a single AZ. All other RDS Databases: MS SQL, PostgreSQL, MySQL, Oracle and MariaDB natively support Multi-AZ deployments. Although Redshift can be architected in a way that has Availability Zone level redundancy, this requires the use of multiple RedShift clusters, and manually setting up DB to DB replication across AZ’s, and therefore does not satisfy the requirement.","links":[{"url":"https://aws.amazon.com/redshift/faqs/","title":"Amazon Redshift FAQs"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"Amazon Relational Database Service"}],"answers":[{"id":"d2727816fa1087ddac7dff69e35c5536","text":"MS SQL","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"35f802e4a5e1cbdf3f99a71a86ae3153","text":"RedShift","correct":true},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false}]},{"id":"9d65d585-d756-42e0-83bb-d8a7f4c83e82","domain":"ResilientDesign","question":"You need to take a snapshot of an EBS volume.  You are concerned about the volume and instance becoming unavailable until the snapshot is complete.  Which of these statements best describe the facts that will allow you to assess the duration of the outage?","explanation":"in General terms a snapshot has two parts; the snapshot catalogue, and the copy off of the data.  Sometimes called 'the snapshot'.  During the catalogue phase all changed files and blocks are catalogued, locked, and a change log is started.  This is a relatively fast process for most disk file systems and is the only part of the process during which the disk cannot be accessed.  the 2nd phase is the slow part during which the data is copied to the backup system.  The system is not locked during this phase. The actual duration when the system is unavailable is most closely related to how many files or blocks have changed since the last backup as this is the only portion of the data that is relevant to the incremental backup (snapshot).","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"Amazon EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html","title":"Creating an Amazon EBS Snapshot"},{"url":"https://help.acloud.guru/hc/en-us/search?utf8=%E2%9C%93&query=ebs+snapshot","title":"EBS Snapshot KBs"},{"url":"https://aws.amazon.com/blogs/aws/new-lifecycle-management-for-amazon-ebs-snapshots/","title":"New – Lifecycle Management for Amazon EBS Snapshots"}],"answers":[{"id":"071b64034823256c8ea3bb0048764787","text":"The duration of the outage is only related to the initial cataloguing phase.","correct":true},{"id":"3ac42d808544b4ab0806225881c0e525","text":"The duration of the outage is determined by the number of files changed since the last backup.","correct":true},{"id":"26583a3f6db686ba6c478f8ee3badf00","text":"The duration of the outage is determined by the age of the server.","correct":false},{"id":"6e2f1ca114ad32c09d2c423450ab61e5","text":"The duration of the outage is determined by the size of the server.","correct":false},{"id":"0462d5d8fc0d1947c3ed97376ea2ceba","text":"The duration of the outage is the time it takes to copy all the files from the disk to the backup.","correct":false},{"id":"c18929ab2ad2fc22f4c285962aaa39c8","text":"The duration of the outage is determined by the number of files on the disk.","correct":false},{"id":"aae5747a54a5f12a114ff2d92fd668c7","text":"The duration of the outage is determined by the number of files changed since the server was commissioned.","correct":false}]},{"id":"07689304-6bbb-46ce-ba91-08edaeee087a","domain":"ResilientDesign","question":"You are creating an RDS database for your production environment and it needs to be highly available and continue to function in the event of an outage to the Primary database. Which of the following options will best meet this requirement?","explanation":"Multi-AZ deployment involves the creation of a standby replica in a different Availability Zone (AZ) from the primary database. A standby replica cannot serve read traffic, it is used to synchronously replicate data from the primary database. AZs are isolated from one another to prevent failure from spreading to them all. So, if the location of the primary database has issues, Amazon RDS automatically fails over to the standby replica. Read replicas are used to scale out to cater for high volumes of read requests - not automated failover. Multi-region deployment is not a valid RDS option and Cross-region deployments enable support for scaling of Read replicas and can be used for cross-region DR, but don't support the automatic failover due to a Primary DB outage.","links":[{"url":" https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Concepts.RegionsAndAvailabilityZones.html","title":"Choosing the Regions and Availability Zones"}],"answers":[{"id":"9256e377c39a64274bd60ff4916a4cb9","text":"Multi-AZ deployment","correct":true},{"id":"a9fa9ab64858fe533c9b65e9b8ba2fb9","text":"Multi-region deployment","correct":false},{"id":"794e9156bdd31164380a7005f8599e08","text":"Cross-region deployment","correct":false},{"id":"b75ef1477da122d3b8733ab5da141356","text":"Read replicas","correct":false}]},{"id":"e9ed5908-d661-4e8d-90ce-f30b7ccf52b4","domain":"SecureSolutions","question":"To enable your Lambda function to access resources inside your private VPC, you must provide additional VPC-specific configuration information. Select all correct statements about that.","explanation":"AWS Lambda does not support connecting to resources within Dedicated Tenancy VPCs. If your Lambda function requires Internet access, you cannot use an Internet gateway attached to your VPC since that requires the ENI to have public IP addresses.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/vpc.html","title":"Configuring a Lambda Function to Access Resources in an Amazon VPC"}],"answers":[{"id":"1f1b5cfe4913b1180428fa247ff5fabe","text":"AWS Lambda uses the provided VPC-specific configuration information to set up elastic network interfaces. Therefore, your Lambda function execution role must have permissions to create, describe and delete these.","correct":true},{"id":"254b36e0842eed2ecae11451f2f2e9a3","text":"If your Lambda function needs to access both VPC resources and the public Internet, the VPC needs to have a NAT instance inside your VPC, you can use the Amazon VPC NAT gateway or you can use an Internet gateway attached to your VPC.","correct":false},{"id":"09487d067c224691d77b18e71cb59b00","text":"When you add VPC configuration to a Lambda function, it can only access resources in that VPC. However, you can specify multiple VPC using the VpcConfig parameter. Simply comma separate the VPC subnet and security group IDs","correct":true},{"id":"be0a713a2ad51fc0b1bcaf1fe7598864","text":"AWS Lambda does also support connecting to resources within Dedicated Tenancy VPCs.","correct":false}]},{"id":"8c8d1581-f004-4d00-a8a0-503b69a1f4d7","domain":"Performant","question":"You've migrated a legacy workflow application that is written in Java 1.4 from an on-prem server to a single M5 EC2 instance configured in an auto scaling group with a max-size of 1 across multiple AZs in the Asia Pacific (Sydney) region. It periodically checks a database for new and updated records and sends out email notifications. In the logs, you see frequent timeout errors. What could be a possible cause and how can you fix this?","explanation":"Amazon EC2 throttles traffic on port 25 of all EC2 instances by default, but you can request for this throttle to be removed or change to another port. In this example, you are not using SES and therefore, its endpoints or sending limits are irrelevant.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-port-25-throttle/","title":"How do I remove the throttle on port 25 from my EC2 instance?"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-connect.html","title":"Connecting to the Amazon SES SMTP Endpoint"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/regions.html","title":"Regions and Amazon SES"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-issues.html","title":"Amazon SES SMTP Issues"}],"answers":[{"id":"385f853c6ca8754ad8dc4289fd42413e","text":"The app uses the standard JavaMail API on port 25. Amazon EC2 throttles traffic on that port of all EC2 instances by default, but you can request for this throttle to be removed.","correct":true},{"id":"3d9ae95c23fe7b09220f12c62ff95f17","text":"Amazon SES Endpoints are only available in the US East (N. Virginia), US West (Oregon) and EU (Ireland) regions. You cannot migrate your legacy app until SES becomes available in Australia.","correct":false},{"id":"cdf61badb6564eb5121bb15b0dba57d6","text":"You change an application properties file and update the currently used port from 25 to 2587, build a new AMI with that new version and configure your launch configuration to use that.","correct":true},{"id":"8a122c9945f5b1a081e098fdeadc94fe","text":"You might have reached your Amazon email sending limits. To increase that, open a Sending Limit case in the AWS Support Center.","correct":false}]},{"id":"ee772b8e-1672-479d-b28d-8952d89b24f5","domain":"SecureSolutions","question":"By default, how many Elastic IP addresses are you limited to per region?","explanation":"By default, all accounts are limited to 5 Elastic IP addresses per region.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Appendix_Limits.html#vpc-limits-eips","title":"Elastic IP Addresses - Limits"}],"answers":[{"id":"98f13708210194c475687be6106a3b84","text":"20","correct":false},{"id":"e4da3b7fbbce2345d7772b0674a318d5","text":"5","correct":true},{"id":"9bf31c7ff062936a96d3c8bd1f8f2ff3","text":"15","correct":false},{"id":"d3d9446802a44259755d38e6d163e820","text":"10","correct":false}]},{"id":"2a2db64e-2e02-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You wish to set up a WordPress website consisting of 4 webpages for your client, who recently founded a logo creation business. Based on the client’s specifications, you will create one webpage that gives a summary of the company and its services, a second one that provides a brief professional biography of the founder, a third one that showcases the business owner’s portfolio, and a fourth one that serves as the contact information page and simply contains an email and phone number. Three of the four webpages will include images which the client doesn’t expect will change much, if at all. Using the EC2 service to set up the website, which of the following instance types would be the most cost-effective choice?","explanation":"Based on the client’s specifications, it doesn’t seem like this website requires an elevated level of compute, memory, storage, or networking power. So, a general purpose instance would be the most cost-effective choice.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types"}],"answers":[{"id":"a97bdc2a34beb1500a16c5a5f41d3234","text":"Memory optimized","correct":false},{"id":"4e8e31d149d66214d0c06fd9ee8b877b","text":"Compute optimized","correct":false},{"id":"3da02f3f7a678b5e2c167fb35dcea8f5","text":"General purpose","correct":true},{"id":"e65781ecdb4e2c3e7af2864d7b875e57","text":"Accelerated computing","correct":false},{"id":"b4820282379b9534539d339e1d898f2b","text":"Storage optimized","correct":false}]},{"id":"126e898c-dd73-4447-b5a7-59701a16a92d","domain":"ResilientDesign","question":"You are reviewing Change Control requests and you note that there is a proposed change designed to reduce errors due to S3 Eventual Consistency by updating the 'DelaySeconds' attribute. What does this mean?","explanation":"Poor timing of SQS processes can significantly impact the cost effectiveness of the solution.","links":[{"url":"http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"6e5b2857717c8cf5b2722dc270183515","text":"While processing a message, a consumer instance can reset the message visibility by restarting the preset timeout counter.","correct":false},{"id":"4b46d6ad9dd090f0143cc40fecbad7b5","text":"When a new message is added to the SQS queue, it will be hidden from consumer instances for a fixed period.","correct":true},{"id":"464400e5333b3beab1128b1b1f7cedf7","text":"While processing a message, a consumer instance can amend the message visibility counter by a fixed amount.","correct":false},{"id":"f170b98804f18cb00b57e135f0a3f116","text":"When the consumer instance polls for new work, the consumer instance will wait a certain time until it has a full workload before closing the connection.","correct":false}]},{"id":"c07cbbaf-7a26-44d9-9e50-86908c1ac754","domain":"ResilientDesign","question":"A football scoreboard app uses an AWS Lambda backend to retrieve game information stored in an Amazon DynamoDB database. An EC2 instance reads multiple Amazon Kinesis streams of scores and stats and writes them to the database. Two app users sitting side-by-side at a restaurant refresh the scoreboard at the same time and get different stats for the same game. What should the app developers do to resolve this?","explanation":"DynamoDB is eventually consistent by default, and may not reflect the results of a recently completed write since data is automatically replicated across three facilities in an AWS region for durability. You can request strongly consistent reads that reflect all previous writes. Consolidating Kinesis streams probably won't help since Kineses producers are generally singular data sources (all stats of a specific type will come from one producer). Replacing Lambda with EC2 will have cost consequences, and in this case will probably result in an undesirable stateful architecture. Timestamp information will not resolve an eventual consistency issue.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","title":"DynamoDB Read Consistency"}],"answers":[{"id":"c606fec0599df4127dba2d5df85a283f","text":"Store score and stat updates timestamps in the database to ensure the most recent information is served by the Lambda backend ","correct":false},{"id":"a8da8441084c1a5b79e47be3f6f98a0d","text":"Have the Lambda function perform a strongly consistent read from the database","correct":true},{"id":"c151deab4b337fd8377eed0413d50903","text":"Consolidate the Kinesis streams into a single stream to avoid writing different results to the database","correct":false},{"id":"95bc7fe6a012dc37b025c1cb8fe566e7","text":"Replace Lambda with an EC2 instance that synchronizes reads of the data with database updates","correct":false}]},{"id":"5c6ec542-13ec-47b0-90b9-747eba40a8dd","domain":"CostOptimized","question":"What main functions can Route 53 perform? Select the best answer from the following options.","explanation":"Route53 is Amazons DNS web service that delivers the domain registration, DNS routing and health checking function in any combination.","links":null,"answers":[{"id":"20cda55464d105018afc584dcdbc80fe","text":"Domain registration, DNS routing, and health checking in any combination","correct":true},{"id":"207068b486e311e8fedb355a6c2edcff","text":"Domain registration and DNS routing","correct":false},{"id":"24f6183de033dcaee97747be7c92a9f3","text":"Amazon Route 53 is a highly available and scalable cloud Domain Name System (DNS) web service that is designed to give developers and businesses an extremely reliable and cost-effective way to route end users to Internet applications. It can be used together with CloudWatch, a service which allows you to monitor and manage applications. While Route 53 is not a domain reseller, it allows customers to bring their own domain names with them.","correct":false},{"id":"fd7a725638e536df09c6ea5a5d0f2b46","text":"DNS routing and health checking for domains hosted on AWS","correct":false}]},{"id":"39236967-6c02-4608-9ddb-9ae5cb590e7f","domain":"CostOptimized","question":"You purchased a reserved instance for hosting your website with a term of one year as this has significant cost savings compared to on-demand instances. What happens to this instance after one year?","explanation":"The reserved instance type has significant cost benefit when compared to the on-demand instance type when purchased in advance with one or three years term. Reserved instances are not physical instances, but rather a billing discount applied to the use of on-demand instances in the account you own. Reserved instances do not renew automatically; when they expire, you can continue using the EC2 instance without interruption, but you are charged on-demand rates.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","title":"Amazon Elastic Compute Cloud - Reserved Instance Type"}],"answers":[{"id":"c412194739de1b9b17bd8734ab35aaa5","text":"The reserved instance will be shutdown automatically after one year and a 2 weeks of notice will be provided by AWS to either renew or terminate.","correct":false},{"id":"85f13ce18baa70ee478fe656e5b02ca6","text":"The reserved instance will renew automatically if the auto-renew option is set to true.","correct":false},{"id":"4c1a861266ab02cfae787e36ebfe54b4","text":"The EC2 instance continues to run without interruption, but the instance is billed at the on-demand rate.","correct":true},{"id":"c97c0ee2fa55e86eeebafc57a4831b3a","text":"The reserved instance will be terminated automatically after one year, with a termination warning notice.","correct":false}]},{"id":"4839a4ad-8c28-42b6-baa4-ef893f842c21","domain":"Performant","question":"Which of the following RDS database types support RDS Read Replicas?","explanation":"Aurora, MySQL, MariaDB, Oracle and PostgreSQL all natively support read replicas in RDS. Although read replicas are available in MS SQL Server, these are not natively available in RDS and must be deployed into EC2 instances to work.","links":[{"url":"https://aws.amazon.com/rds/details/read-replicas/","title":"Amazon RDS Read Replicas"}],"answers":[{"id":"30162ed78b6c10f731411f2fc440c24f","text":"Oracle","correct":true},{"id":"7f9733e208088b1ce6df3d4be1765396","text":"MariaDB","correct":true},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":true},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":true},{"id":"8797fea4e66df215a8f85b78c1dc9c41","text":"Microsoft SQL","correct":false},{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":true}]},{"id":"74895349-5083-446e-a106-a0af4f0853d0","domain":"ResilientDesign","question":"If an instance belonging to an Elastic Load Balancer fails its health check, what will the ELB do?","explanation":"The ELB will de-register the instance and stop sending traffic to it.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html","title":"Health Checks for ELB"}],"answers":[{"id":"3f06dfecb47dd344952d684143ff06e9","text":"The ELB will launch a new instance.","correct":false},{"id":"c1438fa7ade98c37b521fe125b63ce1d","text":"The ELB will de-register the instance and stop sending traffic to it.","correct":true},{"id":"072b06f88cd7172f5098893f72f0011e","text":"ELB will tell Auto Scaling to launch a new instance.","correct":false},{"id":"21558324d05b7fbd37d11ddd53c8964e","text":"Unfortunately, the ELB will continue to send the unhealthy instance traffic until the instance is terminated.","correct":false}]},{"id":"e768ecaa-8e40-4cd8-b6ae-9a344d560c70","domain":"CostOptimized","question":"An organization which runs critical services in AWS has a requirement to store backups in another account.  One application uses S3 as its back-end data store.  The backups should be as automated as possible but resilient and cost-effective.  How would you satisfy backup requirements for this application's S3 objects?","explanation":"The organization requires that backups are held in a separate accounts which means replication cannot be within the same account.  The backups must also be highly-resilient and cost-effective which means One Zone-IA is less desirable (the backups would only be stored in one Availability Zone for that region). Infrequently Accessed is the best storage type to fit these needs.  Lastly since the solution needs to be as automated as possible, it makes sense to use the build-in replication features of S3 rather than coding a custom Lambda function.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-walkthrough-2.html","title":"Configuring Replication When the Source and Destination Buckets Are Owned by Different Accounts"},{"url":"https://aws.amazon.com/s3/storage-classes/","title":"Amazon S3 Storage Classes"}],"answers":[{"id":"686edabc75287b4e419ece13f6eb6c64","text":"Configure cross-account replication and configure the storage class for the replicated objects as S3 One Zone-IA","correct":false},{"id":"1ae32621b4651accf109c1736e5feac1","text":"Configure S3 events in the source bucket to trigger cross-account copies using Lambda into the backup account to S3 Standard Storage","correct":false},{"id":"e2bbecb893a3a44ba253e47129c3119d","text":"Configure S3 events in the source bucket to trigger same-account copies using Lambda into the backup account to S3 Infrequently Accessed","correct":false},{"id":"1cd85e1edc45929e969cd3f8a2469253","text":"Configure cross-account replication and configure the storage class for the replicated objects as S3 Infrequently Accessed","correct":true},{"id":"3c441e2bfc7b0c5824eb8df8bbf8373b","text":"Configure cross-account replication and configure the storage class for the replicated objects as S3 Standard Storage","correct":false}]},{"id":"6f866b44-3c21-444d-bba6-8e4bd7518c71","domain":"SecureSolutions","question":"You need to configure a new subnet in your VPC for a database cluster you are building. The subnet will never need more than six IP addresses. Which of the following is the best choice for this subnet?","explanation":"Databases generally do not require public access from the Internet, so a private subnet is the better choice from a security perspective. /28 is the smallest possible subnet in an AWS VPC.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html","title":"Working with Database Instances in a VPC"}],"answers":[{"id":"59576e63cff32d93d8d2abef68a6b99e","text":"A /28 public subnet","correct":false},{"id":"36d970f20594c42f714fbe7feb90f0ce","text":"A /28 private subnet","correct":true},{"id":"f9f9754c2b663d65bb88ab8ceb7fc40a","text":"A /16 public subnet","correct":false},{"id":"631501125c3f67c533a6eeb749167f34","text":"A /16 private subnet","correct":false}]},{"id":"10118f04-2d87-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You wish to delete an EC2 instance that you no longer use. However, you realize that you can’t do so. Which of the following actions in the EC2 dashboard will you need to execute to enable the deletion?","explanation":"If you can’t delete the instance, click the 'Change Termination Protection' to disable termination protection, which prevents anyone from unintentionally deleting it. Once Termination Deletion is disabled, you can delete the instance. 'Attach to Auto Scaling Group' enables automatic scaling for your EC2 instance, and 'Get System Log' pulls up the history of actions in the instance; both have nothing to do with its termination. 'Change Shutdown Behavior' is for determining whether the EC2 instance is terminated or stopped when the shutdown command is used from within the instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html","title":"Terminate Your Instance – Amazon Elastic Compute Cloud"}],"answers":[{"id":"91a6832787d50d959e40e389e5ac6b7e","text":"Change Shutdown Behavior","correct":false},{"id":"d1168fface65b719f1378443cee9d883","text":"Attach to Auto Scaling Group","correct":false},{"id":"e815242d6e8235575d2814adbe2439dc","text":"Change Termination Protection","correct":true},{"id":"5d4bd148bcf891ce27ceffce5be92781","text":"Get System Log","correct":false}]},{"id":"ed20f2cf-7759-41d0-9463-48c3624e7bf8","domain":"CostOptimized","question":"When deploying a NAT gateway, which of the following will you be billed for?","explanation":"With NAT Gateways, you are billed a flat fee for every hour that the gateway is active, plus an amount per GB processed by the gateway no matter the source or destination. Note that you will also have to pay the standard bandwidth charges for the traffic once it has passed through the gateway, in addition to the gateway costs.","links":[{"url":"https://aws.amazon.com/vpc/pricing/","title":"AWS VPC Pricing"}],"answers":[{"id":"a89c265a0491dbc3c90fcda91959c002","text":"Only outbound traffic","correct":false},{"id":"774e2089dd85e418697003baa7c7cf2e","text":"The instance that the NAT Gateway is running on","correct":false},{"id":"28ab52fb3a68950991911ff132f533e6","text":"Only inbound traffic","correct":false},{"id":"064634bdc8ac6c8fa5b308fdd665e1f3","text":"A cost per hour that the NAT Gateway is active","correct":true},{"id":"cf784879b0aed688d70b47aebb1551b4","text":"All traffic processed, regardless of it's direction","correct":true}]},{"id":"3e648b36-b215-4265-922c-8484055ff8bd","domain":"Performant","question":"You have been tasked with implementing a globally accessible storage solution that will scale from a few terabytes (now) to an unknown, but significantly greater, volume of data in three years time. Which AWS service would best meet your current and projected storage needs?","explanation":"Amazon S3 is highly scalable, secure storage for 'flat' files. S3 will scale to any projected volume of data. In this case, it's your best bet.","links":[{"url":"https://aws.amazon.com/what-is-cloud-object-storage/#benefits","title":"Benefits of Object Storage"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"1574cf43006500eb74cc583eef4a8b87","text":"EC2 with EBS","correct":false}]},{"id":"caa41dad-d6c0-4e39-ba7a-6cb4733057fc","domain":"SecureSolutions","question":"You want to enable EC2 instances in your AWS environment to download software updates over HTTP (Port 80) from the internet. What Security Group settings will enable this?","explanation":"Security Groups are stateful, so you only need to define the Outbound rule in the Security Group for this example as the EC2 instance is initiating the connection. Answers with inbound rules are incorrect, which leaves the answer with the Outbound rule allowing HTTP to 0.0.0.0/0. Once the EC2 instance has established valid HTTP connection with an Internet service, the target systems response is allowed.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups for Your VPC"}],"answers":[{"id":"a97ae85a569a169da98242372287508c","text":"Inbound: Allow ALL Ports from 0.0.0.0/0, Outbound: Allow HTTP (Port 80) to 0.0.0.0/0","correct":false},{"id":"b834b395c8d51e551c3193ed885868ec","text":"Outbound: Allow HTTP (Port 80) to 0.0.0.0/0 ","correct":true},{"id":"3c6469e0e1b096b5754357258ea83ba8","text":"Inbound: Allow HTTP (Port 80) from 0.0.0.0/0 \n Outbound: HTTP (Port 80) to 0.0.0.0/0","correct":false},{"id":"31a5c0b1dba4f28abc65481430837c52","text":"Inbound: Allow HTTP (Port 80) from 0.0.0.0/0","correct":false},{"id":"a0709d6298ca5365980468f590450d25","text":"Inbound: Allow HTTP (Port 80) from 0.0.0.0/0 \n Outbound: HTTP (Port 80) to IP address of Software Repo","correct":false}]},{"id":"5228f828-624d-4fc6-998c-c06c2d0d685b","domain":"SecureSolutions","question":"You need to restore an object from S3-Glacier. Which of the following will help you do that?","explanation":"When discussing GLACIER it is important to distinguish between the storage-class 'Glacier' use by S3, and the 'S3-Glacier' service.  The 1st is managed via the 'S3' console & API, and the 2nd the 'S3-Glacier' console & API.  The Amazon 'S3' service maintains the mapping between your user-defined object name and Amazon Glacier system-defined identifier. These objects are not accessible via the 'S3-Glacier' service.  Objects that are stored using the 'S3-Glacier' service are only accessible through the Amazon 'S3' CLI or APIs. ","links":[{"url":"https://docs.aws.amazon.com/amazonglacier/latest/dev/introduction.html","title":"What Is Amazon S3 Glacier?"},{"url":"https://docs.aws.amazon.com/cli/latest/reference/glacier/initiate-job.html","title":"Restoring S3-Glacier objects with CLI (glacier)"},{"url":"https://docs.aws.amazon.com/amazonglacier/latest/dev/api-initiate-job-post.html","title":"Restoring S3-Glacier objects with API (POST)"}],"answers":[{"id":"95668976125050f1b25d5a3b893d912c","text":"Using the Glacier API","correct":true},{"id":"4896195ad6b3c8d2e0061f7df703cc2c","text":"Using the S3 REST API","correct":false},{"id":"3ff157bf0479ce95fdeaf68388b55232","text":"Using the AWS s3-Glacier Console","correct":false},{"id":"b2f31642b1d69fc886a2b9d175e65fcd","text":"Using the S3 sub-command from the AWS CLI","correct":false}]},{"id":"86bc5815-e2a2-435d-b36a-de0291f03384","domain":"ResilientDesign","question":"A company disaster recovery policy requires that all RDS backups are retained in a secondary AWS region. What is the optimal solution to meet this requirement?","explanation":"RDS automated backups store backup data in the same region as the RDS instance. It is not possible to configure RDS automated backups to store data in a different region. The correct solution to meet the requirement is to copy RDS snapshots to the secondary region. It is not possible to copy RDS DB snapshots to an S3 bucket. Although it is possible to configure an RDS read-replica with automated backups in the secondary region, this is not an optimal solution as it involves additional costs associated with the running RDS instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html","title":"Working With Backups"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html","title":"Creating a DB Snapshot"}],"answers":[{"id":"0ffef8639c8e9a75fa845bb6e9e6488b","text":"Configure RDS Read-Replica instance in the secondary region. Enable RDS automated backups on the read-replica instance.","correct":false},{"id":"bc87f2bd894c0887220a36be79571629","text":"Create an RDS DB snapshot. Copy the RDS DB snapshot to the secondary region.","correct":true},{"id":"6cb16d4a90eb4167d69dad6d62a4afa0","text":"Create an RDS DB snapshot. Copy the RDS DB snapshot to an S3 bucket. Enable Cross-Region replication on the S3 bucket.","correct":false},{"id":"1575bfe0f50108d320a7b04107a11d21","text":"Configure an RDS automated backups target region to the secondary region.","correct":false}]},{"id":"af2b69a9-93b6-42ae-8bb7-df3549b376f4","domain":"ResilientDesign","question":"What type of replication is supported by read replica instances?","explanation":"Updates are applied to your Read Replica(s) after they occur on the source DB Instance using asynchronous replication.","links":[{"url":"https://aws.amazon.com/rds/details/read-replicas/","title":"RDS Read Replicas - Asynchronous Replication"}],"answers":[{"id":"18807bab4162a8219f67943263205f38","text":"Asynchronous replication","correct":true},{"id":"b56265ceb6311e42003e668438136a59","text":"Synchronous replication","correct":false},{"id":"2dba9be51ba243660abd8717959eb4b3","text":"Sequential replication","correct":false},{"id":"4350a58e8d877c13ae12d0a4aa1c3f2f","text":"Continuous replication","correct":false}]},{"id":"81dc73a3-27d5-4080-99ab-d75edfa081b0","domain":"ResilientDesign","question":"You successfully configure VPC Peering between VPC-A  and VPC-B. You then establish an IGW and a Direct-Connect connection in VPC-B. Can instances in VPC-A connect to your corporate office via the Direct-Connect service as well as connect to the Internet via the IGW?","explanation":"VPC peering only routes traffic between source and destination VPCs. VPC peering does not support edge-to-edge routing.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html","title":"Invalid VPC Peering Connection Configurations"}],"answers":[{"id":"d823d585a3fbbbcb9b921454f7d3bd62","text":"VPC peering does not support edge-to-edge routing.","correct":true},{"id":"bdb763fa01cc1ea95bbab61b10394fea","text":"Instances in VPC-A will be able to access the corporate office, but not the Internet.","correct":false},{"id":"3542ee08d9923e029f120a6dc9b3d9db","text":"Instances in VPC-A will be able to access the Internet, but not the corporate office.","correct":false},{"id":"6ce9df55ff92945dc320411540661454","text":"Yes: VPC Peering is designed to route traffic between the VPCs.","correct":false}]},{"id":"5dcee06e-bd95-4dfd-8540-5c54ae7c5fd3","domain":"SecureSolutions","question":"Your application stores your customers' sensitive passport information in S3. You are required by law to encrypt all data at rest. Company policy states that you must maintain control of your encryption keys. For ease of management, however, you do not want to implement or maintain a client-side encryption library. Which S3 encryption option should you use to secure your data at rest?","explanation":"Use SSE-C (C ≈ customer controlled) if you want to maintain your own encryption keys, but don’t want to implement or leverage a client-side encryption library.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html","title":"S3 - SSE-C"}],"answers":[{"id":"1562bb9d2d9567740605dcb1ccab5c80","text":"SSE-S3","correct":false},{"id":"472035b16201f5505380c16ec3eb8518","text":"SSE-C","correct":true},{"id":"bac271f02854883c6bc665637d0a5de6","text":"Amazon S3 Encryption Client","correct":false},{"id":"e17194408dc439e1658a544965724d44","text":"SSE-KMS","correct":false}]},{"id":"3252d84d-08d9-4bde-a8e7-d716502d1855","domain":"Performant","question":"You have a very heavily-trafficked WordPress blog that has approximately 95% read traffic and 5% write traffic. You notice that the blog is getting slower and slower. You discover that the bottleneck is in your RDS instance. Which of the following answers can improve your WordPress blog's performance?","explanation":"You should use a combination of Read Replicas and ElastiCache to help offload the traffic.","links":[{"url":"https://aws.amazon.com/elasticache/","title":"About ElastiCache"}],"answers":[{"id":"1c551a09129057627b3b75fb70e6f527","text":"Export the database to DynamoDB which has push button scalability.","correct":false},{"id":"e94a05a7348f87c7b9c4f7036d632a9c","text":"Use ElastiCache to cache the most commonly read posts of your WordPress blog.","correct":true},{"id":"fdc556bb3ab9b5da3b290c181aaefb3c","text":"Create a number of read replicas and update the connection string on your EC2 instances so that traffic is evenly shared amongst these new RDS instances.","correct":true},{"id":"1af32ee0c62b109e45b92828dbc33f2d","text":"Create a secondary Multi-AZ database and run the queries off the secondary Multi-AZ database.","correct":false}]},{"id":"1a0b1d3a-8954-4a09-8952-177296aa74d9","domain":"CostOptimized","question":"A financial services company is located in New York, while their development and testing is performed in San Francisco. The development team lead wants to ensure that the data stored in their test account Amazon S3 bucket is a current copy of the data in their production account Amazon S3 bucket. What steps implement the solution in the most effective way?","explanation":"S3 Cross-Region Replication is S3 capability that can be configured on an S3 bucket to automatically replicate objects to another bucket in a different region. S3 bucket versioning is a requirement to enable S3 cross-region replication. S3 lifecycle policies are not related to replication of S3 data between accounts or regions. S3 lifecycle policies can be used to transition S3 objects to another Amazon S3 storage class (e.g. Glacier). Using S3 bucket event notifications for implementing object replication is not the optimal solution as it does not use S3 native capabilities. Implementing a Lambda function to replicate S3 objects to another bucket is not the optimal solution as it requires custom code development and testing.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html","title":"Amazon S3 Replication"}],"answers":[{"id":"08bc138542a70d8db6cf01c61ecbe9c2","text":"Configure Cross-Region Replication.","correct":true},{"id":"d685fd084e72386d91439741e993fa1a","text":"Configure S3 Bucket Lifecycle Policy.","correct":false},{"id":"797931651fc0ec6480675746a061a614","text":"Configure S3 Bucket Event Notification.","correct":false},{"id":"a0ebcbd1b7f09f700a7220e87af23e93","text":"Configure S3 Bucket Versioning.","correct":true},{"id":"3dc5e668dc968f6dfd1f7b9df09f4182","text":"Configure an AWS Lambda function to replicate S3 objects.","correct":false}]},{"id":"f3d178d0-2157-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"Which of the following AWS Support elements provide the assessment of how ready your AWS environment is for your application prior to launch?","explanation":"If you need an assessment of your AWS environment to help identify and mitigate risks that can affect your application prior to launch, you need an AWS Support plan that includes Infrastructure Event Management. The other elements mentioned here are not event or launch focused; Technical Account Managers handle more technical issues. The Support Concierge is a team of enterprise account specialists dedicated to billing and account issues, and Trusted Advisor is all about helping you reduce cost, increasing performance, and improving security.","links":[{"url":"https://aws.amazon.com/premiumsupport/programs/iem/","title":"AWS Infrastructure Event Management"},{"url":"https://aws.amazon.com/premiumsupport/plans/enterprise/","title":"AWS Enterprise Support"}],"answers":[{"id":"33b19f092c13caec1202c108b57d2bc1","text":"Support Concierge","correct":false},{"id":"3d582ac943b9ba9113651d26bdee7a79","text":"Technical Account Managers","correct":false},{"id":"af8f25ab81f04f0feba2075a09b65389","text":"Infrastructure Event Management","correct":true},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false}]},{"id":"15c91139-c33f-4583-8864-dba8207c73a0","domain":"Performant","question":"Your organisation is running a business critical application with a backend MySQL DB that has been experiencing performance issues due to an increase in customers hitting the website. Management are concerned that the existing solution will not handle the anticipated customer growth over the next 12 months and any outages could lead to a loss in potential revenue.\\n You’ve been asked to develop a suitable AWS cloud based solution that will best meet the requirements of the organisation and require minimal operational overhead. Which AWS DB service will be most suitable for your organisation?","explanation":"Aurora natively maintains 2 copies of your data in each availability zone (3 AZs x 2 = 6 copies) within a region providing the highly available solution needed for this scenario. It also supports storage autoscaling and CPU and Memory scaling. Aurora also provides up to 5 times improved performance over a traditional DB installation.  MySQL and PostgreSQL support multi-AZ deployments and read replicas, but this requires additional configuration. CPU, memory and storage scaling is not automated and requires additional configuration and design consideration. Redshift does not support Multi-AZ deployments.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/","title":"Amazon Aurora FAQs"}],"answers":[{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"f52a9d91766886fb3a524dd06d1581cb","text":"Redshift","correct":false},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false},{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":true}]},{"id":"446d12ef-f212-4d80-8b31-ca65204c3b45","domain":"Performant","question":"The AMI ID used in an AutoScaling policy is specified in the_____.","explanation":"The Launch Configuration contains most of the parameters that you would set for a manual EC2 launch, and these are applied to each automatic launch.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/LaunchConfiguration.html","title":"Launch Configurations"}],"answers":[{"id":"6bbdc6787549994c5be17383cfea4a40","text":"Security Group","correct":false},{"id":"415107f62d630ab0aa3de0b6ed75a3dd","text":"Launch configuration","correct":true},{"id":"5fdc7c9d0a9fcbddd7977b2d69ce392a","text":"AutoScaling group","correct":false},{"id":"af25a68505a64d038c5cc6de686880af","text":"AutoScaling Policy","correct":false}]},{"id":"27f1f472-2ea9-43e0-b75d-6be01c620049","domain":"CostOptimized","question":"You have a website that allows users in third world countries to store their important documents safely and securely online. Internet connectivity in these countries is unreliable, so you implement multipart uploads to improve the success rate of uploading files. Although this approach works well, you notice that when an object is not uploaded successfully, incomplete parts of that object are still being stored in S3 and you are still being charged for those objects. What S3 feature can you implement to delete incomplete multipart uploads?","explanation":"You can create a lifecycle policy that expires incomplete multipart uploads, allowing you to save on costs by limiting the time non-completed multipart uploads are stored.","links":[{"url":"https://aws.amazon.com/blogs/aws/s3-lifecycle-management-update-support-for-multipart-uploads-and-delete-markers/","title":"S3 Lifecycle Management - Incomplete Multipart Uploads"}],"answers":[{"id":"5ff7e884d027004938c218aafa63c215","text":"S3 Lifecycle Policies","correct":true},{"id":"ee966c2ebd84a4f7add1d9ceabe082c9","text":"Have S3 trigger DataPipeling Auto-delete.","correct":false},{"id":"bc5e8477b1dde2747a8cb281160b01f7","text":"Have CloudWatch trigger a Lambda function that deletes the S3 data.","correct":false},{"id":"86d93427d74df0b30713341818e3d556","text":"S2 Reduced Redundancy Storage","correct":false}]},{"id":"1ae7d81d-4a88-4b2c-8a24-0d23a0b398ca","domain":"Performant","question":"Your company provides an online image recognition service that uses SQS to decouple system components. Your application polls the image queue as often as possible to maximize end-to-end throughput. However, you notice that polling in tight loops is burning CPU cycles and increasing costs with empty responses. How can you reduce the number of empty responses?","explanation":"Long polling will reduce the number of CPU cycles and empty responses, saving you money.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-long-polling.html","title":"SQS Long Polling"}],"answers":[{"id":"aa392ba36a0e879990027e26535b999d","text":"Use AutoScaling to increase the number of instances polling the queue.","correct":false},{"id":"36d85400100c2ac53783d07f58a9f76d","text":"Enable short polling by setting ReceiveMessageWaitTime = 0.","correct":false},{"id":"fb3af9891cf5d5aceb09ff3b42d07fc9","text":"Enable long polling by setting the ReceiveMessageWaitTimeSeconds to a number > 0","correct":true},{"id":"e9986a49c81acbbab4e10ed024c85a46","text":"Enable short polling by setting ReceiveMessageWaitTime > 0.","correct":false}]},{"id":"53fa4466-64d1-446e-8afe-3b4d8e8ae888","domain":"SecureSolutions","question":"You have an S3 bucket which contains sensitive data and as part of an internal audit a recommendation has been made to restrict access to the bucket so that it is only accessible from a specific list of IP addresses. How would you implement this?","explanation":"Bucket policies allow you to control access to your bucket in a number of different ways - including specifying the IP addresses which can access the bucket. NACLS, Security Groups and Firewall Policies do not apply to buckets themselves.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/block-s3-traffic-vpc-ip/","title":"How can I specify which VPCs or IP addresses can access my Amazon S3 bucket?"}],"answers":[{"id":"b9f5938dd4b9907d999c951d70104ae6","text":"Apply a NACL to the bucket","correct":false},{"id":"9c028eac51913ffa839c3498b73dcf20","text":"Apply a Bucket Policy to the bucket","correct":true},{"id":"282167942a90730cee0d01e3a7d4d006","text":"Apply a Firewall Policy to the bucket","correct":false},{"id":"a3e9e86e8dee8489061565cedc7e5a86","text":"Use a Security Group on the bucket","correct":false}]},{"id":"28c98997-c33d-47a1-a924-6d4b58d269cf","domain":"Performant","question":"Which of the following operating systems is NOT supported by EC2?","explanation":"OSX is not supported on EC2","links":[{"url":"https://aws.amazon.com/ec2/faqs/#general","title":"EC2 FAQs"}],"answers":[{"id":"3d945423f8e9496c429a5d8c65b4604f","text":"Ubuntu","correct":false},{"id":"95a90af1d5b68afaa24b9f917e25e4ec","text":"Windows Server","correct":false},{"id":"4893fb6eaf52350ba9ac82d34d329603","text":"OSX","correct":true},{"id":"0916f479fafc28dd10d3cee381041c01","text":"Amazon Linux","correct":false}]},{"id":"655aca00-21a4-11ea-978f-2e728ce88125","domain":"Performant","question":"A wealth intelligence software company currently uses Oracle 12c as its database solution. However, it wants to move its databases to the AWS Cloud. Which of the following services will accommodate the migration?","explanation":"The hint to the answer lies in the company’s current database software. Oracle 12c is a relational database solution, which is what Amazon RDS is. The company can run its Oracle databases using RDS instances. Amazon DynamoDB is a non-relational DB solution and Amazon Redshift is for Big Data and Data Warehouse solutions. Amazon ElastiCache is used to increase DB performance through caching DB data to improve application performance.","links":[{"url":"https://aws.amazon.com/rds/oracle/","title":"Amazon RDS for Oracle"}],"answers":[{"id":"f7415e33f972c03abd4f3fed36748f7a","text":"Amazon Redshift","correct":false},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false},{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":true},{"id":"ecafbaed9f41dac736e496a7cd234ce4","text":"Amazon DynamoDB","correct":false}]},{"id":"58af5529-d965-4ab9-ae2f-a906c0b8c41e","domain":"Performant","question":"You've enabled website hosting on a bucket called 'aspiring-guru' in the us-west-2 Region. Which of the following is the URL that will be assigned to your website?","explanation":"Your bucket name *always* comes first. 's3-website', followed by the Region, *always* comes next.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Website Hosting"}],"answers":[{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"eff2fbc9e562b82d9381082df00c92d6","text":"s3-website.aspiring-guru-us-west-2.amazonaws.com","correct":false},{"id":"09cbf53f89e143efb0fb279e5d14b9e8","text":"s3-website-us-west-2.aspiring-guru.amazonaws.com","correct":false},{"id":"b7ac852a2cf809dc4fb801df9b658c8a","text":"aspiring-guru.s3-website-us-west-2.amazonaws.com","correct":true}]},{"id":"f1eea1a4-0b1e-4702-bb51-0937708005a3","domain":"ResilientDesign","question":"In the future, you will need to preserve, restore, and retrieve every version of every file that you have stored in AWS. Which service should you use?","explanation":"Versioning allows you to preserve, retrieve, and restore every version of every object stored in an Amazon S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"Using Versioning with S3"}],"answers":[{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"8eeeb63c58948c56dc93f4dd229fc796","text":"S3 with Versioning enabled.","correct":true},{"id":"e9a5105fa288ef2b71c037e42d665d91","text":"S3 - OneZone-IA","correct":false},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false}]},{"id":"c55f22ae-80d0-4959-b174-d829799c0ebe","domain":"SecureSolutions","question":"An AWS VPC allows you to:","explanation":"With a VPC, you can connect your cloud resources to your own IPSec VPN connections.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html","title":"AWS Managed VPN Connections"}],"answers":[{"id":"f7ddabca6bedcc81b8b193a009967f58","text":"Connect your cloud resources to your own IPSec VPN connections.","correct":true},{"id":"b6d6372266b9d9c86bea479d7e2ed72f","text":"Forget about security: AWS does it all for you.","correct":false},{"id":"80b64cf6fc3a37e7c804ff0db69f8916","text":"Provision unlimited S3 resources.","correct":false},{"id":"965dceca3b86aea95ef5de037128780c","text":"None of these.","correct":false}]},{"id":"8ce0cff9-4e62-41cb-8edd-a45f0b2a2bd3","domain":"Performant","question":"You have a application that is running in an EC2 instance that performs some heavy processing on sales data stored in S3. This sales data is first loaded into memory and numerous operations are performed on it before it is written back to S3. During the processing phase, a large amount of temporary data is created which is not needed once processing completes. This data needs to be stored on as low-latency storage as possible - which of the below storage types should you use?","explanation":"Although all 4 options would work, Instance Store has the lowest latency as it is located on the same physical infrastructure as the EC2 instance. As data permanency is not required, Instance Store is the best choice.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","title":"AWS Instance Store"}],"answers":[{"id":"248c1b0bcb74394beb4a08030c4a6847","text":"EBS","correct":false},{"id":"41c96096fbbf551daa42cd6455c15603","text":"Instance Store","correct":true},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":false},{"id":"43fd7af2adc3101adebb61366bf16df2","text":"Provisioned IOPS SSD","correct":false}]},{"id":"a37fb7a3-3a49-40f0-b688-1d34af35855e","domain":"SecureSolutions","question":"Contractual requirements mandate the use of AWS CloudHSM as an encryption solution. Application performance is a secondary, but important, concern. Where within your AWS infrastructure should you place the HSM appliances?","explanation":"To decrease latency (and improve application performance), it's best to place your HSMs as close to your EC2 instances as possible.","links":[{"url":"https://aws.amazon.com/cloudhsm/details/#Secure_VPC_access","title":"HSMs and Latency"}],"answers":[{"id":"9df85d664730c5be05001eb90f0aca61","text":"To increase performance, you should locate the HSM as close to the majority of your customers as is possible.","correct":false},{"id":"65c5c381d9312c40bb261deb3ddc7bcd","text":"To increase security, you should place the CloudHSM appliances in their own, private subnet.","correct":false},{"id":"b1b0304054038e008892902f9ecb32b6","text":"To increase security, you should place the HSM appliances on your side of the VPN that connects to AWS.","correct":false},{"id":"81903e4cb00fb844367c771fd69072e7","text":"Locating HSM appliances near your EC2 instances decreases network latency, which improves application performance.","correct":true}]},{"id":"dfc3f2ec-3161-4e55-8132-ac8c4e1a3c81","domain":"ResilientDesign","question":"Which of the following is true with regard to Elastic IP addresses?","explanation":"Elastic IP address is a static IPv4 address and can be associated with a public address for dynamic cloud computing. When Elastic IP is associated with an instance, the existing Public IPv4 address is released back to the Amazon pool. Elastic IP addresses are region specific. Elastic IPs may be recovered if released, only if the IP is not associated with another account. Elastic IPs can be recovered using EC2 API or CLI tool only. In EC2-Classic, an Elastic IP is disassociated from the instance when you stop it.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html","title":"Elastic IP Addressing"}],"answers":[{"id":"933828eae3a2cae2240b99074d71d62a","text":"An Elastic IP address is for a specific region only.","correct":true},{"id":"a2cdfe942dc44e6af7dc620c6625b1d5","text":"An Elastic IP address is for a specific Availability Zone only.","correct":false},{"id":"41fceb47b8c47422341f02c0a017394b","text":"If released, an Elastic IP address can be recovered if it is not associated with another AWS account.","correct":true},{"id":"0cfca15b9f0c8a1563edbf0e6a36171a","text":"When an Elastic IP address is associated with an instance, the instance's Public IPv4 address is released back to the Amazon pool and cannot be reused. The public DNS hostname of the instance changes to match the Elastic IP address.","correct":false},{"id":"4aaf488833f9d54d0834959007c03d78","text":"An Elastic IP address can be recovered using the Amazon EC2 API or a command line tool only.","correct":true},{"id":"9980200da917f7d405e7f6a765bf4586","text":"An Elastic IP address will remain associated with the EC2-Classic instance when the EC2-Classic instance is stopped.","correct":false}]},{"id":"7337c116-fab1-4400-b398-1315ca924cc4","domain":"SecureSolutions","question":"You are about to delete the second snapshot of an EBS volume which had 10 GiB of data at the time when the very first snapshot was taken. 6 GiB of that data has changed before the second snapshot was created. An additional 2 GiB of data have been added before the third and final snapshot was taken. Which of the following statements about that is correct?","explanation":"When you delete a snapshot, only the data unique to that snapshot is removed. Each snapshot contains or references all of the information needed to restore your data (from the moment when the snapshot was taken) to a new EBS volume.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"Amazon EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-snapshot.html","title":"Deleting an Amazon EBS Snapshot"}],"answers":[{"id":"6e2b9212876d0db9a9e41869a7e9ade1","text":"After deletion, the total storage required for the two remaining snapshots is 12 GiB; 10 GiB for the first and 2 GiB for the last snapshot.","correct":false},{"id":"80af6d01abbcd4194141d891cb0d666f","text":"Each EBS volume snapshot is a full backup of the complete data and independent of other snapshots. You can go ahead and delete the second snapshot to save costs. After that, you are charged for only 22 GiB of data for the two remaining snapshots.","correct":false},{"id":"d740c4bcb406d23f82b101e434a867d6","text":"Snapshots are incremental backups, which means that only the blocks on the device that have changed after your most recent snapshot are saved. Therefore, you can only delete them in reverse chronological order, i.e. starting with the third snapshot and then the second one.","correct":false},{"id":"63e57b6a1c92e6f3be354afc213938f4","text":"Before deletion, the total storage required for the three snapshots was 18 GiB of which the second one had 6 GiB of data. After the deletion of that second snapshot, you are still charged for storing 18 GiB of data - 10 GiB from the very first snapshot and 8 GiB (6 + 2) of data from the last snapshot.","correct":true}]},{"id":"1b1cfffe-896f-420c-b64e-8eee23af9a3e","domain":"ResilientDesign","question":"You work at a large financial institution.  You have many files that need to be stored for 7 years or more for regulatory purposes. These files need to be stored at the lowest cost possible. It is acceptable to wait for files to become available. Which of the following S3 Storage Tiers is best suited for this request?","explanation":"S3 Glacier Deep Archive is Amazon S3’s lowest-cost storage class and supports long-term retention and digital preservation for data that won’t be regularly accessed. It is designed for customers — particularly those in highly-regulated industries, such as the Financial Services, Healthcare, and Public Sectors — that retain data sets for 7-10 years or longer to meet regulatory compliance requirements. S3 Glacier Deep Archive can also be used for backup and disaster recovery use cases, and is a cost-effective and easy-to-manage alternative to magnetic tape systems, whether they are on-premises libraries or off-premises services. S3 Glacier Deep Archive complements Amazon S3 Glacier, which is ideal for more active archives where data is regularly retrieved and needed in minutes. All objects stored in S3 Glacier Deep Archive are replicated and stored across at least three geographically-dispersed Availability Zones, protected by 99.999999999% of durability, and can be restored within 12 hours.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#____","title":"Amazon S3 Storage Classes - Glacier Deep Archive"}],"answers":[{"id":"a4172aee8a692bd73f2781afe65fda72","text":"S3 Infrequently Accessed","correct":false},{"id":"a5f6e1bef7eaef71d9ea6446f8c21a2e","text":"S3 Glacier Deep Archive","correct":true},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false}]},{"id":"9fc041cf-1305-46e0-9851-bbf11b320f3c","domain":"Performant","question":"You need to develop an infrastructure that can be replicated and deployed in another AWS Region in a matter of minutes. Which AWS service might you use to build a reproducible, version-controlled infrastructure?","explanation":"AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"About CloudFormation"}],"answers":[{"id":"d8d0959d6dfc410044ed02441ee86c96","text":"EC2 AMIs with EBS snapshots","correct":false},{"id":"c0f075697e6a50da6356e4718f5a1de0","text":"CloudWatch Template","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false}]},{"id":"f464468f-7851-4684-a8a1-ece519bc244c","domain":"Performant","question":"An online music catalog application will use Amazon DynamoDB as it's database. Catalog entries will consist of information about individual song titles. Users will query songs primarily by artist. They'll also have the ability to retrieve a list of songs by genre, and from a specific decade within each genre. How should the music catalog table be structured in order to provide the best performance for these queries?","explanation":"Since users will be given the ability to query songs primarily by artist, the DynamoDB table's Primary Key should be set up with artist as the Partition Key and song title as the Sort Key. To provide the additional capability to query by genre, and to retrieve a list of songs according to decade within genre, a Global Secondary Index with genre as the Partition Key and decade as the Sort Key will give the best query performance. An artist Partition Key in the Primary Key without a song title Sort Key will place song titles randomly on the partition, resulting in poorer query performance. Same thing with a Global Secondary Index on genre without a decade Sort Key. Local Secondary Indexes must have the same Partition Key as the Primary Key. If artist doesn't exist as the Partition Key in the Primary Key or a Secondary Index, the query on artist will be performed as a full scan rather than a direct read.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html","title":"DynamoDB Core Components"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SecondaryIndexes.html","title":"Improving Data Access with Secondary Indexes"}],"answers":[{"id":"a3a841e8ef9cd63612e0a1dce7979275","text":"Create a Primary Key with artist as the Partition Key. Create a Global Secondary Index with genre as the Partition Key. Create a Local Secondary Index with decade as the Partition Key.","correct":false},{"id":"eb1a3f607b1bbeb89019415956a59252","text":"Create a Primary Key with song title as the Partition Key. Create a Local Secondary Index with artist as the Partition Key. Create a Local Secondary Index with genre as the Partition Key and decade as the Sort Key.","correct":false},{"id":"5304348a393031193fcd240783476b14","text":"Create a Primary Key with song title as the Partition Key and artist as the Sort Key. Create a Global Secondary Index with genre as the Partition Key. Create a Local Secondary Index with decade as the Sort Key.","correct":false},{"id":"7ffad0b101f65b02826d61402fa11b74","text":"Create a Primary Key with artist as the Partition Key and song title as the Sort Key. Create a Global Secondary Index with genre as the Partition Key and decade as the Sort Key.","correct":true}]},{"id":"596626b1-f08c-4afb-a723-39c8abf31af5","domain":"ResilientDesign","question":"An EC2 instance retrieves a message from an SQS queue, begins processing the message, then crashes. What happens to the message?","explanation":"When the message visibility timeout expires, the message becomes available for processing by other EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html","title":"SQS Visibility Timeout"}],"answers":[{"id":"82e027481e331aba93999ce96b1af424","text":"To prevent corruption, the message is deleted.","correct":false},{"id":"b7b87efcf5ef61b425d9a60bc33efe62","text":"When the message visibility timeout expires, the message becomes available for processing by other EC2 instances.","correct":true},{"id":"d69db62ea1f468c166c785ced48037ba","text":"It remains in the queue in a locked state until the EC2 instance comes back online.","correct":false},{"id":"77d789cecbe676c6c677cc6cd389b99a","text":"When the message timeout expires, the message is duplicated, the original message is archived, and the duplicate becomes available for processing.","correct":false}]},{"id":"dd6d1773-3b16-4ee2-9766-c5ccbe8fbc8e","domain":"ResilientDesign","question":"Which of the following database engines support read replicas?","explanation":"Read Replicas are supported by Amazon Aurora, Amazon RDS for MySQL, MariaDB, PostgreSQL, and most recently Oracle.","links":[{"url":"https://aws.amazon.com/rds/faqs/#replication","title":"Multi-AZ Deployments and Read Replicas"},{"url":"https://aws.amazon.com/about-aws/whats-new/2019/03/Amazon-RDS-for-Oracle-Now-Supports-In-region-Read-Replicas-with-Active-Data-Guard-for-Read-Scalability-and-Availability/","title":"RDS Oracle now Supports In-region Read Replicas"}],"answers":[{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":true},{"id":"30162ed78b6c10f731411f2fc440c24f","text":"Oracle","correct":true},{"id":"a71f76c3256e4c206a4841d8eb0fed35","text":"SQL Server","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":true}]},{"id":"096baab8-06c7-4b07-8e86-ba304b41102f","domain":"CostOptimized","question":"After migrating an application architecture from on-premise to AWS, you will not be responsible for the ongoing maintenance of which two of the following services.","explanation":"DynamoDB and Amazon RDS are managed services. As such, AWS handles the ongoing maintenance.","links":[{"url":"https://aws.amazon.com/rds/details/","title":"About RDS"},{"url":"https://aws.amazon.com/dynamodb/details/","title":"About DynamoDB"}],"answers":[{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true}]},{"id":"737e3562-19f3-11ea-978f-2e728ce88125","domain":"Performant","question":"Which of the following AWS services enables on-premises applications to use AWS Cloud storage?","explanation":"Although all four responses are similar in that they are AWS storage services, it is Storage Gateway that enables on-premises applications to use cloud-based storage. EFS is for simple, scalable file storage, EBS serves as a virtual disk for virtual servers launched with EC2, and S3 is for object-based storage.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html","title":"What Is AWS Storage Gateway?"}],"answers":[{"id":"d2a6652ddeb631da029d1f2806e11fdc","text":"Amazon Elastic File System (EFS)","correct":false},{"id":"9155453f43b8a6472df0b8ffa5b5a028","text":"Amazon Elastic Block Storage (EBS)","correct":false},{"id":"df346128c45efa43efc29607224fc716","text":"Amazon Simple Storage Service (S3)","correct":false},{"id":"5ba49687f2f5ade4cd1c756a7e9024e3","text":"AWS Storage Gateway","correct":true}]},{"id":"f83080c3-ee9d-4ca9-ada5-f94b6642d2f2","domain":"CostOptimized","question":"Your company is running an older version of Windows on employees' desktops/laptops which will be going off of mainstream support in the near future. The most current version of Windows will require a large capital investment to purchase more powerful hardware to run it. All desktops/laptops require access to the Internet as well as access to multiple business applications running on Amazon EC2 web servers in the AWS cloud. Your manager has tasked you with determining how to move the company's desktops/laptops to the most current version of Windows. Which architecture will provide the most cost effective solution?","explanation":"Amazon Workspaces provides the capability to serve virtual cloud-based desktop sessions to your desktop/laptop users (either Windows or Linux). It eliminates the need for powerful hardware, and it removes the burden of individual desktop/laptop software maintenance. AppStream is not needed to access the Internet, nor is it needed to serve the EC2 applications in this use case since a browser can be used from WorkSpaces to access the web servers. A NAT Gateway is preferred to an Internet Gateway since all traffic is initiated from the desktop/laptop, instead of from out on the Internet. WorkSpaces provides for creating an authentication directory, so creating one separately is not needed. WorkSpaces also creates an ENI for each session inherently.","links":[{"url":"https://docs.aws.amazon.com/workspaces/latest/adminguide/amazon-workspaces.html","title":"What is Amazon WorkSpaces?"},{"url":"https://aws.amazon.com/blogs/desktop-and-application-streaming/why-customers-are-moving-their-windows-desktops-to-the-cloud-with-aws/","title":"Why Customers Are Moving Their Windows Desktops to the Cloud with Amazon WorkSpaces"}],"answers":[{"id":"7c9f90a44ccdb77a69453cc39d1fdba7","text":"Implement Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use an Internet Gateway in the same VPC to provide access to the Internet. Provision Elastic Network Interfaces in the same VPC to connect the desktops/laptops to the EC2 applications.","correct":false},{"id":"58e179301471d5f030ad1b404a5c527f","text":"Deploy Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use a NAT Gateway in the same VPC to provide access to the Internet.","correct":true},{"id":"e33c2a9e2b05853b6c1f1bc548357068","text":"Implement Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use Amazon AppStream to provide access to the Internet and to serve the EC2 applications to the desktops/laptops.","correct":false},{"id":"7c8f5d29af4240a4ec8c68eaa488e933","text":"Use Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use an Internet Gateway in the same VPC to provide access to the Internet. Provision an AWS Managed Microsoft AD instance and link it to your on-premises Active Directory for user authentication.","correct":false}]},{"id":"61614ffb-1208-4742-9ff9-c8b316f13cc4","domain":"Performant","question":"When coding a routine to upload to S3, you have the option of using either single part upload or multipart upload. Identify all the possible reasons below to use Multipart upload.","explanation":"Multipart upload provides options for more robust file upload in addition to handling larger files than single part upload.","links":[{"url":"http://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html","title":"Uploading Objects Using Multipart Upload"}],"answers":[{"id":"d935110c327634d57b66601e6957ed42","text":"Multipart upload delivers improved throughput.","correct":true},{"id":"fceeb753e12f0056c923fc9115be9472","text":"Multipart upload delivers quick recovery from network issues.","correct":true},{"id":"61f9f705b4dc688b86e0b25708cb7d88","text":"Multipart upload delivers the ability to begin an upload before you know the final object size.","correct":true},{"id":"b2b49e9141fe4ce7eb0932d9c62a38b8","text":"Multipart upload delivers the ability to pause and resume object uploads.","correct":true},{"id":"df10e1b59a623a1543c4343ace225b87","text":"Multipart upload delivers the ability to append data into an open data file.","correct":false},{"id":"561cf9617064d07d28982fa0a4c4a5a3","text":"Multipart upload delivers improved security in transit.","correct":false}]},{"id":"96498ab4-1135-4719-bd34-3cb7ef029118","domain":"SecureSolutions","question":"Can you use IPv6 with Amazon S3?","explanation":"Using IPv6 support for Amazon S3, applications can connect to Amazon S3 without needing any IPv6 to IPv4 translation software or systems.","links":[{"url":"https://aws.amazon.com/s3/faqs/#ipv6","title":"S3 - IPv6"}],"answers":[{"id":"d5d04ce0ece293f788b6e7dc9c0e20c3","text":"Yes, but you need IPv6 to IPv4 Translation Software.","correct":false},{"id":"bafd7322c6e97d25b6299b5d6fe8920b","text":"No","correct":false},{"id":"16bc1229a01bece96e46a818e6b48a4a","text":"Yes, but you need IPv4 to IPv6 Translation Software.","correct":false},{"id":"93cba07454f06a4a960172bbd6e2a435","text":"Yes","correct":true}]},{"id":"b4a8013c-2e5f-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"You have four EC2 instances deployed in four Availability Zones, and all of them are associated with a single domain name. You want Amazon Route 53 to split web traffic evenly between the four servers. Which of the following routing policies will accomplish that?","explanation":"With weighted routing, you can associate the IP addresses with the domain name and route 25 percent of the web traffic to each of the four servers.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"9cb2b9aba3714353700c3380fdc9be92","text":"Weighted routing policy","correct":true},{"id":"6d9eaf15402548bd548fd5394c641b5b","text":"Failover routing policy","correct":false},{"id":"152efd7324f202404ed2aa134a02c0c5","text":"Simple routing policy","correct":false},{"id":"fbc89b4465967d97d5b3032d3b73a9b2","text":"Latency routing policy","correct":false}]},{"id":"ebdeed2c-780f-4f28-ab81-0de353938dfb","domain":"ResilientDesign","question":"Your company is migrating a number of its applications to AWS. Services used will include Amazon EC2, Amazon S3, Amazon ELB Application Load Balancers, NAT Gateways, and Amazon RDS MySQL instances. You'll be using AWS's Bring Your Own IP Address (BYOIP) offering to keep all server IP addresses the same as they were on-premises. You'd also like to leverage Elastic IP Addresses for failover scenarios. Which approach will provide the most reliable IP addressing for your new AWS environment?","explanation":"You can bring your public IPv4 address ranges from your on-premises network to your AWS account with the BYOIP offering. You don't need to bring private IP address ranges. You can then create Elastic IP Addresses from your BYOIP pool and use them with AWS resources such as EC2 instances, NAT Gateways, and ELB Network Load Balancers. Elastic IP Addresses cannot be used with ELB Application Load Balancers or RDS instances.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-byoip.html","title":"Bring Your Own IP Addresses (BYOIP)"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-eips.html","title":"Elastic IP Addresses"}],"answers":[{"id":"d332dd2c597e20fddcdce2c0d2725e21","text":"Register your own public IP address ranges with BYOIP. Create Elastic IP Addresses from your BYOIP address pool for the EC2 instances and the NAT Gateways.","correct":true},{"id":"7406ea0371eb195c45ac0db9d8c279b7","text":"Register all of your IP address ranges with BYOIP. Create Elastic IP Addresses from your BYOIP address pool for the EC2 instances and the RDS MySQL instances.","correct":false},{"id":"f719d7ed8ad37a2eac59c037e87ea416","text":"Register your own public IP address ranges with BYOIP. Create Elastic IP Addresses from your BYOIP address pool for the EC2 instances, the Application Load Balancers, and the NAT Gateways.","correct":false},{"id":"87a3a8c3c23724feef9fdbda3a8e5d50","text":"Register your own public IP address ranges with BYOIP. Create Elastic IP Addresses from your BYOIP address pool for the EC2 instances, the NAT Gateways, and the RDS MySQL instances.","correct":false}]},{"id":"7d5db29f-e3f6-4018-bf0f-c80c2f682d42","domain":"ResilientDesign","question":"You have a work load running on RDS MySQL with Multi-AZ turned on. You notice that the primaryDB is in US-East-1a. You go home for the weekend and when you return to work on Monday you noticed that this has changed to US-East-1b. What could have caused the failover to a new availability zone.","explanation":"Failover is a normal process that is triggered whenever the primary node is unavailable or reporting a fault.  Stopping the RDS service would halt all instances, not trigger a failover.  You cannot 'promote' a secondary, only make the primary unavailable.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"RDS Multi-az Failover conditions"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RebootInstance.html","title":"RDS failover - Rebooting a DB Instance"}],"answers":[{"id":"80d1ece0377efa26bbd04cf6311a3e4a","text":"The primary RDS instance becoming unavailable.","correct":true},{"id":"8812217ae2bf88211e570f00b174311d","text":"Promoting the secondary instance to become the primary instance.","correct":false},{"id":"ddcfe4df5417e5a13e12b14d171e0885","text":"Stopping the RDS Instance.","correct":false},{"id":"1e38297e1ea02a40df96d1738a1a31eb","text":"An outage of an availability zone.","correct":true}]},{"id":"fa42251d-b1dd-4f48-89e3-9b2d380cd7e7","domain":"SecureSolutions","question":"As a follow up to a recent security breach you have been asked what steps can be taken to ensure that System Administrators always use signed communication when interacting with your AWS account via the API interface.  Which statements are most accurate?","explanation":"AWS use the signing hash to identify the requester.  The signing hash is unique and is generated from the access key ID and secret access key downloaded from IAM.","links":[{"url":"https://docs.aws.amazon.com/general/latest/gr/signing_aws_api_requests.html","title":"Signing AWS API Requests"},{"url":"https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html","title":"Version 4 Signing Process"}],"answers":[{"id":"2fc0c0ad8f8d7b7e96e9c55eddad0a66","text":"All http requests to the API must be manually signed via the process documented by AWS.","correct":false},{"id":"5fc787c76af6f67cedad71fe3d613e5c","text":"The process of manually signing requests is only needed when writing bespoke low level connections with the API.","correct":true},{"id":"6ed674cf84d9fda42ef11dfe73378e07","text":"It will be necessary to install signing utilities provided by openssl.org to generate personalized signing certificates signed by the Secret key downloaded from IAM.","correct":false},{"id":"c151166b8406fba447b3bd441ed7982c","text":"AWS advise against signing HTTP API traffic as the capability is redundant when communicating with the AWS API.","correct":false},{"id":"ccfd209f6df2f05725814983d4c59a38","text":"You must advise that this is an area over which customers have little control. The signing of all but anonymous requests is enforced by AWS.","correct":true}]},{"id":"42cc5ed7-0d57-429c-973a-79cb287f6a1e","domain":"Performant","question":"You have an extremely high performance compute application that you need to deploy to AWS. You will need extremely low-latency network performance to allow node-to-node communication between your EC2 instances. You will also need a minimum network speed of 10 Gbps in order for your application to work. How should you deploy your instances?","explanation":"Amazon EC2 cluster placement group functionality allows users to group Cluster Compute Instances in clusters – allowing applications to get the low-latency network performance necessary for tightly-coupled node-to-node communication typical of many HPC applications.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"About Placement Groups"}],"answers":[{"id":"49b8db049be133de9f86118999a12827","text":"By creating a cluster placement group","correct":true},{"id":"02aadc5ab6e7cd4f88243caf5bf9fe9b","text":"Using a private VPC","correct":false},{"id":"0994949ea896595c07d97ddc73598ca5","text":"By deploying in multiple availability zones","correct":false},{"id":"414edd18dd54c2a37e611231a1476dc1","text":"By using CloudFront to cache static assets so as to increase performance","correct":false}]},{"id":"5b52d388-382c-4f3c-9d9d-0e15d2c4dccd","domain":"CostOptimized","question":"You have a static HTML website that requires inexpensive, highly available hosting solution that scales automatically to meet traffic demands. Which AWS service would best suit this requirement?","explanation":"S3 Static Website Hosting offers the best solution here: it is highly-available, scales automatically, and is cost-effective.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Static Website Hosting"}],"answers":[{"id":"b0bca3ada773197571a3697e029cdfc4","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 1 instance","correct":false},{"id":"7e247cebfa4700e9281d3e30ac07ac70","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 2 instances","correct":false},{"id":"b812d3912dbd32666e0d2865e0ee9d19","text":"EC2 with CloudFront","correct":false},{"id":"a98f92c3d9a3073bdf1d35f748a53342","text":"S3 - Static Website Hosting","correct":true}]},{"id":"912352c0-d2a0-4e7c-89cd-d4ee66445744","domain":"CostOptimized","question":"You have been asked to design a scalable solution for a simple customer service survey that is shown online after each of the ~10 million chat bot interactions per month: Emoticons for 3 rating options ('positive', 'neutral' and 'negative') are to be presented with the expectation that about 10% of users submit their feedback. The bot is public facing and operates 24x7. Select a feasible and most cost effective solution.","explanation":"RDS alone is more expensive than any of the serverless solutions and therefore not an option here. Because of this use case's simplicity (i.e. no request validation, rate limiting, authentication/authorization, etc. required), there is essentially no need for a Lambda fronting API Gateway. Given the described requirements (load and availability), an ALB is more expensive as it's billed hourly.","links":[{"url":"https://serverless-training.com/articles/save-money-by-replacing-api-gateway-with-application-load-balancer/","title":"Saving Money By Replacing API Gateway With Application Load Balancers Lambda Integration"},{"url":"https://aws.amazon.com/blogs/networking-and-content-delivery/lambda-functions-as-targets-for-application-load-balancers","title":"Lambda functions as targets for Application Load Balancers"},{"url":"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/browser-invoke-lambda-function-example.html","title":"Invoking a Lambda Function in a Browser Script"}],"answers":[{"id":"b63327b72ecc6921a7e43eb0f786a3fe","text":"You invoke a Lambda function on demand in a browser script using the AWS SDK for JavaScript. For that to work you will need to create an Amazon Cognito identity pool with access enabled for unauthenticated identities and include the identity pool ID in your code to obtain credentials for the browser script. The function writes the submitted rating value to a DynamoDB table.","correct":true},{"id":"39329c7ee88152a625a8d565e6b38f36","text":"You front your Lambda that writes the ratings to a DynamoDB table with an ALB.","correct":false},{"id":"909f43a37c73caa5e0c764e4d8d8201c","text":"Given the expected load, you are better off with an Elastic Beanstalk app and RDS such as PostgreSQL or MySQL","correct":false},{"id":"852949aded12102365acbeb1052394f9","text":"You develop a proper API and use an API Gateway, Lambda and DynamoDB solution","correct":false}]},{"id":"3dc35381-00ad-4390-a31b-23a8340f4d57","domain":"SecureSolutions","question":"A co-employee approaches you with the need to access DynamoDB tables consisting of raw web analytics data to complete a required document on your company’s Data Warehouse processes. This is the only time in which the employee needs to access this information, and he needs such access for this day alone. What is the most appropriate course of action?","explanation":"Documenting your company’s Data Warehouse processes is a required task, so you simply can’t refuse access to the DynamoDB tables. However, it must be done in a way that does not risk the access of data by unauthorized users. That definitely rules out giving the employee your user credentials. And while you can simply create an IAM user, this action is for people who need continued and constant access; this employee only needs information from the database within a one-day window. Ultimately, the best course of action is to assign the appropriate IAM role to the employee to access the tables for this day, then remove the role assignment.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/authentication-and-access-control.html","title":"Identity and Access Management in Amazon DynamoDB"}],"answers":[{"id":"890c7f1c8bb33b06433d48f55f6a49d5","text":"Assign the appropriate IAM role to the employee to access the tables.","correct":true},{"id":"dd83c17dcfcf3b3acbb7200de7c2b473","text":"Give the employee your user credentials.","correct":false},{"id":"2b88f12405ab69024649b137e9e3ff74","text":"Refuse access to the tables.","correct":false},{"id":"5cf22da28e8e107eaa66dc1f724a6e34","text":"Create an IAM user for the employee to access the tables.","correct":false}]},{"id":"3072d04e-e5b2-42a6-97d7-dbb17155071d","domain":"SecureSolutions","question":"You have an EC2 Instance with an EIP allocated sitting in a Public subnet in your VPC. This instance is serving web content, and you want to make sure that users on the Internet can only access it via ports 80 and 443. Which of the below options lets you achieve this?","explanation":"DENY Rules cannot be created for security groups - so all options where this is mentioned can be ignored. With inbound traffic, NACLs are evaluated first - so an NACL with a default deny rule will block all incoming traffic before it reaches the instance - so this is not the correct option. This leaves creating an allow rule for the instance's security group as the correct answer.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"3802db4fb97fa84757d5b21b38464fc4","text":"Create a security group with an ALLOW rule for ports 80 & 443, and a DENY Rule for all other ports. Attach it to the instance","correct":false},{"id":"a910e411655dbf1d19c15b2690076861","text":"Create and NACL with a default deny rule on incoming traffic. Create a security group with an ALLOW rule for ports 80 & 443 and attach it to the instance.","correct":false},{"id":"f57136f22cc8a2fb5ed83f93962dd750","text":"Create an NACL with a default allow rule on incoming traffic. Create a security group with a DENY rule for all ports except 80 & 443 and attach it to the instance.","correct":false},{"id":"68d0d074ef501849c8908fe33b77b37f","text":"Create a security group with an ALLOW rule for ports 80 & 443 and attach it to the instance","correct":true}]},{"id":"bce7cb5d-687e-4e77-a516-1cde22e6f4e8","domain":"Performant","question":"How quickly can objects be restored from Glacier?","explanation":"You can expect most restore jobs initiated via the Amazon S3 APIs or Management Console to complete in 3-5 hours. Expedited restore is available at a price. ","links":[{"url":"https://aws.amazon.com/glacier/faqs/#dataretrievals","title":"Retrieving Data From Glacier"}],"answers":[{"id":"72ab9d0304d3e84c6aa2dd15eda282f2","text":"1 hour","correct":false},{"id":"6619a70f8ab8877e4131643fb8ded723","text":"2 hours","correct":false},{"id":"0d714869027c4e08ea9b2943d9bd704e","text":"30 minutes","correct":false},{"id":"99d888e6893ac480abd21ecb8a18e060","text":"3-5 hours","correct":true}]},{"id":"58c6fa98-66ec-4fe9-9870-78876228bfd5","domain":"SecureSolutions","question":"Your Security team is concerned about a recent spate of attacks making use of SYN, ACK and UDP floods to target websites in your industry. They want to make sure that appropriate protections are in place for your infrastructure for when you eventually become a target of this particular attack, as any downtime in your application has significant cost impact. Unfortunately your manager has stated that the budget is a bit tight - and wants you to make sure any protections implemented come at minimal extra cost - how would you proceed?","explanation":"SYN, ACK and UDP flood attacks are common DDoS style attacks. AWS Shield Standard, which comes for free with all AWS services, includes protection from these types of attacks. As budget is a major factor, \"Do nothing\" is the correct answer as you already have protection. Although deploying WAF will give much more robust security, this is not the primary concern in this scenario due to the extra costs, and the fact that the protections you are after are included in the Shield Standard product make this answer incorrect. Deploying extra instances in standby will be an extra cost as well, and they may never be needed. As this type of attack is automatically protected against, you should not need to deploy extra instances to cope with it.","links":[{"url":"https://aws.amazon.com/shield/getting-started/","title":"Getting Started with AWS Shield"}],"answers":[{"id":"cd88ce600576fcc630878b5e374835a5","text":"Do nothing","correct":true},{"id":"094be5110a86ae39df636deb8d20af19","text":"Do nothing until an attack actually happens, then deploy extra instances to take the load until the attack is over.","correct":false},{"id":"3877e96d087d4be7bc8acca2df611d56","text":"Deploy a WAF in front of your web services to protect from these types of attacks","correct":false},{"id":"f2e849409beda014a4933314b0e1ce0d","text":"Deploy extra instances in a \"Cold Standby\" state, so that when you are attacked you have infrastructure on standby ready to take over","correct":false}]},{"id":"1ea8aa1e-9454-49b0-b4e2-379eadf674e0","domain":"CostOptimized","question":"You are an employee at a communications firm that is in the process of migrating its data to Amazon S3. The data will be stored in buckets and is sent to customers to do as they see fit. However, certain data is frequently changed when customers request revisions, while the rest of the data is rarely changed. You must be able to immediately access certain data while minimizing costs. Which S3 storage class should you choose?","explanation":"While S3 Glacier is a low-cost storage class, it is for data archiving and thus not ideal for frequent access or changes to data. And S3 One Zone-Infrequent Access is also low-cost, but it does not address the frequently changed data. Although S3 Standard is a suitable choice, since it addresses frequent access, it is not the least expensive choice for the less frequently accessed data. If it was hard to determine which data is frequently changed and which isn’t, S3 Standard might have been the most cost-effective choice. But in this case, S3 Intelligent Tiering is. Intelligent Tiering stores data in two access tiers: one tier is optimized for frequently accessed data while the other is a lower-cost tier for infrequent access.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"5605213ade8877d8d601580dbd0a8aa2","text":"S3 One Zone-Infrequent Access","correct":false},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":true}]}]}}}}
