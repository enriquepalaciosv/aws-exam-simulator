{"data":{"createNewExamAttempt":{"attempt":{"id":"f75c532b-2ce2-4985-9e5e-62888e59b3fc"},"exam":{"id":"1e02335d-a797-4337-9fc6-8a2da4c9e463","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"126e898c-dd73-4447-b5a7-59701a16a92d","domain":"ResilientDesign","question":"You are reviewing Change Control requests and you note that there is a proposed change designed to reduce errors due to S3 Eventual Consistency by updating the 'DelaySeconds' attribute. What does this mean?","explanation":"Poor timing of SQS processes can significantly impact the cost effectiveness of the solution.","links":[{"url":"http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"464400e5333b3beab1128b1b1f7cedf7","text":"While processing a message, a consumer instance can amend the message visibility counter by a fixed amount.","correct":false},{"id":"f170b98804f18cb00b57e135f0a3f116","text":"When the consumer instance polls for new work, the consumer instance will wait a certain time until it has a full workload before closing the connection.","correct":false},{"id":"4b46d6ad9dd090f0143cc40fecbad7b5","text":"When a new message is added to the SQS queue, it will be hidden from consumer instances for a fixed period.","correct":true},{"id":"6e5b2857717c8cf5b2722dc270183515","text":"While processing a message, a consumer instance can reset the message visibility by restarting the preset timeout counter.","correct":false}]},{"id":"e9205ab6-d7ce-4708-b92d-e6814f79c6d4","domain":"ResilientDesign","question":"The dashboard application for multiple company contact centers requires fast update response times for a large number of concurrent users. Call center metric data is stored in an Oracle version 11 database. Which architecture will provide high-availability and the low response times needed for this mission-critical data?","explanation":"Since the dashboard updates are needed across multiple contact centers, leveraging read-only replicated databases will provide fast response times. Amazon RDS doesn’t support read replicas for Oracle version 11, so hosting the database on EC2 and replicating the data with Oracle Data Guard is the only viable solution. AWS Database Replication Service is not an offered service, and using EBS snapshots won't provide real-time replication.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/oracle-database/overview.html","title":"Oracle Database on AWS"}],"answers":[{"id":"c1e824f46134bc6696eba635f30df032","text":"An Amazon RDS Oracle instance with Multi-AZ and Read Replicas","correct":false},{"id":"5ee29b50026caa8c20c9e469f93b5a2a","text":"Oracle hosted on Amazon EC2 in Multiple Availability Zones with EBS snapshots","correct":false},{"id":"de5ad68debdabd478d7d4f66542b9ca8","text":"An Amazon RDS Oracle Instance with AWS Database Replication Service","correct":false},{"id":"0129ed97e5c2ec017bdc05d836f10049","text":"Oracle hosted on Amazon EC2 in multiple Availability Zones with Oracle Data Guard replication","correct":true}]},{"id":"81dc73a3-27d5-4080-99ab-d75edfa081b0","domain":"ResilientDesign","question":"You successfully configure VPC Peering between VPC-A  and VPC-B. You then establish an IGW and a Direct-Connect connection in VPC-B. Can instances in VPC-A connect to your corporate office via the Direct-Connect service as well as connect to the Internet via the IGW?","explanation":"VPC peering only routes traffic between source and destination VPCs. VPC peering does not support edge-to-edge routing.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html","title":"Invalid VPC Peering Connection Configurations"}],"answers":[{"id":"d823d585a3fbbbcb9b921454f7d3bd62","text":"VPC peering does not support edge-to-edge routing.","correct":true},{"id":"6ce9df55ff92945dc320411540661454","text":"Yes: VPC Peering is designed to route traffic between the VPCs.","correct":false},{"id":"3542ee08d9923e029f120a6dc9b3d9db","text":"Instances in VPC-A will be able to access the Internet, but not the corporate office.","correct":false},{"id":"bdb763fa01cc1ea95bbab61b10394fea","text":"Instances in VPC-A will be able to access the corporate office, but not the Internet.","correct":false}]},{"id":"f1715a54-ef4a-4912-9093-e8e36698b0c9","domain":"CostOptimized","question":"Your company needs to run several monthly workloads that will each take several hours to complete. Although critical, these workloads can be stopped and restarted without adversely affecting the outcome of the job. Which pricing model would you use to deliver the most economical solution?","explanation":"Spot instances are a cost-effective choice if you can be flexible about when your applications run and if your applications can be interrupted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html","title":"About Spot Instances"}],"answers":[{"id":"c658c72ec41cc513ad91a3f3e6d2c060","text":"On-demand Instances","correct":false},{"id":"de53d38fe38e0fce729f15c292a59891","text":"Free-Tier Instances","correct":false},{"id":"29068f6044e3fedf44165e646a2d2bb1","text":"Reserved Instances","correct":false},{"id":"026db7f2265667575c05772f32778b8a","text":"Spot Instances","correct":true}]},{"id":"2a66405e-baf4-44b2-9f82-1473bc4fac96","domain":"SecureSolutions","question":"You've been tasked with migrating an on-premise application architecture to AWS. During the design process, you give consideration to current on-premise security and identify the security attributes you are responsible for on AWS. Which of the following does AWS provide for you as part of the shared responsibility model?","explanation":"Understanding the AWS Shared Responsibility Model will help you answer quite a few exam questions by recognizing false answers very quickly.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"The Shared Responsibility Model"}],"answers":[{"id":"ec260804fcc18ef10e22772f4401253d","text":"Physical network infrastructure","correct":true},{"id":"dd4ec43803918fe3ee9d6c3e8482c1df","text":"User access to the AWS environment","correct":false},{"id":"6de1fb3029549fbd94d79415e8036810","text":"Instance security","correct":false},{"id":"9f437974a72e2dafff526fad12c4c925","text":"Virtualization Infrastructure","correct":true}]},{"id":"cbd65c24-5330-4cbe-aadc-f65637bed971","domain":"CostOptimized","question":"Your SQL server requires a specific type of collation and some unique third party tools installed on it. You will need access to the underlying operating system for management and monitoring of these third party tools. However, you'd like to keep the overall amount of management to a minimum. Which AWS service would best suit your needs?","explanation":"With all services you are trading control of underlying processes for cost saving and ease of management.  In the case of RDS, AWS has exclusive control of the DB engine and underlying processes.  If you need to have access to these, building a bespoke DB server on an EC2 instance is the correct technical choice.","links":[{"url":"https://aws.amazon.com/sql/","title":"SQL Server on AWS"}],"answers":[{"id":"8f23d472ee9e39b19dec8c94f59f497b","text":"ElasticCache","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"8d8f3d54a16acc76a831ced6958141b9","text":"SQL server installed on EC2 with EBS","correct":true},{"id":"0ccd2cb2fe485108788ab60e8dbdfb4e","text":"RDS with SQL Server","correct":false}]},{"id":"42cc5ed7-0d57-429c-973a-79cb287f6a1e","domain":"Performant","question":"You have an extremely high performance compute application that you need to deploy to AWS. You will need extremely low-latency network performance to allow node-to-node communication between your EC2 instances. You will also need a minimum network speed of 10 Gbps in order for your application to work. How should you deploy your instances?","explanation":"Amazon EC2 cluster placement group functionality allows users to group Cluster Compute Instances in clusters – allowing applications to get the low-latency network performance necessary for tightly-coupled node-to-node communication typical of many HPC applications.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"About Placement Groups"}],"answers":[{"id":"0994949ea896595c07d97ddc73598ca5","text":"By deploying in multiple availability zones","correct":false},{"id":"414edd18dd54c2a37e611231a1476dc1","text":"By using CloudFront to cache static assets so as to increase performance","correct":false},{"id":"02aadc5ab6e7cd4f88243caf5bf9fe9b","text":"Using a private VPC","correct":false},{"id":"49b8db049be133de9f86118999a12827","text":"By creating a cluster placement group","correct":true}]},{"id":"ed03b04d-9536-4612-9418-842b35993276","domain":"SecureSolutions","question":"The various components of a web application are supposed to reside in a VPC that is only accessible by a designated System Administrator. Which of the following configurations will enable the SA to communicate with the EC2 Linux web servers that house the application using the Command Line Interface?","explanation":"You will have to go to select the security group associated with the VPC that contains the application’s components, click 'Edit inbound rules', and add a rule with type of protocol set to 'SSH', source of the traffic set to 'Custom', and the IP address of the administrators computer entered in the field next to the Source dropdown menu. Although each of the other responses have the right type of rule (inbound), the other configurations do not specifically grant the SA access to the application. An inbound rule for TCP communications could have been the answer, since SSH communication uses the TCP protocol. However, it is not specifying the type of TCP protocol for the SA, which is SSH. RDP is a Microsoft technology for remote desktop connections and HTTPS is for secure access to websites.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/authorizing-access-to-an-instance.html","title":"Authorizing Inbound Traffic for Your Linux Instances"}],"answers":[{"id":"999d6b54e6a87abb29b94b7170c79e40","text":"Add an inbound rule in the security group associated with the VPC for RDP communication with an IP address range that includes that of the SA.","correct":false},{"id":"4c1f2abb1661d2c12fdd21f3d81d9a96","text":"Add an inbound rule in the security group associated with the VPC for TCP communication with an IP address range that includes that of the SA.","correct":false},{"id":"b3a4bdb6ea7e8979965c11c9b05752a0","text":"Add an inbound rule in the security group associated with the VPC for HTTPS communication.","correct":false},{"id":"097576029cd34dee2612943b1856928a","text":"Add an inbound rule in the security group associated with the VPC for SSH communication with the IP address of the administrators computer.","correct":true}]},{"id":"5b52d388-382c-4f3c-9d9d-0e15d2c4dccd","domain":"CostOptimized","question":"You have a static HTML website that requires inexpensive, highly available hosting solution that scales automatically to meet traffic demands. Which AWS service would best suit this requirement?","explanation":"S3 Static Website Hosting offers the best solution here: it is highly-available, scales automatically, and is cost-effective.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Static Website Hosting"}],"answers":[{"id":"b0bca3ada773197571a3697e029cdfc4","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 1 instance","correct":false},{"id":"a98f92c3d9a3073bdf1d35f748a53342","text":"S3 - Static Website Hosting","correct":true},{"id":"b812d3912dbd32666e0d2865e0ee9d19","text":"EC2 with CloudFront","correct":false},{"id":"7e247cebfa4700e9281d3e30ac07ac70","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 2 instances","correct":false}]},{"id":"e19d68d3-a39e-4056-bef8-7fb2d19df5b9","domain":"SecureSolutions","question":"Which of the following areas of Security in the Cloud involves the identification of potential threats or incidents?","explanation":"Detective controls, such as conducting an inventory of assets or carrying out internal auditing, are employed to look out for anything that poses a threat to the security of a cloud environment. There are five areas of Security in the Cloud: IAM, Detective Controls, Infrastructure Protection, Data Protection, and Incident Response.","links":[{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Security-Pillar.pdf","title":"AWS Security Pillar"}],"answers":[{"id":"7e7397a7b79323762c61941fc0e6b5f9","text":"Data protection","correct":false},{"id":"5fe5bde89ae88d436f1f8ba2d3a64130","text":"Identity and Access Management (IAM)","correct":false},{"id":"7fb1ca7b0dfce3a9a7eaedc329cecc27","text":"Incident response","correct":false},{"id":"caa28027e00cbf3f30f66fe8846f2bb0","text":"Detective controls","correct":true},{"id":"cd978e0acae323979bd0c7a15fdffb2c","text":"Infrastructural protection","correct":false}]},{"id":"ac606721-1133-4438-8a6f-ec7bc24443ed","domain":"SecureSolutions","question":"Your organization has a custom VPC, but you've just discovered that one of your developers has created an RDS instance in the default VPC (in violation of company policy.) You need to re-create this RDS instance inside your custom VPC with as little effort as possible. What should you do?","explanation":"The easiest way would be to take a snapshot of the DB Instance in the Default VPC and restore it to your custom VPC by specifying the DB Subnet Group you want to use.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RestoreFromSnapshot.html","title":"Restoring (or moving) From a Snapshot"}],"answers":[{"id":"71ae0650c202e7da315185fadebdec02","text":"Use the command 'aws rds mv dbname < VPC'.","correct":false},{"id":"c04f8f858073c4a62ff00a4eff9386dc","text":"Use AWS Database Migration Service.","correct":false},{"id":"7a4d78c86de0e51b5dbc37976fdf85cb","text":"Use the RDS Import/Export Wizard to Migrate the RDS instance across to the custom VPC.","correct":false},{"id":"4997ddcea578c38851dfd6681dc85500","text":"Take a snapshot of your DB Instance in the default VPC and restore it to VPC by specifying the DB Subnet Group you want to use in your custom VPC.","correct":true}]},{"id":"caa41dad-d6c0-4e39-ba7a-6cb4733057fc","domain":"SecureSolutions","question":"You want to enable EC2 instances in your AWS environment to download software updates over HTTP (Port 80) from the internet. What Security Group settings will enable this?","explanation":"Security Groups are stateful, so you only need to define the Outbound rule in the Security Group for this example as the EC2 instance is initiating the connection. Answers with inbound rules are incorrect, which leaves the answer with the Outbound rule allowing HTTP to 0.0.0.0/0. Once the EC2 instance has established valid HTTP connection with an Internet service, the target systems response is allowed.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups for Your VPC"}],"answers":[{"id":"31a5c0b1dba4f28abc65481430837c52","text":"Inbound: Allow HTTP (Port 80) from 0.0.0.0/0","correct":false},{"id":"a97ae85a569a169da98242372287508c","text":"Inbound: Allow ALL Ports from 0.0.0.0/0, Outbound: Allow HTTP (Port 80) to 0.0.0.0/0","correct":false},{"id":"a0709d6298ca5365980468f590450d25","text":"Inbound: Allow HTTP (Port 80) from 0.0.0.0/0 \n Outbound: HTTP (Port 80) to IP address of Software Repo","correct":false},{"id":"3c6469e0e1b096b5754357258ea83ba8","text":"Inbound: Allow HTTP (Port 80) from 0.0.0.0/0 \n Outbound: HTTP (Port 80) to 0.0.0.0/0","correct":false},{"id":"b834b395c8d51e551c3193ed885868ec","text":"Outbound: Allow HTTP (Port 80) to 0.0.0.0/0 ","correct":true}]},{"id":"8a4cd8a8-183f-11ea-8d71-362b9e155667","domain":"CostOptimized","question":"Your company recently expressed interest in upgrading to an AWS Support plan that provides infrastructure event management and incident response for the launch of a business-critical application. Which of the following support plans will satisfy your company's requirements?","explanation":"Each AWS account comes with Basic Support, so Basic is not the answer. Either the Business or the Enterprise plan grants access to AWS Infrastructure Event Management, the program your company needs for assistance with launching the application. The Enterprise plan, however, provides up to a 15-minute response time if the business-critical application goes down; the Business plan does not offer this option. In addition, the Busines Plan does not include Infrastructure Event Management - you need to pay an additional fee for this. Therefore the Enterprise plan is the only option that provides the appropriate level of incident response and infrastructure event management required.","links":[{"url":"https://console.aws.amazon.com/support/plans/home?#/","title":"AWS Support Plans"},{"url":"https://aws.amazon.com/premiumsupport/programs/iem/","title":"AWS Infrastructure Event Management"}],"answers":[{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":false},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false}]},{"id":"da14a91d-ff38-4ee2-976e-87ab89ed2b57","domain":"Performant","question":"You are attempting to move data from one EBS volume to a duplicate volume in a separate region. Which of the following methods will do this best?","explanation":"After you've created a snapshot and it has finished copying to Amazon S3, you can copy it from one AWS region to another, or within the same region.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-copy-snapshot.html","title":"Copying an EBS Snapshot"}],"answers":[{"id":"7ed5cf49719e006c801d0e6fe0f4cf7e","text":"Allow a VPC peering connection to pull the data over.","correct":false},{"id":"cf0d4fd3cb2d1497b6e5699ec4ee8ed5","text":"Take a snapshot of the EBS volume and copy it to the desired region.","correct":true},{"id":"f1ce9b0c80209553a22ede320d2ce91f","text":"Use a Linux tool like rsync to sync the volume to the other region.","correct":false},{"id":"2d58342b23166c9f5556bbe76440bd28","text":"Move the data to S3 and enable cross-region replication.","correct":false}]},{"id":"2f18032b-ba16-4cf1-a9f4-0ee458e316bb","domain":"ResilientDesign","question":"Your development team have created a cloud specific application which is decoupled from other services.  You have been tasked with choosing an AWS service to use as message queue in this service.  The developers have specified that the chosen service must cope with at least 5000 transactions per second, guarantee delivery of each message but allows for the message being sent a number of times.","explanation":"The Standard SQS Queue meets all of the goals listed in the question, each message will be delivered at least once, but may be sent more than once. It can also cope with almost unlimited number of transactions per second. The FIFO queue can guarantee to deliver messages at least once, but can only handle 300 transactions per second.  Amazon MQ is specifically developed to move existing applications to the cloud without changing your code and it may work in this context, but it is not recommended.  SNS is a notification service not a messaging queue.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"Amazon SQS FAQs"},{"url":"https://aws.amazon.com/sqs/features/","title":"Amazon SQS features"}],"answers":[{"id":"6d0cf8e6998da0736797ae76fc1b5071","text":"SQS FIFO","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":false},{"id":"0a4adfe9c9d87e31e94e1e13e2f44441","text":"SQS Standard","correct":true}]},{"id":"e8d01592-5b1f-418e-84e9-fcc23e15ae0d","domain":"Performant","question":"You need to store files as objects in Amazon S3. Which AWS service provides that ability?","explanation":"You will need to go with Storage Gateway, which gives you the option of creating a file gateway so that S3 can support files. EFS provides file storage, but without the compatibility with S3. True to its naming, EBS is a block-level storage service. And RDS is for creating relational databases, not file gateways.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html","title":"What Is AWS Storage Gateway?"}],"answers":[{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":false},{"id":"9155453f43b8a6472df0b8ffa5b5a028","text":"Amazon Elastic Block Storage (EBS)","correct":false},{"id":"d2a6652ddeb631da029d1f2806e11fdc","text":"Amazon Elastic File System (EFS)","correct":false},{"id":"5ba49687f2f5ade4cd1c756a7e9024e3","text":"AWS Storage Gateway","correct":true}]},{"id":"c487c002-443f-4d86-bdde-a915adb7924d","domain":"ResilientDesign","question":"You have chosen to use S3 - OneZone-IA with your cloud application. Which limitations have you considered in doing so?","explanation":"In exchange for a significant cost savings, 1Zone-IA has the same Durability as S3, but a lower Availability SLA.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/?nc=sn&loc=3","title":"S3 Storage Classes"}],"answers":[{"id":"bcddbe2d89ec46d45172296d890040c3","text":"1Zone-IA is available only in the US-STANDARD region.","correct":false},{"id":"4068f35933f215b2818a03234567736a","text":"1Zone-IA requires supplementary Access Control Lists.","correct":false},{"id":"3ffe3458e13ccc426e49a1893b78a3f3","text":"1Zone-IA has a 3 - 5 hour data recovery windows.","correct":false},{"id":"a86f1cf2d99a9643587b837f464b5ef8","text":"1Zone-IA offers only 99.50% availability. Therefore you have to design your application to re-create any objects that may be temporally unavailable.","correct":true},{"id":"e0a1c69e07da2a370da0dedf28084491","text":"1Zone-IA offers only 99.50% durability. Therefore you have to design your application to re-create any objects that may be lost.","correct":false}]},{"id":"1def4473-403d-432b-a5fe-4a3671e41fa8","domain":"Performant","question":"You have a huge dataset for an insurance company which is located in Amazon Redshift. The data is used by data scientists intermittently to calculate risks of particular events so that the company can charge the correct premiums. The data is also used by TV’s in the office which run fast SQL queries that calculate data such as the number of claims today and the total value of claims. This data is updated every hour, however the dashboards query the data every minute. Recently your data scientists have been complaining that their queries are taking longer and longer. What should you do to increase the performance of your redshift cluster?","explanation":"Elasticache is a purpose built cache to offload reads from database systems. This is an ideal use case for it. CloudFront is a web content cache not a database cache.  DAX is specifically designed for DynamoDB.","links":[{"url":"https://aws.amazon.com/elasticache/features/","title":"ElastiCache features"},{"url":"https://aws.amazon.com/blogs/big-data/using-pgpool-and-amazon-elasticache-for-query-caching-with-amazon-redshift/","title":"ElastiCache for Query Caching with Amazon Redshift"},{"url":"https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-redshift-introduces-result-caching-for-sub-second-response-for-repeat-queries/","title":"Redshift Introduces Result Caching"}],"answers":[{"id":"63a67f6a01dc9eec3668660975e89e79","text":"Use AWS CloudFront to cache the data at global edge locations and update the origin of the CloudFront distribution to point to the Redshift Cluster.","correct":false},{"id":"99d160edacf191e386a8aad4629ceeca","text":"Enable DynamoDB Accelerator (DAX) and update the dashboards to point to the DAX endpoint.","correct":false},{"id":"7088a4438456fc4c2545c57d8a2bc2f0","text":"Configure ElastiCache cluster to store the most frequently accessed data by the dashboards and update the dashboards to query elasticache rather than Redshift.","correct":true},{"id":"bdbc824cad7340d1baab1e1909e5f976","text":"Change the storage from Magnetic to Provisioned IOPS so as to increase the underlying storage IO.","correct":false}]},{"id":"b864406d-be60-4f6a-82dc-9160d5585ca0","domain":"SecureSolutions","question":"Your manager has noticed that some members of your team are using the AWS Account Root User to undertake certain tasks.  They have asked you to confirm when is it correct procedure to use the Root User.  Choose from the correct options.","explanation":"You cannot use policies within your account to explicitly deny access to the Root user. However, if an IAM user accidentally revokes their own permissions, you can sign in as the Root user to edit policies and restore those permissions.  All other options are valid uses of the AWS Account Root User.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html","title":"The AWS Account Root User"},{"url":"https://docs.aws.amazon.com/general/latest/gr/aws_tasks-that-require-root.html","title":"AWS Tasks That Require AWS Account Root User Credentials"}],"answers":[{"id":"e7e875a434ddf25dfe250989b53ca2ce","text":"Move the level of your AWS Support Plan from Business to Enterprise","correct":true},{"id":"d0623de1aeb9bae95ad7fd9df219e156","text":"Submitting a Request to perform an external penetration test that isn't a permitted service","correct":true},{"id":"767fe082a112680443e319c832c4f06f","text":"Create a CloudFront Key Pair","correct":true},{"id":"fe713e15c6b90a9c07f22b8fd92d6f70","text":"Using IAM policies to deny Root account access","correct":false},{"id":"5799714fbea5ac62293b5ace786552dd","text":"Closing an AWS Account","correct":true}]},{"id":"2d66f5e8-54d1-4364-af7a-52ebcffda715","domain":"Performant","question":"A startup clothing retailer has begun designing their online ordering application. The user interface will require presentation of four different screens to complete an order (product selection, shopping cart, payment, order confirmation). Orders can contain multiple line items. The application backend will need to scale seamlessly for seasonal spikes in demand. Which architecture will provide the most elastic and highest performing solution?","explanation":"Deploying individual Lambda functions with different order processing capabilities provides scalability and performance at an atomic function level. A deployment package that includes all of the order processing logic will take longer to cold-start. DynamoDB will provide faster overall performance for interim order data than RDS. Storing all interim order data in browser cookies is not feasible, especially if the order contains multiple line items","links":[{"url":"https://aws.amazon.com/serverless/build-a-web-app/","title":"Serverless Web Application"}],"answers":[{"id":"9585d6076d65862d61c9bec06c0d9ef5","text":"Store all interim order information in browser cookies and submit it to a single EC2 instance at the end of the ordering process. Implement Auto Scaling to handle the fluctuations in demand","correct":false},{"id":"6e475a25a83c4ef5618fd3979e83b690","text":"Use a single Lambda function with the capability to process all the steps of the ordering process. Submit interim order information to the backend after each ordering step and store it in an Amazon RDS database. Keep track of order state in a database table","correct":false},{"id":"bc1e03e1b048963acfa7d91267d73450","text":"Deploy a different Lambda function to process each step of the ordering process. Submit interim order information to the backend after each ordering step and store it in Amazon DynamoDB. Index the data with a transaction ID cookie stored in the browser","correct":true},{"id":"ba250a1b654920d1974ffae0ae713e76","text":"Deploy EC2 instances, each with the capability to process all the steps of the ordering process. Submit interim order information to the backend after each ordering step and store it on EBS volumes for persistence. Implement Auto Scaling to handle the fluctuations in demand","correct":false}]},{"id":"ee772b8e-1672-479d-b28d-8952d89b24f5","domain":"SecureSolutions","question":"By default, how many Elastic IP addresses are you limited to per region?","explanation":"By default, all accounts are limited to 5 Elastic IP addresses per region.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Appendix_Limits.html#vpc-limits-eips","title":"Elastic IP Addresses - Limits"}],"answers":[{"id":"98f13708210194c475687be6106a3b84","text":"20","correct":false},{"id":"d3d9446802a44259755d38e6d163e820","text":"10","correct":false},{"id":"e4da3b7fbbce2345d7772b0674a318d5","text":"5","correct":true},{"id":"9bf31c7ff062936a96d3c8bd1f8f2ff3","text":"15","correct":false}]},{"id":"5c6ec542-13ec-47b0-90b9-747eba40a8dd","domain":"CostOptimized","question":"What main functions can Route 53 perform? Select the best answer from the following options.","explanation":"Route53 is Amazons DNS web service that delivers the domain registration, DNS routing and health checking function in any combination.","links":null,"answers":[{"id":"24f6183de033dcaee97747be7c92a9f3","text":"Amazon Route 53 is a highly available and scalable cloud Domain Name System (DNS) web service that is designed to give developers and businesses an extremely reliable and cost-effective way to route end users to Internet applications. It can be used together with CloudWatch, a service which allows you to monitor and manage applications. While Route 53 is not a domain reseller, it allows customers to bring their own domain names with them.","correct":false},{"id":"20cda55464d105018afc584dcdbc80fe","text":"Domain registration, DNS routing, and health checking in any combination","correct":true},{"id":"fd7a725638e536df09c6ea5a5d0f2b46","text":"DNS routing and health checking for domains hosted on AWS","correct":false},{"id":"207068b486e311e8fedb355a6c2edcff","text":"Domain registration and DNS routing","correct":false}]},{"id":"7dafc126-8f93-4ac8-97ba-01818de79dc1","domain":"SecureSolutions","question":"As a junior Cloud Engineer, you receive a CloudWatch alarm indicating that there might be a layer 7 attack of your environment. You recall that your company has an AWS Shield Advanced subscription. Which of the following options is the best response?","explanation":"You *can* investigate and mitigate the DDoS attack on your own, so that is a potentially correct answer. Similarly, requesting internal assistance is another possible answer because of your tech lead’s expertise. However, the best course of action is to take advantage of your AWS Shield Advanced subscription, which routes you to true DDoS experts. In this case the *most correct* answer is to work with AWS Support. Doing nothing should never be considered as an answer.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-responding.html","title":"Responding to DDoS Attacks"}],"answers":[{"id":"43d522d2e9a722af4df45616e09e2ff4","text":"Contact AWS Support Center.","correct":true},{"id":"0b9ac6496fca4f50d60b7665f91d9209","text":"Investigate and mitigate the attack on your own.","correct":false},{"id":"e13ab7a7dcc291aa8a8f5e4e1c3a8646","text":"Do nothing; it is an AWS issue that will resolve itself.","correct":false},{"id":"b62d821db1c6397935c957ddd8214d47","text":"Request assistance from tech lead.","correct":false}]},{"id":"e62d3927-3172-4d89-a2f2-b70a62da50d7","domain":"CostOptimized","question":"What are the key instance attribute variables that determine reserved instance price?","explanation":"Reserved instances provide significant savings on Amazon EC2 costs compared to on-demand instance pricing. Reserved instances are not physical instances, but rather a billing discount applied to the use of on-demand instances in your account. These on-demand instances must match certain attributes, such as instance type and region, in order to benefit from the billing discount. A reserved instance has four instance attributes that determine its price. They are Instance Type, Scope, Tenancy, Platform. The attributes also determine how the reserved instance is applied to a running instance in your account.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","title":"Reserved Instance Attribute"}],"answers":[{"id":"8f1f69be4b7932f83f66e28cfee82568","text":"Instance Type, Scope, Tenancy, Network","correct":false},{"id":"e5a48e08950e10c8e11c7de25d41b2ae","text":"Instance Type, Scope, Tenancy, Platform","correct":true},{"id":"6650ae9522d5793a5a4f0818eba78ed6","text":"Instance Type, Usage/Load, Tenancy, Platform","correct":false},{"id":"f7925fb10a7a695858fd864c7a5ba10b","text":"Instance Type, Usage/Load, Tenancy, Network","correct":false}]},{"id":"7bcf3cb7-6154-4148-96ca-7e9ff7c16f27","domain":"ResilientDesign","question":"Your company is a heavy user of CloudFormation to deploy standard websites using WordPress for Media, PR and Marketing clients. As your company grows you are repeating the same load balancer configuration for most of your stacks. Currently you are manually copying and pasting the same configurations from one template to another. You want to reduce the administrative overhead in deploying CloudFormation templates. What options are there to achieve this?","explanation":"Breaking large complex builds into sections gives you the advantage of being able to reuse common templates patterns with a known and proven configuration, plus being able to share responsibility to SME for their portion of the architecture.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html","title":"CloudFormation - Nested Stacks"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks.html","title":"CloudFormation - Stacks Updates"}],"answers":[{"id":"57bd133b2237789f413b1486e2bac4a5","text":"Create an Elastic Beanstalk Deployment stack.","correct":false},{"id":"d605a2578632e3bf9fe88e8b645c335f","text":"Reference the template as part of a nested stack.","correct":true},{"id":"8511646bc9edf9631791dd72182f9c76","text":"Use AWS lambda to automatically deploy the load balancer once your CloudFormation Template has finished provisioning.","correct":false},{"id":"b8291da95d71714b3f5314572a6d5e47","text":"Create a dedicated template for the load balancer.","correct":true}]},{"id":"f354dcdd-8250-4f18-a666-c1da3a174154","domain":"ResilientDesign","question":"You are configuring your application load balancer to enable users to access your application, which is in a staging environment and only has a private IP address. Which of the following schemes will enable this type of access?","explanation":"When configuring load balancers, you get two scheme choices, which are internet-facing and internal. If the users were to access the application through the Internet, then internet-facing would be the correct answer. Internal load balancing is right in this instance because the internal scheme choice will create an internal load balancer for routing requests from the users to the application with the private IP address.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-internal-load-balancers.html","title":"Internal Classic Load Balancers"}],"answers":[{"id":"b206a1b4ea1097761f78e8876f6da779","text":"External","correct":false},{"id":"ef85538ce0d687a7f414634e39f842dc","text":"User-facing","correct":false},{"id":"afbf0897a5a83fdd873dfb032ec695d3","text":"Internal","correct":true},{"id":"e82fcc3d0c37dcaf93bb7b620da3c563","text":"Internet-facing","correct":false}]},{"id":"2bf7c178-22a7-4278-b5b0-53cc05846468","domain":"ResilientDesign","question":"Your company is migrating an on-premise 15 TB PostrgreSQL database to AWS. The company expects this database to triple in size and has a business requirement of synchronous replica lag be under 100 ms. Which AWS RDS service will meet the requirement best?","explanation":"Aurora Cluster can grow up 64 TB in size and replica lag is less than 100 ms after the primary instance has written an update.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.html","title":"Amazon Aurora DB Clusters"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html","title":"Amazon Aurora Replicas"},{"url":"https://forums.aws.amazon.com/thread.jspa?threadID=230133","title":"notes form teh AWS support forum"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Limits.html","title":"RDS limits"}],"answers":[{"id":"30162ed78b6c10f731411f2fc440c24f","text":"Oracle","correct":false},{"id":"0284c831e4dee575b707cc920ab09ae6","text":"PostrgreSQL","correct":false},{"id":"69670a9d53817d1ec89e685997343ce2","text":"Amazon Aurora","correct":true},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false}]},{"id":"62c40f57-a8f9-4280-849b-34440bbcbef9","domain":"SecureSolutions","question":"Which of the following is an invalid VPC peering configuration?","explanation":"Edge-to-edge routing is not allowed through a VPN connection.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html","title":"Invalid VPC Peering Connection Configurations"}],"answers":[{"id":"2fa2fe643e096fd3d938fa5cd569209f","text":"You have a VPC peering connection between VPC A and VPC B. VPC A also has a VPN connection to a corporate network. You use VPC A to extend the peering relationship to exist between VPC B and the corporate network so that traffic from the corporate network can directly access VPC B by using the VPN connection to VPC A.","correct":true},{"id":"ebd4315b15afc456004798c874243bf9","text":"You have a VPC peering connection between VPCs A and B. They are in the same AWS account, and they do not have overlapping CIDR blocks.","correct":false},{"id":"808626de978678cbd8fba9cdf7ede572","text":"You have peered three VPCs in a full-mesh configuration. The VPCs are in the same AWS account and do not overlapping CIDR blocks.","correct":false},{"id":"63722d8924a7b714eb8a8000961ebf13","text":"VPC A has peering connections to VPCs B and C. All three VPCs are in the same AWS account, and there are no overlapping CIDR blocks.","correct":false}]},{"id":"9cfdc945-a7e0-479c-9bcc-973f9ebfd7dc","domain":"CostOptimized","question":"You want to set up 2 CloudWatch alarms in addition to the 6 you already have to monitor your cloud environment. It has been 13 months since you created your AWS account, and you want to avoid being charged for creating the alarms. What should you do?","explanation":"Upon signing up for an AWS account, you will get a range of service usage that will never cost you anything. Such offers include 10 alarms with CloudWatch. That’s why creating the alarms is the correct answer. Contacting support is wrong because it’s not necessary to request a service increase limit. Avoiding creating new alarms is also wrong because there’s no term limits on the CloudWatch alarm offer; it’s always free. Creating more alarms in this case is still free of charge because the free offer is limited to 10 CloudWatch alarms.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsm.page-all-free-tier=1","title":"AWS Free Tier"}],"answers":[{"id":"d8991b206aa9d731ab999eddedf26d6e","text":"Go ahead and create the alarms; you can have up to 10 CloudWatch alarms without being charged.","correct":true},{"id":"3e9a7ae3a0c82f4aaf031d7400a3774f","text":"Do not create the alarms; you will be charged, since you get a maximum of 10 alarms with CloudWatch for the first 12 months after your account sign-up.","correct":false},{"id":"a336fb6001d622e126c7d02da7ab218f","text":"Go ahead and create the alarms; CloudWatch alarms are always free of charge, regardless of number.","correct":false},{"id":"222fcbee1f68dae67b4406597659a622","text":"Contact AWS Support for a service increase limit.","correct":false}]},{"id":"9ddc17c5-4849-4869-b79f-a7e2b6630be1","domain":"Performant","question":"Which AWS service should you use to host MySQL, MariaDB, Oracle, SQL Server, or PostgreSQL database where you do not need to manage the underlying operating system?","explanation":"Amazon RDS is available on several database instance types - optimized for memory, performance or I/O - and provides you with six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle, and Microsoft SQL Server.","links":[{"url":"https://aws.amazon.com/rds/","title":"AWS RDS: Available Engines"}],"answers":[{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":false},{"id":"1574cf43006500eb74cc583eef4a8b87","text":"EC2 with EBS","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true}]},{"id":"8195d824-418f-4a5a-a599-fe3d07a530b3","domain":"SecureSolutions","question":"A shipping company brokers transportation arrangements for a large freight carrier. The shipping company currently uses an online form to make reservations with the freight carrier, but they'd like to automate the ordering process. The freight carrier runs its logistics system on AWS. The shipping company also runs its IT infrastructure on AWS. Which architecture should the shipping company put in place to provide the best security and operational efficiency for their transactions with the freight carrier?","explanation":"AWS PrivateLink provides private connectivity between VPCs and AWS services securely on the AWS network without exposure to the public Internet. AWS PrivateLink is implemented by a service provider creating an Endpoint Service and a service consumer connecting via an Interface VPC Endpoint. Direct Connect is established between a customer and AWS, not between two AWS customers. VPC Peering and VPN connections will work, but will require more operational overhead than PrivateLink.","links":[{"url":"https://aws.amazon.com/privatelink/","title":"AWS PrivateLink"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/endpoint-service.html","title":"VPC Endpoint Services"}],"answers":[{"id":"b8f2bb6bbe7e63e7b530dd7f39f28422","text":"Have the freight carrier create an Endpoint Service and use an Interface VPC Endpoint to connect","correct":true},{"id":"43204aec60483f400cb38e62488b58cd","text":"Implement VPC Peering to the freight carrier's VPC","correct":false},{"id":"5fbd35f29f2fcaae8769b6cda42eb9ec","text":"Create an IPSec VPN tunnel to the freight carrier's network thorough a Virtual Private Gateway","correct":false},{"id":"9ea31725e0202dfe6aede430c505bded","text":"Establish a Direct Connect circuit to the freight company","correct":false}]},{"id":"c2e05533-6321-46fa-a778-47c27ca274d5","domain":"CostOptimized","question":"Your co-worker is about to create a new EC2 instance, and would like to know from what point your company will be billed for it. You tell them that it will be billed from: ","explanation":"In EC2, Instance-hours are  billed only for time your instance is in the \"Running\" state.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-instance-hour-billing/","title":"Instance-Hour Billing"}],"answers":[{"id":"61b5406c1efb94f47d6a875a56ac05c4","text":"When it is in the \"Stopped\" state","correct":false},{"id":"c40f2931153694959f22d5efc95b2a45","text":"When it is in the \"Running\" state","correct":true},{"id":"92f171915935cf43d7367038a0ceb076","text":"When it is in the \"Pending\" state","correct":false},{"id":"6672e2e78662b895923af9d5f73207be","text":"When it is in the \"Provisioned\" state","correct":false}]},{"id":"389f02f0-27ea-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"Which of the following layers of DDoS attacks does AWS automatically address?","explanation":"AWS automatically addresses DDoS attacks at the network and transport layers, which are Layer 3 and Layer 4, respectively.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-responding.html","title":"Responding to DDoS Attacks"}],"answers":[{"id":"73d19b475178ae97c94ed26431e3b138","text":"Layer 4","correct":true},{"id":"5ab5764b458bd4674dffe82c5f1cda53","text":"Layer 1","correct":false},{"id":"537c230a6d35c80a253f85b1c6d607c4","text":"Layer 7","correct":false},{"id":"9041d5d59c0e46d987baf883fd77e227","text":"Layer 3","correct":true}]},{"id":"c063bb9e-6292-467f-9726-ead44957e35a","domain":"SecureSolutions","question":"Which of the following are TRUE statements when considering VPC Peering?","explanation":"IP addresses in peered VPCs cannot overlap as this would cause many issues due to potential duplicates and routing confusion. Transitive peering, where traffic passes through one VPC on its way to a destination VPC is also not supported","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/peering/invalid-peering-configurations.html","title":"Unsupported VPC Configurations"}],"answers":[{"id":"42779f097f29607628d638c524ab4a9c","text":"If VPC A is peered to VPC B, and VPC B is peered to VPC C, VPC A will be able to communicate to VPC C through VPC B","correct":false},{"id":"78bb04119aded58be7b23a20cca7729a","text":"IP Addresses in peered VPCs cannot overlap","correct":true},{"id":"9beb5c6a9d1d0b9ec70c42ffeca8f408","text":"If VPC A is peered to VPC B, and VPC B is peered to VPC C, VPC A will NOT be able to communicate to VPC C through VPC B","correct":true},{"id":"10153b49aa50a996d1310d257211490a","text":"IP Addresses in peered VPCs can overlap with a NAT Instance used in the middle","correct":false}]},{"id":"04a5e1e1-9fc6-4371-a53c-cecc6fad3b2a","domain":"ResilientDesign","question":"Elasticity is a fundamental property of the cloud. Which of the following best describes elasticity?","explanation":"In cloud computing, elasticity is defined as 'the degree to which a system is able to adapt to workload changes by provisioning and de-provisioning resources in an autonomic manner, such that at each point in time the available resources match the current demand as closely as possible'.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html","title":"Scalable Computing Capacity"}],"answers":[{"id":"80b90762201e3ac35c7921416cc86c81","text":"The power to increase the number of resources at your hands at the click of a mouse.","correct":false},{"id":"71babaf2f5ed118cdbb0f5ff115354ce","text":"The ability to deploy managed services into your environment.","correct":false},{"id":"9b1cc2503b70776f795a2155b7f2e380","text":"The ability to manually deploy instances quickly in response to events.","correct":false},{"id":"2d60e660232553b4fb11100329fdb97e","text":"The power to scale resources both up and down with changes in demand.","correct":true}]},{"id":"18f5f9ac-72ae-44e6-a607-875acd4b7508","domain":"CostOptimized","question":"Your company is moving their entire 20 TB data warehouse to the cloud. With your current bandwidth, it would take 2 months to transfer the data. Which service would you use to quickly get your data into AWS?","explanation":"At that amount of data and those bandwidth restrictions, Snowball would be the most expedient choice.","links":[{"url":"https://aws.amazon.com/snowball/faqs/#when-to-use","title":"When to Use Snowball"}],"answers":[{"id":"25e163616bb5cc20c769ad3e8b7a0703","text":"Multipart Upload","correct":false},{"id":"a8e1dc43989241e706e31c52d23be15c","text":"S3 with Transfer Acceleration","correct":false},{"id":"c0429b6a658dd488f7262d983c7e02bb","text":"Snowball","correct":true},{"id":"cdd0d04de2b79c78e792aec6263d2d3d","text":"DirectConnect","correct":false}]},{"id":"b6275c5c-1ac1-4382-9ee0-540d5b7e499a","domain":"SecureSolutions","question":"A contract management application stores its content in Amazon Simple Storage Service. The documents are encrypted with AWS Key Management Service keys. A security engineer imports a new Customer Master Key, manually rotates the keys, and deletes the previous key. The IT service center begins to receive calls that those trying to retrieve older contracts are receiving 'data inaccessible' errors. What needs to be done to resolve the issue?","explanation":"KMS supports keeping older versions of imported keys available, but in this case, the security team neglected to do so. Unfortunately, the contract documents need to be re-encrypted. AWS does not offer a KMS Sync operation or a KMS Restore capability. KMS won't be able to tie a re-imported key back to the older documents.","links":[{"url":"https://aws.amazon.com/kms/","title":"AWS Key Management Service (KMS)"},{"url":"https://aws.amazon.com/kms/faqs/","title":"AWS Key Management Service FAQs"}],"answers":[{"id":"ebe28348d4f30f69bfa81ccded9bae95","text":"Re-encrypt the contract documents with the new Customer Master Key","correct":true},{"id":"ce9a8e2d9aba9a5b8e82432d3220852e","text":"Perform a KMS Restore to re-establish the relationship between older contract documents and the previous key","correct":false},{"id":"ab06ac4163b2759feeed0c0255c614fc","text":"Perform a KMS Sync operation to align all of the documents with the new Customer Master Key","correct":false},{"id":"cd5e0e6c549884e3e0c9aa1630412b3c","text":"Re-import the previous key into KMS and rotate the keys again","correct":false}]},{"id":"cdb5b6d9-37bb-41e5-bd69-985dabcc7bd0","domain":"SecureSolutions","question":"You are hosting a web application that runs on a number of Web Servers in public subnets and Database Servers in private subnets. A NAT Instance is being used for connectivity to the internet for the Private Subnets. The NAT Instance is now becoming a bottleneck, and you are looking to replace it with NAT Gateway. Which of the following would ensure high availability for the NAT Gateway?","explanation":"If you have resources in multiple Availability Zones and they share one NAT gateway, in the event that the NAT gateway’s Availability Zone is down, resources in the other Availability Zones lose internet access. To create an Availability Zone-independent architecture, create a NAT gateway in each Availability Zone and configure your routing to ensure that resources use the NAT gateway in the same Availability Zone.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","title":"NAT Gateways"}],"answers":[{"id":"18c2392152bcb34e4f0933dfcff0de2b","text":"Deploy a NAT Gateway in 2 Regions","correct":false},{"id":"5ae78abee9f8fe1afe2ab443a4480098","text":"Disable source/destination check on the NAT Instances","correct":false},{"id":"b0b35801e71ae33d446780112d8438dc","text":"Deploy a NAT Gateway in 2 Availability Zones","correct":true},{"id":"8956081d09cf7a5203cbb2fe0a9cbd9e","text":"Deploy a NAT Gateway along with the NAT Instance","correct":false}]},{"id":"22315d49-9040-4de7-ae4f-ead04e5b4966","domain":"CostOptimized","question":"An application that performs statistical analysis on weather data receives files once a week. It assimilates the data in these files with previously collected data via its algorithms, and publishes a report at the end of each month. At unspecified times during the week, interim results need to be made available to meteorologists within minutes. Which architecture will meet the data availability requirements for the solution at the least cost, and with the simplest application code?","explanation":"Hibernating an EC2 instance provides a warm-start capability. When an EC2 instance is hibernated, RAM contents are saved to the EBS root volume. RAM contents are reloaded when the instance is restarted. AWS doesn't charge for the time that an instance is in the hibernated state. Storing data in Amazon DynamoDB costs more than EBS. EMR clusters cost more than EC2 instances. Stopping an EC2 instance clears RAM and requires the application to reload the data from a storage source when the instance is restarted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html","title":"Hibernate Your Instance"}],"answers":[{"id":"e45f5352867fe69bdbc5efaad38e34b2","text":"Process the data on a transient EMR cluster and store temporary results in S3","correct":false},{"id":"1270950fb1ac5049d96bd1c8633745fe","text":"Process the data on EC2 and stop the instance until new data files arrive or an interim results request is made","correct":false},{"id":"79010e5d6c3a7a1b4739890ce79939bd","text":"Process the data on EC2 and store temporary results in Amazon DynamoDB","correct":false},{"id":"591c99dbc7dc2331d09abbc9ee1fb721","text":"Process the data on EC2 and hibernate the instance until new data files arrive or an interim results request is made","correct":true}]},{"id":"e33d4c87-1230-4f2b-88b2-effd138ff06a","domain":"ResilientDesign","question":"Your legal company is moving its production estate to AWS. They currently have a private cloud platform with VMDK files as their virtual machines. You need to move these files to AWS and create EC2 instances using the VMDK files. Which AWS service would help you achieve this goal?","explanation":"","links":[{"url":"https://docs.aws.amazon.com/vm-import/latest/userguide/what-is-vmimport.html","title":"VM Import/Export"}],"answers":[{"id":"87703e16953f8b2edf255258a29aa823","text":"Data Pipeline","correct":false},{"id":"06a107211eb5871f858a954edc47c1eb","text":"VM Migrate","correct":false},{"id":"7445033ef83270814e799cba3c9fb637","text":"CloudMigration","correct":false},{"id":"42966c9ba8482ffc6ec12178fc18895c","text":"VM Import/Export","correct":true}]},{"id":"f8d65d36-54ed-4e56-b834-28ce0b81d1dc","domain":"ResilientDesign","question":"Which of the following components are not part of Amazon ECS?","explanation":"Service Discovery makes it easy for containers within an ECS cluster to discover and connect with each other, using Route 53 endpoints. Task Definitions define the resource utilisation and configuration of tasks, using JSON templates. Task Scheduling allows you to run batch processing jobs run on a schedule.  File Storage is not a component of ECS.  Storage within ECS is handled by EBS volumes attached to the underlying EC2 instances and not by ECS itself.","links":[{"url":"https://aws.amazon.com/ecs/features/","title":"Amazon Elastic Container Service Features"}],"answers":[{"id":"bad3bdff2e2f94dfef18eaff5b083c20","text":"Task Definitions","correct":false},{"id":"b7b5c32036d1bb9dd91e97886fc1b1f3","text":"Task Scheduling","correct":false},{"id":"f95e8e0f0b7d916cc84d1098655eaa1e","text":"File Storage","correct":true},{"id":"24bbdaf375ddacbe3973587b50d98790","text":"Service Discovery","correct":false}]},{"id":"0e567584-0bb5-4dd8-afa7-6afa3281ade6","domain":"ResilientDesign","question":"You and your Developer team are building a web application for a real estate company that will include a field for conducting full-text keyword searches. Which of the following AWS services must you choose to provide this type of search experience?","explanation":"Elasticsearch Service is based on a full-text search engine. As a result, developers can use the service to help potential buyers find their desired homes, price ranges, and neighborhood locations with the real estate web application. EBS and EFS are storage tools, and ElastiCache is an in-memory cache service.","links":[{"url":"https://aws.amazon.com/elasticsearch-service/","title":"Amazon Elasticsearch Service"}],"answers":[{"id":"9155453f43b8a6472df0b8ffa5b5a028","text":"Amazon Elastic Block Storage (EBS)","correct":false},{"id":"d2a6652ddeb631da029d1f2806e11fdc","text":"Amazon Elastic File System (EFS)","correct":false},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false},{"id":"9bd4d2488a57ffddd2506feb893c6ca5","text":"Amazon Elasticsearch Service","correct":true}]},{"id":"536131e1-bbd8-4ef5-b765-4bd089487b28","domain":"Performant","question":"Your on-premise servers are running low on disk storage space, but your company is not yet ready for a complete move to the public cloud. You've been tasked with finding an interim storage solution that also offers backup and archiving capabilities. Which AWS service would you recommend to meet this immediate need?","explanation":"Storage Gateway is a storage solution that provides on-premise capacity while taking advantage of some of the benefits of Cloud Storage.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/StorageGatewayConcepts.html#storage-gateway-cached-concepts","title":"Gateway-Cached Volumes Architecture"}],"answers":[{"id":"04567b32a7bb8490dda99a0fe4c3323a","text":"Storage Gateway with Gateway-Cached Volumes","correct":true},{"id":"759533f205f8af35f7da47dc76331eee","text":"Storage Gateway with Gateway-Stored Volumes.","correct":false},{"id":"cdd0d04de2b79c78e792aec6263d2d3d","text":"DirectConnect","correct":false},{"id":"c0429b6a658dd488f7262d983c7e02bb","text":"Snowball","correct":false}]},{"id":"6686ab14-14fd-11ea-8d71-362b9e155667","domain":"ResilientDesign","question":"You want a storage solution to store all e-commerce sales numbers processed on a daily basis. Notably, this solution must be designed in a way that protects against accidental deletion of data. Which of the following actions will satisfy your requirements?","explanation":"Enabling versioning will mean that if someone accidentally deletes an object, S3 would insert a delete marker to make that the current object version. In addition, you can always restore the previous object version if needed. Although storing data in three S3 buckets gives you an extra layer of protection, users can still delete the objects in both buckets. With a new EBS snapshot, the changes made since the last one are lost. And Redshift is the least likely response, since it is used for data warehousing rather than simple straightforward storage.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"Using Versioning"}],"answers":[{"id":"a402eb2caf5dae12b4abc6d85c669024","text":"Store the sales numbers in an S3 bucket and enable versioning.","correct":true},{"id":"2a3b97d09893c4810970c8557d4e9933","text":"Store the sales numbers in an EBS volume and create snapshots at the end of each day.","correct":false},{"id":"be181d98494c2caf02d54e25874885ac","text":"Store the sales numbers in a Redshift cluster.","correct":false},{"id":"7b87e237a929b789241cfd271cfbf5eb","text":"Store the sales numbers in three S3 buckets and in different AWS Regions.","correct":false}]},{"id":"58af5529-d965-4ab9-ae2f-a906c0b8c41e","domain":"Performant","question":"You've enabled website hosting on a bucket called 'aspiring-guru' in the us-west-2 Region. Which of the following is the URL that will be assigned to your website?","explanation":"Your bucket name *always* comes first. 's3-website', followed by the Region, *always* comes next.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Website Hosting"}],"answers":[{"id":"eff2fbc9e562b82d9381082df00c92d6","text":"s3-website.aspiring-guru-us-west-2.amazonaws.com","correct":false},{"id":"b7ac852a2cf809dc4fb801df9b658c8a","text":"aspiring-guru.s3-website-us-west-2.amazonaws.com","correct":true},{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"09cbf53f89e143efb0fb279e5d14b9e8","text":"s3-website-us-west-2.aspiring-guru.amazonaws.com","correct":false}]},{"id":"fb005f63-f7ec-4219-a509-0be9a1c6177a","domain":"ResilientDesign","question":"You are migrating a production website to AWS. The site will be using EC2, Application Load Balancers and RDS Multi-AZ across 3 AZs. You need a minimum of 6 EC2 instances at any given time and your site must be able to tolerate the loss of 1 Availability Zone. What is the most cost effective way of meeting these requirements?","explanation":"S3 Sta xxxxxxxxxxxxx.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html","title":"Benefits of Auto Scaling"},{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html","title":"Autoscaling with Multi-AZ ELB"}],"answers":[{"id":"23c83f5eec11b24316a37be4ab4fcd44","text":"3 instances in 2 Availability Zones each.","correct":false},{"id":"90b873045418d59670454ca34ccb08c6","text":"6 instances in 3 Availability Zones each.","correct":false},{"id":"59e343895f33803418aeb6c89a533c09","text":"2 instances in 2 Availability Zones each.","correct":false},{"id":"2cdc460773914fca2de6ff43f23e52f7","text":"3 instances in 3 Availability Zones each.","correct":true}]},{"id":"263940e4-1502-11ea-8d71-362b9e155667","domain":"Performant","question":"You work for a digital media company and have been tasked with designing a solution for storing all CloudWatch logs. Which of the following solutions would you recommended when applying best practices?","explanation":"CloudWatch log data consists of files, which means that S3 is the most suitable storage service for this application. RDS, on the other hand, is a database service; and Amazon Elasticsearch Service is used for streaming CloudWatch log data instead of storing it. Although you can use an existing bucket to export the log data to S3, it is an AWS best practice to create a dedicated S3 bucket specifically for storing your CloudWatch Logs.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/S3ExportTasksConsole.html","title":"Export Log Data to Amazon S3 Using the Console"}],"answers":[{"id":"818a59284d05a35c0f93dcef80e55fe1","text":"Store CloudWatch log data in an RDS instance.","correct":false},{"id":"f4b568c1cb1ddb17fdb76089fa04ad8d","text":"Use Elasticsearch Service for the CloudWatch log data.","correct":false},{"id":"fb77a37699b9da358561f0841ee07b2d","text":"Use an existing bucket to export the CloudWatch log data to S3.","correct":false},{"id":"ca8178d77067bfd4c1e2feeb95937a6e","text":"Create an S3 bucket specifically for exporting the CloudWatch log data.","correct":true}]},{"id":"04904bc2-f76b-4c53-aa26-ecf42d9413ec","domain":"Performant","question":"You create a standard SQS queue and test it by creating a simple application that polls the queue for messages. After a message is retrieved, the application should delete it. You create three test messages in your SQS queue and discover that messages 1 and 3 are quickly deleted, but message 2 has remained in the queue. Which of the following could account for your findings?","explanation":"With short-polling, multiple polls of the queue may be necessary to find all messages on the various nodes in the queue. The queue not being FIFO may impact the order, but not the eventual successful processing. SQS has options to control access to create messages and retrieve them.  However these are not per-message controls. That just leaves the possibility that it is a malformed message","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-long-polling.html","title":"SQS Long Polling"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-authentication-and-access-control.html","title":"SQS permissions"}],"answers":[{"id":"f965f764803db0611837bc3498e1d2a6","text":"Standard SQS queues cannot guarantee that messages are retrieved in first-in, first-out (FIFO) order.","correct":false},{"id":"b94d1535142908b5e85cceca7b83776d","text":"Message 2 is invalid.","correct":true},{"id":"bd3c9bf63a62235371cb07750f2101a3","text":"Your application uses short-polling.","correct":true},{"id":"a347780de92164dde42dbc8a9b2420a1","text":"The permissions on message 2 were incorrectly written.","correct":false}]},{"id":"76529c49-69f6-4680-bb7b-596b41bf7296","domain":"ResilientDesign","question":"A Multi-AZ RDS deployment will automatically fail-over as a result of which two of the following?","explanation":"Amazon RDS detects and automatically recovers from the most common failure scenarios for Multi-AZ deployments so that you can resume database operations as quickly as possible without administrative intervention. Amazon RDS automatically performs a failover in the event of any of the following: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, Storage failure on primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"Failover Process for Amazon RDS"}],"answers":[{"id":"215b7e6d7f48e4225c06a3c50bf400d2","text":"Loss of availability in primary Availability Zone","correct":true},{"id":"8851c500044adfe0ba4a247acdb86eda","text":"Loss of network connectivity to the Primary","correct":true},{"id":"7b75b57dbe879950151e7a40cf0aed41","text":"A region-wide loss of service","correct":false},{"id":"7ecc550bc4f7f4c4d01c334d359bb0d9","text":"Loss of availability in standby Availability Zone","correct":false}]},{"id":"8db02025-839b-4cba-9396-3bf3d30f5c41","domain":"ResilientDesign","question":"You are a system administrator and you need to take a consistent snapshot of your EC2 instance. Your application holds large amounts of data in cache that is not written to disk automatically. What would be the best approach to taking an application consistent snapshot?","explanation":"As you need an application consistent snapshot, your best option would be to shutdown the EC2 instance and detach the EBS volume, then take the snapshot.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html","title":"Creating an EBS Snapshot"}],"answers":[{"id":"0ca1045c8304935b9a8a2966f9558b13","text":"Shut down the EC2 instance and detach the EBS volume, then take the snapshot.","correct":true},{"id":"f9074c78a685a4482c46191309041432","text":"Take a snapshot using the AWS CLI.","correct":false},{"id":"35151eb8d8b2db302878d62b44030835","text":"In the AWS console, take a snapshot and ensure that the 'application consistent' check box is ticked.","correct":false},{"id":"8f8e16b428381fb3d36f848931c82fb2","text":"Take a snapshot in real time using the EC2 API.","correct":false}]},{"id":"2a2db64e-2e02-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You wish to set up a WordPress website consisting of 4 webpages for your client, who recently founded a logo creation business. Based on the client’s specifications, you will create one webpage that gives a summary of the company and its services, a second one that provides a brief professional biography of the founder, a third one that showcases the business owner’s portfolio, and a fourth one that serves as the contact information page and simply contains an email and phone number. Three of the four webpages will include images which the client doesn’t expect will change much, if at all. Using the EC2 service to set up the website, which of the following instance types would be the most cost-effective choice?","explanation":"Based on the client’s specifications, it doesn’t seem like this website requires an elevated level of compute, memory, storage, or networking power. So, a general purpose instance would be the most cost-effective choice.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types"}],"answers":[{"id":"a97bdc2a34beb1500a16c5a5f41d3234","text":"Memory optimized","correct":false},{"id":"b4820282379b9534539d339e1d898f2b","text":"Storage optimized","correct":false},{"id":"e65781ecdb4e2c3e7af2864d7b875e57","text":"Accelerated computing","correct":false},{"id":"3da02f3f7a678b5e2c167fb35dcea8f5","text":"General purpose","correct":true},{"id":"4e8e31d149d66214d0c06fd9ee8b877b","text":"Compute optimized","correct":false}]},{"id":"bee3fc3a-4738-4c3f-b6ad-e6f25e600772","domain":"Performant","question":"Which of the following are types of virtualization available on AWS?","explanation":"The two different types of virtualization available are Hardware Virtual Machine (HVM) & Paravirtual Machine (PVM)","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#instance-virtualization-type","title":"EC2 Virtualization Types"}],"answers":[{"id":"fc9184bf07a56c1342576d092d7cdf15","text":"Physical Virtual Machine (PVM)","correct":false},{"id":"5136698bc5a65f152fe16da0719dd612","text":"Paravirtual Machine (PV)","correct":true},{"id":"e526c533a9df6aff264b1313a0908f9d","text":"Cloud Virtual Machine (CVM)","correct":false},{"id":"4b796a884a8b85e9857127deafecc5e7","text":"Hardware Virtual Machine (HVM)","correct":true}]},{"id":"4eb40e8a-8251-44ca-a55f-7a2d2e39a78c","domain":"CostOptimized","question":"A large company is running multiple Amazon EC2 and Amazon RDS services across several AWS Regions. You are an AWS consultant and the company approaches you to provide recommendations on how to reduce operational cost without any major changes. The company confirms that certain instances are required to be run only during business hours from 8AM to 6PM on weekdays and can be shutdown on weekends and non-business hours. Which of the following automated solutions best matches the requirements?","explanation":"AWS offers infrastructure on demand so that customers can control their resource capacity and pay only for what they consume. One simple method to reduce costs is to stop resources that are not in use, and then start those resources again when their capacity is needed. The AWS Instance Scheduler is a simple AWS-provided solution that enables customers to easily configure custom start and stop schedules for their Amazon EC2 and Amazon RDS instances. The solution is easy to deploy and can help reduce operational costs for both development and production environments. Customers who use this solution to run instances during regular business hours can save up to 70% compared to running those instances 24 hours a day. AWS Auto Scaling is not a correct solution as auto-scaling groups can contain Amazon EC2 instances from multiple Availability Zones within the same Region and cannot contain instances from multiple regions. As the company confirms that the instances are required to be run during Business hours, Spot Instance is not a good choice as spot instances may be terminated if the spot price is higher than the bid price. Also, moving AWS Instances to lesser configurations is neither an automated solution nor guarantees saving operational cost if run 24 hours.","links":[{"url":"https://docs.aws.amazon.com/solutions/latest/instance-scheduler/overview.html","title":"AWS Instance Scheduler"}],"answers":[{"id":"c9eccc5399c22049703ce9be447d23d7","text":"AWS Instance Scheduler","correct":true},{"id":"f657bd5509ffc79a6cb033747ff52f50","text":"Move AWS instances to lesser configuration Instance Type","correct":false},{"id":"f4bf61a51bd424cab4d9129fd4f2ef6a","text":"Move Instances to Spot Instances","correct":false},{"id":"2f766b7c3ac605171e839f447d7e239c","text":"AWS Auto Scaling","correct":false}]},{"id":"1b1cfffe-896f-420c-b64e-8eee23af9a3e","domain":"ResilientDesign","question":"You work at a large financial institution.  You have many files that need to be stored for 7 years or more for regulatory purposes. These files need to be stored at the lowest cost possible. It is acceptable to wait for files to become available. Which of the following S3 Storage Tiers is best suited for this request?","explanation":"S3 Glacier Deep Archive is Amazon S3’s lowest-cost storage class and supports long-term retention and digital preservation for data that won’t be regularly accessed. It is designed for customers — particularly those in highly-regulated industries, such as the Financial Services, Healthcare, and Public Sectors — that retain data sets for 7-10 years or longer to meet regulatory compliance requirements. S3 Glacier Deep Archive can also be used for backup and disaster recovery use cases, and is a cost-effective and easy-to-manage alternative to magnetic tape systems, whether they are on-premises libraries or off-premises services. S3 Glacier Deep Archive complements Amazon S3 Glacier, which is ideal for more active archives where data is regularly retrieved and needed in minutes. All objects stored in S3 Glacier Deep Archive are replicated and stored across at least three geographically-dispersed Availability Zones, protected by 99.999999999% of durability, and can be restored within 12 hours.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#____","title":"Amazon S3 Storage Classes - Glacier Deep Archive"}],"answers":[{"id":"a4172aee8a692bd73f2781afe65fda72","text":"S3 Infrequently Accessed","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"a5f6e1bef7eaef71d9ea6446f8c21a2e","text":"S3 Glacier Deep Archive","correct":true},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false}]},{"id":"d5e8caaa-e2d5-4d00-b9bc-53efee2b366f","domain":"Performant","question":"You have a production work load on AWS consisting of a Web Tier, Application Tier and Database Tier. Your web application starts to slow down under heavy use and can even become unresponsive. You investigate the issue and discover the issues are with the PostgreSQL RDS. What two steps could you do to improve performance?","explanation":"This is a classic scale-up or scale-out question. upgrading the disk is a scale-up solution, and adding read-replicas is a scale-out solution. Multi-AZ is possible, but will not help with performance, only resiliency.  RDS autoscaling is available only with Aurora","links":[{"url":"https://aws.amazon.com/blogs/database/scaling-your-amazon-rds-instance-vertically-and-horizontally/","title":"Scaling Your Amazon RDS Instance Vertically and Horizontally"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html","title":"Aurora Auto Scaling"}],"answers":[{"id":"ad6b88231cab9ea7642a5c16ce20722e","text":"Upgrade the storage type from General Purpose SSD to Provisioned IOPS SSD.","correct":true},{"id":"bd7d139b54a720f913080f4bec971220","text":"Provision 3 Read Replicas and direct all read traffic to these new instances.","correct":true},{"id":"4b8062204769a36aff6ebc2fb3ffb313","text":" Turn on RDS Autoscaling and scale when CPU Utilization reaches 90% for 5 minutes.","correct":false},{"id":"eda178658eacb51c3dcfd2f1f9e2c4c5","text":"Add multi-AZ to the RDS cluster and direct all read traffic to the secondary instance.","correct":false}]},{"id":"b174893b-d033-43b8-9070-8de922c52c68","domain":"ResilientDesign","question":"The media company Starbright Entertainment owns the domain name starbright.net. They want to provide an online customer portal which will be addressed via the starbright.net domain. They create an ELB Classic Load Balancer in front of the portal’s web servers which gets assigned the host name clb1-1234.us-west-2.elb.amazonaws.com. Which type of Route 53 hosted zone record will they use to point to the load balancer?","explanation":"An Amazon Route 53 Alias Record is an extension to DNS functionality. It provides the ability to map a domain name to select AWS services, including ELB load balancers. DNS PTR records are used for reverse DNS lookups. CNAME records map aliases to true or other canonical names, but a Route 53 Alias record is better for this use case because it will point to the load balancer even if its IP address changes. An SRV record is used for specifying data in a DNS system.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html","title":"Choosing Between Alias and Non-Alias Records"}],"answers":[{"id":"5c2c9d6d43404c842112e5d131dcdd2a","text":"Pointer Record (PTR)","correct":false},{"id":"fec87765574d413df958ab0919c376ba","text":"Service Locator (SRV)","correct":false},{"id":"d18b59d66f501e7b1a56ed4d0386307b","text":"Alias Record (Alias)","correct":true},{"id":"8eb8a20a36bde09550dd95d5e9c75da2","text":"Canonical Name Record (CNAME)","correct":false}]},{"id":"bccba3fe-36b1-4122-a4d9-dbdaced2250a","domain":"Performant","question":"Your supervisor wants you to specifically record the configuration changes of all the EC2 instances in the environment. Which of the following AWS services will do that?","explanation":"It can be easy to confuse Config and CloudTrail, since both are AWS management-and-governance tools. However, they operate differently. While CloudTrail provides event history of your AWS account activity, Config specifically focuses on listing the resources in your AWS account and presenting their configuration change history.","links":[{"url":"https://aws.amazon.com/config/","title":"AWS Config"}],"answers":[{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"621f4719cc9f27432c4c095f76df474e","text":"Amazon GuardDuty","correct":false},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":false},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":false}]},{"id":"3f2e5bb1-a59e-43b6-b8ae-e259613ea7f0","domain":"Performant","question":"You have an application that allows people in very remote locations to store their files safely and securely. You need to leverage CloudFront's globally distributed Edge Locations, so that as data arrives at an Edge Location the data is routed to your Amazon S3 bucket over an optimized network path. Which of the following services should you use?","explanation":"Amazon S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and your Amazon S3 bucket. Transfer Acceleration leverages Amazon CloudFront's globally distributed AWS Edge Locations.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html","title":"S3 Transfer Acceleration"}],"answers":[{"id":"1ac055ca7e4a6e0dbbf0b1e7a224ea1f","text":"S3 Multipart Upload","correct":false},{"id":"ac27af728db591b665d751dc0178ad25","text":"S3 Transfer Acceleration","correct":true},{"id":"00a7fea0b5c382041a8f16e4f30edd83","text":"CloudFront Multipart Upload","correct":false},{"id":"89dba4392223291ad101e5636df095ea","text":"CloudFront Transfer Acceleration","correct":false}]},{"id":"067a4664-2e5b-11ea-978f-2e728ce88125","domain":"Performant","question":"As a Solutions Architect employed at a niche clothing and accessories company, you are assigned the task of figuring out how to record requests made to S3 buckets that contain the images. The Director of Marketing Strategy needs that information to help her understand the company’s customer base and help her shape her marketing strategy in the coming months. Which of the following features should be enabled to record this information?","explanation":"Server access logging is what you should enable to record and get information on the requests made to the company’s S3 buckets. You choose object-level logging for recording object-level API activity using AWS CloudTrail, which comes with a cost. Enabling versioning would keep all versions of an object in the same bucket, and tags are for tracking project costs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html","title":"Amazon S3 Server Access Logging"}],"answers":[{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false},{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":false},{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":true},{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":false}]},{"id":"1ea8aa1e-9454-49b0-b4e2-379eadf674e0","domain":"CostOptimized","question":"You are an employee at a communications firm that is in the process of migrating its data to Amazon S3. The data will be stored in buckets and is sent to customers to do as they see fit. However, certain data is frequently changed when customers request revisions, while the rest of the data is rarely changed. You must be able to immediately access certain data while minimizing costs. Which S3 storage class should you choose?","explanation":"While S3 Glacier is a low-cost storage class, it is for data archiving and thus not ideal for frequent access or changes to data. And S3 One Zone-Infrequent Access is also low-cost, but it does not address the frequently changed data. Although S3 Standard is a suitable choice, since it addresses frequent access, it is not the least expensive choice for the less frequently accessed data. If it was hard to determine which data is frequently changed and which isn’t, S3 Standard might have been the most cost-effective choice. But in this case, S3 Intelligent Tiering is. Intelligent Tiering stores data in two access tiers: one tier is optimized for frequently accessed data while the other is a lower-cost tier for infrequent access.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"5605213ade8877d8d601580dbd0a8aa2","text":"S3 One Zone-Infrequent Access","correct":false},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":true}]},{"id":"6ff5a65b-eaf6-440a-b652-a87cda695ee7","domain":"ResilientDesign","question":"Which of the following is NOT a valid EC2 instance type?","explanation":"D2, C4, M3 are all valid EC2 instances.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types - Overview"}],"answers":[{"id":"c4d62b6dcca08e5caf06c01889282859","text":"D2","correct":false},{"id":"b713e6323a68d3ddabf4855826c50148","text":"C4","correct":false},{"id":"f1c6eb6f4e48eb34ab40b2987d4976a8","text":"M3","correct":false},{"id":"10cabbedf836057c57d03730b32c6fa5","text":"Z2","correct":true}]},{"id":"e9ed5908-d661-4e8d-90ce-f30b7ccf52b4","domain":"SecureSolutions","question":"To enable your Lambda function to access resources inside your private VPC, you must provide additional VPC-specific configuration information. Select all correct statements about that.","explanation":"AWS Lambda does not support connecting to resources within Dedicated Tenancy VPCs. If your Lambda function requires Internet access, you cannot use an Internet gateway attached to your VPC since that requires the ENI to have public IP addresses.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/vpc.html","title":"Configuring a Lambda Function to Access Resources in an Amazon VPC"}],"answers":[{"id":"1f1b5cfe4913b1180428fa247ff5fabe","text":"AWS Lambda uses the provided VPC-specific configuration information to set up elastic network interfaces. Therefore, your Lambda function execution role must have permissions to create, describe and delete these.","correct":true},{"id":"be0a713a2ad51fc0b1bcaf1fe7598864","text":"AWS Lambda does also support connecting to resources within Dedicated Tenancy VPCs.","correct":false},{"id":"09487d067c224691d77b18e71cb59b00","text":"When you add VPC configuration to a Lambda function, it can only access resources in that VPC. However, you can specify multiple VPC using the VpcConfig parameter. Simply comma separate the VPC subnet and security group IDs","correct":true},{"id":"254b36e0842eed2ecae11451f2f2e9a3","text":"If your Lambda function needs to access both VPC resources and the public Internet, the VPC needs to have a NAT instance inside your VPC, you can use the Amazon VPC NAT gateway or you can use an Internet gateway attached to your VPC.","correct":false}]},{"id":"99b3a227-a362-456e-8474-dba3e0b3f6ff","domain":"Performant","question":"You are developing a video conferencing service that translates spoken language to sign language in near real time using AWS Lambda. One of your functions does the heavy video/audio lifting by using common utilities including FFmpeg, Sound eXchange (SoX) and ImageMagick - each provided as a separate layer. Your function is also connected to nltk, the Python Natural Language Toolkit library and your own custom archive with some shared code - both provided as additional layers. You encounter a problem after you've updated your function's configuration to change to the latest version of your code. What are possible reasons for that and how can you resolve that issue?","explanation":"You can specify up to 5 layers in your function's configuration, during or after function creation.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html","title":"AWS Lambda Layers"}],"answers":[{"id":"4a90d094e62078f6c53fa5c71052b723","text":"You reached the 50MB zipped deployment package size limit for direct uploads. Refactor your function and move some code into a new layer.","correct":false},{"id":"00133f9caaca04cea058c5ceb62d5a8a","text":"You have gone over the 250MB unzipped deployment package size limit. Remove some unused libraries from your own archive.","correct":true},{"id":"14a4dc8ed5178c4185b29595e49de3df","text":"When you added the last layer to your function, the previous list was overwritten by the new one. Include all layers every time you update the layer configuration.","correct":true},{"id":"dbc5c5e38dfb1c3c8d8f6d0a1d1ca917","text":"Layers are extracted to the /opt directory in the function execution environment and applied in the order that's specified, merging any folders with the same name. If the same file appears in multiple layers, the version in the last applied layer is used. Rename the conflicting file in your archive.","correct":true}]},{"id":"09223b1a-2169-4791-94b1-9ecf1716c8eb","domain":"Performant","question":"Which of the following AWS services store data as key-value pairs?","explanation":"Both DynamoDB and S3 use key-value pairs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html","title":"Working With S3 Objects"},{"url":"https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs","title":"DynamoDB Data Models"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false}]},{"id":"8fb0e794-243d-11ea-978f-2e728ce88125","domain":"Performant","question":"You work as a Cloud Engineer for a healthcare company that would like to archive patients’ records after 30 days. In addition, the company wants the records to be accessible from the archive within 12 hours. Which of the following storage services will fulfill this company’s requirements?","explanation":"Although Response B would have been the correct answer, this question demands the answer to be more specific. S3 Glacier is the S3 storage class that you need to archive the records. Storage Gateway is for connecting an on-premises software appliance with cloud-based storage to the company’s AWS storage infrastructure, which can include S3. And Amazon EFS is ideal for providing simple, scalable file storage – not data archival.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"Amazon S3 Storage Classes"}],"answers":[{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":true},{"id":"df346128c45efa43efc29607224fc716","text":"Amazon Simple Storage Service (S3)","correct":false},{"id":"cb30b70cc5c8955781b75b49f1e20fe0","text":"Amazon Elastic File Service (EFS)","correct":false},{"id":"5ba49687f2f5ade4cd1c756a7e9024e3","text":"AWS Storage Gateway","correct":false}]}]}}}}
