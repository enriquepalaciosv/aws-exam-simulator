{"data":{"createNewExamAttempt":{"attempt":{"id":"a52ccda8-a2ff-451a-bd74-fe971cd5dfc3"},"exam":{"id":"798c908e-6037-4c13-be47-5ebf424dfe41","title":"AWS Certified Developer - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"1c37eac2-4401-11ea-b77f-2e728ce88125","domain":"security","question":"Which of the following protocols are used to set up secure connections to AWS CodeCommit repositories?","explanation":"AWS allows you to use either the HTTPS or the SSH protocol to connect to CodeCommit repositories. Thereâ€™s no option to select HTTP or RDP connections.","links":[{"url":"https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up.html","title":"Setting Up for AWS CodeCommit"}],"answers":[{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":true},{"id":"a66d0b3ece299ba53eafac86750cfb4a","text":"RDP","correct":false},{"id":"293c9ea246ff9985dc6f62a650f78986","text":"HTTP","correct":false},{"id":"765553e6c7ac8592c389acb9878a050a","text":"SSH","correct":true}]},{"id":"a2d52dd6-9826-449b-b96b-fc7f4edb46eb","domain":"development","question":"You need to announce emergency downtime for a production AWS web application. This downtime notification requires different sets of instructions for different devices. All of the application users signed up to receive SNS notifications from the downtime topic when they began using the application and they are currently subscribed to this topic. What are appropriate ways for you to provide timely, device-specific instructions to end users when announcing this downtime?","explanation":"Using the SNS JSON message generator, you can choose the appropriate endpoint types and edit the generated code to send different text to the different endpoint types.","links":[{"url":"https://docs.aws.amazon.com/sns/latest/dg/mobile-push-send-custommessage.html","title":"Platform-Specific Payloads in Messages to Mobile Devices"}],"answers":[{"id":"41ffaa9f13c5d08d4448e6f04dcc2fc6","text":"Create a different topic for each subscription type, then send one topic to SMS endpoints and the other topic to email endpoints.","correct":false},{"id":"a533b37c270c3d5b92e043a2fe21c3b3","text":"Send multiple messages to the topic and ask users to please ignore message formats that don't pertain to them.","correct":false},{"id":"20231f9d3f6d52b54459fecad9bf9b14","text":"Send a single message, but customize the text in the SNS message field so that each device gets only the information that is appropriate for them.","correct":true},{"id":"954d71e78bf180ff122f720542c09639","text":"It's not possible to send SNS messages manually.","correct":false}]},{"id":"1ff687ab-5cc2-477e-a5d6-2b7341f37562","domain":"refactoring","question":"You are developing a serverless application and you need somewhere to persist user state data. Which if the following would you recommend?","explanation":"Out of the possible answers, DynamoDB is the only solution that can be used to save state. Lambda by itself does not persist data, API gateway is used to expose APIs to make them available to your users and the Serverless Application Model (SAM) is a framework to build serverless applications.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"What is SAM?"},{"url":"https://aws.amazon.com/lambda/","title":"What is Lambda?"},{"url":"https://aws.amazon.com/api-gateway/","title":"What is API Gateway?"},{"url":"https://aws.amazon.com/serverless/","title":"Serverless"}],"answers":[{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"9c6ff7999454bedded4c4a17f7a61b99","text":"Serverless Application Model","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"2ef9dd82927a3196ca2df3fc0cdf2e0b","text":"API Gateway","correct":false}]},{"id":"0d9472d0-587b-4961-9457-e37e75979b7c","domain":"development","question":"You are working on a Serverless application written in Python and running in Lambda. You have uploaded multiple versions of your code to Lambda, but would like to make sure your test environment always utilizes the latest version. How can you configure this?","explanation":"When you create a Lambda function, there is only one version: $LATEST. You can refer to the function using its Amazon Resource Name (ARN). There are two ARNs associated with this initial version, the qualified ARN which is the function ARN plus a version suffix e.g. $LATEST. Or the unqualified ARN which is the function ARN without the version suffix. The function version for an unqualified function always maps to $LATEST, so you can access the latest version using either the qualified ARN with $LATEST, or the unqualified function ARN. Lambda also supports creating aliases for each of your Lambda function versions. An alias is a pointer to a specific Lambda function version, aliases will not be updated automatically when a new version of the function becomes available.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-intro.html","title":"Introduction To Lambda Function Versioning"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda Function Versioning and Aliases"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/how-to-manage-versioning.html","title":"Lambda Versioning"}],"answers":[{"id":"02f663ae252fea90c711171a5572d211","text":"Reference the function using a qualified ARN and the $LATEST suffix","correct":true},{"id":"0311fc386b14ce5afd0843ecf4a6ff16","text":"Create another function to automatically update your function alias to point to the latest version of the code every time it is updated","correct":false},{"id":"cc67dedc36d230ab3574dc07b41b7443","text":"Configure the alias to automatically update to point to the latest version of the code every time it is updated","correct":false},{"id":"d483464867986a2d830ac23858944891","text":"Create an alias to point to the correct version of your code","correct":false},{"id":"07c1095b47175c42406ba59e91205281","text":"Reference the function using an unqualified ARN","correct":true}]},{"id":"43f82a5f-84eb-4bda-9424-b03f27fa79ab","domain":"security","question":"What is the recommended approach to configuring a mobile application to allow users to sign-in and sign-up to your application via Facebook?","explanation":"Cognito is the preferred Web ID Federation mechanism in AWS","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc_cognito.html","title":"Cognito For Mobile Apps"}],"answers":[{"id":"a9d9e07070663e9217c3fcc296f07259","text":"Use Cognito as an Identity Broker between your application and the Web Identity Provider","correct":true},{"id":"09bea5739247e8d082cd79bd90905562","text":"Use encrypted AWS credentials within your application code and store them locally on the device","correct":false},{"id":"0aed15971d7cc88de6e66d66abc629f5","text":"Use IAM as an Identity Broker between your application and the Web Identity Provider","correct":false},{"id":"51e84803699eae0c33a7fd3c998881df","text":"Use a custom Lambda function to act as an Identity Broker between your application and the Web Identity Provider","correct":false}]},{"id":"45bb762d-32a6-4fc7-a9e3-1377f0161979","domain":"security","question":"Which of the following activities are the responsibility of the customer?","explanation":"Security and Compliance is a shared responsibility between AWS and the customer. The customer assumes responsibility and management of the guest operating system (including updates and security patches), other associated application software as well as the configuration of the AWS-provided security group firewall. AWS is responsible for protecting the infrastructure that runs all of the services offered in the AWS Cloud. This infrastructure is composed of the hardware, software, networking, and facilities that run AWS Cloud services.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"AWS Shared Responsibility Model"}],"answers":[{"id":"24950338a19d0ddaa9b785b69709702f","text":"Encryption of sensitive data","correct":true},{"id":"a505eb81276d69b88b77d5b605ad4a9a","text":"Safe disposal of storage devices","correct":false},{"id":"e64e7c083b43e01c37b09547a9d7fa31","text":"Management of user credentials","correct":true},{"id":"2b169fd2a3342cf14cd9fdfca94943c5","text":"Security Group configuration settings","correct":true},{"id":"a66d0f8d16b1d93bbe53e387d4b62b37","text":"Controls around who can physically access the data center","correct":false}]},{"id":"7bd7a103-821e-40af-9665-7695fac3de16","domain":"deployment","question":"AWS recommends that you use Multipart Upload for files larger than _____.","explanation":"","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html","title":"Uploading Objects Using Multipart Upload"}],"answers":[{"id":"84fb7b98e6e50302bf6cc709c92a6192","text":"5TB","correct":false},{"id":"0be25e5b91d25f9db3b4d3dcaf2cfd1f","text":"5GB","correct":false},{"id":"208b4367cf771ded0e29ff6f9282442e","text":"1GB","correct":false},{"id":"6df47862fbfbd67605dc294d3f41925a","text":"100MB","correct":true}]},{"id":"68ab8138-66fb-43fd-b5cc-c639875461b3","domain":"development","question":"You are developing an application in API Gateway, and need to categorize your APIs based on their status as: sandbox, test, or prod. You want to use a name-value pair system to label and manage your APIs. What feature of API Gateway would you use to accomplish this task?","explanation":"Stage variables are name-value pairs that you can define as configuration attributes associated with a deployment stage of a REST API. They act like environment variables and can be used in your API setup and mapping templates. With deployment stages in API Gateway, you can manage multiple release stages for each API, such as: alpha, beta, and production. Using stage variables you can configure an API deployment stage to interact with different backend endpoints. Environment variables apply to AWS Lambda. Canary release is a software development strategy in which a new version of an API (as well as other software) is deployed as a canary release for testing purposes, and the base version remains deployed as a production release for normal operations on the same stage. (This would be appropriate when your application is live and you'd want to reduce the risk inherent in a new software version release.) A tag is a metadata label that you assign or that AWS assigns to an AWS resource and would not impact the functionality of your APIs.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/stage-variables.html","title":"Set up Stage Variables for a REST API Deployment"}],"answers":[{"id":"728a86cd5cbdede9b11bece5753de3c0","text":"Use tags based on stages. The tag can be set directly on the stage of the API.","correct":false},{"id":"55420a5f29f3d3c0d5ebbdca81d18b74","text":"Use stage variables based on the API deployment stage to interact with different backend endpoints.","correct":true},{"id":"9c758b8244c31cda3eb63d52672989a0","text":"Use the API Gateway console to create a canary release deployment.","correct":false},{"id":"05e2467d5ea65bd259b0e9dd64cfe2f3","text":"Use environment variables based on the API deployment stage to interact with different backend endpoints.","correct":false}]},{"id":"3a01c37a-6939-444b-89b0-f73b1f232601","domain":"deployment","question":"You are developing a social media messaging and photo-sharing application which consists of a web front end, with persistent data stored in S3 and RDS. Which of the following instance pricing models should you choose to make running this application as cost-effective as possible?","explanation":"Reserved instances provide a significant discount compared to running instances On-Demand. You can take advantage of Spot Instances to run and scale applications such as stateless web services, image rendering, big data analytics, and massively parallel computations. Dedicated Instances are Amazon EC2 instances that run in a VPC on hardware that is dedicated to a single customer.","links":[{"url":"https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/when-to-use-spot-instances.html","title":"When To Use Spot Instances"},{"url":"https://aws.amazon.com/ec2/pricing/reserved-instances/","title":"When To Use Reserved Instances"},{"url":"https://aws.amazon.com/ec2/pricing/dedicated-instances/","title":"When To Use Dedicated Instances"},{"url":"https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/when-to-use-spot-instances.html","title":"Cost Optimization White Paper"}],"answers":[{"id":"86ed636cf8296c0bedacc99ec10c39f0","text":"Use dedicated instances for the database servers","correct":false},{"id":"7e5d7958c67ef51985894e5f8b2a25a8","text":"Use Spot instances for the database","correct":false},{"id":"1b65fa924bf38ff7e68d41f3495434bd","text":"Use reserved instances for the web servers","correct":false},{"id":"04be777131f511081730fe2b34662123","text":"Use dedicated instances for the web servers","correct":false},{"id":"a057af2fca16fcc4c6997976ea994e95","text":"Use Spot instances for the web servers","correct":true},{"id":"60e31915c1c4910787bf03781555aa97","text":"Use reserved instances for the database","correct":true}]},{"id":"91e59ee8-028b-44f1-9d03-1081d09738d3","domain":"development","question":"A clothing company needs to build a REST service to allow salespeople quick access to stock levels. The service must be accessible from an HTTP request. Which of the following solutions addresses the company's requirements?","explanation":"In an AWS Lambda integration in Amazon API Gateway, the HTTP method request from the client is mapped to a backend Lambda function invocation. Depending on your use case, you may choose to use Lambda proxy integration, Lambda non-proxy integration, or both in your API Gateway API. In a Lambda proxy integration, the entire client request is sent to the backend Lambda function as is, except that the order of the request parameters isn't preserved. In a Lambda non-proxy integration (also called a custom integration), you configure the way the parameters, headers, and body of the client's request are translated into the format that your backend Lambda function requires. ","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-getting-started-with-rest-apis.html","title":"Create a REST API with Lambda Integrations in Amazon API Gateway"}],"answers":[{"id":"e8445389785666bd90da881eada7e373","text":"Amazon CloudFront and Amazon S3","correct":false},{"id":"d87496b040e2581c8e89e43a7e5ed235","text":"Amazon SQS and DynamoDB","correct":false},{"id":"01f2c91643488c78436cc962fca2f2d7","text":"Amazon EC2 and AWS Auto Scaling","correct":false},{"id":"e9f6666f3057d0c266ac855cbae770b8","text":"Amazon API Gateway and AWS Lambda","correct":true}]},{"id":"daa8b2ee-b810-4e35-947d-9ad26196189d","domain":"mon-trb","question":"You can use X-Ray with applications running on which platforms? ","explanation":"X-Ray works with Lambda, EC2, API Gateway, Elastic Beanstalk and ECS","links":[{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"}],"answers":[{"id":"c8f63ecaff5e983a2441126a241c4cfa","text":"ECS","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true}]},{"id":"299fae20-4401-11ea-b77f-2e728ce88125","domain":"development","question":"You are about to work on a brand-new feature that you wish to propose for the upcoming second release of a job search engine application. However, you do not want to use the production-ready code. How will you keep your work separate from it?","explanation":"AWS CodeCommit is what you need for creating the code repository necessary for developing the application. To work on the appâ€™s new feature while keeping it separate from production-ready code, you must create a branch off of the default branch, which is the repository's base branch. You create a pull request if you want to review, comment on, and merge code changes from one branch to another. AWS CodeStar is for developing, building, and deploying applications so is not a suitable response. Creating a 'delineator' is not a valid answer; you canâ€™t create a delineator in the repo.","links":[{"url":"https://docs.aws.amazon.com/codecommit/latest/userguide/pull-requests.html","title":"Working with Pull Requests in AWS CodeCommit Repositories"}],"answers":[{"id":"168edbcd84078a04198e3014d9b51203","text":"Create a branch from your default branch in AWS CodeStar.","correct":false},{"id":"ae6130a05e4453a96fb07e1c7ee587ee","text":"Create a branch from your default branch in AWS CodeCommit.","correct":true},{"id":"adf09a361eb87ccc1da535b146808ec0","text":"Create a delineator between your code for the new feature and the production-ready code in AWS CodeCommit.","correct":false},{"id":"daafb08efeb8922237b6264c42e7de8f","text":"Create a pull request in AWS CodeCommit.","correct":false}]},{"id":"aef3c172-a47c-4705-8241-936c06d9bb7c","domain":"development","question":"You have configured your CI/CD process using CodePipeline, however you want to introduce a manual sign-off and approval process which needs to be completed before a new version of your application is deployed to Production. How can you achieve this?","explanation":"With CodePipeline, you can add an approval action to a stage in a pipeline at the point where you want the pipeline execution to stop so that someone with the required AWS Identity and Access Management permissions can approve or reject the action.","links":[{"url":"https://docs.aws.amazon.com/codepipeline/latest/userguide/approvals.html","title":"Manual Approvals in CodePipeline"}],"answers":[{"id":"fbfc1e99b3679cb29f80f55cf63c4a8d","text":"Use the CodePipeline Manual Approvals feature","correct":true},{"id":"e53c0ca92d915920a376534f6d7a4e99","text":"Configure MFA for CodeDeploy deployments","correct":false},{"id":"5c0749c1409b05011fac6531c17f2cf8","text":"Configure two pipelines, one to handle code build and test, and one to handle automated deployment. Use SNS and Lambda to trigger the Deployment Pipeline following notification of successful completion of the Build and Test Pipeline","correct":false},{"id":"dc965161695cb07b80f56150a5a689f1","text":"Use CodePipeline to handle build, compile, test and packaging activities, then manually start a CodeDeploy job to run an automated deployment of successfully tested code","correct":false}]},{"id":"60de4860-8791-4fd6-b3af-364209ceb5ab","domain":"mon-trb","question":"You are working on an application for an online training company which stores product data in DynamoDB. This week, the company is running a big promotion on a few courses and this is bringing lots of new traffic to your website, causing an increased number of queries to the database.  Database queries are now running much slower than usual and the Operations Team are concerned that the DynamoDB table is being throttled. Which of the following approaches would you recommend to improve read performance?","explanation":"Using DAX is the recommended approach to reducing response times for read-intensive applications, applications which read a small number of items frequently and also applications which perform repeated reads against a large set of data. Read Replicas are not a feature of DynamoDB. Configuring the application to use scans instead is not an efficient solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.html","title":"DynamoDB DAX"}],"answers":[{"id":"df31657d8e3247caf5b704d87a7fced3","text":"Redesign your table to use a more distinct partition key to enable the I/O load to be more evenly distributed across partitions","correct":false},{"id":"1fdd30d4d2259438830cf9536f3da218","text":"Configure a DAX cluster and point the DynamoDB API calls at the DAX cluster","correct":true},{"id":"c9e5713b3f811b188f8770ffd016beaf","text":"Configure the application to use scans rather than queries and run multiple scans in parallel","correct":false},{"id":"7d691dd8fcbce5a87b1211b09b47541a","text":"Add a Read Replica and point the DynamoDB API calls at the Read Replica","correct":false}]},{"id":"b53892aa-b2ee-477b-8134-59dc1ecdb6ae","domain":"mon-trb","question":"You are testing a new Serverless application which uses Lambda, S3, DynamoDB and API Gateway. You are suddenly seeing a large number of 4XX HTTP response codes coming from API Gateway. What could be the problem and what should you do about this?","explanation":"Client errors: Client errors are indicated by a 4xx HTTP response code. Client errors indicate that Amazon API Gateway found a problem with the client request, such as an authentication failure or missing required parameters. Fix the issue in the client application before submitting the request again. Server errors: Server errors are indicated by a 5xx HTTP response code, and need to be resolved by Amazon. You can resubmit/retry the request until it succeeds.","links":[{"url":"https://docs.aws.amazon.com/apigateway/api-reference/handling-errors/","title":"Handling Errors in Amazon API Gateway"},{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/supported-gateway-response-types.html","title":"API Gateway Response Codes"}],"answers":[{"id":"124f3974a500fed15e9abdf20ef3f21c","text":"This indicates an internal problem with your API Gateway instance. Provision a new API Gateway instance and try the request again","correct":false},{"id":"55cbbc610757f0c31c57e53cbcffd5e8","text":"This is a client error, you should fix the issue in your application and retry the request","correct":true},{"id":"f642a919ac2888a46eed52e71d2cfa5a","text":"This indicates an internal problem with your API. Fix the issue in your API and try the request again","correct":false},{"id":"0418207b636375af9298fb62ab2f3f3a","text":"This is an AWS error, you should wait for AWS to fix the issue and retry the request","correct":false}]},{"id":"b9cada23-dafc-48d0-8dba-cff32007e3b2","domain":"security","question":"You are developing a mobile web application using Lambda and API Gateway which stores persistent data in a DynamoDB table. You want to configure the application to allow new users to sign-up to your website using their Google mail credentials. Which is the best approach?","explanation":"Cognito is the recommended approach for user sign-up and sign-in for mobile applications which allow access to users with Facebook, Google or Amazon.com credentials. User pools are user directories that provide sign-up and sign-in options for your app users. Identity pools enable you to grant your users access to other AWS services.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/what-is-amazon-cognito.html","title":"What Is Cognito?"}],"answers":[{"id":"4e37a1d7f9c18456157c1080b7628ef8","text":"Write custom code to act as an identity broker to federate with Google","correct":false},{"id":"2f52b4f250a2df2a6b4cc5b1e4f2ded8","text":"Configure AD federation with Google as the relying party","correct":false},{"id":"3a5db953c143ae9ceb70cfeda3a7d477","text":"Configure a Cognito User Pool to handle new user sign-up","correct":true},{"id":"38ad8b2eb26395b051faf111282db4de","text":"Use a Cognito Identity Pool to handle new user sign-up","correct":false}]},{"id":"d36289fe-be3b-4a73-8cc2-c216cfd47b05","domain":"security","question":"You're part of a developer team which is building an application that requires access to S3. Everyone on your team requires the same IAM permissions. As your team grows, how would you manage IAM policies and access to the right AWS resources in the most efficient manner?","explanation":"IAM groups are collections of IAM users in one AWS account. You can create IAM groups on a functional, organizational, or geographic basis, or by project, or on any other basis where IAM users need to access similar AWS resources to do their jobs. You can provide each IAM group with permissions to access AWS resources by assigning one or more IAM policies. All policies assigned to an IAM group are inherited by the IAM users who are members of the group. Creating IAM Users for each team member is not the most efficient manner; IAM Groups is more efficient. You cannot log into the AWS Management Console using an IAM role, nor can you do the same with Amazon Cognito. Amazon Cognito is best suited for mobile applications.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"a834e2bd501ea84ca860e5213b4290ea","text":"Create one IAM role with the necessary permissions. Have all team members log into the AWS Management Console using that role. Rotate the password regularly.","correct":false},{"id":"9ef5172ef2f91f7f79640375254443b1","text":"Create an IAM Group called 'Developers'. Attach an IAM policy to the group with the appropriate permissions. Associate your IAM user and your team members' users to the Group. Add new team members to the group as appropriate.","correct":true},{"id":"7c9871a327396074304930d0dbe0fcee","text":"Create IAM Users for each team member. Attach an IAM policy to each user. Edit the IAM policy for each user adhering to the Principle of Least Privilege. Create new IAM policies for new team members as appropriate.","correct":false},{"id":"d81d323b3e2be35dfba6061c653ce5d1","text":"Create an Amazon Cognito user pool for each user and a corresponding S3 bucket. Grant S3 bucket GET requests for each bucket to each Cognito user. Require users to log into the Console using their Cognito credentials.","correct":false}]},{"id":"15a0fdc7-3a7a-42b2-a937-ccfda81d4261","domain":"mon-trb","question":"You have developed a CloudFormation stack in the AWS Management Console. You have a few small number of CloudFormation stacks saved in the Region in which you are operating in. When you launch your stack that contains many EC2 resources, you receive the error Status=start_failed. How would you troubleshoot this issue?","explanation":"Verify that you didn't reach a resource limit. For example, the default number Amazon EC2 instances that you can launch is 20. If you try to create more Amazon EC2 instances than your account limit, the instance creation fails and you receive the error Status=start_failed. Also, during an update, if a resource is replaced, AWS CloudFormation creates new resource before it deletes the old one. This replacement might put your account over the resource limit, which would cause your update to fail. You can delete excess resources or request a limit increase. Saving the template in the CLI or waiting a few minutes will have no impact. The default limit for CloudFormation stacks is 200 and the question explicitly states that there are only a very small number of existing stacks.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/troubleshooting.html","title":"Troubleshooting AWS CloudFormation"}],"answers":[{"id":"3e994bcee300070c97a3c141bc9967bd","text":"Use the Support Center in the AWS Management Console to request an increase in the number of EC2 instances.","correct":true},{"id":"57b1bceff40ae164e764946db0128ea0","text":"Save the template via the AWS CLI.","correct":false},{"id":"2e0c1157e1b5a9bc0a985d53a1a60aa6","text":"Wait a few minutes before saving the template and retry the process.","correct":false},{"id":"dae0c844938d270767115f5f50079227","text":"Use the Support Center in the AWS Management Console to request an increase in the number of CloudFormation stacks.","correct":false}]},{"id":"ba5e871c-930d-46d2-9eaf-32c2f6cb4de9","domain":"security","question":"You are developing a batch process job on Amazon EMR. The EMR instances need to access data stored in Amazon RDS in order to initialize the batch processing. The application code ran properly during testing but is not able to properly retrieve data from the RDS instance as there appears to be no connectivity. How would you remedy this situation in the most effective manner?","explanation":"For AWS Container services, customers are responsible for the data and for firewall rules for access to the container service. For example, Amazon RDS provides RDS security groups, and Amazon EMR allows customers to manage firewall rules through Amazon EC2 security groups for Amazon EMR instances. Editing the security group rules will solve the issue. Although AWS does manage the underlying RDS and EMR infrastructure, customers are responsible for the data and firewall rules for access to container services. Key pairs related to infrastructure services such as EC2 and is not relevant in this case. Migrating to EC2 would work but is unnecessary, more costly and require additional administrative overhead.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"2a0df43acefc1bd6e1699ab4687aba2b","text":"Edit the security group rules associated with the RDS and EMR instances to allow inbound/outbound access.","correct":true},{"id":"b8d421cecf4e1c5c38ce7a7a17bd7dbb","text":"Create a new key pair associated with the EMR instance. The current key pair is invalid.","correct":false},{"id":"4b17f971232d5dfe553d666c762dbac5","text":"This an AWS issue. AWS manages the underlying RDS and EMR infrastructure; they should be able to communicate with each other. Open a Support Case to resolve the issue.","correct":false},{"id":"d54de36cd37205ed20bf55d26d757f9e","text":"Migrate the application to run on Amazon EC2 instead. Create an auto-scaling group to scale the batch process when it exceeds a CPU threshold.","correct":false}]},{"id":"af4f8b9c-bfe1-44dd-803f-d12581a91f6d","domain":"development","question":"You are developing a scalable application which will run in Docker on ECS. You would like to be able to run multiple tasks on the same ECS service. How should you approach this?","explanation":"Port mappings allow containers to access ports on the host container instance to send or receive traffic. Port mappings are specified as part of the container definition. Dynamic port mapping with an Application Load Balancer makes it easier to run multiple tasks on the same Amazon ECS service on an Amazon ECS cluster.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/dynamic-port-mapping-ecs/","title":"Dynamic Port Mapping for Amazon ECS"},{"url":"https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PortMapping.html","title":"Port Mapping for Amazon ECS"},{"url":"https://aws.amazon.com/blogs/compute/microservice-delivery-with-amazon-ecs-and-application-load-balancers/","title":"Run Containerized Microservices with Amazon ECS and Application Load Balancer"}],"answers":[{"id":"e211f72442bce02b412217a3983c847f","text":"Dynamic Port Mapping","correct":true},{"id":"f4a166b164c896d2e4f9aa43541f5c30","text":"Dynamic Port Wrapping","correct":false},{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":false},{"id":"978e984e16276c17104b4c922731f3f8","text":"Virtual Port Mapping","correct":false}]},{"id":"427e94b9-4fba-461b-aea9-d1a0c40a150e","domain":"development","question":"A DynamoDB table is configured in provisioned throughput mode with 500 RCU and 100 WCU.  How much data can be read and written to the table each second?","explanation":"One read capacity unit is equivalent to one strongly consistent read per second, or two eventually consistent reads per second, for an item up to 4 KB in size. One write capacity unit is equivalent to one write per second for an item up to 1 KB in size.  Therefore, 500 RCU is equivalent to: 1) 500 RCU * 4KB = 2000 KB per second for strongly consistent read operations; 2) 500 RCU * 4KB = 2000 KB per second * 2 = 4000 KB per second for eventually consistent read operations; 3) 100 WCU * 1KB = 100 KB per second for write operations.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.ProvisionedThroughput.Manual","title":"Provisioned Mode"}],"answers":[{"id":"28e9c06ef3d9789d4e86426c1a59bbcf","text":"2000 KB for strongly consistent read operations, 4000 KB for eventually consistent read operations, 100 KB for write operations.","correct":true},{"id":"3d31cbf18bacabdeabf60932252ab4e0","text":"2000 KB for strongly consistent read operations, 4000 KB for eventually consistent read operations, 400 KB for write operations.","correct":false},{"id":"3e1674995e5d9212840ca5a62310ccf9","text":"500 KB for strongly consistent read operations, 1000 KB for eventually consistent read operations, 100 KB for write operations.","correct":false},{"id":"c233b8f618b2e1721b960acd0f8a9c81","text":"500 KB for strongly consistent read operations, 1000 KB for eventually consistent read operations, 400 KB for write operations.","correct":false}]},{"id":"418aa386-2a62-4e41-8724-c4d4adf6a318","domain":"refactoring","question":"You require a data storage solution for an application running on EC2. The data running on the application is not well-structured to fit into a defined schema. Even so, the schema would change very often as data is dependent on users. What choice of database solution would best support your application?","explanation":"Transactional data, such as e-commerce purchase transactions and financial transactions, are typically stored in relational database management systems (RDBMS) or SQL database systems. The choice of database solution depends on the use case and application characteristics. A NoSQL database is suitable when the data is not well-structured to fit into a defined schema, or when the schema changes very often. An RDBMS solution, on the other hand, is suitable when transactions happen across multiple table rows and the queries require complex joins. Amazon DynamoDB would be a better use case in this scenario versus Amazon RDS (which is a SQL-based, structured, relational database solution). AWS IoT can work with other AWS services like Lambda, Kinesis, S3, and DynamoDB to build applications that gather, process, analyze, and act on IoT data but is not a database solution. Amazon Kinesis is not a database solution, but rather a streaming data solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SQLtoNoSQL.html","title":"From SQL to NoSQL"}],"answers":[{"id":"6211995f3e47e0e7423efeb101148a29","text":"Use Amazon Kinesis services to be able to collect, store, and process your users' data continuously.","correct":false},{"id":"763409014035e2e7dad1fd45adc43794","text":"Use AWS IoT connected devices to interact easily and securely with AWS Lambda, Amazon Kinesis, and Amazon S3.","correct":false},{"id":"b1f7c088e6e85841d4830922aa622f9e","text":"Use a NoSQL database such as Amazon DynamoDB that can be used as an OLTP store for your application.","correct":true},{"id":"58e198b9da277384f8be4026cb2431e1","text":"Use an RDBMS solution such as Amazon RDS to implement a SQL-based relational database solution for your application.","correct":false}]},{"id":"71b8b773-eed1-4335-9631-5bfe132f16c7","domain":"development","question":"You are the development lead on a large project to launch a new e-commerce website specialising in fishing supplies. Your developers are located in India, USA and the Middle East. You need to find a source code repository that everyone can use, and that will allow developers to continue to work on their code even when they are not connected to the internet. Which of the following would you suggest to the team?","explanation":"CodeCommit is based on Git, which is a distributed version control system, meaning there is no single, central place where everything is stored. In a distributed system, there are multiple backups in the event that you need one. This approach also means that you can work offline and commit your changes when you are ready.","links":[{"url":"https://aws.amazon.com/devops/source-control/git/","title":"Source Control In AWS"}],"answers":[{"id":"94efdca7e5940d3078c950c64e833082","text":"Use CodeCommit to manage your source code","correct":true},{"id":"c2a2ffe5e9352016e58fe01b3c304de3","text":"Install Git on 2 EC2 instances in an auto-scaling group","correct":false},{"id":"c3a56d6c63ca88e19d3e6afc5b896c46","text":"Use CodeBuild in offline mode to manage your source code","correct":false},{"id":"4e1b47d595e44072d3890d332ead7f86","text":"Run an instance of Git in a docker container on AWS ECS","correct":false}]},{"id":"86c22858-5cf0-4a67-b1c5-54d1de3ca2da","domain":"refactoring","question":"You store a new object in Amazon S3 and receive a confirmation that it has been successfully stored. You then immediately make another API call attempting to read this object. Will you be able to read this object immediately?","explanation":"Amazon S3 buckets in all Regions provide read-after-write consistency for PUTS of new objects and eventual consistency for overwrite PUTS and DELETES.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel","title":"Amazon S3 Data Consistency Model"}],"answers":[{"id":"3ac4811c4441245d5a9b35dec13054fd","text":"It depends, because S3 objects are not available until they have replicated to another region. This replication can take up to several seconds.","correct":false},{"id":"8596049a57e596b85941153836ade663","text":"Yes, unless you exceed API call limits.","correct":false},{"id":"07fc991ba9f0a91e26627f8af0c332ac","text":"No. S3 imposes a one second delay on all reads.","correct":false},{"id":"9093951ee8a45059ab694f2f97f8d00a","text":"Yes. S3 has read-after-write consistency, which means you will have access to the object immediately.","correct":true}]},{"id":"e4d5998a-073a-4507-991c-ac138ac609c5","domain":"mon-trb","question":"Your application reads data from an SQS queue. The reads are then forwarded to Lambda downstream for processing critical customer information including purchasing and inventory data. It is critical that this data is not lost. How would you accommodate failed Lambda captures of the data?","explanation":"A dead letter queue would allow you to prevent data loss. After a message is taken from the queue and returned for the maximum number of retries, it is automatically sent to a dead letter queue, if one has been configured. It stays there until you retrieve it for forensic purposes. To prevent other consumers from processing the message again, Amazon SQS sets a visibility timeout, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. The default visibility timeout for a message is 30 seconds. DelaySeconds for individual messages are similar to visibility timeouts because both features make messages unavailable to consumers for a specific period of time. The difference between the two is that, for delay queues, a message is hidden when it is first added to queue, whereas for visibility timeouts a message is hidden only after it is consumed from the queue. A FIFO queue guarantees first-in-first-out.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html","title":"Amazon SQS Dead-Letter Queues"}],"answers":[{"id":"5d63d8895abd795fa4b98f12304185dc","text":"Create a dead letter queue and set the Maximum Receives to 3.","correct":true},{"id":"7e66715cc7d52627f1372ab97dbd2350","text":"Requeue the message with DelaySeconds to 3.","correct":false},{"id":"029cff5be66415e342452d104b4e2e57","text":"Requeue the message with a VisibilityTimeout of 30 seconds.","correct":false},{"id":"b431614eebc36d55520274500ed9ba2d","text":"Create a FIFO queue and set DelaySeconds to 3.","correct":false}]},{"id":"4102ce86-6e8c-47b2-86d4-86e3b8b08558","domain":"mon-trb","question":"Your application runs in an Auto Scaling group to scale based on user demand. The Auto Scaling group runs behind an Elastic Load Balancer (ELB). When you check the ELB logs, you notice that a number of instances are failing the health check during periods of high demand. New instances are launching but they periodically fail health checks and subsequent instances are being launched which is increasing costs. What would you do to troubleshoot this issue?","explanation":"Amazon EC2 Auto Scaling waits until the health check grace period ends before checking the health status of the instance. Amazon EC2 status checks and Elastic Load Balancing health checks can complete before the health check grace period expires. However, Amazon EC2 Auto Scaling does not act on them until the health check grace period expires. To provide ample warm-up time for your instances, ensure that the health check grace period covers the expected startup time for your application. In this scenario, the health checks are most likely occurring before the EC2 instance and its applications have fully loaded, so increasing the health check grace period would likely resolve the issue. The cooldown period helps to ensure that your Auto Scaling group doesn't launch or terminate additional instances before the previous scaling activity takes effect, and are not used for health checks. Creating a new ELB or Auto Scaling group would have no impact but the problem would persist. AWS Config is a governance and management tool and is incapable of itself executing automated actions.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html","title":"Health Checks for Auto Scaling Instances"}],"answers":[{"id":"1fec64ae8a7c39cb26d12b3f50438dde","text":"Increase the cooldown period of the Auto Scaling group.","correct":false},{"id":"fe8f15e29da594ce0b07d192b5e8f4f3","text":"Use AWS Config to monitor instances with failed health checks to terminate them.","correct":false},{"id":"828102b2cd5f2f5f2873afea3714c7eb","text":"Increase the health check grace period.","correct":true},{"id":"47d484cdd97dff7b054f3cc746f8bbc6","text":"Create a new Auto Scaling group behind a new ELB. The current ELB is malfunctioning.","correct":false}]},{"id":"ec1a76ef-7748-442c-8335-6946ab71d4cf","domain":"mon-trb","question":"A company compliance policy mandates that all production account data must be stored across multiple geographically distant locations. In order to meet this requirement, they configured Amazon S3 Cross-Region Replication on their production account buckets. They find that S3 objects are not being replicated. What needs to be implemented to resolve this issue?","explanation":"S3 Bucket Versioning is a requirement to configure S3 Cross-Region Replication and must be enabled before S3 Cross-Region Replication can even be configured. This is therefore not part of the correct answer. S3 lifecycle policies are not related to replication of S3 data between accounts or regions. S3 lifecycle policies can be used to transition S3 objects to another Amazon S3 storage class. Using bucket event notifications would also not resolve this issue. Source bucket owner must have permissions to replicate objects on the destination S3 bucket in order for replication to succeed. This is accomplished by providing the source bucket owner permissions in the destination bucket policy. Additionally, source bucket owner must have access permissions to objects in the source bucket that are being replicated in order for replication to succeed. It is possible that IAM users other than the S3 bucket owner have permissions to put objects in the source bucket. In that scenario, the object owner must grant access permissions on the objects to the bucket owner.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-troubleshoot.html","title":"Troubleshooting Replication"}],"answers":[{"id":"45e81330579f9aff0a7899e4391df01b","text":"S3 source object owner must grant source bucket owner full access permissions.","correct":true},{"id":"458121bce565bd7f3f18b1bb88fcd54f","text":"S3 Bucket Versioning must be enabled.","correct":false},{"id":"bb861c75c9a7820314f89f054fc67334","text":"S3 Bucket Event Notifications must be configured.","correct":false},{"id":"3a890ed88544caf9acc9c3ab791fa815","text":"Bucket policy on the destination bucket must allow the source bucket owner to replicate objects.","correct":true},{"id":"7cf3b4d7efa9a9120305b06649d29c0e","text":"S3 Bucket Lifecycle Policy must be configured.","correct":false}]},{"id":"4216cacb-ee8a-42e5-acff-9b1ea39357e6","domain":"development","question":"A developer is implementing an IoT application using DynamoDB as the data store for device event data. An application requirement is to automatically purge all event data older than 30 days. What is the optimal option to implement this requirement?","explanation":"Time to Live (TTL) for Amazon DynamoDB is functionality that enables automatic deletion of items after a specified expiration time. The expiration time is defined by a timestamp in the TTL attribute. When Time to Live (TTL) is enabled on a table in Amazon DynamoDB, a background job checks the TTL attribute of items. The background job compares the current time in epoch time format to the time stored in the Time to Live attribute of an item to determine whether the item is expired. If the epoch time value stored in the attribute is less than the current time, the item is marked as expired and then deleted.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/howitworks-ttl.html","title":"Time to Live: How It Works"}],"answers":[{"id":"0a4018a4dc09457f483a0fb75a49f140","text":"Enable DynamoDB streams on the table. Implement Lambda function to read events from the stream and delete expired items.","correct":false},{"id":"89ff2a65dcb0d5ab07793957e16ed650","text":"Enable TTL on the DynamoDB table and store the expiration timestamp in the TTL attribute in the epoch time format.","correct":true},{"id":"ac0b210d52da3eacb34d48327798c599","text":"Create a new DynamoDB table every 30 days. Delete the old DynamoDB table.","correct":false},{"id":"c408a205dcdc64e12ad635afc658fa61","text":"Implement a Lambda function to perform a query on the table and delete items with timestamp greater than 30 days. Use CloudWatch events to trigger Lambda function.","correct":false}]},{"id":"bc3ffcc3-4225-4da3-8819-17ae2ee5c3dc","domain":"security","question":"A VPC has four subnets: 1) Subnet1 has a route table entry with destination: 0.0.0.0/0 and target: VPC Internet Gateway ID; 2) Subnet2 has a route table entry with destination 0.0.0.0/0 and target: NAT Gateway ID; 3) Subnet3 has a EC2 instance that serves as a bastion host 4) Subnet4 has an NSG Inbound Rule with Source: 0.0.0.0/0; Protocol: TCP; and Port Range: 1433. What would be the recommended subnet for hosting an RDS database instance?","explanation":"Security best practice would state that RDS Database instances should be deployed to a private subnet. A private subnet would only have private IP's with no direct access to the public internet. Outbound connectivity would be provided via a NAT gateway. Thus, Subnet2 is a suitable choice for deploying RDS instances as it is characterized as a private subnet. Subnet1 has direct connectivity to the public internet via the Internet gateway. Thus, it is characterized as a public subnet and would not be recommended location for deploying databases. Bastion hosts allow direct inbound connections from public internet. This means that Subnet3 would not be a good choice to host databases. Lastly, Subnet4 contains NSG rule that allows inbound connectivity from the public internet on the database port (1433). This makes it a poor candidate to host databases.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html","title":"VPC with Public and Private Subnets (NAT)"}],"answers":[{"id":"58726f362b0b49454806dac56cdef893","text":"Subnet4","correct":false},{"id":"6415a7d7642468e623d92a6df2333f86","text":"Subnet1","correct":false},{"id":"5cf0f214c90cf601b2f5f3bb0c6ec507","text":"Subnet3","correct":false},{"id":"5fb3d14ca24c9ce9e6eecb5a650bf8c9","text":"Subnet2","correct":true}]},{"id":"52dc8f6c-a34e-48cd-afbf-8a3b5ecd7e34","domain":"refactoring","question":"Your application is experiencing a large number of failed requests when making calls to the S3 API. Which of the following best describes the approach used by AWS SDKs for regulating flow control when retrying failed API requests?","explanation":"Numerous components on a network, such as DNS servers, switches, load balancers, and others can generate errors anywhere in the life of a given request. The usual technique for dealing with these error responses in a networked environment is to implement retries in the client application. In addition to simple retries, each AWS SDK implements exponential backoff algorithm for better flow control. The idea behind exponential backoff is to use progressively longer waits between retries for consecutive error responses.","links":[{"url":"https://docs.aws.amazon.com/general/latest/gr/api-retries.html","title":"Error Retries and Exponential Backoff in AWS"}],"answers":[{"id":"78d0dc3ec6366e5ac975d5108a27106f","text":"Feedback Based Flow Control is used to avoid contention when retrying failed requests","correct":false},{"id":"c57cdded61f3bd3c9d54c8575f424941","text":"AWS uses Exponential Backoff to manage error retries","correct":true},{"id":"401eaf63ec9626a306617946768f9d43","text":"By default, the request is continuously retried until it is successful","correct":false},{"id":"1515fbc0c63bfb67a5ec940447b2480c","text":"AWS uses bandwidth throttling to manage flow control","correct":false}]},{"id":"47e074a7-e675-4918-92bf-d9a34b82803c","domain":"security","question":"Your application needs to access content located in an S3 bucket which is residing in a different AWS account, which of the following API calls should be used to gain access?","explanation":"The STS AssumeRole API call returns a set of temporary security credentials which can be used to access AWS resources, including those in a different account","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html","title":"Providing temporary access to AWS resources"}],"answers":[{"id":"818a55892aa657e5ef8dae6d12ee9273","text":"IAM:AddRoleToInstanceProfile","correct":false},{"id":"c2599de6f471b00ab3948981939f8315","text":"STS:GetFederationToken","correct":false},{"id":"100979100796827d7bcafe4666e4984f","text":"STS:AssumeRole","correct":true},{"id":"5854d57d52033e05be8f9fda06330abd","text":"STS:AttachRole","correct":false}]},{"id":"6a5ea0b3-2527-4c20-9410-d8807d16fcd3","domain":"security","question":"An organization is hosting their static website on S3, using a custom domain name. Users have started reporting that their web browsers' are alerting them to the fact that the organization's website is \"Not Secure\" because it is not served via a secure HTTPS connection.\n\nWhat is the easiest way to start serving the website via HTTPS?","explanation":"S3 buckets do not directly support HTTPS with a custom domain name. The simplest solution is to create a CloudFront distribution and set its origin to the S3 bucket. CloudFront allows you to specify a custom domain name, and supports managed certificates via Amazon Certificate Manager.\n\nEnabling AES-256 Default Encryption on the S3 bucket only affects the object at rest.\n\nApplication Load Balancers do support SSL termination but do not support S3 as a target.\n\nAWS Shield relates to Distributed Denial of Service protection, not encryption over the wire.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-requests-s3/","title":"Use CloudFront to serve HTTPS requests for Amazon S3"}],"answers":[{"id":"6d63f6dae98a20c7db6446021c83e7f5","text":"Enable AWS Shield on the S3 bucket. Browsers automatically detect that Shield is enabled and report that the website is secure.","correct":false},{"id":"674d0590e06799926f232e63b73894a8","text":"Add a CloudFront distribution in front of the S3 static website, which supports HTTPS with a custom domain name.","correct":true},{"id":"27631f4c194c5ea5116e308788e945f2","text":"Enable AES-256 Default Encryption on the S3 bucket, which ensures all content is delivered via HTTPS.","correct":false},{"id":"d76d398f54d04a531867ae84eda26050","text":"Add an Application Load Balancer in front of the S3 bucket and enable SSL termination.","correct":false}]},{"id":"d1b0d0fe-4931-441c-83d5-716d63424a58","domain":"mon-trb","question":"You are working on an application which shares video content to subscribed users. This morning you have received a number of complaints that users are unable to access your content and they are seeing an HTTP 504 Status Code. Which of the following could be a possible explanation?","explanation":"An HTTP 504 status code is a Gateway Timeout which indicates that when CloudFront forwarded a request to the origin, because the requested object was not in the edge cache, one of the following happened: The origin returned an HTTP 504 status code to CloudFront; or, the origin didnâ€™t respond before the request expired. This is a server side issue, i.e. a problem or misconfiguration in your AWS infrastructure. Remember that any 5XX error indicates a server-side error, and a 4XX error indicates a client-side error.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/http-504-gateway-timeout.html","title":"HTTP 504 Gateway Timeout"}],"answers":[{"id":"76b78bdea733c0e70e13c80add3c975d","text":"There is a client side error in the user's infrastructure","correct":false},{"id":"84f05e093a7f246d10fef9ea043d217a","text":"The users have a network connectivity problem","correct":false},{"id":"c8cffd0bf5d95cfc0541c7ad2d54d740","text":"The users could be attempting to access your site using an unsupported browser","correct":false},{"id":"b9434940d2516177efc8f8eef8b3de37","text":"There is a server side error within your AWS infrastructure","correct":true}]},{"id":"9548796c-789c-42ea-9e90-3da3a9252c1b","domain":"security","question":"Your Security team have recently reviewed the security standards across your entire AWS environment. They have identified that a number of EC2 instances in your development environment have read and write access to an S3 bucket containing highly confidential production data. You have been asked to help investigate and suggest a way to remedy this. Which of the following can you use to find out what is going on so that you can suggest a solution?","explanation":"With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies attached to IAM users, groups, or roles in your AWS account. You can test which actions are allowed or denied by the selected policies for specific resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html","title":"Testing IAM Policies with the IAM Policy Simulator"}],"answers":[{"id":"5bc514eb754ea13140481ed2afc68d45","text":"Use the VPC flow logs to identify which EC2 instances are attempting to access the bucket","correct":false},{"id":"58f20da8b31f9e9da2e5a374608338ef","text":"Use the CLI or console to check the public access permissions of the S3 bucket","correct":false},{"id":"aac02aded2357ef60d7cc0b8f32df947","text":"Use CloudTrail and Athena to identify which role or policy is granting access","correct":false},{"id":"17d9101067c49b2ec4b35087e24ce8eb","text":"Use the IAM Policy Simulator to identify which role or policy is granting access","correct":true}]},{"id":"847e9972-b2da-4c6c-b5b5-74fde22cf193","domain":"refactoring","question":"Your application is storing a lot of data in an S3 bucket called mybucket and is routinely exceeding 100 requests per second using a mix of GET, PUT and DELETE operations. Which of the following naming strategies will ensure low latency performance with S3?","explanation":"Prior to July 2018, AWS recommendation was to use random keyname prefixes to ensure objects were stored on separate partitions in order to give the best performance for mixed workloads. Since July 2017 this is no longer necessary, however we expect the use of random key names to still be tested in the exam so it is still important to be aware of this approach.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","title":"Updated guidance on S3 performance - for reference"}],"answers":[{"id":"a4df002d6a19b2b0edf9097af5315fce","text":"mybucket/customers/cust26347456/file1.txt","correct":false},{"id":"015205126ff1a0346b8753dbe82a2306","text":"mybucket/2018-02-07-12-00-00/cust26347456/file1.txt","correct":false},{"id":"214a113d4fbf2063b6cbae4047f7e027","text":"mybucket/2018-02-07-12-00-00/cust26347456/8761file1.txt","correct":false},{"id":"e327db1b1bbc74ad0be34391c8c54367","text":"mybucket/8761-2018-02-07-12-00-00/cust26347456/file1.txt","correct":true}]},{"id":"03ea5729-a486-470f-8cf7-a006c62c2045","domain":"deployment","question":"You have been asked to run your in-house application code using Lambda. Which of the following services could you use to deploy your code?","explanation":"You cannot deploy code using CodeCommit or CodeBuild. All of the other services can be used to deploy code in a Serverless environment","links":[{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/deploying-aws-lambda-functions-using-aws-cloudformation-the-portable-way/","title":"Deploying Lambda Functions Using CloudFormation"},{"url":"https://aws.amazon.com/blogs/compute/implementing-safe-aws-lambda-deployments-with-aws-codedeploy/","title":"Deploying Lambda Functions Using CodeDeploy"},{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"AWS SAM"}],"answers":[{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":true},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"2565605f16beacf2f11c0ac6e7510e80","text":"AWS Serverless Application Model","correct":true},{"id":"56c20df941e069e1a35a1871f662298a","text":"CodeCommit","correct":false}]},{"id":"32d5da0f-0ed7-436c-98cf-a16053badf54","domain":"development","question":"Your application runs on Lambda and you would like to enable your functions to communicate with EC2 instances in your private subnet. How can you enable this?","explanation":"In order to enable Lambda to communicate with your private VPC, you need to add VPC config information. You do not need to add a NAT or Internet gateway and it is not possible to launch a Lambda function inside your own VPC or subnet. - Please be aware that in September 2019, AWS announced that they are simplifying VPC networking for Lambda functions, with changes planned to be rolled out on a per region basis. However the exams do generally run at least 6-12 months behind any new updates or announcements, so unfortunately, you may still see exam questions referring to the old way of doing things.","links":[{"url":"https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/","title":"Announcing improved VPC networking for AWS Lambda functions"}],"answers":[{"id":"d77b6ba1a84152571b9b01b57aa78774","text":"Add an internet gateway to your VPC","correct":false},{"id":"4f2ebe62076f1314a2b7ece1aae5f495","text":"Update your Lambda function with the relevant VPC config information","correct":true},{"id":"a8f43c529989f897c2749cb29caeb890","text":"Add a NAT gateway to the subnet","correct":false},{"id":"9b7ce49759154447fc7d7666f84adf68","text":"Launch the Lambda function in the same subnet as your EC2 instances","correct":false}]},{"id":"88bcdf37-e9ac-4a5a-9561-a0b40b3d5942","domain":"deployment","question":"You have deployed your application on EC2 using Elastic Beanstalk. You would like to configure your application to send data to X-Ray. Where should you install the X-Ray daemon?","explanation":"To relay trace data from your application to AWS X-Ray, you can run the X-Ray daemon on your Elastic Beanstalk environment's Amazon EC2 instances. Elastic Beanstalk platforms provide a configuration option that you can set to run the daemon automatically. You can enable the daemon in a configuration file in your source code or by choosing an option in the Elastic Beanstalk console. When you enable the configuration option, the daemon is installed on the instance and runs as a service.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-beanstalk.html","title":"Running the X-Ray daemon on AWS Elastic Beanstalk"}],"answers":[{"id":"020611c7739a39c03183a066978fdad7","text":"Install the X-Ray daemon on the EC2 instances located in your own data center","correct":false},{"id":"815e2ca172c43e652a7d680047998174","text":"Install the X-Ray daemon on a Docker container running on your EC2 instance","correct":false},{"id":"2e3b28f6b658014b7006069d657a21b0","text":"Manually provision a new EC2 instance and install the X-Ray daemon on the new instance","correct":false},{"id":"b869cc613e5695b1535e3509f2226824","text":"Install the X-Ray daemon on the EC2 instances inside your Elastic Beanstalk environment.","correct":true}]},{"id":"2204af3d-2ed7-41c4-9182-2df403ce77df","domain":"security","question":"An organization receives documents from its users, which must be put into a SQS queue, ready for processing. The documents range in size from 3 MB to 20 MB, and must always be encrypted at rest.\n\nWhat is the best was to queue these documents?","explanation":"SQS has a maximum message size of 256 KB, and DynamoDB has a maximum Item size of 400 KB; therefore, neither of these would be suitable for storing such large documents.\n\nGlacier would not be suitable as its use-case is for long term document archiving, not short term document processing.\n\nAll options listed provide encryption at rest.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-limits.html","title":"SQS Limits"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"19455cef763d19eace0135946b6c4a0b","text":"Store the document in Glacier. Include a reference to the object in a SQS message.","correct":false},{"id":"23a28d35794f1802b4590c8433d5f0be","text":"Store the document in S3. Include a reference to the object in a SQS message.","correct":true},{"id":"e0d9c5dbccbb6899d85b6efde57b2929","text":"Base64 encode the document, then attached it to the SQS message as a Message Attribute.Â ","correct":false},{"id":"f9c2efbd72c96aab06a14e4f3be9b830","text":"Store the document in DynamoDB. Include a reference to the item in a SQS message.","correct":false}]},{"id":"54fce7fa-7d85-4dde-92e6-4e6d1e12327c","domain":"deployment","question":"You have developed an application to run on Amazon EC2. Users have increased and you've found latency issues for users from various geographic locations. You decide to create a CloudFormation template of the application's environment in order to streamline application launch in other AWS Regions to improve performance for users. When creating the CloudFormation template, what is one thing you have to ensure for the resources to launch successfully?","explanation":"AWS CloudFormation templates that declare an Amazon Elastic Compute Cloud (Amazon EC2) instance must also specify an Amazon Machine Image (AMI) ID, which includes an operating system and other software and configuration information used to launch the instance. The correct AMI ID depends on the instance type and region in which you're launching your stack. And IDs can change regularly, such as when an AMI is updated with software updates. AMIs are stored in a region and cannot be accessed in other regions. To use the AMI in another region, you must copy it to that region. IAM roles are valid across the entire account. AWS CloudFormation StackSets let you provision a common set of AWS resources across multiple accounts and regions with a single CloudFormation template. Tags are not a universal namespace and are used as metadata or labels for your resources.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/walkthrough-custom-resources-lambda-lookup-amiids.html","title":"Walkthrough: Looking Up Amazon Machine Image IDs"}],"answers":[{"id":"e2c092a149099f0d0ae393acb19afd6d","text":"This is not possible. CloudFormation templates can be launched only in a single region.","correct":false},{"id":"c2a7b7d4dab7e7ef0dc554e6054d7f77","text":"Create and validate the right IAM roles in the template in the desired Region.","correct":false},{"id":"5b8b4dc7a6004401e2e0fb8002dfd3c7","text":"Ensure the tags of the resources are not the same in the new Region as they are a universal namespace.","correct":false},{"id":"fbbfa698853564b32d5e961010c48e36","text":"Ensure the AMIs referenced in the template correspond to the AMI IDs in the desired Region.","correct":true}]},{"id":"5cd0d201-9b93-42f0-9ae7-585263307009","domain":"development","question":"You've been asked to create a Web application with an endpoint that can handle thousands of REST calls a minute.  What AWS service can be used in front of an application to assist in achieving this?","explanation":"Questions containing 'REST' are usually related to APIs, so API Gateway looks the best answer.  Elastic Beanstalk is a service which allows you to run applications without understanding the infrastructure and can be discounted, as can Global Accelerator which is a networking service that improves the availability and performance of applications.  CloudFront can be used in conjunction with API Gateway to assist in geographically disparate calls, but won't process calls by itself.","links":[{"url":"https://aws.amazon.com/api-gateway/faqs/","title":"Amazon API Gateway FAQs"}],"answers":[{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"9ce65e2b30ed635c84bef82218a94fdf","text":"Global Accelerator","correct":false},{"id":"2ef9dd82927a3196ca2df3fc0cdf2e0b","text":"API Gateway","correct":true}]},{"id":"3efc0266-4c2e-11ea-b77f-2e728ce88125","domain":"deployment","question":"Which of the following statements are true about the concept of blue/green deployment regarding development and deployment of your application?","explanation":"With blue/green deployment, you can shift traffic between two identical environments that are running different versions of your application. It allows you to easily deploy changes to your application and roll-back on changes very quickly.","links":[{"url":" https://d1.awsstatic.com/whitepapers/AWS_Blue_Green_Deployments.pdf","title":"Blue/Green Deployments on AWS"}],"answers":[{"id":"72f75a1c7558a3b8e4c011917ad6105d","text":"The green environment represents the production environment.","correct":false},{"id":"545fd2a37ac85b63dad4f92c91401436","text":"The green environment represents the staging environment.","correct":false},{"id":"3dae7ad4a3084f0fa3d2598654de9066","text":"The blue environment represents the current version of your application serving production traffic.","correct":false},{"id":"69da7fc6d495def048f27d73e7e55e82","text":"It allows you to shift traffic between two identical environments that are running different versions of your application.","correct":true}]},{"id":"17aedf6b-012a-448d-805b-784c7f87ba15","domain":"deployment","question":"What is the CloudFormation helper script cfn-init used for?","explanation":"CloudFormation helper scripts are Python scripts that can be used as part of a CloudFormation template to automate common tasks during stack creation. cfn-init helper script can be used to install packages, create files, and start/stop services. cfn-get-metadata can be used to fetch a metadata block from AWS CloudFormation and print it to standard out.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-init.html","title":"cfn-init"}],"answers":[{"id":"6fe3f8fbab579b6b679da8d9b773b7c2","text":"Fetch a metadata block from AWS CloudFormation template.","correct":false},{"id":"ab8e55f1fd87a343e434da332b588142","text":"Initialize CloudFormation IAM Service Role.","correct":false},{"id":"2a5d8dc3f4b9ee91839db7f876a01872","text":"Install packages and start/stop services on EC2 instance.","correct":true},{"id":"2831dc5c18284a29977a09e8fc481cbb","text":"Fetch required credentials before provisioning AWS resources.","correct":false}]},{"id":"21efb969-377d-45b1-a907-8994e94aa26b","domain":"development","question":"An organization is considering making use of AWS Fargate in their next project. Which of the following statements best describes AWS Fargate?","explanation":"AWS Fargate is a compute engine for Amazon ECS that allows you to run containers without having to manage servers or clusters.","links":[{"url":"https://aws.amazon.com/fargate/","title":"AWS Fargate"}],"answers":[{"id":"9996f92567fdefae4123ba718e107bbf","text":"Deploys Compute logic to an AWS Edge location.","correct":false},{"id":"fbe3eadaa96811fdb58081b395eb6164","text":"Stores Docker containers within a registry, making them available for use by AWS ECS.","correct":false},{"id":"5c10facdecd8cb3ff129afb77d315739","text":"Deploys Docker containers within AWS, without having to manage underlying EC2 instances.","correct":true},{"id":"940863780b5c57669b92b1fc551543ca","text":"Automates management of the control plane within a Kubernetes cluster.","correct":false}]},{"id":"88a77a58-b901-4605-a657-98cdc90dff65","domain":"deployment","question":"A developer needs to compile Java code to produce a deployment artifact. Which Amazon service can the developer use for this task?","explanation":"Amazon CodeBuild is a service that compiles source code, runs tests, and produces software packages that are ready to deploy. Amazon CodeCommit is a source control service that hosts Git-based repositories. Amazon CodeDeploy is a deployment service that automates software deployments. Amazon CodePipeline is a continuous delivery service that helps you automate your release pipelines.","links":[{"url":"https://aws.amazon.com/codebuild/","title":"AWS CodeBuild"}],"answers":[{"id":"5f6f48261d96567b3014b43c23382021","text":"CodePipeline","correct":false},{"id":"56c20df941e069e1a35a1871f662298a","text":"CodeCommit","correct":false},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":false},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":true}]},{"id":"4b9c267c-f41d-4325-919e-7863e0abb6f3","domain":"development","question":"A three-tier web application is deployed using CloudFormation template. How can the CloudFormation developer ensure that the database resource is saved for backup purposes upon stack deletion?","explanation":"The DeletionPolicy attribute can be used to preserve a specific resource when its stack is deleted. The DeletionPolicy Retain option can be used to ensure AWS CloudFormation keeps the resource without deleting the resource.  The Stack Termination Protection feature enables protection against accidental deletion of an entire stack, not preservation of a specific resource. Similarly, the 'cloudformation:DeleteStack' Action applies to entire stack(s).","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html","title":"DeletionPolicy Attribute"}],"answers":[{"id":"6983aeb4c0d42bb293c8ec93966aedbb","text":"Set the DeletionProtection to True in the CloudFormation template.","correct":false},{"id":"eee064b70f79422e8511f18b251253ef","text":"Create IAM Policy with Effect of Deny for 'cloudformation:DeleteStack' Action.","correct":false},{"id":"558cc27970e2b64a29bdc85f381b8cb9","text":"Set the DeletionPolicy to Retain in the CloudFormation template.","correct":true},{"id":"8093dacb1a766d0f91fa60e48baa87ed","text":"Set Stack Termination Protection to Enable.","correct":false}]},{"id":"a45d7c37-eb4b-4a39-9fb2-d5298cb40491","domain":"security","question":"You work for a large I.T. recruitment company that are launching a mobile application which will allow job seekers to apply for jobs online and attach their rÃ©sumÃ© to their application. Users will be able to log in to their account using Facebook and the application stores their contact and profile details in a DynamoDB table. Which of the following approaches would you recommend for enabling the users to gain access to view and update their data?","explanation":"With Web Identity Federation, you don't need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well-known external identity provider (IdP), such as Login with Amazon, Facebook, Google. For most Web Identity Federation scenarios, we recommend that you use Amazon Cognito because it acts as an identity broker and does much of the federation work for you.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html","title":"Web Identity Federation"}],"answers":[{"id":"f11ad00f139ee7fd7ecde821e3769c1a","text":"Configure cross-account access between the mobile app and DynamoDB ","correct":false},{"id":"3b5209dda18fcdea46a196b06d17c586","text":"Configure Web Identity Federation with Cognito","correct":true},{"id":"ff1fd8b56d2c836edd2795619fa9b681","text":"Configure Web Identity Federation with ADFS","correct":false},{"id":"e0bc3be9eb85e3ef437aac25d15f5be4","text":"Allow customers to embed user credentials in settings of the mobile app","correct":false}]},{"id":"031bc6f7-17b3-47aa-b449-a97b2ae63aa6","domain":"deployment","question":"Which section of the AWS Serverless Application Model template would you use to describe the configuration of a Lambda function and an API Gateway endpoint, if you were deploying your application using AWS SAM?","explanation":"Use the Transform section to describe your Serverless functions when using the serverless application model. Under the Transform section, you define the resources you want to deploy.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/appendix-appendix-sam-templates-and-cf-templates.html","title":"CloudFormation Resources"},{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-template-basics.html","title":"AWS SAM Template Concepts"}],"answers":[{"id":"7df96b18c230f90ada0a9e2307226338","text":"Templates","correct":false},{"id":"2ff4148554480a37f85efd299df04850","text":"Transform","correct":true},{"id":"e93acb146e114b5dfa6ce2d12dcb96e4","text":"Functions","correct":false},{"id":"ba0e0cde1bf72c28d435c89a66afc61a","text":"Sam","correct":false}]},{"id":"1710c298-c975-4762-8948-da98b2900d8a","domain":"development","question":"You are developing a web application which has been deployed using Lambda. Today you updated the code and uploaded the new version of your code to the Lambda console. Your test team have begun testing but have reported today that the application seems to still be using the original code. What could be the reason for this?","explanation":"The problem is that the application is referencing the function using an alias pointing to a previous version of the code. When you use versioning in AWS Lambda, you can publish one or more versions of your function. So that you can use different variations of your Lambda function in your development workflow, such as development, beta, and production. Lambda also supports creating aliases for each of your Lambda function versions. Conceptually, an AWS Lambda alias is a pointer to a specific Lambda function version. You can update aliases to point to different versions of functions.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda Function Versioning and Aliases"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/how-to-manage-versioning.html","title":"Lambda Versioning"}],"answers":[{"id":"2fcd244fd0d8e7833b6bf94d70f01295","text":"Your application is referencing the function using an unqualified ARN","correct":false},{"id":"b67108883bf2590e9f79b9ab834a84cd","text":"Your application is referencing the function using $LATEST","correct":false},{"id":"ce472c670d174e72811d57156684bb1e","text":"You forgot to publish the version","correct":false},{"id":"b099c8a69bf8eac2d39f02ac07d53702","text":"Your application is referencing the function using an alias which points to a previous version of the code","correct":true},{"id":"078229fa3cd7070c357a105fd9f1584d","text":"Your application is referencing the function using a qualified ARN","correct":false}]},{"id":"7e589557-fe47-4b17-8c0a-f4afe1a9c764","domain":"mon-trb","question":"Your application servers are behind an Application Load Balancer with sticky sessions configured. However during busy times you are occasionally finding that one of your application servers is becoming overloaded. Which of the following options could help avoid this from happening?","explanation":"The use of Sticky Sessions means that requests which are part of the same session get routed to the same target, which may cause the host to become throttled. ElastiCache can be accessed by multiple servers, allowing the load to be distributed more evenly.","links":[{"url":"https://aws.amazon.com/caching/session-management/","title":"Session Management"}],"answers":[{"id":"b225818943ba4680b8e7dc9d9c376359","text":"Store session state in RDS","correct":false},{"id":"88efe13a943c7fa646b910592ecda2f9","text":"Store session state in memory","correct":false},{"id":"2aa6ae3b5971bedd1a05b4d5636afbac","text":"Store session state in an ElastiCache cluster","correct":true},{"id":"be8019a0436605aff98fc69abd0feeec","text":"Store session state locally on the EC2 instance","correct":false}]},{"id":"1a6ef8eb-4675-4004-ab47-3f8682a6e038","domain":"security","question":"Your EC2 instance needs to access files located in an S3 bucket, what is the best way to enable access?","explanation":"Using an IAM role associated with the EC2 instance is the recommended way, storing credentials locally is not recommended.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html","title":"IAM Roles"}],"answers":[{"id":"246491a279b8f11f71b3c083962c0e75","text":"Create a new IAM role and grant read access to S3. Store the role's credentials locally on the EC2 instance and configure your application to supply the credentials with each API request","correct":false},{"id":"7e00e264a60465681fb267faf13307e9","text":"Configure a bucket policy which grants read access based on the EC2 instance name","correct":false},{"id":"6642e43e9a2808c204a04b7c07a1f5ac","text":"Create a new IAM user and grant read access to S3. Store the user's credentials locally on the EC2 instance and configure your application to supply the credentials with each API request","correct":false},{"id":"f47981b92302bc40c2c9dc5f0ec40a23","text":"Create an IAM role with read access to S3 and assign the role to the EC2 instance","correct":true}]},{"id":"c73f812b-373b-4429-9a32-a3d71186c137","domain":"deployment","question":"Your application needs 100 strongly consistent reads on items that are 9KB in size every second. How many units of read capacity units should you provision?","explanation":"9KB rounds up to 12KB. 12KB/4KB=3 strongly consistent read capacity units each. 3*100=300 strongly consistent read capacity units.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html","title":"Throughput Capacity for Reads and Writes"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","title":"DDB - Read Consistency"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CapacityUnitCalculations.html","title":"Calculating CU"}],"answers":[{"id":"3644a684f98ea8fe223c713b77189a77","text":"200","correct":false},{"id":"94f6d7e04a4d452035300f18b984988c","text":"300","correct":true},{"id":"9de6d14fff9806d4bcd1ef555be766cd","text":"350","correct":false},{"id":"7ef605fc8dba5425d6965fbd4c8fbe1f","text":"150","correct":false}]},{"id":"76e6d618-2134-4a73-94dc-dc1c3af9eac3","domain":"development","question":"Which of the following are supported ways to upload and deploy your Lambda code?","explanation":"You can paste code or upload a zip file directly to the console, upload your code to S3 or use a CloudFormation template. Elastic Beanstalk is not a supported method of deploying Lambda.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html","title":"Lambda Deployment Packages"},{"url":"https://docs.aws.amazon.com/toolkit-for-eclipse/v1/user-guide/lambda-tutorial.html#lambda-tutorial-upload-code","title":"Uploading Lambda Code"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html","title":"CloudFormation and Lambda"}],"answers":[{"id":"5c0aaa802c93c303836e0babb6d7e99c","text":"Zip your code into a zip file, upload it to an S3 bucket and have Lambda download it from S3","correct":true},{"id":"a1d81e8594c3bbc120a7270f2475c2b1","text":"Zip your code into a zip file and upload it via the Lambda console","correct":true},{"id":"cf448e03c3d4d06aae12f839f0b9c6ec","text":"Zip your code into a zip file, upload it to Elastic Beanstalk, then deploy your environment using Elastic Beanstalk","correct":false},{"id":"185133cc98a2cbb85e317fd8493e7a26","text":"Copy and paste your code in to the integrated development environment (IDE) inside Lambda","correct":true},{"id":"9a700b9b08c4e3228582eae88ca49df0","text":"Write a CloudFormation template that will deploy your environment including your code.","correct":true}]},{"id":"dbc263cc-9e31-4671-b11a-674870a5dcd3","domain":"deployment","question":"You have been asked to use Elastic Beanstalk to build a number of web servers to use in your development environment, which of the following services can you use?","explanation":"Except for Lambda, all of the services listed can be used to create a web server farm. AWS Lambda automatically runs your code without requiring you to provision or manage servers. Lambda is generally used for stateless, short-running tasks and is not suitable for long-running tasks like running a web server.","links":[{"url":"https://aws.amazon.com/lambda/","title":"What Is Lambda?"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html","title":"What Is AWS Elastic Beanstalk?"}],"answers":[{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"b578e821ab9be9669c17208a583b5899","text":"Auto Scaling Group","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"e95e5a2a3cc8625bca3d71b817367e2d","text":"Elastic Load Balancer","correct":true}]},{"id":"6a4ef89c-dbe0-491d-88d4-11b09f0a272a","domain":"development","question":"What is NOT the best practice when deploying production applications using Elastic Beanstalk?","explanation":"It is a good practice to decouple an Amazon RDS instance from an Elastic Beanstalk environment, especially in production environment.  Launching an RDS database as part of an Elastic Beanstalk environment may be suitable for development or PoC environments. However, in general, it isnâ€™t ideal as this means that termination of the Elastic Beanstalk environment will result in termination of the database as well. To protect important data from potential data loss, Amazon RDS database should be launched outside of the Elastic Beanstalk environment. With this approach, we decouple the life-cycle of the database from the life-cycle of the Elastic Beanstalk environment. This method also allows us to connect multiple environments to the same RDS instance. This may be useful for performing advanced deployment scenarios such as blue-green deployments. Storing RDS connection string in an encrypted, secured, and controlled S3 bucket and using Elastic Beanstalk configuration files is a valid method that can be used to securely store this data outside of the application code. Protecting the RDS databases from accidental deletion by enabling Delete Protection is always a good practice.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.RDS.html","title":"Using Elastic Beanstalk with Amazon RDS"},{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/decouple-rds-from-beanstalk/","title":"How do I decouple an Amazon RDS instance from an Elastic Beanstalk environment without downtime, database sync issues, or data loss?"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/rds-external-credentials.html","title":"Storing the connection string in Amazon S3"}],"answers":[{"id":"f8ac7ea397ed3bf0d0dcf3a3d5123521","text":"Amazon RDS databases should be included in the Elastic Beanstalk environment as that maintains the same life cycle for all components of the environment.","correct":true},{"id":"9e19947230060c5fdc4610175989a39e","text":"Amazon RDS Connection String should be stored in a controlled S3 bucket.","correct":false},{"id":"1a265bcccdb4ad642b0a09989c931196","text":"Amazon RDS database should be launched outside of the Elastic Beanstalk environment as that provides more flexibility.","correct":false},{"id":"24e8e8250f45def68ec55670ac2390e7","text":"Amazon RDS Delete Protection should be enabled.","correct":false}]},{"id":"2988d8a0-c66e-434f-948b-acee623892fc","domain":"mon-trb","question":"You work for an electric car company that has its front-end website on EC2. Company policy dictates that you must retain a history of all EC2 API calls made on your account for security analysis and operational troubleshooting purposes. Which AWS service should you use to do this?","explanation":"CloudTrail is a web service that records AWS API calls for your AWS account and delivers log files to an Amazon S3 bucket. The recorded information includes the identity of the user, the start time of the AWS API call, the source IP address, the request parameters, and the response elements returned by the service.","links":[{"url":"https://aws.amazon.com/documentation/cloudtrail/","title":"CloudTrail Overview"}],"answers":[{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"a907a7338c1fb3821fbe8ed113c64b33","text":"CloudHSM","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false}]},{"id":"dc3e7895-b954-4fa8-8d4f-faffeca401d2","domain":"security","question":"Which of the following methods will allow you to *securely* upload/download your data to the S3 service? Pick all that apply.","explanation":"You can securely upload/download your data to Amazon S3 via SSL endpoints using the HTTPS protocol.","links":[{"url":"https://aws.amazon.com/s3/faqs/#security","title":"S3 Security"}],"answers":[{"id":"1019a747b087f11f97ef6a2bf46a1978","text":"HTTP endpoints using HTTPS protocol","correct":true},{"id":"2b716d646634dd42d3d1ab628b210081","text":"SSL endpoints using the HTTPS protocol","correct":true},{"id":"d7ad40729fa333427d4d8c3032d43fdf","text":"SSL endpoints using HTTP protocol","correct":false},{"id":"937a8b8e84ad5481f1983a1842154e18","text":"HTTP endpoints using HTTP protocol","correct":false}]},{"id":"8856df48-5866-4ee3-a5a7-2033444e21eb","domain":"security","question":"You have provisioned an RDS database and then deployed your application servers using Elastic Beanstalk. You now need to connect your application servers to the database. What should you do?","explanation":"As you are connecting to a database that was not created within your Elastic Beanstalk environment, you will need to create the Security Group yourself and also provide connection string and credentials to allow your application servers to connect to the database","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.RDS.html#rds-external-defaultvpc","title":"Elastic Beanstalk And RDS"}],"answers":[{"id":"50021ae41e50f1b10069ebcccab3c0ef","text":"Provide the database connection information to your application","correct":true},{"id":"26b897f7474a08158506b32e7c566323","text":"Provide the ip address of the RDS instance to Elastic Beanstalk","correct":false},{"id":"24e204c62e09f215959e144cbb8611d4","text":"Configure a security group allowing access to the database and add it to your environments auto-scaling group","correct":true},{"id":"1aa1798c4c20c22832e9a949af74ada3","text":"Configure Elastic Beanstalk to install a database client on your application servers","correct":false}]},{"id":"b668531f-edd2-43f5-bf40-b7e68dad0d08","domain":"development","question":"A developer is working on a new green field project within an organization. The developer has been asked to recommend what technology could be used if the project is to be deployed with Elastic Beanstalk.\n\nWhich of the following platforms could the developer recommend for the project to meet its requirements?","explanation":"Elastic Beanstalk currently supports Docker, Ruby, and Go (amongst others). It does not support Perl or Swift.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html","title":"Elastic Beanstalk Supported Platforms"}],"answers":[{"id":"5f075ae3e1f9d0382bb8c4632991f96f","text":"Go","correct":true},{"id":"9916d1fc59fe22cc046a2fe1615bc764","text":"Ruby","correct":true},{"id":"ae832e9b5bda2699db45f3fa6aa8c556","text":"Swift","correct":false},{"id":"c5fd214cdd0d2b3b4272e73b022ba5c2","text":"Docker","correct":true},{"id":"0114ad06d728f1834e36fe1a39574ef4","text":"Perl","correct":false}]},{"id":"6d133985-53e5-48d7-a1e9-6db8bb940208","domain":"security","question":"You are working as a Developer for an online retailer. Your Security Architect has requested that any files stored in S3 must be encrypted. However some teams are continuing to upload their files without encrypting them. Which of the following will ensure that only encrypted data is uploaded?","explanation":"There are a few different ways to enforce encryption, however from the provided options, the use of a bucket policy to reject requests that do not include encryption in their header is the best answer","links":[{"url":"https://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/","title":"How to Prevent Uploads of Un-encrypted Objects to Amazon S3"}],"answers":[{"id":"e7d6b8da11c238d437edeadb18bf5493","text":"Create a bucket ACL that only allows PUT operations which include the x-amz-encryption parameter in request header","correct":false},{"id":"d61960e2fc2a82679514fe6f3401150f","text":"Select the Encrypted Files Only checkbox in the S3 Permissions tab in the AWS console","correct":false},{"id":"0f6a3c5c345549f63a0da92ac93e45cf","text":"Use a bucket policy that only allows PUT operations which include the x-amz-server-side-encryption parameter in the request header","correct":true},{"id":"da402b6935d7bb0b6868419dc1fcf54f","text":"Tell all team members to include the x-amz-encryption parameter in request header","correct":false}]},{"id":"075f4eef-bd5d-49b2-ba18-f94cc15c377f","domain":"deployment","question":"Which of the following statements is correct?","explanation":"A primary key can either be a single-attribute partition key or a composite partition-sort key.","links":[{"url":"https://aws.amazon.com/dynamodb/faqs/#Getting_Started","title":"DynamoDB Query Functionality"}],"answers":[{"id":"20cdfac45e66ccd0a06ccea3d171de20","text":"In DynamoDB, a primary key can be a range of values.","correct":false},{"id":"a6bead04f6018113a477c5e6ebb0e82d","text":"In DynamoDB, a primary key can be composite partition/sort key.","correct":true},{"id":"d7f04a911ddfe5da2f4356ffbd52b25a","text":"In DynamoDB, a primary key can be a single-attribute partition key","correct":true},{"id":"e2240879e0c017447c6a1c59d0abd816","text":"In DynamoDB, a primary key must be a single-attribute","correct":false}]},{"id":"779acf8c-3df3-43fe-9714-3ebaf8e40ef2","domain":"refactoring","question":"You are working for an investment bank and have been asked to help the application support team with their annual Disaster Recovery testing. The main production PostgreSQL database is hosted in RDS Multi-AZ deployment, with multiple applications running on a combination of EC2 and Lambda. You have been asked to help the team to demonstrate the impact that a failed Availability Zone will have on the database. Which of the following do you suggest?","explanation":"If the Amazon RDS instance is configured for Multi-AZ, you can perform the reboot with a failover. An Amazon RDS event is created when the reboot is completed. If your DB instance is a Multi-AZ deployment, you can force a failover from one Availability Zone (AZ) to another when you reboot. When you force a failover of your DB instance, Amazon RDS automatically switches to a standby replica in another Availability Zone, and updates the DNS record for the DB instance to point to the standby DB instance. As a result, you need to clean up and re-establish any existing connections to your DB instance. Rebooting with failover is beneficial when you want to simulate a failure of a DB instance for testing, or restore operations to the original AZ after a failover occurs.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RebootInstance.html","title":"RDS - Rebooting a DB Instance"}],"answers":[{"id":"4496cfe7afc55864d488f038430be2b5","text":"Simulate an AZ failure by disconnecting your RDS instance from the network","correct":false},{"id":"1db313c348c46e6cefc8bf25ce3e0d15","text":"Simulate an AZ failure by moving your RDS instance to a different subnet","correct":false},{"id":"e8d6fb964d48234750126a73a5fa41f4","text":"Simulate an AZ failure by performing a reboot with forced failover on the RDS instance","correct":true},{"id":"428c5da3acc9c6986847b2511e6129f5","text":"Simulate an AZ failure by rebooting the underlying EC2 instance which is running the database","correct":false},{"id":"222811da7a574ef8ec4e058ece75fe23","text":"Simulate an AZ failure by deleting the primary RDS instance","correct":false}]},{"id":"efa5e898-d746-4a5f-b112-11861aa90108","domain":"deployment","question":"A developer is making changes to the CloudFormation template used to deploy an application. They would like to know if any existing resources will be deleted or replaced before applying the template updates. What service feature will enable this?","explanation":"CloudFormation Change sets enable the preview of proposed changes to a stack in order to assess the impact on running resources. This functionality allows the developer to check if any existing resources will be deleted or replaced upon application of the CloudFormation template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html","title":"Updating Stacks Using Change Sets"}],"answers":[{"id":"400f40520b42783d45e80c35c9b18641","text":"CloudFormation Registry","correct":false},{"id":"e340c6d6c2f5866020158726104d63d7","text":"CloudFormation Change Sets","correct":true},{"id":"b5b91cf0fb04ab0cccd3dc8d197bfdaf","text":"CloudFormation Rolling Updates","correct":false},{"id":"e3692dda22879fd00506eaa434a3913b","text":"CloudFormation StackSets","correct":false}]},{"id":"f5072793-928c-4fc3-8ce0-bd18571b6765","domain":"deployment","question":"You are developing a gaming website which scores all players scores in a DynamoDB table. You are using a Partition key of user_ID and a Sort Key of game_ID as well as storing the user_score which is the user's highest score for the game and also a timestamp. You need to find a way get the top scorers for each game, who have scored over 50,000 points. Which of the following will allow to to find this information in the most efficient way?","explanation":"A scan operation would be less efficient than a query, so that is definitely not the most efficient way. The Query operation described won't help you find the top scorers for each game. A local secondary index is an index that has the same partition key as the base table, but a different sort key. A global secondary index is an index with a partition key and a sort key that can be different from those on the base table.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Queries and Scans"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-indexes-general.html","title":"DynamoDB Indexes"}],"answers":[{"id":"7b9684c68079e7ca02fe44efb81fa0eb","text":"Query the table using a partition key of user_ID and sort by game_ID","correct":false},{"id":"eae4d20326b1ecd862aed8669ad068ca","text":"Use a global secondary index with a partition key of game_ID and a sort key of user_ID","correct":false},{"id":"efcb11f92c2fff3dca6935cb74653ad7","text":"Scan the table and order by score","correct":false},{"id":"1e267d3212493fc534c9b2e9de826341","text":"Use a local secondary index with a partition key of user_ID and a sort key of user_score","correct":true}]},{"id":"b9987e32-c46c-4c78-b9db-e9a5283d7b16","domain":"development","question":"You are planning to use CodeDeploy to deploy an application for the first time to a brand new fleet of EC2 instances. Which deployment approach would you recommend?","explanation":"In-Place is the one to use as you are installing to a new fleet of instances, therefore Blue/Green is not possible. Canary and Rolling updates are not an option for CodeDeploy","links":[{"url":"https://docs.aws.amazon.com/codedeploy/latest/userguide/deployments.html","title":"Working with Deployments in AWS CodeDeploy"}],"answers":[{"id":"53b8ba497ea2cdea89f60da12d94b46d","text":"In-Place","correct":true},{"id":"ecf715d6d79a2698b7fec0357f9d721f","text":"Canary","correct":false},{"id":"ff2713a6181db42fded101c670bbd0dd","text":"Rolling with additional batch","correct":false},{"id":"3a27747f75c4e73e94223a9e4065cd9c","text":"Blue / Green","correct":false}]}]}}}}
