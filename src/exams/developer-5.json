{"data":{"createNewExamAttempt":{"attempt":{"id":"5ef6f68e-e9fe-43fe-bef3-e57dc93d5f02"},"exam":{"id":"05b256f8-3272-46cc-978e-95c90cb96767","title":"AWS Certified Developer - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"c6126f50-a373-47bf-8245-6037dcea0b5a","domain":"security","question":"Your e-commerce application needs to use database connection strings to access a database containing product and customer data. Which of the following is a secure and scalable way to manage this?","explanation":"Using secure string parameters in Parameter Store is an appropriate way to avoid hard coding a password in your template code. This ensures that sensitive runtime parameters are kept as secure as you keep other secrets, while also keeping them separate from your deployment code.","links":[{"url":"https://aws.amazon.com/systems-manager/features/","title":"Systems Manager - Parameter Store"},{"url":"https://aws.amazon.com/blogs/mt/using-aws-systems-manager-parameter-store-secure-string-parameters-in-aws-cloudformation-templates/","title":"Using AWS Systems Manager Parameter Store Secure String parameters"}],"answers":[{"id":"0d2bb1f681b1226217a023c4cb989aaa","text":"Hard code the connection strings in the application code","correct":false},{"id":"1c2a034c75f70a59fff1e639175239dd","text":"Allow the EC2 instance to access the database using an instance role","correct":false},{"id":"62fc1a48d6c466824dfef123b5407ab3","text":"Store the encrypted credentials in an S3 bucket","correct":false},{"id":"7cb38c21a4fc2e2ad04aca2dfe89bb59","text":"Add encrypted IAM credentials to the application server and use an IAM role to access the database","correct":false},{"id":"65b9be4196a653fc5de9a6427a2f168a","text":"Store the credentials in Parameter Store","correct":true}]},{"id":"8f888c41-8c19-4f1a-8682-7a8f8235182a","domain":"security","question":"A developer is working on a new HR application that must be able to encrypt sensitive documents, each of which is approximately 100 MB in size. The encryption needs to take place within the HR application, and each document must be encrypted using a unique key. The developer has decided to use envelope encryption, and KMS to manage their keys.\n\nWhat KMS operation should be called for each document, to most efficiently meet the requirements of the HR application?","explanation":"generate-data-key returns a plaintext data key, ready to be used to encrypt a document, and a ciphertext version of the key, encrypted using the Customer Master Key. The command should be called for each document, so a different key is used for each. Once the document is encrypted, the plaintext key is securely discarded, and the encrypted data key is stored along with the encrypted document.\n\ngenerate-data-key-without-plaintext is incorrect because it is the plaintext key that is used to encrypt the document within the application.\n\ngenerate-random is incorrect as while the response could be used as a data key; a second step would also be needed to acquire the ciphertext version of the key. It is, therefore, not the best solution.\n\nencrypt is incorrect because it can only encrypt up to 4 kilobytes of data, and because the encryption process itself would take place within KMS, directly using the Customer Master Key, not within the application. To that end, using 'encrypt' directly does not fall under AWS's definition of envelope encryption.","links":[{"url":"https://docs.aws.amazon.com/cli/latest/reference/kms/generate-data-key.html","title":"KMS CLI: generate-data-key"},{"url":"https://docs.aws.amazon.com/cli/latest/reference/kms/encrypt.html","title":"KMS CLI: encrypt"}],"answers":[{"id":"f71001650370495dc4bb6bccf8fc3ac9","text":"generate-data-key-without-plaintext","correct":false},{"id":"0b6eb26a9e685b2edba22d0b9f8534a3","text":"generate-data-key","correct":true},{"id":"53c82eba31f6d416f331de9162ebe997","text":"encrypt","correct":false},{"id":"966a36d051e3b8290953bce53c3513bf","text":"generate-random","correct":false}]},{"id":"cd7c8d61-2ce7-401a-956f-c01c33305ae2","domain":"deployment","question":"Which of the following statements is correct?","explanation":"EBS-backed instances can be stopped and restarted without losing the data on the volume.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/instance-store-vs-ebs/","title":"Differences between EBS and Instance Store"}],"answers":[{"id":"36e118d467e9fcf94627a5fa1bc11446","text":"Instance-store backed instances can be stopped and restarted.","correct":false},{"id":"b335920b9f6cd5d6425a787a6183b378","text":"If you want to use auto-scaling, you must use an EBS-backed instance.","correct":false},{"id":"18eb677e835b4b7214b432d085e121fb","text":"An EBS backed instance can be stopped and restarted.","correct":true},{"id":"91fff5146ee33778a9158bd16a8ba469","text":"An Amazon VPC requires that instances be backed with EBS.","correct":false}]},{"id":"97d06b4f-a564-4de7-9faa-b4a421e676de","domain":"deployment","question":"You are developing a Serverless application written in Node.js, which will run on Lambda. During performance testing, you notice that the application is not running as quickly as you would like and you suspect that your Lambda function does not have enough CPU capacity. Which of the following options will improve the overall performance of your function?","explanation":"In the AWS Lambda resource model, you choose the amount of memory you want for your function, and are allocated proportional CPU power and other resources. For example, choosing 256MB of memory allocates approximately twice as much CPU power to your Lambda function as requesting 128MB of memory and half as much CPU power as choosing 512MB of memory. Lambda allocates CPU power linearly in proportion to the amount of memory configured.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html","title":"AWS Lambda Function Configuration"}],"answers":[{"id":"0ee93a043ba5d3a9009482ac05272be4","text":"Configure more CPU capacity in the Lambda settings","correct":false},{"id":"79ff2269ee5c54ff3301f83a7e9e763c","text":" Configure an ElastiCache cluster and place it in front of your Lambda function","correct":false},{"id":"0bfe8be5a6b97f1817eed73015acf072","text":"Configure more memory for your function","correct":true},{"id":"5f8bedb50d2fe04bbfba29e3f41e9cda","text":"Use API Gateway to expose the Lambda function in a more scalable way","correct":false}]},{"id":"e362623f-0040-49f7-8b76-f0d7484d7ade","domain":"mon-trb","question":"You have a distributed application which is made up of a number of different Lambda functions as well as API gateway endpoints and DynamoDB tables. You have noticed that the application is running unusually slowly today. Which of the following tools would be the best choice to help identify what is going on?","explanation":"AWS X-Ray helps developers analyze and debug production, distributed applications, such as those built using a micro-service architecture. With X-Ray, you can understand how your application and its underlying services are performing to identify and troubleshoot the root cause of performance issues and errors.","links":[{"url":"https://aws.amazon.com/xray/","title":"What Is X-Ray?"}],"answers":[{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"8db8c2b0bbd0ff71d1d15bb32f69e3b8","text":"VPC Flow Logs","correct":false},{"id":"0863526e514d88cd2d00b39f8dda0920","text":"X-Ray","correct":true},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false}]},{"id":"2d2bf934-5970-454e-846b-eaec6bf8d227","domain":"security","question":"A financial services organization is using Amazon S3 service to store highly sensitive data. What is the correct IAM Policy that must be applied to ensure that all objects uploaded to the S3 bucket are encrypted?","explanation":"In IAM Policy, the optional condition block enables specification of conditions for when a policy is in effect. In the Condition block, condition operators (such as equal, less than, etc.), the condition keys, and values can be combined into an expression to be evaluated. The IAM policy is applied when the condition expression is true. Condition key s3:x-amz-server-side-encryption must be used to validate that the object being uploaded is encrypted. Resource S3 ARN must include /* at the end of the S3 bucket name to be a valid ARN.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/amazon-s3-policy-keys.html","title":"Specifying Conditions in a Policy"}],"answers":[{"id":"1cf9545900a32abf21ee1166aa1f7d3d","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket/*\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:sse-encryption-cipher\":\"AES256\"\n                   }\n                }\n             }\n          ]\n       }\n       ","correct":false},{"id":"6d70f3311566d7a45c1ee462595ab321","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:x-amz-server-side-encryption\":\"AES256\"\n                   }\n                }\n             }\n          ]\n       }\n       ","correct":false},{"id":"38189a723781ee6f9148edfaeaf7f44b","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket/*\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:x-amz-server-side-encryption\":\"AES256\"\n                   }\n                }\n             }\n       ","correct":true},{"id":"ca109710bb536d634e22f18fabf99d28","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:sse-encryption-cipher\":\"AES256\"\n                   }\n                }\n             }\n          ]\n       }\n       ","correct":false}]},{"id":"33d838eb-6e2a-499f-b1a0-0d385c20732a","domain":"deployment","question":"You have deployed an application using Elastic Beanstalk and your code is running in a Docker container. What is the process for upgrading this application?","explanation":"When you use the Elastic Beanstalk console to deploy a new application or an application version, you'll need to upload a source bundle. Your source bundle must consist of a single ZIP file or WAR file which does not exceed 512 MB. By using Docker with Elastic Beanstalk, you have an infrastructure that automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html","title":"Create an Application Source Bundle"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html","title":"Deploying Elastic Beanstalk Applications from Docker Containers"}],"answers":[{"id":"9142b51f935ad294eb31a909cbe9336e","text":"Upload a zip file containing the new version of your code using the \"Upload and Deploy\" button in the ElasticBeanstalk console","correct":true},{"id":"50ca13bdc867153ec83d6d066d4950b3","text":"Use CodeBuild to deploy the new code to the docker container","correct":false},{"id":"f65c3a605a6af1f8f362fab1debc50b2","text":"Upload your code to CodeCommit and select the \"Deploy Now\" option in Elastic Container Service console","correct":false},{"id":"c9bd7c34b6482e6240a3a8a6404e5d09","text":"Upload your code to Elastic Container Registry and select the \"Deploy Now\" option in Elastic Container Service console","correct":false}]},{"id":"d36289fe-be3b-4a73-8cc2-c216cfd47b05","domain":"security","question":"You're part of a developer team which is building an application that requires access to S3. Everyone on your team requires the same IAM permissions. As your team grows, how would you manage IAM policies and access to the right AWS resources in the most efficient manner?","explanation":"IAM groups are collections of IAM users in one AWS account. You can create IAM groups on a functional, organizational, or geographic basis, or by project, or on any other basis where IAM users need to access similar AWS resources to do their jobs. You can provide each IAM group with permissions to access AWS resources by assigning one or more IAM policies. All policies assigned to an IAM group are inherited by the IAM users who are members of the group. Creating IAM Users for each team member is not the most efficient manner; IAM Groups is more efficient. You cannot log into the AWS Management Console using an IAM role, nor can you do the same with Amazon Cognito. Amazon Cognito is best suited for mobile applications.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"7c9871a327396074304930d0dbe0fcee","text":"Create IAM Users for each team member. Attach an IAM policy to each user. Edit the IAM policy for each user adhering to the Principle of Least Privilege. Create new IAM policies for new team members as appropriate.","correct":false},{"id":"a834e2bd501ea84ca860e5213b4290ea","text":"Create one IAM role with the necessary permissions. Have all team members log into the AWS Management Console using that role. Rotate the password regularly.","correct":false},{"id":"9ef5172ef2f91f7f79640375254443b1","text":"Create an IAM Group called 'Developers'. Attach an IAM policy to the group with the appropriate permissions. Associate your IAM user and your team members' users to the Group. Add new team members to the group as appropriate.","correct":true},{"id":"d81d323b3e2be35dfba6061c653ce5d1","text":"Create an Amazon Cognito user pool for each user and a corresponding S3 bucket. Grant S3 bucket GET requests for each bucket to each Cognito user. Require users to log into the Console using their Cognito credentials.","correct":false}]},{"id":"779acf8c-3df3-43fe-9714-3ebaf8e40ef2","domain":"refactoring","question":"You are working for an investment bank and have been asked to help the application support team with their annual Disaster Recovery testing. The main production PostgreSQL database is hosted in RDS Multi-AZ deployment, with multiple applications running on a combination of EC2 and Lambda. You have been asked to help the team to demonstrate the impact that a failed Availability Zone will have on the database. Which of the following do you suggest?","explanation":"If the Amazon RDS instance is configured for Multi-AZ, you can perform the reboot with a failover. An Amazon RDS event is created when the reboot is completed. If your DB instance is a Multi-AZ deployment, you can force a failover from one Availability Zone (AZ) to another when you reboot. When you force a failover of your DB instance, Amazon RDS automatically switches to a standby replica in another Availability Zone, and updates the DNS record for the DB instance to point to the standby DB instance. As a result, you need to clean up and re-establish any existing connections to your DB instance. Rebooting with failover is beneficial when you want to simulate a failure of a DB instance for testing, or restore operations to the original AZ after a failover occurs.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RebootInstance.html","title":"RDS - Rebooting a DB Instance"}],"answers":[{"id":"e8d6fb964d48234750126a73a5fa41f4","text":"Simulate an AZ failure by performing a reboot with forced failover on the RDS instance","correct":true},{"id":"4496cfe7afc55864d488f038430be2b5","text":"Simulate an AZ failure by disconnecting your RDS instance from the network","correct":false},{"id":"428c5da3acc9c6986847b2511e6129f5","text":"Simulate an AZ failure by rebooting the underlying EC2 instance which is running the database","correct":false},{"id":"222811da7a574ef8ec4e058ece75fe23","text":"Simulate an AZ failure by deleting the primary RDS instance","correct":false},{"id":"1db313c348c46e6cefc8bf25ce3e0d15","text":"Simulate an AZ failure by moving your RDS instance to a different subnet","correct":false}]},{"id":"a45d7c37-eb4b-4a39-9fb2-d5298cb40491","domain":"security","question":"You work for a large I.T. recruitment company that are launching a mobile application which will allow job seekers to apply for jobs online and attach their résumé to their application. Users will be able to log in to their account using Facebook and the application stores their contact and profile details in a DynamoDB table. Which of the following approaches would you recommend for enabling the users to gain access to view and update their data?","explanation":"With Web Identity Federation, you don't need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well-known external identity provider (IdP), such as Login with Amazon, Facebook, Google. For most Web Identity Federation scenarios, we recommend that you use Amazon Cognito because it acts as an identity broker and does much of the federation work for you.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html","title":"Web Identity Federation"}],"answers":[{"id":"f11ad00f139ee7fd7ecde821e3769c1a","text":"Configure cross-account access between the mobile app and DynamoDB ","correct":false},{"id":"e0bc3be9eb85e3ef437aac25d15f5be4","text":"Allow customers to embed user credentials in settings of the mobile app","correct":false},{"id":"3b5209dda18fcdea46a196b06d17c586","text":"Configure Web Identity Federation with Cognito","correct":true},{"id":"ff1fd8b56d2c836edd2795619fa9b681","text":"Configure Web Identity Federation with ADFS","correct":false}]},{"id":"18db8cf0-407c-4547-a64f-eabdcbf3566a","domain":"development","question":"Which of the following DynamoDB features allows Items to be automatically deleted at a given date and time?","explanation":"DynamoDB TTL allows each Item to include a date and time at which DynamoDB will automatically delete the Item.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/howitworks-ttl.html","title":"Time to Live: How It Works"}],"answers":[{"id":"b0d30a23fde41c669e0592b4be4d6093","text":"DynamoDB Exponential Backoff","correct":false},{"id":"fdce91249547ab22d875d26aad3493bd","text":"DynamoDB auto-delete","correct":false},{"id":"f15851a368334eb82668e066053bb738","text":"DynamoDB Timeout","correct":false},{"id":"52d5592ad24a2cda379ce38e9c218d65","text":"DynamoDB TTL","correct":true}]},{"id":"0394976d-f5c9-489a-8411-0dca671a3f67","domain":"deployment","question":"An application connects to an external third-party service with API keys being managed by AWS Secrets Manager. The development team uses CodeBuild for source code compilation activities in their CI/CD process.   Where should the reference to the third-party service API keys be specified?","explanation":"CodeBuild uses the BuildSpec file as a specification of build commands and settings.  “secrets-manager” syntax can be used to retrieve API Keys stored in AWS Secrets Manager. Build Environment variables should NOT be used for storing sensitive information as they are displayed in plain text. AppSpec file is used by CodeDeploy to specify and manage deployments. CloudFormation templates are used by CloudFormation and not by CodeBuild.","links":[{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html","title":"Build Specification Reference for CodeBuild"}],"answers":[{"id":"5bd169bcf0b77c844c2f4bf1bf3eac9d","text":"CloudFormation Template","correct":false},{"id":"ef56db4cbf113c83bf357241b3fe4418","text":"BuildSpec file","correct":true},{"id":"3e1115820889c27bfd8aca3774b9c1f0","text":"AppSpec file","correct":false},{"id":"47d4255c389a3bcdca135b3871c5238d","text":"CodeBuild Environment Variable","correct":false}]},{"id":"c11f4354-0409-46a1-a058-1e377939c655","domain":"development","question":"You are in a development team working on a popular serverless web application which allows users to book late availability flights and hotels at a significant discount. You occasionally receive complaints that the website is running slowly. After some investigation, you notice that at the time of the complaints, DynamoDB reported a ProvisionedThroughputExceeded error. Which of the following approaches is a recommended way to handle this error?","explanation":"Increasing Lambda capacity will not fix the issue because the problem is with DynamoDB. As the error only appears occasionally, the first thing to do is to ensure that the application is using Exponential Backoff to improve flow control. Increasing the capacity on the DynamoDB table could be considered but only if the problem persists.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff","title":"DynamoDB Error Handling"}],"answers":[{"id":"e7668448048601413de55468a4091b5d","text":"Increase the RAM capacity of the Lambda function","correct":false},{"id":"7f6f787080ee787e0f7554f770e0c693","text":"Ensure your application is using Exponential Backoff","correct":true},{"id":"cbf47ddd16d15ef42c8c335fe895c69f","text":"Increase the CPU capacity of the Lambda function","correct":false},{"id":"528fd1044e587b850c48dc8d209cfe11","text":"Increase the read/write capacity of the DynamoDB table","correct":false}]},{"id":"004b0e0e-f5a4-4354-b130-46786f367c11","domain":"security","question":"A developer is running an application on an Amazon EC2 instance that requires access to an Amazon S3 bucket. An administrator creates a role that includes policies that grant read permissions to the bucket and that allow the developer to launch the role with an Amazon EC2 instance. The instance is launched with the created role attached. What additional step is required for the application running on the instance to access the objects in the bucket?","explanation":"Applications that run on an Amazon EC2 instance and that need access to AWS resources such as Amazon S3 buckets or an Amazon DynamoDB table must have security credentials in order to make programmatic requests to AWS. In this case, no other steps are necessary since the application running on the instance will have the necessary permissions by assuming the role attached to the EC2 instance. Since the developer is not using the bucket (the application on the instance is) granting access to the developer will have no impact. There is no need to share credentials with the bucket policy.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"d57505894b0e8e826335fc1b6ca1f88c","text":"No other steps are necessary. The application running on the instance will be able to access the bucket.","correct":true},{"id":"1bc25b995801c49945fc1175ebfaf95d","text":"The administrator must grant the developer permissions to access the bucket.","correct":false},{"id":"ff86c6c144ca49f130e8a6024c26d48c","text":"Create an IAM policy that allows the developer permissions to access the bucket. Attach the policy to the developer's IAM User.","correct":false},{"id":"723ec04523ad8f60803dd2ae402f886f","text":"The developer must share his/her credentials with the bucket policy.","correct":false}]},{"id":"c1271c56-09c1-44e0-9e24-840abbf8ad96","domain":"development","question":"You are deploying a new version of your application using a CodeDeploy In-Place upgrade. At the end of the deployment you test the application and discover that something has gone wrong. You need to roll back your changes as quickly as possible. What do you do?","explanation":"With an In-Place upgrade you will need to redeploy the original version. Only a Blue / Green upgrade allows you to keep the original instances and roll back by routing all requests to the original instances","links":[{"url":"https://docs.aws.amazon.com/codedeploy/latest/userguide/deployments-rollback-and-redeploy.html#deployments-rollback-and-redeploy-manual-rollbacks","title":"CodeDeploy Rollback and Redeploy"}],"answers":[{"id":"d2949de6ed3d3a5197775436b9302635","text":"Point all incoming requests to your development environment while you fix the problem with the failed deployment","correct":false},{"id":"63d25b1e978fde1df3b91bb3d47c31a6","text":"Use CodeDeploy to redeploy the previous version of the application","correct":true},{"id":"079d9ac5765ea898c4d08a65d8e35c53","text":"Configure your load balancer to send all incoming requests to the original instances running the old version of the application","correct":false},{"id":"f7d2972260a5229eaad04f071022e255","text":"Use the CodeDeploy roll back feature to seamlessly roll back to the previous version","correct":false}]},{"id":"e475aa36-e8a9-4d0d-81db-abf30a055ef5","domain":"mon-trb","question":"How can you configure CodeBuild to notify the DevOps team of a failure in the build process?","explanation":"CodeBuild natively supports CloudWatch Events, SNS is a subscription based notification service which integrates with CloudWatch.","links":[{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/sample-build-notifications.html","title":"Build Notifications"}],"answers":[{"id":"1448724d0c2de970718ae2bfe3159256","text":"Use CloudWatch Events and SES notifications to send an email to the DevOps team","correct":false},{"id":"d6c5ab1abdce3cd74b1ebe325b88d27e","text":"Use the CodePipeline dashboard to view the CodeBuild events log","correct":false},{"id":"571ab39fe2270d1c1193587ccfd234f1","text":"Add the name of the email group to the notifications section of the CodeBuild console","correct":false},{"id":"4a31b4240a14801eefb085b05f7985a6","text":"Use CloudWatch Events and an SNS topic to notify subscribers of build events","correct":true}]},{"id":"f7a67868-ec20-40ae-a334-1bca9d02bdb7","domain":"deployment","question":"You are developing a website which allows customers to purchase tickets to popular sporting events. Your application uses S3 for static web hosting, Lambda for business logic, stores transaction data in RDS and uses DynamoDB for product and stock information. After the customer has paid for their purchase, a message is sent to an SQS queue to trigger a confirmation email to be sent out to the customer including an e-ticket for their chosen event. You want to send out the email as soon as the payment has been processed, however during testing you discover that the confirmation emails are being processed a few seconds before the stock control database has finished updating. This sometimes results in selling the same ticket twice. How can you quickly fix this without re-engineering the application?","explanation":"Delay queues let you postpone the delivery of new messages to a queue for a number of seconds. If you create a delay queue, any messages that you send to the queue remain invisible to consumers for the duration of the delay period. The default (minimum) delay for a queue is 0 seconds. The maximum is 15 minutes.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"2c519c2e315e56078976351bc313bbf9","text":"Use a FIFO queue to ensure the messages are always processed in the correct order","correct":false},{"id":"93afc9503f6f41866e3fb6bf957bc816","text":"Use Kinesis to stream the SQS messages, adding a delay of a few seconds","correct":false},{"id":"dc7f3b8fe45a2bd74a545027f1178792","text":"Use an SQS delay queue to let you postpone the delivery of SQS messages by a few seconds","correct":true},{"id":"953522fe58e17a4a74978232a8b50608","text":"Set the delay flag on the queue to 5 seconds, to ensure messages are not processed too quickly","correct":false}]},{"id":"51600664-99f9-48f5-97cc-ec860d378f89","domain":"development","question":"Which AWS service allows you to build and model your serverless application as a visual workflow consisting of a series of steps where the output of one stage can be input into another?","explanation":"Step Functions provide this functionality","links":[{"url":"https://aws.amazon.com/step-functions/faqs/","title":"Step Functions FAQ"}],"answers":[{"id":"1f4072738a4917bea022b11256fb46a4","text":"Simple Workflow Service","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":false},{"id":"42816db0ecfffdf3baff90b7f2545874","text":"Step Functions","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false}]},{"id":"a2d52dd6-9826-449b-b96b-fc7f4edb46eb","domain":"development","question":"You need to announce emergency downtime for a production AWS web application. This downtime notification requires different sets of instructions for different devices. All of the application users signed up to receive SNS notifications from the downtime topic when they began using the application and they are currently subscribed to this topic. What are appropriate ways for you to provide timely, device-specific instructions to end users when announcing this downtime?","explanation":"Using the SNS JSON message generator, you can choose the appropriate endpoint types and edit the generated code to send different text to the different endpoint types.","links":[{"url":"https://docs.aws.amazon.com/sns/latest/dg/mobile-push-send-custommessage.html","title":"Platform-Specific Payloads in Messages to Mobile Devices"}],"answers":[{"id":"954d71e78bf180ff122f720542c09639","text":"It's not possible to send SNS messages manually.","correct":false},{"id":"41ffaa9f13c5d08d4448e6f04dcc2fc6","text":"Create a different topic for each subscription type, then send one topic to SMS endpoints and the other topic to email endpoints.","correct":false},{"id":"a533b37c270c3d5b92e043a2fe21c3b3","text":"Send multiple messages to the topic and ask users to please ignore message formats that don't pertain to them.","correct":false},{"id":"20231f9d3f6d52b54459fecad9bf9b14","text":"Send a single message, but customize the text in the SNS message field so that each device gets only the information that is appropriate for them.","correct":true}]},{"id":"d38a2534-f7bb-4cc2-9b9a-0c50dfb7707b","domain":"security","question":"You are attempting to analyse the CloudWatch metrics for a number of your application servers, however when you try to view the metrics you cannot access them, however one of your colleagues is able to access them without any issues. What could be the problem?","explanation":"Access to Amazon CloudWatch Logs requires credentials that AWS can use to authenticate your requests. Those credentials must have permissions to access AWS resources, such as to retrieve CloudWatch Logs data about your cloud resources.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/auth-and-access-control-cw.html","title":"CloudWatch Access Control"}],"answers":[{"id":"a0ff1e54243f914c3324d8826543cdd2","text":"Your IAM user doesn't have permission to view CloudWatch metrics","correct":true},{"id":"dcd1178c83830f41078c6b19fcd33f05","text":"The CloudWatch agent has stopped running","correct":false},{"id":"691a929a32273fce2328658fc4c41fa6","text":"Your EC2 instance role does not have permission to push the metrics to CloudWatch","correct":false},{"id":"2578745b37e7d610c9f6227f920c4cb5","text":"CloudWatch doesn't have permission to collect the metrics","correct":false}]},{"id":"6db2c293-ed5d-41ff-84fb-803e2970a0f9","domain":"development","question":"A developer is working on a new application which will use DynamoDB. One of the DynamoDB tables that the developer must create requires an index sort key. When creating this DynamoDB table, the developer must select an Attribute Type for the sort key.\n\nWhich of the following DynamoDB data types can the developer select to use for their index sort key?","explanation":"Both partition and sort keys attributes must be defined as type string, number, or binary.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.NamingRulesDataTypes.html#HowItWorks.DataTypes","title":"DynamoDB Data Types"}],"answers":[{"id":"46f3ea056caa3126b91f3f70beea068c","text":"Map","correct":false},{"id":"27118326006d3829667a400ad23d5d98","text":"String","correct":true},{"id":"6ce976e8f061b2b5cfe4d0c50c3405dd","text":"Binary","correct":true},{"id":"b2ee912b91d69b435159c7c3f6df7f5f","text":"Number","correct":true},{"id":"27226c864bac7454a8504f8edb15d95b","text":"Boolean","correct":false},{"id":"4ee29ca12c7d126654bd0e5275de6135","text":"List","correct":false}]},{"id":"c793570e-264f-4352-8ba9-2c2f3cf6a7e0","domain":"refactoring","question":"A enterprise company is migrating their ERP system from on-premise to AWS.  The ERP system comprises of a stateful web application operating over HTTP. Various components of the system are being implemented as microservices utilizing Docker. What load balancer configuration would be a suitable solution for the ERP system migration to AWS?","explanation":"AWS Application Load Balancer receives incoming traffic and distributes the requests across targets based on evaluation of listener rules. As such, it serves as a load balancer service in AWS. More specifically, AWS Application Load Balancer works at layer 7 of the OSI model, and supports HTTP traffic. Additionally, it provides path based routing thus enabling forwarding of requests based on URL. This functionality supports microservices architecture proposed in the question. Lastly, AWS Application Load Balancer supports sticky sessions, enabling stateful applications. This meets all the requirements specified in the question scenario. Classic Load Balancer supports traffic at layer 7 (HTTP) and sticky sessions. However, it does not provide path based routing ability necessary for a microservices application design. Network load balancer operates at layer 4 of the OSI model, and thus is not appropriate for this scenario. Route53 is used to distribute traffic across geographical regions and so it is not suitable solution in this case.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html","title":"What Is an Application Load Balancer?"}],"answers":[{"id":"2c25600a1df6a32f15194f6fa7c5d056","text":"Network Load Balancer with an Elastic IP.","correct":false},{"id":"fca383fefad22bd3ef8d6ac8a24503c8","text":"Route53 with a CNAME and a CloudFront distribution.","correct":false},{"id":"9bc634e1e1185d8d1e5b96383c28b28a","text":"Application Load Balancer with sticky sessions.","correct":true},{"id":"c92cf9cdebc4be47d4192cffa30a533d","text":"Classic Load Balancer with sticky sessions.","correct":false}]},{"id":"802be8c8-07cc-48a7-94c8-21d785d18f5a","domain":"deployment","question":"Your organization is developing a CI/CD environment to improve software delivery of your applications. It has already adopted a plan to execute the various phases of the CI/CD pipeline from continuous integration to continuous deployment. There are now discussions around restructuring the team make-up to implement a CI/CD environment. How would you recommend creating developer teams as a best practice to support this change in the long run?","explanation":"AWS recommends organizing three developer teams for implementing a CI/CD environment: an application team, an infrastructure team, and a tools team. This organization represents a set of best practices that have been developed and applied in fast-moving startups, large enterprise organizations, and in Amazon itself. The teams should be no larger than groups that two pizzas can feed, or about 10-12 people. This follows the communication rule that meaningful conversations hit limits as group sizes increase and lines of communication multiply. Hiring an external consulting firm will not be beneficial in the long run. Setting up a single team is not best practice. AWS CodePipeline is a continuous integration and continuous delivery service for fast and reliable application and infrastructure updates and not used for team structuring.","links":[{"url":"https://d0.awsstatic.com/whitepapers/DevOps/practicing-continuous-integration-continuous-delivery-on-AWS.pdf","title":"Practicing Continuous Integration and Continuous Delivery on AWS"}],"answers":[{"id":"f3054a7a017a533ace8f081538d0b664","text":"Set up an application team to develop applications. Set up an infrastructure team to create and configure the infrastructure to run the applications. Set up a tools team to build and manage the CI/CD pipeline.","correct":true},{"id":"3e514092970cfe2b9a3ea7331a0828cf","text":"Use CodePipeline to manage your CI/CD environment and assign team members to own different phases within your CodePipeline.","correct":false},{"id":"d163f1cc494b3cde77122207a42d9de1","text":"Set up one team to own an operate all components of the CI/CD pipeline to consolidate tasks and improve efficiency.","correct":false},{"id":"b943ddf4265197477c4036cdd230b033","text":"Hire an external consulting firm to build and manage the pipeline. Provide them with the proper IAM roles to access your AWS environment.","correct":false}]},{"id":"f6676496-9451-49c5-b9a0-d9f6db7a2b42","domain":"development","question":"Which of the following Elastic Beanstalk deployment approaches allow you to maintain full capacity while performing an update?","explanation":"Rolling with Additional Batch and Immutable both involve provisioning new servers to ensure capacity is not reduced. All At Once means the application will be offline for the duration of the update. Performing a Rolling Update without an additional batch of servers means a reduction in capacity.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.deploy-existing-version.html","title":"Elastic Beanstalk Deployments"}],"answers":[{"id":"caf75ce833223dcb2c5cfbbcad2ec02a","text":"All At Once","correct":false},{"id":"11efd9ae6f76e706e3f1b34d97584ebc","text":"Immutable","correct":true},{"id":"f4920797afb92022a9c6608efcd86317","text":"Rolling","correct":false},{"id":"431fffe43dba24b87f7ce578ca6f418c","text":"Rolling With Additional Batch","correct":true}]},{"id":"0f02f4b2-9d11-4efb-b467-19bc558ef33d","domain":"security","question":"Your application on EC2 must write to an Aurora cluster to store user and purchasing data. Your CISO implements a new company-wide policy that requires all AWS credentials are encrypted and rotated monthly. How would you fulfill the new security policy with minimum administrative burden?","explanation":"AWS designed IAM roles so that your applications can securely make API requests from your instances, without requiring you to manage the security credentials that the applications use. IAM roles are based on temporary security tokens, so they are rotated automatically. Credentials embedded in source code cannot be rotated without it being an administrative burden, and is a bad practice. It’s impossible to retrieve credentials from an S3 bucket if you don’t already have credentials for that bucket. IAM users cannot be associated with resources, and Active Directory authorization will not grant access to AWS resources.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html","title":"IAM Roles for Amazon EC2"}],"answers":[{"id":"05a57da8fa8c802639a4f49ed0d59116","text":"Associate an IAM user with the application. Enroll that user with your Active Directory domain to use AD authorization.","correct":false},{"id":"c3e276ad3302f173e7d92b40534f2074","text":"Allow the application to fetch the credentials from an S3 bucket with SSE-S3. Upload new credentials monthly.","correct":false},{"id":"fc14a6fe77ae1367c0f776ae96c7379c","text":"Attach an IAM role to the instance with proper credentials.","correct":true},{"id":"5fa27e0170ca1f467557d0d8db5502ff","text":"Encrypt the Aurora clusters' credentials using SHA-256 hash function in the application code, and schedule a CRON job to rotate monthly.","correct":false}]},{"id":"832e5d50-044a-49a0-8e39-b67b7325b242","domain":"refactoring","question":"You have software on an EC2 instance that needs to access both the private and public IP address of that instance. What's the best way for the software to get that information?","explanation":"To view all categories of instance metadata from within a running instance, use the following URI: http://169.254.169.254/latest/meta-data/","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html","title":"Instance Metadata and User Data"}],"answers":[{"id":"239df81185d957b59d31a19adbc9322c","text":"Have the software use cURL or GET to access the instance metadata.","correct":true},{"id":"2ee1ba64e47acbacf84d2d788ee960f6","text":"Have the software use cURL or GET to access the instance user data.","correct":false},{"id":"d7f090ce9cc095c4e147cb891beeb897","text":"Call the EC2 API.","correct":false},{"id":"62683b06759958dafa2f12da5889a9b3","text":"Reference the instance metadata for the private IP and the instance user data for the public IP.","correct":false}]},{"id":"ac3347a8-a8e9-482f-b9e1-cf55b44e51f4","domain":"mon-trb","question":"You are hosting your website in an S3 bucket located in us-east-1, however many of your users are located in India, Africa and Europe and they are experiencing long delays. How can you improve response times for these users?","explanation":"CloudFront can speed up the delivery of your static content to users across the globe. Creating additional buckets and replicating data is not an efficient approach. Connect Direct and ElastiCache cannot be used in the ways described.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/IntroductionUseCases.html#IntroductionUseCasesStaticWebsite","title":"CloudFront Use Cases"}],"answers":[{"id":"019191e8a1a081a3818038b8cdceadd5","text":"Configure a CloudFront CDN","correct":true},{"id":"a4ad24886aec69baee149f06fe05ad2e","text":"Create 3 additional S3 buckets in regions local to your users and replicate the data across to the new buckets","correct":false},{"id":"ecbdb73e217f81efac6bf02c459d6091","text":"Implement Connect Direct","correct":false},{"id":"e225c4ebf2d1a40e5aabd2ecc669e13e","text":"Use ElastiCache to cache the content in each Region","correct":false}]},{"id":"ba5e871c-930d-46d2-9eaf-32c2f6cb4de9","domain":"security","question":"You are developing a batch process job on Amazon EMR. The EMR instances need to access data stored in Amazon RDS in order to initialize the batch processing. The application code ran properly during testing but is not able to properly retrieve data from the RDS instance as there appears to be no connectivity. How would you remedy this situation in the most effective manner?","explanation":"For AWS Container services, customers are responsible for the data and for firewall rules for access to the container service. For example, Amazon RDS provides RDS security groups, and Amazon EMR allows customers to manage firewall rules through Amazon EC2 security groups for Amazon EMR instances. Editing the security group rules will solve the issue. Although AWS does manage the underlying RDS and EMR infrastructure, customers are responsible for the data and firewall rules for access to container services. Key pairs related to infrastructure services such as EC2 and is not relevant in this case. Migrating to EC2 would work but is unnecessary, more costly and require additional administrative overhead.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"4b17f971232d5dfe553d666c762dbac5","text":"This an AWS issue. AWS manages the underlying RDS and EMR infrastructure; they should be able to communicate with each other. Open a Support Case to resolve the issue.","correct":false},{"id":"2a0df43acefc1bd6e1699ab4687aba2b","text":"Edit the security group rules associated with the RDS and EMR instances to allow inbound/outbound access.","correct":true},{"id":"b8d421cecf4e1c5c38ce7a7a17bd7dbb","text":"Create a new key pair associated with the EMR instance. The current key pair is invalid.","correct":false},{"id":"d54de36cd37205ed20bf55d26d757f9e","text":"Migrate the application to run on Amazon EC2 instead. Create an auto-scaling group to scale the batch process when it exceeds a CPU threshold.","correct":false}]},{"id":"93862748-7e4b-4c90-a475-b52a4d1f6f4c","domain":"development","question":"You are planning to deploy a new version of your application using CodeDeploy. You only have a window of 2 hours to complete the deployment and test it. Your team leader is concerned about the time it could take to roll back the upgrade if it should fail. Which deployment approach would you recommend?","explanation":"Blue / Green is the one to use as this allows you to roll back with minimal disruption. An In-Place upgrade is very disruptive to roll back as it will involve re-deploying the original version of the code and during this time your application will be unavailable. Canary and Rolling updates are not an option for CodeDeploy","links":[{"url":"https://aws.amazon.com/blogs/devops/performing-bluegreen-deployments-with-aws-codedeploy-and-auto-scaling-groups/","title":"Blue/Green Deployments with AWS CodeDeploy"}],"answers":[{"id":"ecf715d6d79a2698b7fec0357f9d721f","text":"Canary","correct":false},{"id":"ff2713a6181db42fded101c670bbd0dd","text":"Rolling with additional batch","correct":false},{"id":"53b8ba497ea2cdea89f60da12d94b46d","text":"In-Place","correct":false},{"id":"3a27747f75c4e73e94223a9e4065cd9c","text":"Blue / Green","correct":true}]},{"id":"075f4eef-bd5d-49b2-ba18-f94cc15c377f","domain":"deployment","question":"Which of the following statements is correct?","explanation":"A primary key can either be a single-attribute partition key or a composite partition-sort key.","links":[{"url":"https://aws.amazon.com/dynamodb/faqs/#Getting_Started","title":"DynamoDB Query Functionality"}],"answers":[{"id":"a6bead04f6018113a477c5e6ebb0e82d","text":"In DynamoDB, a primary key can be composite partition/sort key.","correct":true},{"id":"d7f04a911ddfe5da2f4356ffbd52b25a","text":"In DynamoDB, a primary key can be a single-attribute partition key","correct":true},{"id":"20cdfac45e66ccd0a06ccea3d171de20","text":"In DynamoDB, a primary key can be a range of values.","correct":false},{"id":"e2240879e0c017447c6a1c59d0abd816","text":"In DynamoDB, a primary key must be a single-attribute","correct":false}]},{"id":"1ff687ab-5cc2-477e-a5d6-2b7341f37562","domain":"refactoring","question":"You are developing a serverless application and you need somewhere to persist user state data. Which if the following would you recommend?","explanation":"Out of the possible answers, DynamoDB is the only solution that can be used to save state. Lambda by itself does not persist data, API gateway is used to expose APIs to make them available to your users and the Serverless Application Model (SAM) is a framework to build serverless applications.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"What is SAM?"},{"url":"https://aws.amazon.com/lambda/","title":"What is Lambda?"},{"url":"https://aws.amazon.com/api-gateway/","title":"What is API Gateway?"},{"url":"https://aws.amazon.com/serverless/","title":"Serverless"}],"answers":[{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"9c6ff7999454bedded4c4a17f7a61b99","text":"Serverless Application Model","correct":false},{"id":"2ef9dd82927a3196ca2df3fc0cdf2e0b","text":"API Gateway","correct":false}]},{"id":"17aedf6b-012a-448d-805b-784c7f87ba15","domain":"deployment","question":"What is the CloudFormation helper script cfn-init used for?","explanation":"CloudFormation helper scripts are Python scripts that can be used as part of a CloudFormation template to automate common tasks during stack creation. cfn-init helper script can be used to install packages, create files, and start/stop services. cfn-get-metadata can be used to fetch a metadata block from AWS CloudFormation and print it to standard out.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-init.html","title":"cfn-init"}],"answers":[{"id":"2a5d8dc3f4b9ee91839db7f876a01872","text":"Install packages and start/stop services on EC2 instance.","correct":true},{"id":"6fe3f8fbab579b6b679da8d9b773b7c2","text":"Fetch a metadata block from AWS CloudFormation template.","correct":false},{"id":"2831dc5c18284a29977a09e8fc481cbb","text":"Fetch required credentials before provisioning AWS resources.","correct":false},{"id":"ab8e55f1fd87a343e434da332b588142","text":"Initialize CloudFormation IAM Service Role.","correct":false}]},{"id":"2204af3d-2ed7-41c4-9182-2df403ce77df","domain":"security","question":"An organization receives documents from its users, which must be put into a SQS queue, ready for processing. The documents range in size from 3 MB to 20 MB, and must always be encrypted at rest.\n\nWhat is the best was to queue these documents?","explanation":"SQS has a maximum message size of 256 KB, and DynamoDB has a maximum Item size of 400 KB; therefore, neither of these would be suitable for storing such large documents.\n\nGlacier would not be suitable as its use-case is for long term document archiving, not short term document processing.\n\nAll options listed provide encryption at rest.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-limits.html","title":"SQS Limits"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"19455cef763d19eace0135946b6c4a0b","text":"Store the document in Glacier. Include a reference to the object in a SQS message.","correct":false},{"id":"23a28d35794f1802b4590c8433d5f0be","text":"Store the document in S3. Include a reference to the object in a SQS message.","correct":true},{"id":"f9c2efbd72c96aab06a14e4f3be9b830","text":"Store the document in DynamoDB. Include a reference to the item in a SQS message.","correct":false},{"id":"e0d9c5dbccbb6899d85b6efde57b2929","text":"Base64 encode the document, then attached it to the SQS message as a Message Attribute. ","correct":false}]},{"id":"b9cada23-dafc-48d0-8dba-cff32007e3b2","domain":"security","question":"You are developing a mobile web application using Lambda and API Gateway which stores persistent data in a DynamoDB table. You want to configure the application to allow new users to sign-up to your website using their Google mail credentials. Which is the best approach?","explanation":"Cognito is the recommended approach for user sign-up and sign-in for mobile applications which allow access to users with Facebook, Google or Amazon.com credentials. User pools are user directories that provide sign-up and sign-in options for your app users. Identity pools enable you to grant your users access to other AWS services.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/what-is-amazon-cognito.html","title":"What Is Cognito?"}],"answers":[{"id":"2f52b4f250a2df2a6b4cc5b1e4f2ded8","text":"Configure AD federation with Google as the relying party","correct":false},{"id":"4e37a1d7f9c18456157c1080b7628ef8","text":"Write custom code to act as an identity broker to federate with Google","correct":false},{"id":"3a5db953c143ae9ceb70cfeda3a7d477","text":"Configure a Cognito User Pool to handle new user sign-up","correct":true},{"id":"38ad8b2eb26395b051faf111282db4de","text":"Use a Cognito Identity Pool to handle new user sign-up","correct":false}]},{"id":"52bc2a05-9de5-46cb-ab80-feb67dadc6d9","domain":"deployment","question":"What is the maximum size of an S3 object?","explanation":"The minimum size of an object is 0 bytes (empty or 'touched' files are permitted) and the maximum size of an object is 5TB.","links":[{"url":"https://aws.amazon.com/s3/faqs/#general","title":"How Much Data Can I Store?"}],"answers":[{"id":"b3dd42c7956751be5d38b5c0cb2e09c0","text":"5 TB","correct":true},{"id":"47a5e6e39f64ff5d5dfb25da1aa3f3f2","text":"500 GB","correct":false},{"id":"6aaa2ffc817cac34a806a149bee36350","text":"50 GB","correct":false},{"id":"951b67b6006b1e714e7d8b65b90d56b5","text":"50 TB","correct":false}]},{"id":"616a7b1c-bc17-42a4-b361-74af9a86607f","domain":"development","question":"A financial services company is implementing a payments processing application utilizing DynamoDB tables for its data store. To process payments, the application needs to perform a write operation on a sequence of items, and roll back and reverse all operations in case of any one faulty operation.  What is the best method to accomplish this requirement?","explanation":"DynamoDB transactions feature provides ability to group multiple items into a single atomic transaction and perform all-or-nothing coordinated operations.  This can be done programmatically using the TransactWriteItems operation. The BatchWriteItem operation does not meet the question requirements as it does not guarantee that the actions will be performed on all items as a single atomic coordinated operation. It is possible that only some of the actions in the batch succeed while the others do not. Updating the payments application is not the ideal solution.  It requires application code change and tracking all connected operations and reversing them as required is not trivial to implement.  Using the native transaction ability provided by DynamoDB is a better option.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html","title":"Amazon DynamoDB Transactions: How It Works"}],"answers":[{"id":"aa5647f8e2c8e7147097b79d2b2a5555","text":"Use the BatchWriteItem operation.","correct":false},{"id":"758e6d47da6512d38526cfcfa39bb5c1","text":"Update the application to manage and perform roll-back operations.","correct":false},{"id":"cb748237c6e223d0f4506cff55c6b259","text":"Use the TransactWriteItems operation.","correct":true},{"id":"3b08e25699a7082805a9be123c9acbbb","text":"DynamoDB does not support atomic transactions.  Use relational database (such as RDS) that supports atomic transactions.","correct":false}]},{"id":"5cf3b6d4-9a0e-4602-8dab-26e687207049","domain":"development","question":"Which of the following platforms are supported in ElasticBeanstalk?","explanation":"Elastic beanstalk supports common platforms like including Tomcat, Passenger, Puma and Docker","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html","title":"Elastic Beanstalk Supported Platforms"}],"answers":[{"id":"c5fd214cdd0d2b3b4272e73b022ba5c2","text":"Docker","correct":true},{"id":"bf2528a296adb62d041a7519aa77f248","text":"Passenger","correct":true},{"id":"8f72e28063c30c7468fb6af4653f4f9c","text":"Tomcat","correct":true},{"id":"7345f7045e4668138112c100f25517a4","text":"JBoss","correct":false}]},{"id":"2671403f-a54f-4822-8a1b-fd45645826fe","domain":"development","question":"A transport company uses a mobile GPS application to track the location of each of their 60 vehicles. The application records each vehicle's location to a DynamoDB table every 6 seconds. Each transmission is just under 1KB and throughput is spread evenly within that minute. How many units of write capacity should you specify for this table?","explanation":"Writing to the database every six seconds, there are 10 writes/minute/vehicle. There are sixty vehicles in the fleet, so there are 600 writes/minute overall. 600/60 seconds = 10 writes/second.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html","title":"Throughput Capacity for Reads and Writes"}],"answers":[{"id":"f899139df5e1059396431415e770c6dd","text":"100","correct":false},{"id":"d3d9446802a44259755d38e6d163e820","text":"10","correct":true},{"id":"072b030ba126b2f4b2374f342be9ed44","text":"60","correct":false},{"id":"d490d7b4576290fa60eb31b5fc917ad1","text":"600","correct":false}]},{"id":"f26b6227-d443-4a48-9a39-d52161ec3ef5","domain":"security","question":"What is the name of the service that allows users to use their social media account to gain temporary access to the AWS platform?","explanation":"Web Identity Federation is the services which allows users to authenticate with web Identity Providers like Facebook, Google and Amazon receive an authentication token and then exchange that token for temporary security credentials in AWS.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html","title":"Web Identity Federation"}],"answers":[{"id":"876393862947dc478af3ab7b02c30ba9","text":"Facebook Sign In Service","correct":false},{"id":"fba87e436c5368fd112fc79eddacea80","text":"Active Directory Authentication Services","correct":false},{"id":"9cc6ff53d9bbecc10bacb7866e5e957d","text":"Web Confederation Services","correct":false},{"id":"91c75725a837ff613915a3cf3f8208e1","text":"Web Identity Federation","correct":true}]},{"id":"5820892f-2759-4cd8-be11-8b2dbcc5d1b5","domain":"development","question":"Your Lambda function requires a few libraries which are not available as standard in the Lambda runtime environment. Which of the following is a recommended way to make the libraries available to your function?","explanation":"A deployment package is a ZIP archive that contains your function code and dependencies. You need to create a deployment package if you use the Lambda API to manage functions, or if you need to include libraries and dependencies other than the AWS SDK. You can upload the package directly to Lambda, or you can use an Amazon S3 bucket, and then upload it to Lambda. If the deployment package is larger than 50 MB, you must use Amazon S3.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html","title":"AWS Lambda Deployment Package"}],"answers":[{"id":"c5aba36fa7ce91daccd7cb3a4e3cf9a1","text":"Add the dependencies to S3 and create an environment variable to reference them","correct":false},{"id":"24030d747fefc92f6c68f2934974ba96","text":"Upload the deployment package to Lambda","correct":true},{"id":"d43e57bd5184ca5787e6827646b30fa5","text":"Create a handler function downloads the libraries you need","correct":false},{"id":"f21d58a10f3609c9feab39647fa533cf","text":"Store the deployment package in an S3 bucket and then upload it to Lambda","correct":true},{"id":"a74c95d1ac4aa0e191861afb10c345d4","text":"Create a deployment package containing your function code and libraries","correct":true},{"id":"585237ca133be02e26db990e229ab6f4","text":"Create a custom runtime which includes the libraries you need","correct":false}]},{"id":"313867da-7161-4083-9745-77950b6208dd","domain":"development","question":"You are using CodeBuild to create a Docker image and add the image to your Elastic Container Registry. Which of the following commands should you include in the buildspec.yml?","explanation":"Use the docker push command to add your image to your Elastic Container Registry","links":[{"url":"https://aws.amazon.com/blogs/devops/build-a-continuous-delivery-pipeline-for-your-container-images-with-amazon-ecr-as-source/","title":"Build a Continuous Delivery Pipeline for Your Container Images with Amazon ECR as Source"}],"answers":[{"id":"87c7975f8fe350f6f133c1f3d3b6b9f2","text":"aws codebuild docker -t $REPOSITORY_URI:latest .","correct":false},{"id":"ec1f85b16af01c1d7ec994f6ba6efa32","text":"docker push $REPOSITORY_URI:latest","correct":true},{"id":"585a787c56d351517a27b9d64d3db8ae","text":"docker add $REPOSITORY_URI:latest","correct":false},{"id":"c1520af238ed7b988b389f732c0d6287","text":"docker build -t $REPOSITORY_URI:latest .","correct":true},{"id":"d2d39a1ed4490154f045931eee5d18e4","text":"aws ecr push $REPOSITORY_URI:latest","correct":false}]},{"id":"51ffcd4d-d314-49e3-8b95-fbbcfa102515","domain":"deployment","question":"You are responsible for developing a mobile application that allows people to store and search for reviews of their favourite local restaurants. The application stores all ratings and restaurant data in a DynamoDB table. You need to decide which DynamoDB operations you will allow your users to run on the table and you would like to keep the cost of the application as low as possible as well as provide great performance for the users. Which of the following DynamoDB operations uses the least amount of throughput?","explanation":"A query is generally more efficient than a scan, because a scan returns the whole table. An eventually consistent operation is more efficient than a strongly consistent operation, because it uses fewer read capacity units.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Scan Vs Query"}],"answers":[{"id":"272dfa82a03b2bece6b417c774500919","text":"Eventually consistent scan","correct":false},{"id":"ce8155fdac81b2571251c35d8d93141a","text":"Strongly consistent scan","correct":false},{"id":"9c2019be4d041eca1a3b9205da836a1d","text":"Eventually consistent query","correct":true},{"id":"f59a2010f3a6608dcca2419d85124f94","text":"Strongly consistent query","correct":false}]},{"id":"af4efcf0-4c08-4c5c-ade1-6e8196c9f0b7","domain":"deployment","question":"Your application needs to process large numbers of job requests and you need to ensure that they are processed in order, and that each request is processed only once. How would you deploy SQS to achieve this end?","explanation":"FIFO queues offer FIFO (First-In-First-Out) delivery and exactly-once processing: The order in which messages are sent and received is strictly preserved and a message is delivered once and remains available until a consumer processes and deletes it; duplicates are not introduced into the queue.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html","title":"SQS FIFO Queues"}],"answers":[{"id":"31ea3ce575bc576b9ed1b36ce7cccbbc","text":"Configure FIFO delivery in a standard SQS queue.","correct":false},{"id":"bbd8881e023d2e48310f360e90cc7582","text":"Convert your standard queue to a FIFO queue by renaming your standard queue with the .fifo suffix.","correct":false},{"id":"54bf18f30fcf900dcdce5a9bcd553058","text":"Use an SQS FIFO queue to process the jobs.","correct":true},{"id":"78f49aed62525e2d821207ac91af1b24","text":"Use the SetOrder attribute ensure sequential job processing.","correct":false}]},{"id":"7bd7a103-821e-40af-9665-7695fac3de16","domain":"deployment","question":"AWS recommends that you use Multipart Upload for files larger than _____.","explanation":"","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html","title":"Uploading Objects Using Multipart Upload"}],"answers":[{"id":"6df47862fbfbd67605dc294d3f41925a","text":"100MB","correct":true},{"id":"0be25e5b91d25f9db3b4d3dcaf2cfd1f","text":"5GB","correct":false},{"id":"84fb7b98e6e50302bf6cc709c92a6192","text":"5TB","correct":false},{"id":"208b4367cf771ded0e29ff6f9282442e","text":"1GB","correct":false}]},{"id":"2692273f-3f45-48a9-8db1-bd08542db08c","domain":"security","question":"You need to allow another AWS account access to resources in your AWS account, what is the recommended mechanism to configure this?","explanation":"Roles are the primary way to grant cross-account access.  With IAM roles, you can grant third parties access to your AWS resources without sharing your AWS security credentials. Instead, the third party can access your AWS resources by assuming a role that you create in your AWS account.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_terms-and-concepts.html","title":"IAM Roles and Cross Account Access"},{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_third-party.html","title":"Providing Access to AWS Accounts Owned by Third Parties"}],"answers":[{"id":"573753accb681d032a85cdc6773bf08e","text":"Configure Web Identity Federation to allow them to log in to your account","correct":false},{"id":"353c57d4949d688d413dfe136b6a3e2b","text":"Provide AWS credentials to the third party so that they can log into your account and access the resources they need","correct":false},{"id":"b2cc52fe397cf7827353562b7ca92e91","text":"Configure cross account access by creating a role in your account which has permission to access only the resources they need. Allow the third party account to assume the role based on their account ID and unique external ID","correct":true},{"id":"bf90de82812c0e6a3c80cf9c3579975d","text":"Use Cognito to allow the third party to sign-up as a guest user to get temporary access to your account","correct":false}]},{"id":"031bc6f7-17b3-47aa-b449-a97b2ae63aa6","domain":"deployment","question":"Which section of the AWS Serverless Application Model template would you use to describe the configuration of a Lambda function and an API Gateway endpoint, if you were deploying your application using AWS SAM?","explanation":"Use the Transform section to describe your Serverless functions when using the serverless application model. Under the Transform section, you define the resources you want to deploy.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/appendix-appendix-sam-templates-and-cf-templates.html","title":"CloudFormation Resources"},{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-template-basics.html","title":"AWS SAM Template Concepts"}],"answers":[{"id":"7df96b18c230f90ada0a9e2307226338","text":"Templates","correct":false},{"id":"2ff4148554480a37f85efd299df04850","text":"Transform","correct":true},{"id":"ba0e0cde1bf72c28d435c89a66afc61a","text":"Sam","correct":false},{"id":"e93acb146e114b5dfa6ce2d12dcb96e4","text":"Functions","correct":false}]},{"id":"44e023dc-183c-4d0a-8c35-a1779dcd7437","domain":"refactoring","question":"Your organization wants you to lead a development project that will perform real-time processing. The application requires the analytics and field teams to respond promptly to emerging situations based on server activity, website clicks, geo-location of devices, people, and service usage. As the development lead, what combination of services would you recommend to build out this project most efficiently and cost-effectively?","explanation":"Streaming data capture and processing is called real-time processing. The best AWS solution in this case is Amazon Kinesis. You can process data captured and stored with Kinesis sequentially and incrementally on a record-by-record basis or over sliding time windows, and use the processed data for a wide variety of analytics including correlations, aggregations, filtering, and sampling. Use AWS Lambda to process streaming data in real time. Lambda can process the data directly from Kinesis Streams, and lets you run code without provisioning or managing servers with help reduce costs. Running regular queries on Redshift is inefficient and expensive. S3 buckets will be able to store data, but won't be able to process data in real-time as efficiently as Kinesis. Amazon Aurora is a relational database solution and does not fulfill the real-time processing requirement.","links":[{"url":"https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html","title":"Amazon Kinesis Data Streams Terminology and Concepts"}],"answers":[{"id":"5d7d039072621b361ce8bde466f0efc4","text":"Use Amazon Kinesis to capture and store streaming data. Process streaming data with Lambda.","correct":true},{"id":"f255642584a78d5f043cde30cd580abc","text":"Use Amazon Aurora to store data in real time. Aurora will automatically replicate the data in multiple Availability Zones. Build an application on EC2 that users can call using APIs to retrieve the relevant information they need.","correct":false},{"id":"5a50b0d5b285340be18f4a4c59ba1fd2","text":"Store all data in an S3 bucket with the correct prefixes. Develop Lambda functions for each prefix that will routinely scan and extract necessary information to another S3 bucket that will be the source for an Amazon QuickSight dashboard.","correct":false},{"id":"24f2f053a48d8b02ceaae4dc44a376ca","text":"Store the data on Amazon Redshift. Run queries on the Redshift cluster regularly to refresh a dashboard built on Amazon QuickSight.","correct":false}]},{"id":"e4d5998a-073a-4507-991c-ac138ac609c5","domain":"mon-trb","question":"Your application reads data from an SQS queue. The reads are then forwarded to Lambda downstream for processing critical customer information including purchasing and inventory data. It is critical that this data is not lost. How would you accommodate failed Lambda captures of the data?","explanation":"A dead letter queue would allow you to prevent data loss. After a message is taken from the queue and returned for the maximum number of retries, it is automatically sent to a dead letter queue, if one has been configured. It stays there until you retrieve it for forensic purposes. To prevent other consumers from processing the message again, Amazon SQS sets a visibility timeout, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. The default visibility timeout for a message is 30 seconds. DelaySeconds for individual messages are similar to visibility timeouts because both features make messages unavailable to consumers for a specific period of time. The difference between the two is that, for delay queues, a message is hidden when it is first added to queue, whereas for visibility timeouts a message is hidden only after it is consumed from the queue. A FIFO queue guarantees first-in-first-out.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html","title":"Amazon SQS Dead-Letter Queues"}],"answers":[{"id":"5d63d8895abd795fa4b98f12304185dc","text":"Create a dead letter queue and set the Maximum Receives to 3.","correct":true},{"id":"029cff5be66415e342452d104b4e2e57","text":"Requeue the message with a VisibilityTimeout of 30 seconds.","correct":false},{"id":"b431614eebc36d55520274500ed9ba2d","text":"Create a FIFO queue and set DelaySeconds to 3.","correct":false},{"id":"7e66715cc7d52627f1372ab97dbd2350","text":"Requeue the message with DelaySeconds to 3.","correct":false}]},{"id":"fe61a353-eb18-40dc-9e65-30f7106d3e6e","domain":"mon-trb","question":"Your application is running on EC2 and on Linux virtual machines in your own data center. You would like to configure your application to send data to X-Ray for troubleshooting and performance analysis. Which of the following steps will you need to complete?","explanation":"You need the X-Ray SDK and the X-Ray daemon on your EC2 instances and on-premises systems, you then need to instrument your application to send the required data to X-Ray","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html","title":"X-Ray Developer Guide"}],"answers":[{"id":"6ffb986aa2b49eb856b38668f9a44fc2","text":"Install the AWS CLI, then instrument your application to send data to X-Ray.","correct":false},{"id":"da1eaa5b340d64b20d5b526dc0de4b85","text":"Install the X-Ray SDK and the X-Ray daemon, then instrument your application to send data to X-Ray.","correct":true},{"id":"998a1f353d1923ec24b66b6ae427d343","text":"Install the X-Ray daemon, then instrument your application to send data to X-Ray.","correct":false},{"id":"ff31ac1442cb9f28ad8f65a358816a25","text":"Install the AWS SDK and the X-Ray CLI, then instrument your application to send data to X-Ray.","correct":false}]},{"id":"bb8e72f1-89d8-436d-9e0b-743e86abe4d9","domain":"development","question":"A CustomerOrders DynamoDB table contains attributes Customer Name (PK), Order Item, and Cost. What DynamoDB operation would be used to find all orders with cost greater than $10?","explanation":"A query operation is used to search for an item using a primary key value and so requires a Customer Name value to be specified. This would limit results to a specific customer and would not return all items with cost greater than $10. On the other hand, a scan operation reads every item in a table. A filter expression parameter can be used to narrow down the results based on some required criteria (Cost of the item in this case). We do not want to use projection-expression parameter as it is used to limit what attributes are returned as part of the results (not to filter the results).","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.html","title":"Working with Queries in DynamoDB"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html","title":"Working with Scans in DynamoDB"}],"answers":[{"id":"919fd8f793713cd1732ad46d123afb96","text":"query operation with “--filter-expression” parameter","correct":false},{"id":"b33f1b1eeb8c0862730ccd17773fa0ba","text":"query operation with “--key-condition-expression” parameter","correct":false},{"id":"7b572c69a9cc3a5fc180c5ae6ec3fde0","text":"scan operation with “--filter-expression” parameter","correct":true},{"id":"66838b7caff8435bce812744e2907fd5","text":"scan operation with “--projection-expression” parameter","correct":false}]},{"id":"52d02968-6d43-434e-8d41-eaa3d8e69b68","domain":"mon-trb","question":"You are trying to diagnose a performance problem with your serverless application, which uses Lambda, API Gateway, S3 and DynamoDB. Your DynamoDB table is performing well and you suspect that your Lambda function is taking too long to execute. Which of the following could you use to investigate the source of the issue?","explanation":"AWS X-Ray can be used to display a histogram showing the latency of your Lambda function. Latency is the amount of time between when a request starts and when it completes. API Gateway Integration Latency in the time between when API Gateway relays a request to the backend and when it receives a response from the backend. API Gateway Latency is the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Lambda Invocations Sum measures the number of times a function is invoked in response to an event or invocation API call.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html","title":"API Gateway CloudWatch Metrics"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-metrics.html","title":"Lambda CloudWatch Metrics"},{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"},{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-histograms.html","title":"Using Latency Histograms in the AWS X-Ray Console"}],"answers":[{"id":"c464cce256f4ab986973ddae5e8fdf34","text":"Lambda Invocations Sum metric in CloudWatch","correct":false},{"id":"3dc993924bceb799c7009d281aa91408","text":"AWS X-Ray","correct":true},{"id":"90099b94810e3f14b68c4739eb4c456c","text":"API Gateway Integration Latency metric in CloudWatch","correct":true},{"id":"a8d172dc1d7797b755f243837a74be36","text":"API Gateway Latency metric in CloudWatch","correct":false}]},{"id":"6641f65a-c837-49a2-bbeb-11af158d44e0","domain":"mon-trb","question":"What is the maximum execution duration for a Lambda request?","explanation":"As of Oct 2018 the maximum execution duration has been increased from 300 seconds to 900 seconds (15 minutes)","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/limits.html","title":"Lambda Limits"},{"url":"https://aws.amazon.com/about-aws/whats-new/2018/10/aws-lambda-supports-functions-that-can-run-up-to-15-minutes/","title":"Update notice- Oct 2018"}],"answers":[{"id":"7ed53d277129b356be62369ec930e3b8","text":"500 seconds","correct":false},{"id":"a51534ea662db3ce23238035e25859e2","text":"900 seconds","correct":true},{"id":"533f546e5ddb63fb2c810f7cca06678f","text":"300 seconds","correct":false},{"id":"8d15ed7d27d83ed6229a66b1f44b7696","text":"3 minutes","correct":false},{"id":"4234838a99b7912e550babb083c205c4","text":"60 seconds","correct":false}]},{"id":"2988d8a0-c66e-434f-948b-acee623892fc","domain":"mon-trb","question":"You work for an electric car company that has its front-end website on EC2. Company policy dictates that you must retain a history of all EC2 API calls made on your account for security analysis and operational troubleshooting purposes. Which AWS service should you use to do this?","explanation":"CloudTrail is a web service that records AWS API calls for your AWS account and delivers log files to an Amazon S3 bucket. The recorded information includes the identity of the user, the start time of the AWS API call, the source IP address, the request parameters, and the response elements returned by the service.","links":[{"url":"https://aws.amazon.com/documentation/cloudtrail/","title":"CloudTrail Overview"}],"answers":[{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"a907a7338c1fb3821fbe8ed113c64b33","text":"CloudHSM","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false}]},{"id":"a94b2c88-352b-4c39-83fc-7edfa8190fca","domain":"development","question":"Your application communicates using messages in an SQS queue. You have noticed recently that you are seeing a large number of empty responses where no messages exist in the queue. You want to make sure that your application is responsive as possible, but the cost of the solution is also a concern. What can you do to ensure your application is both cost-effective and responsive?","explanation":"In almost all cases, Amazon SQS long polling is preferable to short polling. Long-polling requests let your queue consumers receive messages as soon as they arrive in your queue while reducing the number of empty ReceiveMessageResponse instances returned. In general, you should use maximum 20 seconds for a long-poll timeout. Because higher long-poll timeout values reduce the number of empty ReceiveMessageResponse instances returned, try to set your long-poll timeout as high as possible.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"SQS FAQs"}],"answers":[{"id":"2247660601daf03d12f2fb4a1fccbf55","text":"Use long polling","correct":true},{"id":"f11916957f37c9cd171f126572d34864","text":"Use short polling","correct":false},{"id":"66a35e1198bcce83d8654873aab562c6","text":"Configure multiple queues with short polling","correct":false},{"id":"b2ccbf04a8f468dbcaad76b35f8f076b","text":"Configure multiple queues","correct":false},{"id":"cef7badd821b93647928923359f863e4","text":"Use a FIFO queue","correct":false}]},{"id":"f89c8e58-528b-49fd-aa15-79de8988d6b3","domain":"refactoring","question":"A developer has just finished amending a Lambda function. Originally, the function ran outside of a VPC, but after the update, it now connects to a VPC. Since the change, part of the function that accesses a HTTPS endpoint on a third-party website has stopped working.\n\nWhat is the most likely cause of the Lambda function no longer being able to access the third-party endpoint?","explanation":"If a Lambda function is connected to a VPC, it must have a route out to the internet via a NAT Gateway or NAT instance in order to connect to external services. You must also ensure that the relevant Security Groups and Network Access Control Lists are configured to allow the required ports.\n\nFrom the perspective of the third-party web server, a request that originates from a Lambda function is no different from any other request, so no changes are needed.\n\nLambda functions connect to a VPC via an Elastic Network Interface. Security controls are therefore managed by network Security Groups and NACLs, not IAM policies. The function's execution role does, however, need permissions to initially connect to the VPC. This can be done with the AWS Managed AWSLambdaVPCAccessExecutionRole policy, for example.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html","title":"Configuring a Lambda Function to Access Resources in a VPC"}],"answers":[{"id":"305feb7678afbbe3cc3591f084988eaf","text":"The third-party web server does not support access from a Lambda function that is connected to a VPC. Contact the third-party to request they create a VPC endpoint.","correct":false},{"id":"addf6deaedc46deb808c104b5a9d2cb0","text":"It is not possible to access external web services from a Lambda function that is connected to a VPC. The amend should be rolled back.","correct":false},{"id":"3f9ad00efae1c7e9aab7cf03afa538b7","text":"The Lambda function no longer has any route out to the Internet. A NAT Gateway, and associated route, should be added.","correct":true},{"id":"acf36c68916ef9dff04cf50b1c90ede7","text":"The Lambda's execution role does not have the required permissions. Attach the AWS Managed AWSLambdaInternetAccess policy to the Lambda's execution role.","correct":false}]},{"id":"d91b5d09-a238-441f-b247-d81789372ec1","domain":"development","question":"GetItem operation is used to read data from a DynamoDB table. What strategy can be used to reduce the size of the read operations and increase read efficiency?","explanation":"Projection Expressions are a DynamoDB feature used to limit the attributes returned by the GetItem operation. Thus, this can be used to reduce the size of the payload returned by a read operation. Parallel Scans allows multi-threaded applications to perform DynamoDB Scan operations quicker. It cannot be used with GetItem operations to make them more efficient. Pagination allows developer to perform a Scan operation on a table and divide the result set into multiple pages. It cannot be used to make GetItem operations more efficient. Filter expression can be used with Scan operations to filter the results returned by the scan operation. It is not a GetItem operation feature.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ProjectionExpressions.html","title":"Projection Expressions"}],"answers":[{"id":"e37aefa5950be4eef211c98b18690f64","text":"Use Projection Expression.","correct":true},{"id":"30eb0435ad1702227f2d730850a75e93","text":"Use Pagination.","correct":false},{"id":"ba803153fcb13208c9f26c6ae0dedef6","text":"Use Filter Expression.","correct":false},{"id":"5081ca486a2f5aed471c714c6d81489f","text":"Use Parallel Scan.","correct":false}]},{"id":"91e59ee8-028b-44f1-9d03-1081d09738d3","domain":"development","question":"A clothing company needs to build a REST service to allow salespeople quick access to stock levels. The service must be accessible from an HTTP request. Which of the following solutions addresses the company's requirements?","explanation":"In an AWS Lambda integration in Amazon API Gateway, the HTTP method request from the client is mapped to a backend Lambda function invocation. Depending on your use case, you may choose to use Lambda proxy integration, Lambda non-proxy integration, or both in your API Gateway API. In a Lambda proxy integration, the entire client request is sent to the backend Lambda function as is, except that the order of the request parameters isn't preserved. In a Lambda non-proxy integration (also called a custom integration), you configure the way the parameters, headers, and body of the client's request are translated into the format that your backend Lambda function requires. ","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-getting-started-with-rest-apis.html","title":"Create a REST API with Lambda Integrations in Amazon API Gateway"}],"answers":[{"id":"01f2c91643488c78436cc962fca2f2d7","text":"Amazon EC2 and AWS Auto Scaling","correct":false},{"id":"e9f6666f3057d0c266ac855cbae770b8","text":"Amazon API Gateway and AWS Lambda","correct":true},{"id":"d87496b040e2581c8e89e43a7e5ed235","text":"Amazon SQS and DynamoDB","correct":false},{"id":"e8445389785666bd90da881eada7e373","text":"Amazon CloudFront and Amazon S3","correct":false}]},{"id":"bc69cb14-0b50-4173-925a-a9c2fdb00bb5","domain":"mon-trb","question":"You have multiple applications running on a large number of EC2 instances. You need to access the application logs from a single central location, what should you do?","explanation":"You can use Amazon CloudWatch Logs to monitor, store, and access your log files from Amazon Elastic Compute Cloud (Amazon EC2) instances, AWS CloudTrail, Route 53, and other sources. CloudWatch Logs enables you to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service. You can create CloudWatch custom metrics for your EC2 instance statistics by creating a script through the AWS Command Line Interface and then monitor that metric by pushing it to CloudWatch. However, custom metrics are only metrics or findings reported by running a script, they are not pushing log files into CloudWatch.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html","title":"What Is Amazon CloudWatch Logs?"},{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/cloudwatch-custom-metrics/","title":"Custom Metrics and CloudWatch"}],"answers":[{"id":"208fa683260008af411c8bfe394bb8bf","text":"Write a script to send the application logs to CloudWatch. Install the script on each of your application servers","correct":false},{"id":"f0d36f4f7323e9b431c82349dcc3ab89","text":"CloudTrail Logs","correct":false},{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":true},{"id":"458bb7239f53c3a09ada45ce8d2eb321","text":"CloudWatch custom metrics","correct":false}]},{"id":"87896ba2-d675-4fce-97b9-f144f05d42f1","domain":"security","question":"You are building an S3 hosted website and your website is accessing javascript and image files located in another S3 bucket. How can you enable this? ","explanation":"Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html","title":"Cross-Origin Resource Sharing (CORS)"}],"answers":[{"id":"39e38061c46bfab6a44c6c8b5482763f","text":"Cross Origin Resource Sharing (CORS)","correct":true},{"id":"bef5f130edd0f036b2ca659d3295d5c7","text":"IAM roles","correct":false},{"id":"0e0c1a7e0b6fe582226b82afc8eec89b","text":"S3 bucket policies","correct":false},{"id":"be48e3ddc7b57744c693982774a47dad","text":"S3 ACLs","correct":false}]},{"id":"7ff30792-25db-4803-a4db-867473e5ca8a","domain":"security","question":"In order to enable encryption at rest using EC2 and Elastic Block Store,  you must ________.","explanation":"To enable encryption, you must specify encryption when creating the EBS volume.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html","title":"About EBS Encryption"}],"answers":[{"id":"d8e355c7726e173ad29951d3461865d6","text":"Configure encryption when creating the EBS volume","correct":true},{"id":"aaed5dee4871b8256093659e8bbeba4a","text":"Configure encryption using the appropriate Operating Systems file system","correct":false},{"id":"64237cc9809266ebc9fb12b6cede9aa8","text":"Configure encryption using X.509 certificates","correct":false},{"id":"4bd8d581e477097d1396901aab8b3cf4","text":"Mount the EBS volume in to S3 and then encrypt the bucket using a bucket policy","correct":false}]},{"id":"af4f8b9c-bfe1-44dd-803f-d12581a91f6d","domain":"development","question":"You are developing a scalable application which will run in Docker on ECS. You would like to be able to run multiple tasks on the same ECS service. How should you approach this?","explanation":"Port mappings allow containers to access ports on the host container instance to send or receive traffic. Port mappings are specified as part of the container definition. Dynamic port mapping with an Application Load Balancer makes it easier to run multiple tasks on the same Amazon ECS service on an Amazon ECS cluster.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/dynamic-port-mapping-ecs/","title":"Dynamic Port Mapping for Amazon ECS"},{"url":"https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PortMapping.html","title":"Port Mapping for Amazon ECS"},{"url":"https://aws.amazon.com/blogs/compute/microservice-delivery-with-amazon-ecs-and-application-load-balancers/","title":"Run Containerized Microservices with Amazon ECS and Application Load Balancer"}],"answers":[{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":false},{"id":"e211f72442bce02b412217a3983c847f","text":"Dynamic Port Mapping","correct":true},{"id":"978e984e16276c17104b4c922731f3f8","text":"Virtual Port Mapping","correct":false},{"id":"f4a166b164c896d2e4f9aa43541f5c30","text":"Dynamic Port Wrapping","correct":false}]},{"id":"2863369f-3c52-497f-887b-1e6d5a13e5fe","domain":"security","question":"A developer needs to share an EBS volume with a second AWS account. What actions need to be performed to accomplish this task in the most optimal way?","explanation":"It is not possible to directly share an EBS volume with another account. In order to accomplish the required task, it is required to create an EBS volume snapshot and grant permissions to that snapshot to the second AWS account. Although EBS volume snapshots are stored in S3, they are not in a user-visible bucket. Sharing a private AMI with a second account does not meet the specific requirement as defined in the question.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modifying-snapshot-permissions.html","title":"Sharing an Amazon EBS Snapshot"}],"answers":[{"id":"823ae734c13e3b7ed146146637c1df42","text":"Create an EBS volume snapshot. Modify EBS snapshot permissions and add the second AWS account ID to share the snapshot. In the second AWS account, create an EBS volume from the snapshot.","correct":true},{"id":"683e6c4bef943d4c2e5871fcc39e1ebd","text":"Create an AMI from the EC2 instance. Modify image permissions and add a second AWS account ID to share the AMI. Ensure 'create volume' permissions are added. In the second AWS account, create an EC2 instance using the shared AMI.","correct":false},{"id":"d477177fe8b8bb5a16854f7c5632856d","text":"Create an EBS volume snapshot. Modify S3 bucket policy granting the second AWS account access to the S3 object of the snapshot. In the second AWS account, create an EBS volume from the S3 object.","correct":false},{"id":"f2cb6e39eb1e99f97c84895d0c6b0cc8","text":"Create an IAM policy granting necessary actions on the specific EBS volume. Add the second AWS account ID in the Principal element.","correct":false}]},{"id":"75298fe2-86e7-4945-b359-fa66efa511a5","domain":"deployment","question":"Your application is running on Docker in an Elastic Beanstalk. You have been asked to deploy a new version of the application code. What is the process for doing this?","explanation":"When you use the AWS Elastic Beanstalk console to deploy a new application or an application version, you'll need to upload a source bundle. Your source bundle must consist of a single ZIP file or WAR file which does not exceed 512 MB.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html","title":"Create an Application Source Bundle"}],"answers":[{"id":"f63680af566b899e62b6b0110b5677d7","text":"Log in to the EC2 instance, update the dockerfile and restart the container","correct":false},{"id":"ef19372b909be8f395f79dce7fd549c0","text":"Use the Elastic Beanstalk console to upload and deploy the new version of your application using a zip file containing your code","correct":true},{"id":"349146001f426f05effeb7bf24d3d9e3","text":"Delete your environment and redeploy using the new code","correct":false},{"id":"cb68a9fcd34702aca58b9c8e1ca910e9","text":"Log in to the underlying EC2 instance and replace the existing Docker image with the new code","correct":false}]},{"id":"9abb4110-4b7b-11ea-b77f-2e728ce88125","domain":"development","question":"You want to add a cross-origin resource sharing (CORS) configuration to one of your S3 buckets. Which of the following tabs should you choose to do so?","explanation":"To add a CORS configuration to your S3 bucket, you have to click the 'Permissions' tab and choose 'CORS configuration'. The 'Properties' tab is for configuring object settings such as versioning, transfer acceleration, and logging. The 'Management' tab is for managing object replication, analytics, and storage lifecycle. If you want to simplify bucket access by creating endpoints, you choose 'Access points'.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/add-cors-configuration.html","title":"How Do I Add Cross-Domain Resource Sharing with CORS?"}],"answers":[{"id":"d08ccf52b4cdd08e41cfb99ec42e0b29","text":"Permissions","correct":true},{"id":"9fc2d28c05ed9eb1d75ba4465abf15a9","text":"Properties","correct":false},{"id":"902c305d02b28c2f6199601e7128ed36","text":"Access points","correct":false},{"id":"fe4dbcab9b910577e5035e97ac068dae","text":"Management","correct":false}]},{"id":"08861bdf-6813-43f1-9def-4255492b4533","domain":"mon-trb","question":"Your application is using SQS to send and receive messages, your application needs to receive the messages as soon as they arrive and you need to ensure the architecture is as cost efficient as possible. Which of the following approaches will optimise the cost and performance of the application?","explanation":"In almost all cases, Amazon SQS long polling is preferable to short polling and results in higher performance and reduced cost in the majority of use cases.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"SQS FAQs"}],"answers":[{"id":"8757c7e091bc29e7b9225334f00531ac","text":"Reduce the total number of message queues","correct":false},{"id":"33e24a8e438593d0ed4994ce9ea68ccd","text":"Enable Long Polling","correct":true},{"id":"64dab6674843dc03406bdc90b1c5b21d","text":"Lower the message Visibility Timeout","correct":false},{"id":"9ef993bf7e61fa02b5f6ac0fc8da6b18","text":"Enable Short Polling","correct":false}]}]}}}}
