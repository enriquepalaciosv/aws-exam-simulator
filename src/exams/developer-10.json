{"data":{"createNewExamAttempt":{"attempt":{"id":"697d1e8e-dd8d-43bf-bef8-60e63f869c48"},"exam":{"id":"eb888c89-7bf1-4f7a-9033-fdcfce3b4608","title":"AWS Certified Developer - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"0c35721a-5f70-44fa-b450-3a734cffe32d","domain":"development","question":"You are working on an application which runs inside a Docker container. All your images are stored in a repository named mydockerrepo AWS ECR. Which of the following commands could you use to pull the Docker image to your local workstation?","explanation":"If you would like to run a Docker image that is available in Amazon ECR, you can pull it to your local environment with the docker pull command.","links":[{"url":"https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-pull-ecr-image.html","title":"Pulling an Image From ECR To Your Local Machine"}],"answers":[{"id":"d2b7e2822cfd2c34e140e5a2b38a8844","text":"docker clone aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":false},{"id":"2adf07d0af0f83b4c0e540b293950cae","text":"docker pull aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":true},{"id":"90dc63a057ad01f414275df9fe070ea1","text":"docker get aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":false},{"id":"3de38211ddfad5912196a8d85b693d6b","text":"docker push aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":false}]},{"id":"2671403f-a54f-4822-8a1b-fd45645826fe","domain":"development","question":"A transport company uses a mobile GPS application to track the location of each of their 60 vehicles. The application records each vehicle's location to a DynamoDB table every 6 seconds. Each transmission is just under 1KB and throughput is spread evenly within that minute. How many units of write capacity should you specify for this table?","explanation":"Writing to the database every six seconds, there are 10 writes/minute/vehicle. There are sixty vehicles in the fleet, so there are 600 writes/minute overall. 600/60 seconds = 10 writes/second.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html","title":"Throughput Capacity for Reads and Writes"}],"answers":[{"id":"f899139df5e1059396431415e770c6dd","text":"100","correct":false},{"id":"072b030ba126b2f4b2374f342be9ed44","text":"60","correct":false},{"id":"d3d9446802a44259755d38e6d163e820","text":"10","correct":true},{"id":"d490d7b4576290fa60eb31b5fc917ad1","text":"600","correct":false}]},{"id":"331062f4-325b-4205-8f7b-0d7af956d7d2","domain":"development","question":"How does API Gateway handle SOAP?","explanation":"API Gateway supports the legacy SOAP protocol, which returns results in xml format rather than JSON, in pass-through mode.","links":[{"url":"https://www.rubix.nl/blogs/how-configure-amazon-api-gateway-soap-webservice-passthrough-minutes","title":"Configuring SOAP Web Service Pass-Through with API Gateway"}],"answers":[{"id":"1deb9d05d2561d899fbf9b7ddc218dcd","text":"The API Gateway converts the SOAP API to a RESTful API","correct":false},{"id":"59028be6a7a6ca137dfcc0ef0c6b7415","text":"The API gateway converts the xml response received by the SOAP API to JSON","correct":false},{"id":"2ea57db3530b67b7c9d0a760772338e8","text":"SOAP is handled as web service pass-through","correct":true},{"id":"9421a86b8ea1ce095c60a8551f33914c","text":"SOAP is deprecated and not supported","correct":false}]},{"id":"b9cada23-dafc-48d0-8dba-cff32007e3b2","domain":"security","question":"You are developing a mobile web application using Lambda and API Gateway which stores persistent data in a DynamoDB table. You want to configure the application to allow new users to sign-up to your website using their Google mail credentials. Which is the best approach?","explanation":"Cognito is the recommended approach for user sign-up and sign-in for mobile applications which allow access to users with Facebook, Google or Amazon.com credentials. User pools are user directories that provide sign-up and sign-in options for your app users. Identity pools enable you to grant your users access to other AWS services.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/what-is-amazon-cognito.html","title":"What Is Cognito?"}],"answers":[{"id":"2f52b4f250a2df2a6b4cc5b1e4f2ded8","text":"Configure AD federation with Google as the relying party","correct":false},{"id":"38ad8b2eb26395b051faf111282db4de","text":"Use a Cognito Identity Pool to handle new user sign-up","correct":false},{"id":"3a5db953c143ae9ceb70cfeda3a7d477","text":"Configure a Cognito User Pool to handle new user sign-up","correct":true},{"id":"4e37a1d7f9c18456157c1080b7628ef8","text":"Write custom code to act as an identity broker to federate with Google","correct":false}]},{"id":"914fca77-6b5e-4b8e-afd1-d6e423835341","domain":"refactoring","question":"Your application is trying to upload a 6TB file to S3 and you receive an error message telling you that your proposed upload exceeds the maximum allowed object size. What is the best way to accomplish this file upload?","explanation":"Amazon S3 allows a maximum object size of 5TB. However, objects 5GB or larger are required to be uploaded using the multipart upload API.","links":[{"url":"https://aws.amazon.com/s3/faqs/","title":"S3 FAQs"},{"url":"https://aws.amazon.com/blogs/aws/amazon-s3-multipart-upload/","title":"Multipart upload"}],"answers":[{"id":"73d0d8288e849f30fc95922108ef6a15","text":"Use the Multipart Upload API for this object.","correct":false},{"id":"07b09839951d99bc4114d8fdf4c16454","text":"Use the S3 LargeObjectUpload API.","correct":false},{"id":"eac600adbe8c5aff9f9bc513cea6c0f0","text":"Contact AWS support to increase the maximum size of your S3 object.","correct":false},{"id":"199f05e3820037e7815b1de805cc4d7d","text":"You cannot fix this, as the maximum size of an S3 object is 5TB.","correct":true}]},{"id":"2689a73b-04ed-4719-9cdf-49c4ffe3eb17","domain":"deployment","question":"A developer is deploying a new application to ECS. The application requires permissions to send messages to an SQS queue. \n\nWhich role should the developer apply the policy to so that the application can access the SQS queue?","explanation":"The policy must be attached to the ECS Task's execution role to allow the application running in the container access SQS.","links":[{"url":"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html","title":"Amazon ECS Task Execution IAM Role"}],"answers":[{"id":"2d64ba22b9f8e2998aed499099374359","text":"The execution role attached to the ECS Service.","correct":false},{"id":"29aefbd6a89941ca26d2ef879d25237c","text":"The execution role attached to the ECS Task.","correct":true},{"id":"2413a4993d7f9395b5ddf84bc7b51b62","text":"The execution role attached to the ECS Container.","correct":false},{"id":"d89a15f255b7e5a2b6cfe8aa7d628173","text":"The execution role attached to the ECS Cluster.","correct":false}]},{"id":"54fce7fa-7d85-4dde-92e6-4e6d1e12327c","domain":"deployment","question":"You have developed an application to run on Amazon EC2. Users have increased and you've found latency issues for users from various geographic locations. You decide to create a CloudFormation template of the application's environment in order to streamline application launch in other AWS Regions to improve performance for users. When creating the CloudFormation template, what is one thing you have to ensure for the resources to launch successfully?","explanation":"AWS CloudFormation templates that declare an Amazon Elastic Compute Cloud (Amazon EC2) instance must also specify an Amazon Machine Image (AMI) ID, which includes an operating system and other software and configuration information used to launch the instance. The correct AMI ID depends on the instance type and region in which you're launching your stack. And IDs can change regularly, such as when an AMI is updated with software updates. AMIs are stored in a region and cannot be accessed in other regions. To use the AMI in another region, you must copy it to that region. IAM roles are valid across the entire account. AWS CloudFormation StackSets let you provision a common set of AWS resources across multiple accounts and regions with a single CloudFormation template. Tags are not a universal namespace and are used as metadata or labels for your resources.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/walkthrough-custom-resources-lambda-lookup-amiids.html","title":"Walkthrough: Looking Up Amazon Machine Image IDs"}],"answers":[{"id":"fbbfa698853564b32d5e961010c48e36","text":"Ensure the AMIs referenced in the template correspond to the AMI IDs in the desired Region.","correct":true},{"id":"c2a7b7d4dab7e7ef0dc554e6054d7f77","text":"Create and validate the right IAM roles in the template in the desired Region.","correct":false},{"id":"5b8b4dc7a6004401e2e0fb8002dfd3c7","text":"Ensure the tags of the resources are not the same in the new Region as they are a universal namespace.","correct":false},{"id":"e2c092a149099f0d0ae393acb19afd6d","text":"This is not possible. CloudFormation templates can be launched only in a single region.","correct":false}]},{"id":"53899b37-d74d-42b3-9be9-4f9f0d37155d","domain":"security","question":"Your company has a corporate identity store used to authenticate its users. Your company also has resources running on AWS. Your admin has created IAM roles and an identity broker that sits between your corporate users and your AWS resources to manage the authentication and authorization process without needing to re-create all your users as IAM users in AWS. Your CISO asked you to summarize the AWS identity federation process to ensure compliance with your applications' security. Which of the following statements correctly describes the authentication process?","explanation":"Users might already have identities outside of AWS, such as in your corporate directory. However, those users might need to work with AWS resources (or work with applications that access those resources). If so, these users also need AWS security credentials in order to make requests to AWS. The process can be summarized as follows: 1. The enterprise user accesses the identity broker application. 2. The identity broker application authenticates the users against the corporate identity store. 3. The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials. 4. Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console. A sample identity broker application for use with Microsoft Active Directory is provided by AWS. Details on page 22 of the URL link.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"2870fde359fa2a54b4e99faccf44cb32","text":"The enterprise user accesses the identity broker application.  Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console. The identity broker application authenticates the users against the corporate identity store. The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials.","correct":false},{"id":"fe4c072b395ee1d0521094c0d1b4a005","text":"The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials. The enterprise user accesses the identity broker application. The identity broker application authenticates the users against the corporate identity store. Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console.","correct":false},{"id":"26461a0c133d31dd86bb803278256573","text":"The enterprise user accesses the identity broker application. The identity broker application authenticates the users against the corporate identity store. The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials. Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console.","correct":true},{"id":"9b6e91665534238e195af79b94bb3233","text":"The enterprise user accesses the identity broker application. The identity broker application authenticates the users against the corporate identity store. Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console. The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials.","correct":false}]},{"id":"bd3b8069-4ee1-480b-8738-d0683a3de962","domain":"security","question":"A company security team wants to implement a solution for securely storing RDS database credentials.  The solution should provide automatic rotation of database credentials.  What AWS service can the team use to meet these requirements?","explanation":"AWS Secrets Manager is an AWS service that can be used to securely store, retrieve, and automatically rotate database credentials. AWS Secrets Manager has built-in integration for RDS databases. Applications use Secrets Manager API's to retrieve database credentials, enabling secure storage of sensitive information outside of the application code. Systems Manager Parameter Store provides secure storage of sensitive information. However, it does not provide automatic credentials rotation capability specified as a requirement in the question scenario. Key Management Service (KMS) is used for management of cryptographic encryption keys, not for storage of sensitive information. Resource Access Manager is not applicable here as it is used for managing access to AWS resources between multiple accounts.","links":[{"url":"https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html","title":"What Is AWS Secrets Manager?"}],"answers":[{"id":"b77e6ac1dd339ec1c0d94107e6c9d3d2","text":"AWS Systems Manager Parameter Store","correct":false},{"id":"7c09430feea9bf5bdf657bd178ce574c","text":"AWS Resource Access Manager","correct":false},{"id":"fcba7bd474eb1fdf49705827bbb6f28c","text":"AWS Key Management Service","correct":false},{"id":"7898cb92c418aeed6974ede9cb146462","text":"AWS Secrets Manager","correct":true}]},{"id":"bb8e72f1-89d8-436d-9e0b-743e86abe4d9","domain":"development","question":"A CustomerOrders DynamoDB table contains attributes Customer Name (PK), Order Item, and Cost. What DynamoDB operation would be used to find all orders with cost greater than $10?","explanation":"A query operation is used to search for an item using a primary key value and so requires a Customer Name value to be specified. This would limit results to a specific customer and would not return all items with cost greater than $10. On the other hand, a scan operation reads every item in a table. A filter expression parameter can be used to narrow down the results based on some required criteria (Cost of the item in this case). We do not want to use projection-expression parameter as it is used to limit what attributes are returned as part of the results (not to filter the results).","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.html","title":"Working with Queries in DynamoDB"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html","title":"Working with Scans in DynamoDB"}],"answers":[{"id":"7b572c69a9cc3a5fc180c5ae6ec3fde0","text":"scan operation with “--filter-expression” parameter","correct":true},{"id":"919fd8f793713cd1732ad46d123afb96","text":"query operation with “--filter-expression” parameter","correct":false},{"id":"b33f1b1eeb8c0862730ccd17773fa0ba","text":"query operation with “--key-condition-expression” parameter","correct":false},{"id":"66838b7caff8435bce812744e2907fd5","text":"scan operation with “--projection-expression” parameter","correct":false}]},{"id":"8b887631-86bd-436d-adee-4e2ba3b02111","domain":"security","question":"You have an application running on multiple EC2 instances, however every time an instance fails, your users complain that they lose their session. What can you do to prevent this from happening?","explanation":"There are various ways to manage user sessions including storing those sessions locally to the node responding to the HTTP request or designating a layer in your architecture which can store those sessions in a scalable and robust manner. Common approaches used include utilizing Sticky sessions or using a Distributed Cache for your session management. In order to address scalability and to provide a shared data storage for sessions that can be accessed from any individual web server, you can abstract the HTTP sessions from the web servers themselves. A common solution for this is to leverage an In-Memory Key/Value store such as ElastiCache.","links":[{"url":"https://aws.amazon.com/caching/session-management/","title":"Session management in AWS"}],"answers":[{"id":"76fc6bddee6b0f8d088ea5cbe4e57160","text":"Store session state in S3","correct":false},{"id":"b225818943ba4680b8e7dc9d9c376359","text":"Store session state in RDS","correct":false},{"id":"ef4fd36fa55c3c499f3fffa82a0c95e8","text":"Store session state in on the Elastic Load Balancer","correct":false},{"id":"b193b1caff1bda86125cc326ca1058ac","text":"Store session state on a dedicated EC2 instance","correct":false},{"id":"89230492f141a4f85234c624287bb96a","text":"Store session state in ElastiCache","correct":true}]},{"id":"f8566b59-119b-4a20-9402-3f0b8ab8cf73","domain":"development","question":"You are developing a serverless retail application which includes a mobile app. All your product data is stored in DynamoDB, whilst the application itself runs on Lambda. The product catalogue is updated once every 6 months, to reflect seasonal stock and price updates. Each database read is 3KB in size and the application performs around 20 reads per second. Which of the following DynamoDB settings would you recommend?","explanation":"A read capacity unit represents one strongly consistent read per second, or two eventually consistent reads per second, for an item up to 4 KB in size. Eventually consistent reads provide greater throughput than strongly consistent. In this case the data changes infrequently, so eventually consistent is a good option.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ProvisionedThroughput.html#ProvisionedThroughput.CapacityUnits.Read","title":"DynamoDB Provisioned throughput"}],"answers":[{"id":"744a67c638333d2ab1dc7063094dae67","text":"Configure the table with 10 read capacity units","correct":true},{"id":"1cff2c2aa83b7775e9cd6b16efc7c78a","text":"Use strongly consistent reads","correct":false},{"id":"e35b7f703854cc79bba03d472f38eaca","text":"Configure your application to use a query rather than a scan","correct":false},{"id":"b35bcd1ffd25ca5d2feccdfaf102e6bf","text":"Configure the table with 20 read capacity units","correct":false},{"id":"bfd40f3271d850d341d74d81e5e0208b","text":"Configure the table to use high performance reads","correct":false},{"id":"d983271d85e1d9a838703052106e6190","text":"Use eventually consistent reads","correct":true}]},{"id":"868cb94f-ce60-4590-bfd2-60e8295cc413","domain":"security","question":"You are developing a online-banking website which will be accessed by a global customer base. You are planning to use CloudFront to ensure users experience good performance regardless of their location. The Security Architect working on the project asks you to ensure that all requests to CloudFront are encrypted using HTTPS. How can you configure this?","explanation":"Viewer Protocol Policy defines the protocols which can be used to access CloudFront content","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.html","title":"Requiring HTTPS for Communication Between Viewers and CloudFront"}],"answers":[{"id":"c40022183e6d5dd97e4c778332064ed2","text":"Set the Viewer Protocol Policy to redirect HTTP to HTTPS","correct":true},{"id":"659099387a57b1f316abf3c6afac459d","text":"Set the Session Protocol Policy to redirect HTTP to HTTPS","correct":false},{"id":"052066815497ced9f9852e55d66c6782","text":"Set the Request Protocol Policy to redirect HTTP to HTTPS","correct":false},{"id":"ae41866f6b2df14a344847e9629076db","text":"Set the User Protocol Policy to redirect HTTP to HTTPS","correct":false}]},{"id":"f7a67868-ec20-40ae-a334-1bca9d02bdb7","domain":"deployment","question":"You are developing a website which allows customers to purchase tickets to popular sporting events. Your application uses S3 for static web hosting, Lambda for business logic, stores transaction data in RDS and uses DynamoDB for product and stock information. After the customer has paid for their purchase, a message is sent to an SQS queue to trigger a confirmation email to be sent out to the customer including an e-ticket for their chosen event. You want to send out the email as soon as the payment has been processed, however during testing you discover that the confirmation emails are being processed a few seconds before the stock control database has finished updating. This sometimes results in selling the same ticket twice. How can you quickly fix this without re-engineering the application?","explanation":"Delay queues let you postpone the delivery of new messages to a queue for a number of seconds. If you create a delay queue, any messages that you send to the queue remain invisible to consumers for the duration of the delay period. The default (minimum) delay for a queue is 0 seconds. The maximum is 15 minutes.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"dc7f3b8fe45a2bd74a545027f1178792","text":"Use an SQS delay queue to let you postpone the delivery of SQS messages by a few seconds","correct":true},{"id":"2c519c2e315e56078976351bc313bbf9","text":"Use a FIFO queue to ensure the messages are always processed in the correct order","correct":false},{"id":"953522fe58e17a4a74978232a8b50608","text":"Set the delay flag on the queue to 5 seconds, to ensure messages are not processed too quickly","correct":false},{"id":"93afc9503f6f41866e3fb6bf957bc816","text":"Use Kinesis to stream the SQS messages, adding a delay of a few seconds","correct":false}]},{"id":"9feaacea-e1e9-4fc6-9602-e7d8c50faa0d","domain":"development","question":"You have a simple, stateless Python application which processes the contents of an S3 bucket once an hour and takes about 6 minutes to complete once started. Which AWS service should you run this application on in order to provide the most reliable and cost effective solution?","explanation":"The question states that the application is to run once every hour, which immediately means we should be looking for an option which only utilizes resources when needed.  Lambda is the only option in the above list which bills you only when an application is running. The EC2 and ECS options will bill for all resources, regardless of whether the application is running or not.  S3 should be discounted because although you can host static Websites, you cannot run Python applications from it.","links":[{"url":"https://aws.amazon.com/lambda/faqs/","title":"Amazon Lambda FAQs"}],"answers":[{"id":"f31120d65a588f0acc604ac80cf32c3c","text":"Make the application a Lambda function and create a Scheduled Event Trigger set to 1 hour","correct":true},{"id":"640c9577ed0b4efae9a09e7f32b9f36d","text":"Create an ECS Cluster and run the application as a service on that cluster","correct":false},{"id":"c0ee3176dc24aa0728823bd03bd0936b","text":"Create an Auto Scaling Group for an EC2 instance. Run the application on that instance with crontab set to 1 hour","correct":false},{"id":"4a155d7bbaa5f82abb58d55f1274a1cd","text":"Create a CloudFront endpoint and point it to an S3 bucket. Run the application from that bucket","correct":false}]},{"id":"a45d7c37-eb4b-4a39-9fb2-d5298cb40491","domain":"security","question":"You work for a large I.T. recruitment company that are launching a mobile application which will allow job seekers to apply for jobs online and attach their résumé to their application. Users will be able to log in to their account using Facebook and the application stores their contact and profile details in a DynamoDB table. Which of the following approaches would you recommend for enabling the users to gain access to view and update their data?","explanation":"With Web Identity Federation, you don't need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well-known external identity provider (IdP), such as Login with Amazon, Facebook, Google. For most Web Identity Federation scenarios, we recommend that you use Amazon Cognito because it acts as an identity broker and does much of the federation work for you.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html","title":"Web Identity Federation"}],"answers":[{"id":"3b5209dda18fcdea46a196b06d17c586","text":"Configure Web Identity Federation with Cognito","correct":true},{"id":"ff1fd8b56d2c836edd2795619fa9b681","text":"Configure Web Identity Federation with ADFS","correct":false},{"id":"f11ad00f139ee7fd7ecde821e3769c1a","text":"Configure cross-account access between the mobile app and DynamoDB ","correct":false},{"id":"e0bc3be9eb85e3ef437aac25d15f5be4","text":"Allow customers to embed user credentials in settings of the mobile app","correct":false}]},{"id":"1afa6661-6523-49f7-912c-46b740714117","domain":"deployment","question":"You are deploying a number of Lambda functions using CloudFormation. Which section of the CloudFormation template should you use to define your Lambda resources?","explanation":"Use the Resources section of the CloudFormation template to define the resources you are going to deploy, e.g. EC2 instances, S3 buckets, IAM roles, Lambda functions etc.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"},{"url":"https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-lambda-state-machine-cloudformation.html#lambda-state-machine-cfn-step-2","title":"Example CloudFormation Template"}],"answers":[{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false}]},{"id":"eeabb3b1-06bd-4a2f-89e9-425c07670c09","domain":"security","question":"Your application uses the STS API call AssumeRoleWithWebIdentity to enable access for users who have authenticated using a Web ID provider. Which of the following best describe what is returned by a successful call to AssumeRoleWithWebIdentity?","explanation":"AssumeRoleWithWebIdentity returns a set of temporary credentials, giving the user temporary access to AWS. It also returns an Amazon Resource Name (ARN) and the assumed role ID, which are identifiers that you can use to refer to the temporary security credentials.","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithWebIdentity.html","title":"STS: AssumeRoleWithWebIdentity"}],"answers":[{"id":"5cf1fe7b63a8a99d7d3457d8b021e2c4","text":"AssumeRoleWithWebIdentity returns an ARN of the IAM user that the user is allowed to assume temporarily","correct":false},{"id":"c4dee05a317f3836954c0577fb8df356","text":"AssumeRoleWithWebIdentity returns an assumed role ID which the user is allowed to assume temporarily","correct":false},{"id":"33401d97362173f45bb04e5a8c41b8a3","text":"AssumeRoleWithWebIdentity returns a set of temporary credentials (access key ID, secret access key and security token) which give temporary access to AWS services","correct":true},{"id":"b80ac03d28d57f31929047a4ce86a48c","text":"AssumeRoleWithWebIdentity returns an ARN of the IAM role that the user is allowed to assume temporarily","correct":false}]},{"id":"36bd2e7a-adf7-4dae-ad6f-5e04d3ca873e","domain":"security","question":"You work for a large government agency which is conducting research for a top secret defense project. You are using SQS to handle messaging between components of a large, distributed application. You need to ensure that confidential data relating to your research is encrypted by the messaging system, which of the following services can you use to centrally manage your encryption keys?","explanation":"You can use a CMK to encrypt and decrypt up to 4 KB (4096 bytes) of data. Typically, you use CMKs to generate, encrypt, and decrypt the data keys that you use outside of AWS KMS to encrypt your data. This strategy is known as envelope encryption. CMKs are created in AWS KMS and never leave AWS KMS un-encrypted. To use or manage your CMK, you access them through AWS KMS.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys","title":"KMS Concepts"}],"answers":[{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"fa9c36d7e57eae51ce84cfd30a7346a3","text":"Systems Manager Parameter Store","correct":false},{"id":"4a4df63c87b4f42081b846d9b9189984","text":"KMS","correct":true},{"id":"ea52c36203c5f99c3ce2442d531b1a22","text":"SSL","correct":false},{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":false}]},{"id":"c1fc5f56-f74e-405f-a974-d9bb2e2c57e6","domain":"deployment","question":"You have deployed a new version of your Lambda function, however during testing, you notice that  your application is not behaving as expected. How can you roll back to the previous version of your code?","explanation":"Remapping the PROD alias to the previous version will allow you to quickly roll back","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda versioning and Aliases"}],"answers":[{"id":"aa97bfdc9437ce44352de51699501c4d","text":"Make a new version of your function using the original Lambda code","correct":false},{"id":"60682da7d7f6df421c71e7e42cf4b227","text":"Redeploy your original code to $LATEST","correct":false},{"id":"1ba636d1ad4c4e2a9239fc75d17ffc41","text":"Update the $LATEST alias to point to the previous version of your function","correct":false},{"id":"28ab809ddc3a2aee352db2592bca020a","text":"Remap the PROD alias to point to the previous version of your function","correct":true}]},{"id":"4750f3bd-de92-4efb-ad08-06c9ea71eccb","domain":"refactoring","question":"Kinesis allows consumer applications to consume records in which order?","explanation":"Kinesis gives you the ability to consume records according to a sequence number applied when data is written to the Kinesis shard","links":[{"url":"https://aws.amazon.com/kinesis/data-streams/faqs/","title":"Kinesis FAQ"}],"answers":[{"id":"689f6f887e0c13fb07b437de23303cac","text":"Last In First Out","correct":false},{"id":"cb1ab21304b72197113dbe18c491e9c2","text":"According a sequence number assigned when the record is written to the stream","correct":true},{"id":"e71e8f5a50819b4773c68991d0c9f602","text":"Records are processed in no particular order","correct":false},{"id":"b1e05f0db70da1b8dee8592d942ed2e1","text":"According to the timestamp assigned when the record is written to the stream","correct":false}]},{"id":"21efb969-377d-45b1-a907-8994e94aa26b","domain":"development","question":"An organization is considering making use of AWS Fargate in their next project. Which of the following statements best describes AWS Fargate?","explanation":"AWS Fargate is a compute engine for Amazon ECS that allows you to run containers without having to manage servers or clusters.","links":[{"url":"https://aws.amazon.com/fargate/","title":"AWS Fargate"}],"answers":[{"id":"940863780b5c57669b92b1fc551543ca","text":"Automates management of the control plane within a Kubernetes cluster.","correct":false},{"id":"fbe3eadaa96811fdb58081b395eb6164","text":"Stores Docker containers within a registry, making them available for use by AWS ECS.","correct":false},{"id":"5c10facdecd8cb3ff129afb77d315739","text":"Deploys Docker containers within AWS, without having to manage underlying EC2 instances.","correct":true},{"id":"9996f92567fdefae4123ba718e107bbf","text":"Deploys Compute logic to an AWS Edge location.","correct":false}]},{"id":"33d838eb-6e2a-499f-b1a0-0d385c20732a","domain":"deployment","question":"You have deployed an application using Elastic Beanstalk and your code is running in a Docker container. What is the process for upgrading this application?","explanation":"When you use the Elastic Beanstalk console to deploy a new application or an application version, you'll need to upload a source bundle. Your source bundle must consist of a single ZIP file or WAR file which does not exceed 512 MB. By using Docker with Elastic Beanstalk, you have an infrastructure that automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html","title":"Create an Application Source Bundle"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html","title":"Deploying Elastic Beanstalk Applications from Docker Containers"}],"answers":[{"id":"50ca13bdc867153ec83d6d066d4950b3","text":"Use CodeBuild to deploy the new code to the docker container","correct":false},{"id":"c9bd7c34b6482e6240a3a8a6404e5d09","text":"Upload your code to Elastic Container Registry and select the \"Deploy Now\" option in Elastic Container Service console","correct":false},{"id":"f65c3a605a6af1f8f362fab1debc50b2","text":"Upload your code to CodeCommit and select the \"Deploy Now\" option in Elastic Container Service console","correct":false},{"id":"9142b51f935ad294eb31a909cbe9336e","text":"Upload a zip file containing the new version of your code using the \"Upload and Deploy\" button in the ElasticBeanstalk console","correct":true}]},{"id":"cbd79fed-da8e-4342-9ce7-e646673c2690","domain":"deployment","question":"A developer is creating a CloudFormation template to deploy an application stack. The administrator password for the application needs to be configured at CloudFormation runtime. What CloudFormation section should be used for this requirement?","explanation":"CloudFormation template parameters section is used to pass input values to the template.  The template parameters can be set to custom values when the template is used to create a new stack. A parameter for the administrator password can be used to meet the question requirement. Metadata section is used to provide information about the template. Mappings section is used to define key and matching value mapping pairs. Resources section is used to specify resources that constitute the stack and need to be provisioned by the template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"Template Anatomy"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html","title":"Parameters"}],"answers":[{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":true},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":false},{"id":"ce21470ab49d1d1976bc3dc72438c183","text":"Metadata","correct":false}]},{"id":"24137be2-c9b8-4be2-a4f0-0a5476fc15f9","domain":"development","question":"A developer has been tasked with migrating a large legacy web application, written in C++, to AWS. The developer wants to benefit from using Elastic Beanstalk to simplify the management of the infrastructure.\n\nWhich of the following methods would allow the developer to migrate the application with the least amount of work?\n","explanation":"Elastic Beanstalk supports Docker containers and custom AMIs via Packer. Both would allow the legacy application to be wrapped in a layer of abstraction such that Elastic Beanstalk itself would not need to support the specific language of the legacy application.\n\nThe Go platform only supports applications written in Go.\n\nThe application could be re-written in Node.js, but as it's a large application, a full rewrite is unlikely to require the least amount of work.\n\nElastic Beanstalk cannot be used to manage Lambda functions.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html","title":"Docker on Elastic Beanstalk"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/custom-platforms.html","title":"Packer with Elastic Beanstalk"}],"answers":[{"id":"8711e00909d504f51f9e7cc0aea8ed4d","text":"Use Packer to generate a custom AMI that contains the application, which can then be deployed via Elastic Beanstalk.","correct":true},{"id":"dadd577f7c15163f58854c17403e2a6d","text":"Use Docker to containerize the application, which can then be deployed via Elastic Beanstalk.","correct":true},{"id":"ea130ff77bca2e340acf49c464cdd620","text":"Rewrite the application in Node.js, which can then run natively via Elastic Beanstalk.","correct":false},{"id":"37d73c08ebaf765061f6ad4fe756430a","text":"Create a custom Lambda layer with a C++ runtime, which can be called from within Elastic Beanstalk.","correct":false},{"id":"680517836f5d3fd52719bcc51f4f57e9","text":"Use the Go platform, which can support any compiled language such as C++.","correct":false}]},{"id":"af4f8b9c-bfe1-44dd-803f-d12581a91f6d","domain":"development","question":"You are developing a scalable application which will run in Docker on ECS. You would like to be able to run multiple tasks on the same ECS service. How should you approach this?","explanation":"Port mappings allow containers to access ports on the host container instance to send or receive traffic. Port mappings are specified as part of the container definition. Dynamic port mapping with an Application Load Balancer makes it easier to run multiple tasks on the same Amazon ECS service on an Amazon ECS cluster.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/dynamic-port-mapping-ecs/","title":"Dynamic Port Mapping for Amazon ECS"},{"url":"https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_PortMapping.html","title":"Port Mapping for Amazon ECS"},{"url":"https://aws.amazon.com/blogs/compute/microservice-delivery-with-amazon-ecs-and-application-load-balancers/","title":"Run Containerized Microservices with Amazon ECS and Application Load Balancer"}],"answers":[{"id":"978e984e16276c17104b4c922731f3f8","text":"Virtual Port Mapping","correct":false},{"id":"f4a166b164c896d2e4f9aa43541f5c30","text":"Dynamic Port Wrapping","correct":false},{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":false},{"id":"e211f72442bce02b412217a3983c847f","text":"Dynamic Port Mapping","correct":true}]},{"id":"3eb49e2e-25b6-4fe6-8bbe-e3ccedcd1efd","domain":"security","question":"A developer is looking to implement a load balancing solution for web-based service oriented application deployed in AWS EC2. The solution must support path based routing and all communication to the users must be encrypted. What is the most performant method to achieve these requirement?","explanation":"The application requirement states support for path based routing. This means that we must use an Application Load Balancer as Network Load Balancer does not have this feature. It is best practice to deploy the SSL certificates on the Load Balancer. This implements SSL termination on the load balancer and off-loads this task from the application, thus reducing the load on EC2 instances. Additionally, it removes the requirement of distributing the certificate to all target EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html","title":"Create an HTTPS Listener for Your Application Load Balancer"}],"answers":[{"id":"b97b895cbdc513c48c5bfb7564a38aa7","text":"Use Network Load Balancer. Deploy SSL certificates on the EC2 instances.","correct":false},{"id":"7ebcbebf7f00c8f17f377813b31cc76e","text":"Use Network Load Balancer. Deploy SSL certificates on the Network Load Balancer.","correct":false},{"id":"a5a020608230cb06058ddd6291c7886a","text":"Use Application Load Balancer. Deploy SSL certificates on the EC2 instances.","correct":false},{"id":"206131d0e41aa9e13214ac701d6f08e2","text":"Use Application Load Balancer. Deploy SSL certificate on the Application Load Balancer.","correct":true}]},{"id":"235fa5cd-42b5-4017-af9a-e62d0503651a","domain":"security","question":"You are working on a Lambda function which needs to access data in RDS, which of the below are valid approaches for securely storing the encrypted database connection strings and other secrets which your function needs to use?","explanation":"Parameter Store provides secure storage for configuration data, connection strings, passwords and secrets management. None of the other options are secure.","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html","title":"AWS Systems Manager Parameter Store"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/tutorial-env_console.html","title":"Create a Lambda Function Using Environment Variables To Store Sensitive Information"}],"answers":[{"id":"913d4a9f910c7f6b836d623b39131480","text":"Use Systems Manager Parameter Store","correct":true},{"id":"ca7c47bd30833fb42e5bc78f6c7583be","text":"Use Lambda Environment Variables","correct":true},{"id":"53708b71a9f9d0c3994b3bd1d470b254","text":"Use DynamoDB to store the encrypted connection string and secrets","correct":false},{"id":"f2523ec5429fa4e1be124d650a69a0f5","text":"Store the encrypted connection string and other secrets in S3","correct":false}]},{"id":"1c37eac2-4401-11ea-b77f-2e728ce88125","domain":"security","question":"Which of the following protocols are used to set up secure connections to AWS CodeCommit repositories?","explanation":"AWS allows you to use either the HTTPS or the SSH protocol to connect to CodeCommit repositories. There’s no option to select HTTP or RDP connections.","links":[{"url":"https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up.html","title":"Setting Up for AWS CodeCommit"}],"answers":[{"id":"293c9ea246ff9985dc6f62a650f78986","text":"HTTP","correct":false},{"id":"a66d0b3ece299ba53eafac86750cfb4a","text":"RDP","correct":false},{"id":"765553e6c7ac8592c389acb9878a050a","text":"SSH","correct":true},{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":true}]},{"id":"d38a2534-f7bb-4cc2-9b9a-0c50dfb7707b","domain":"security","question":"You are attempting to analyse the CloudWatch metrics for a number of your application servers, however when you try to view the metrics you cannot access them, however one of your colleagues is able to access them without any issues. What could be the problem?","explanation":"Access to Amazon CloudWatch Logs requires credentials that AWS can use to authenticate your requests. Those credentials must have permissions to access AWS resources, such as to retrieve CloudWatch Logs data about your cloud resources.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/auth-and-access-control-cw.html","title":"CloudWatch Access Control"}],"answers":[{"id":"691a929a32273fce2328658fc4c41fa6","text":"Your EC2 instance role does not have permission to push the metrics to CloudWatch","correct":false},{"id":"a0ff1e54243f914c3324d8826543cdd2","text":"Your IAM user doesn't have permission to view CloudWatch metrics","correct":true},{"id":"2578745b37e7d610c9f6227f920c4cb5","text":"CloudWatch doesn't have permission to collect the metrics","correct":false},{"id":"dcd1178c83830f41078c6b19fcd33f05","text":"The CloudWatch agent has stopped running","correct":false}]},{"id":"ba5e871c-930d-46d2-9eaf-32c2f6cb4de9","domain":"security","question":"You are developing a batch process job on Amazon EMR. The EMR instances need to access data stored in Amazon RDS in order to initialize the batch processing. The application code ran properly during testing but is not able to properly retrieve data from the RDS instance as there appears to be no connectivity. How would you remedy this situation in the most effective manner?","explanation":"For AWS Container services, customers are responsible for the data and for firewall rules for access to the container service. For example, Amazon RDS provides RDS security groups, and Amazon EMR allows customers to manage firewall rules through Amazon EC2 security groups for Amazon EMR instances. Editing the security group rules will solve the issue. Although AWS does manage the underlying RDS and EMR infrastructure, customers are responsible for the data and firewall rules for access to container services. Key pairs related to infrastructure services such as EC2 and is not relevant in this case. Migrating to EC2 would work but is unnecessary, more costly and require additional administrative overhead.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"2a0df43acefc1bd6e1699ab4687aba2b","text":"Edit the security group rules associated with the RDS and EMR instances to allow inbound/outbound access.","correct":true},{"id":"d54de36cd37205ed20bf55d26d757f9e","text":"Migrate the application to run on Amazon EC2 instead. Create an auto-scaling group to scale the batch process when it exceeds a CPU threshold.","correct":false},{"id":"b8d421cecf4e1c5c38ce7a7a17bd7dbb","text":"Create a new key pair associated with the EMR instance. The current key pair is invalid.","correct":false},{"id":"4b17f971232d5dfe553d666c762dbac5","text":"This an AWS issue. AWS manages the underlying RDS and EMR infrastructure; they should be able to communicate with each other. Open a Support Case to resolve the issue.","correct":false}]},{"id":"86c22858-5cf0-4a67-b1c5-54d1de3ca2da","domain":"refactoring","question":"You store a new object in Amazon S3 and receive a confirmation that it has been successfully stored. You then immediately make another API call attempting to read this object. Will you be able to read this object immediately?","explanation":"Amazon S3 buckets in all Regions provide read-after-write consistency for PUTS of new objects and eventual consistency for overwrite PUTS and DELETES.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel","title":"Amazon S3 Data Consistency Model"}],"answers":[{"id":"07fc991ba9f0a91e26627f8af0c332ac","text":"No. S3 imposes a one second delay on all reads.","correct":false},{"id":"3ac4811c4441245d5a9b35dec13054fd","text":"It depends, because S3 objects are not available until they have replicated to another region. This replication can take up to several seconds.","correct":false},{"id":"8596049a57e596b85941153836ade663","text":"Yes, unless you exceed API call limits.","correct":false},{"id":"9093951ee8a45059ab694f2f97f8d00a","text":"Yes. S3 has read-after-write consistency, which means you will have access to the object immediately.","correct":true}]},{"id":"6ecb35a6-d644-4dd7-8dee-9264c6d7b67c","domain":"development","question":"You want to receive an email whenever a user pushes code to your CodeCommit repository, how can you configure this?","explanation":"You can configure the SNS notifications in the CodeCommit console","links":[{"url":"https://docs.aws.amazon.com/codecommit/latest/userguide/how-to-repository-email.html","title":"CodeCommit Notifications"}],"answers":[{"id":"40bcd068ac2fef95893a5dda7f9771f8","text":"Configure Notifications in the console, this will create a CloudWatch Events rule to send a notification to an SNS topic which will trigger an email to be sent to the user","correct":true},{"id":"06e8bf1f8ae4cd753cdf1252219dc249","text":"Configure a CloudWatch Events rule to send a message to SQS which will trigger an email to be sent whenever a user pushes code to the repository","correct":false},{"id":"6ee0768c21ad21c01da89ef43da77d1b","text":"Configure a CloudWatch Events rule to send a message to SES which will trigger an email to be sent whenever a user pushes code to the repository","correct":false},{"id":"ff0d6ff99cc6fab031ef95183cb6b0e9","text":"Create a new SNS topic and configure it to poll for CodeCommit events. Ask all your users subscribe to the topic to receive notifications","correct":false}]},{"id":"8856df48-5866-4ee3-a5a7-2033444e21eb","domain":"security","question":"You have provisioned an RDS database and then deployed your application servers using Elastic Beanstalk. You now need to connect your application servers to the database. What should you do?","explanation":"As you are connecting to a database that was not created within your Elastic Beanstalk environment, you will need to create the Security Group yourself and also provide connection string and credentials to allow your application servers to connect to the database","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.RDS.html#rds-external-defaultvpc","title":"Elastic Beanstalk And RDS"}],"answers":[{"id":"26b897f7474a08158506b32e7c566323","text":"Provide the ip address of the RDS instance to Elastic Beanstalk","correct":false},{"id":"1aa1798c4c20c22832e9a949af74ada3","text":"Configure Elastic Beanstalk to install a database client on your application servers","correct":false},{"id":"50021ae41e50f1b10069ebcccab3c0ef","text":"Provide the database connection information to your application","correct":true},{"id":"24e204c62e09f215959e144cbb8611d4","text":"Configure a security group allowing access to the database and add it to your environments auto-scaling group","correct":true}]},{"id":"3cfbe3a0-1340-4fde-9a94-c1f8c88280af","domain":"development","question":"Where would you expect to find Elastic Beanstalk configuration files like healthcheckurl.config, environmentvariables.config etc?","explanation":"E/B has configuration options for before, during, and after environment creation. these files are loaded from configuration files in the .ebextensions folder at the root of the application source bundle. ","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/command-options.html","title":"Elastic Beanstalk Configuration Options"}],"answers":[{"id":"2f5dad241fd1ac7fdb6396de1a2ed3c7","text":"The .ebextensions folder","correct":true},{"id":"525b032d6f715f1fcf1e4b7a9a2452a8","text":"The .ebconfigurations folder","correct":false},{"id":"c7a78c946f7e3bbabe6e9861292f35ac","text":"The root directory of your project folder","correct":false},{"id":"2045080e088be61fd27420ff9c10b0e8","text":"The .ebenvironments folder","correct":false}]},{"id":"66c6afb4-04e0-4eda-aa5b-745c464d5cad","domain":"mon-trb","question":"You deployed a new Lambda function a few days ago and your code seems to be executing successfully, however when you check CloudWatch there isn't any log data for your function. What could be the reason for this?","explanation":"A service needs to have permissions to write log data to CloudWatch logs, Lambda is associated with an execution role which needs to grant the relevant IAM permissions","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions.html","title":"Using CloudWatch"}],"answers":[{"id":"0261bd378f9288b971d24a9076d27d22","text":"The execution role for the Lambda function did not grant permissions to write log data to CloudWatch Logs","correct":true},{"id":"122cf71e8d5e76b7cfa4409633b0e4bf","text":"There is an issue with S3 in your region","correct":false},{"id":"ec216d5f36d3705950b7957bbb31d565","text":"The CloudWatch agent has stopped","correct":false},{"id":"dfa1603ecab090efaf75db7e3a0456e3","text":"Your code is taking too long to execute, it could be that your function does not have enough compute resources to generate the log files","correct":false}]},{"id":"6db2c293-ed5d-41ff-84fb-803e2970a0f9","domain":"development","question":"A developer is working on a new application which will use DynamoDB. One of the DynamoDB tables that the developer must create requires an index sort key. When creating this DynamoDB table, the developer must select an Attribute Type for the sort key.\n\nWhich of the following DynamoDB data types can the developer select to use for their index sort key?","explanation":"Both partition and sort keys attributes must be defined as type string, number, or binary.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.NamingRulesDataTypes.html#HowItWorks.DataTypes","title":"DynamoDB Data Types"}],"answers":[{"id":"27226c864bac7454a8504f8edb15d95b","text":"Boolean","correct":false},{"id":"b2ee912b91d69b435159c7c3f6df7f5f","text":"Number","correct":true},{"id":"6ce976e8f061b2b5cfe4d0c50c3405dd","text":"Binary","correct":true},{"id":"27118326006d3829667a400ad23d5d98","text":"String","correct":true},{"id":"4ee29ca12c7d126654bd0e5275de6135","text":"List","correct":false},{"id":"46f3ea056caa3126b91f3f70beea068c","text":"Map","correct":false}]},{"id":"18db8cf0-407c-4547-a64f-eabdcbf3566a","domain":"development","question":"Which of the following DynamoDB features allows Items to be automatically deleted at a given date and time?","explanation":"DynamoDB TTL allows each Item to include a date and time at which DynamoDB will automatically delete the Item.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/howitworks-ttl.html","title":"Time to Live: How It Works"}],"answers":[{"id":"52d5592ad24a2cda379ce38e9c218d65","text":"DynamoDB TTL","correct":true},{"id":"fdce91249547ab22d875d26aad3493bd","text":"DynamoDB auto-delete","correct":false},{"id":"f15851a368334eb82668e066053bb738","text":"DynamoDB Timeout","correct":false},{"id":"b0d30a23fde41c669e0592b4be4d6093","text":"DynamoDB Exponential Backoff","correct":false}]},{"id":"fef4400a-946f-4f47-8a06-1d8cac177396","domain":"mon-trb","question":"You are attempting to list the objects contained in an S3 bucket. The bucket contains over 3000 objects and the list-objects command times out and does not complete successfully, however when you run the same command on a different bucket, it works without errors. What could be the reason for this?","explanation":"If you see issues when running list commands on a large number of resources, the default page size of 1000 might be too high. This can cause calls to AWS services to exceed the maximum allowed time and generate a \"timed out\" error. You can use the --page-size option to specify that the AWS CLI request a smaller number of items from each call to the AWS service. The CLI still retrieves the full list, but performs a larger number of service API calls in the background and retrieves a smaller number of items with each call. This gives the individual calls a better chance of succeeding without a timeout. Changing the page size doesn't affect the output; it affects only the number of API calls that need to be made to generate the output.","links":[{"url":"https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-pagination.html","title":"AWS CLI Pagination"}],"answers":[{"id":"12b3ee65ff4239dcb2e54ada9d0307d5","text":"You are running the command on a bucket which contains a large number of resources, and the default page size might be need to be increased.","correct":false},{"id":"abf2e493ee10caa92d340b7832cc908f","text":"You do not have the required permission to run the list-objects command on the bucket.","correct":false},{"id":"c105a5c0f66ee44cff21cb53bd7ec1e5","text":"You are running the command on a bucket which contains a large number of resources, and the default page size might be too high.","correct":true},{"id":"fe6ecb35fc38b38806053192af45aadd","text":"The command is generating too many API calls due to the large number of objects in the bucket.","correct":false}]},{"id":"68d79e4d-f827-496d-9fc3-606615dd6fe5","domain":"security","question":"When using Web Identity Federation and Cognito to allow a user to access an AWS service (such as an S3 bucket), which of the following is the correct order of steps?","explanation":"A user authenticates with Facebook first. They are then given an ID token by Facebook. An API call, AssumeRoleWithWebIdentity, is then used in conjunction with the ID token. A user is then granted temporary security credentials.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc_manual.html","title":"Using Web Identity Federation APIs"}],"answers":[{"id":"e95a8dc9c210c0c1e6e36f8215ab4978","text":"A user makes the AssumeRoleWithWebIdentity API Call. The user is then redirected to Facebook to authenticate. Once authenticated, the user is given an ID token. The user is then granted temporary access to the AWS platform.","correct":false},{"id":"811872e18604a3d8118cc1c9381bf702","text":"Users cannot use Facebook credentials to access the AWS platform.","correct":false},{"id":"b66b1e5f0bf94eca60bce37aa0702f6e","text":"A user logs in to the AWS platform using their Facebook credentials. AWS authenticates with Facebook to check the credentials. Temporary Security Access is granted to AWS.","correct":false},{"id":"13bdd19ca71c9978a4642bd95fcb92c5","text":"A user authenticates with Facebook first. They are then given an ID token by Facebook. An API call, AssumeRoleWithWebIdentity, is then used in conjunction with the ID token. A user is then granted temporary security credentials.","correct":true}]},{"id":"6969665b-60e1-4b4b-88db-b3a70e483f9a","domain":"security","question":"Which of the following does Cognito use to manage sign-up and sign-in functionality for mobile and web applications?","explanation":"Cognito User Pools are like a directory, allowing users sign-up and sign-in. Identity pools are used to grant temporary access to unauthenticated guests. IAM users are user account entities which allow you to interact with AWS resources. IAM groups are collections of IAM users and are used to specify permissions for multiple users.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools.html","title":"Cognito User Pools"}],"answers":[{"id":"cb40a6c9df6d32418e5f67e35ed37fd0","text":"User Pools","correct":true},{"id":"a07a0085c7712cdcacc4b2cc1359a351","text":"Identity Pools","correct":false},{"id":"6b92da4fed3ac1c921485e4de62af19b","text":"IAM Users","correct":false},{"id":"2a3ae7e866e21a59b0cdd627c7f7da55","text":"IAM Groups","correct":false}]},{"id":"d193b6e5-b33d-429a-8334-2295b5032bf0","domain":"mon-trb","question":"You are responsible for a number of different applications which are hosted across multiple regions. You would like to use CloudWatch to view all system metrics data in one place. Which of the following approaches should you choose?","explanation":"CloudWatch dashboards are customizable home pages in the CloudWatch console that you can use to monitor your resources in a single view, even those resources that are spread across different Regions.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Dashboards.html","title":"Using Amazon CloudWatch Dashboards"}],"answers":[{"id":"9f39dac5a56fd07170a15a0ee5a2e338","text":"Create a dashboard for each region and group the applications together on a regional basis","correct":false},{"id":"7456dbc94be76b5a2f0b98bc81920d8f","text":"Create a different dashboard for each resource type on a regional basis","correct":false},{"id":"e87ab0fb6d9ac17e828c3df9b699fe9a","text":"Create a single dashboard to cover all the regions and include metrics for each application","correct":true},{"id":"ac051baaf2ee5b9115dd035726ab1f51","text":"Create a dashboard to cover all the applications and use separate namespace for each region","correct":false}]},{"id":"e516825d-bec2-463c-9a64-63be7bc91509","domain":"refactoring","question":"You are developing a serverless application which runs on Lambda, DynamoDB and API Gateway. The application needs to support an average of 5,000 requests per second. During testing, the Test Team want to test for peaks of 2.5 x the average load (12,500 requests per second). Shortly after testing begins, your application crashes with API Gateway generating a 429 error code. What could be the reason for this?","explanation":"By default, API Gateway limits the steady-state request rate to 10,000 requests per second. The 429 error means that the application is generating too many requests and is being throttled.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html","title":"API Request Throttling"}],"answers":[{"id":"71cfc755a5cb85f74a6c94a83c5a102b","text":"Your Lambda function has run out of CPU, you need to increase the memory allocation in order to increase CPU capacity","correct":false},{"id":"e33a82eb6c47467dbddcc3cebfdd8dae","text":"Your tests have caused the application to hit the default limit of 10,000 requests per second for Lambda","correct":false},{"id":"c44bbd8c68bc540a9f4ec1eb6aef1f14","text":"Your Lambda function has run out of memory, you need to increase CPU capacity in order to increase memory capacity","correct":false},{"id":"998c50932ec426f49890c7568b789ab0","text":"Your tests have caused the application to hit the default limit of 10,000 requests per second for API Gateway","correct":true}]},{"id":"ac3347a8-a8e9-482f-b9e1-cf55b44e51f4","domain":"mon-trb","question":"You are hosting your website in an S3 bucket located in us-east-1, however many of your users are located in India, Africa and Europe and they are experiencing long delays. How can you improve response times for these users?","explanation":"CloudFront can speed up the delivery of your static content to users across the globe. Creating additional buckets and replicating data is not an efficient approach. Connect Direct and ElastiCache cannot be used in the ways described.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/IntroductionUseCases.html#IntroductionUseCasesStaticWebsite","title":"CloudFront Use Cases"}],"answers":[{"id":"ecbdb73e217f81efac6bf02c459d6091","text":"Implement Connect Direct","correct":false},{"id":"019191e8a1a081a3818038b8cdceadd5","text":"Configure a CloudFront CDN","correct":true},{"id":"e225c4ebf2d1a40e5aabd2ecc669e13e","text":"Use ElastiCache to cache the content in each Region","correct":false},{"id":"a4ad24886aec69baee149f06fe05ad2e","text":"Create 3 additional S3 buckets in regions local to your users and replicate the data across to the new buckets","correct":false}]},{"id":"5820892f-2759-4cd8-be11-8b2dbcc5d1b5","domain":"development","question":"Your Lambda function requires a few libraries which are not available as standard in the Lambda runtime environment. Which of the following is a recommended way to make the libraries available to your function?","explanation":"A deployment package is a ZIP archive that contains your function code and dependencies. You need to create a deployment package if you use the Lambda API to manage functions, or if you need to include libraries and dependencies other than the AWS SDK. You can upload the package directly to Lambda, or you can use an Amazon S3 bucket, and then upload it to Lambda. If the deployment package is larger than 50 MB, you must use Amazon S3.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html","title":"AWS Lambda Deployment Package"}],"answers":[{"id":"a74c95d1ac4aa0e191861afb10c345d4","text":"Create a deployment package containing your function code and libraries","correct":true},{"id":"24030d747fefc92f6c68f2934974ba96","text":"Upload the deployment package to Lambda","correct":true},{"id":"d43e57bd5184ca5787e6827646b30fa5","text":"Create a handler function downloads the libraries you need","correct":false},{"id":"f21d58a10f3609c9feab39647fa533cf","text":"Store the deployment package in an S3 bucket and then upload it to Lambda","correct":true},{"id":"585237ca133be02e26db990e229ab6f4","text":"Create a custom runtime which includes the libraries you need","correct":false},{"id":"c5aba36fa7ce91daccd7cb3a4e3cf9a1","text":"Add the dependencies to S3 and create an environment variable to reference them","correct":false}]},{"id":"fcee1e83-0558-4267-ba27-58a978b7003c","domain":"deployment","question":"You are working on an application which is made up of a number of Lambda functions as well as API Gateway endpoints. Which of the following technologies would you use to build and deploy this application in AWS?","explanation":"CloudFormation and the AWS SAM CLI can be used to deploy serverless applications. Use the Transform section of the CloudFormation template to specify the serverless resources you would like to deploy. The other technologies cannot be used to deploy serverless applications. OpsWorks provides configuration management using managed instances of Puppet or Chef. Elastic Beanstalk is for deploying and scaling web applications on familiar servers such as Apache, Nginx, Passenger, and IIS. CodeBuild is an automated build system, and CodeDeploy deploys your built code to either EC2 or an on-premises server.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"What is the AWS Serverless Application Model?"},{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/appendix-appendix-sam-templates-and-cf-templates.html","title":"CloudFormation & the AWS Serverless Application Model"}],"answers":[{"id":"c42aaccedc51aac929c8ae313066f320","text":"OpsWorks","correct":false},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":false},{"id":"4d926e7259ad82fea671d810b2211451","text":"AWS Serverless Application Model CLI","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true}]},{"id":"0dfd155c-e9fa-4a85-baba-ba51ae43d152","domain":"deployment","question":"As a developer you have built a WordPress site. Traffic to the site has increased and you have improved the site's functionality to meet the demand of your viewers since launch. Changes are coming frequently, and you are considering using AWS CloudFormation to automate the process of building test stacks, creating a change set, and executing the change set. How would you streamline this process in AWS most efficiently?","explanation":"Continuous delivery is a release practice in which code changes are automatically built, tested, and prepared for release to production. With AWS CloudFormation and CodePipeline, you can use continuous delivery to automatically build and test changes to your AWS CloudFormation templates before promoting them to production stacks. This release process lets you rapidly and reliably make changes to your AWS infrastructure. Although you can manually interact with CloudFormation to execute the various stages, this is not the most efficient method. Amazon Inspector is an automated security assessment service which evaluates the security loopholes in deployed resources specific to EC2. Config is a monitoring and governance tool that tracks changes to your AWS environment based on rules you configure.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/continuous-delivery-codepipeline-basic-walkthrough.html","title":"Walkthrough: Building a Pipeline for Test and Production Stacks"}],"answers":[{"id":"87149b0d9dbfaac4e8ba219e908d57a1","text":"Build your test stack, create a change set, and then execute the change set by manually interacting with AWS CloudFormation.","correct":false},{"id":"4b808c56dbbec61b1137c70708faf855","text":"Create a Config rule that will look for changes within your CloudFormation stack that will trigger Lambda functions to execute actions based on the pipeline.","correct":false},{"id":"6e617dd2e008968aea6984c58b17c139","text":"Use Amazon Inspector to monitor your CloudFormation environment that will send an SNS notification to Lambda when a pipeline stage is complete. Subscribe the Lambda function to the SNS topic.","correct":false},{"id":"1498c0d02e9c619808313a425479642f","text":"Create a CodePipeline separated by three stages. For each stage organize actions in a pipeline. Have CodePipeline complete all actions in a stage before the stage processes new artifacts.","correct":true}]},{"id":"08861bdf-6813-43f1-9def-4255492b4533","domain":"mon-trb","question":"Your application is using SQS to send and receive messages, your application needs to receive the messages as soon as they arrive and you need to ensure the architecture is as cost efficient as possible. Which of the following approaches will optimise the cost and performance of the application?","explanation":"In almost all cases, Amazon SQS long polling is preferable to short polling and results in higher performance and reduced cost in the majority of use cases.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"SQS FAQs"}],"answers":[{"id":"33e24a8e438593d0ed4994ce9ea68ccd","text":"Enable Long Polling","correct":true},{"id":"64dab6674843dc03406bdc90b1c5b21d","text":"Lower the message Visibility Timeout","correct":false},{"id":"9ef993bf7e61fa02b5f6ac0fc8da6b18","text":"Enable Short Polling","correct":false},{"id":"8757c7e091bc29e7b9225334f00531ac","text":"Reduce the total number of message queues","correct":false}]},{"id":"60de4860-8791-4fd6-b3af-364209ceb5ab","domain":"mon-trb","question":"You are working on an application for an online training company which stores product data in DynamoDB. This week, the company is running a big promotion on a few courses and this is bringing lots of new traffic to your website, causing an increased number of queries to the database.  Database queries are now running much slower than usual and the Operations Team are concerned that the DynamoDB table is being throttled. Which of the following approaches would you recommend to improve read performance?","explanation":"Using DAX is the recommended approach to reducing response times for read-intensive applications, applications which read a small number of items frequently and also applications which perform repeated reads against a large set of data. Read Replicas are not a feature of DynamoDB. Configuring the application to use scans instead is not an efficient solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.html","title":"DynamoDB DAX"}],"answers":[{"id":"c9e5713b3f811b188f8770ffd016beaf","text":"Configure the application to use scans rather than queries and run multiple scans in parallel","correct":false},{"id":"7d691dd8fcbce5a87b1211b09b47541a","text":"Add a Read Replica and point the DynamoDB API calls at the Read Replica","correct":false},{"id":"1fdd30d4d2259438830cf9536f3da218","text":"Configure a DAX cluster and point the DynamoDB API calls at the DAX cluster","correct":true},{"id":"df31657d8e3247caf5b704d87a7fced3","text":"Redesign your table to use a more distinct partition key to enable the I/O load to be more evenly distributed across partitions","correct":false}]},{"id":"efa5e898-d746-4a5f-b112-11861aa90108","domain":"deployment","question":"A developer is making changes to the CloudFormation template used to deploy an application. They would like to know if any existing resources will be deleted or replaced before applying the template updates. What service feature will enable this?","explanation":"CloudFormation Change sets enable the preview of proposed changes to a stack in order to assess the impact on running resources. This functionality allows the developer to check if any existing resources will be deleted or replaced upon application of the CloudFormation template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html","title":"Updating Stacks Using Change Sets"}],"answers":[{"id":"400f40520b42783d45e80c35c9b18641","text":"CloudFormation Registry","correct":false},{"id":"e3692dda22879fd00506eaa434a3913b","text":"CloudFormation StackSets","correct":false},{"id":"e340c6d6c2f5866020158726104d63d7","text":"CloudFormation Change Sets","correct":true},{"id":"b5b91cf0fb04ab0cccd3dc8d197bfdaf","text":"CloudFormation Rolling Updates","correct":false}]},{"id":"9c5acd8e-0651-4a0c-ab57-af28f3a6cc96","domain":"mon-trb","question":"You receive a \"timed out\" error message when running an AWS CLI against a large number of resources. What can you do to avoid this?","explanation":"If you see issues when running list commands on a large number of resources, the default page size of 1000 might be too high. This can cause calls to AWS services to exceed the maximum allowed time and generate a \"timed out\" error. You can use the --page-size option to specify that the AWS CLI request a smaller number of items from each call to the AWS service. The CLI still retrieves the full list, but performs a larger number of service API calls in the background and retrieves a smaller number of items with each call. This gives the individual calls a better chance of succeeding without a timeout. Changing the page size doesn't affect the output; it affects only the number of API calls that need to be made to generate the output.","links":[{"url":"https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-pagination.html","title":"AWS CLI Pagination"}],"answers":[{"id":"80edba19b0a6e2ba687897cf6b0f0f29","text":"Reduce the size of the output by simplifying the command so that you are not querying so many resources at once","correct":false},{"id":"bbc1cf23d1c726d389f714076cc32722","text":"Reduce the page size to specify that the AWS CLI request a smaller number of items from each call when generating the output","correct":true},{"id":"a62e7e1034bc7af78d66c2813ad934e6","text":"Increase the maximum allowed time for the CLI to generate the output to avoid time out errors","correct":false},{"id":"8cd9e54172bcc8d8917b1cfcd3e7d869","text":"Increase the page size to specify that the AWS CLI request a smaller number of API calls when generating the output","correct":false}]},{"id":"b41da940-4b4e-11ea-b77f-2e728ce88125","domain":"mon-trb","question":"You created a CloudFormation template that launched a web application in us-west-1. However, you are experiencing a problem creating a development stack in us-east-1 to serve clients in another geographical location. What should you do to solve the problem?","explanation":"An Amazon Machine Image, or AMI, is used to launch an EC2 instance in a specified region. So, to use it in another region, you will have to copy it to the region of your choice. Recreating the resources is unnecessary since you only need to copy the AMI. And the IAM role is irrelevant to the question, since IAM roles are valid across the entire AWS account.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"6971fa728cde2ee82b21faac08aeb60a","text":"Copy your IAM role to us-east-1 region so that you have permissions to deploy CloudFormation stacks in that region.","correct":false},{"id":"e72b5dc8983df71bdc1fa0c5b4985e4f","text":"Copy the AMI in the template from us-east-1 to us-west-1.","correct":false},{"id":"b5a9be3c7b03258224fb637458459b99","text":"Recreate the AWS resources used for the application in us-west-1.","correct":false},{"id":"e3bebd36eb37842d75a71b0a69c37abe","text":"Copy the AMI in the template from us-west-1 to us-east-1.","correct":true}]},{"id":"eebfef11-98bd-48f5-9775-b70b3600480a","domain":"development","question":"You are working on updates to your .NET application which has been deployed using Elastic Beanstalk. Your environment consists of 4 EC2 instances, as well as a number of different Lambda functions and DynamoDB tables. The application requires at least 2 instances to cope with the average workload and a minimum of 3 instances to cope with peak-time traffic. The Project Manager has asked you to roll out the updates as quickly as possible. Which of the following deployment strategies do you recommend?","explanation":"An all-at-once deployment deploys to all instances simultaneously which will put all of your web servers out of action at once. Rolling with additional batch launches an extra batch of instances before starting the deployment, to maintain full capacity. However, full capacity is not required in this scenario. Immutable deployments perform an immutable update to launch a full set of new instances running the new version of the application in a separate Auto Scaling group, alongside the instances running the old version; this is not required in this scenario. You can use a rolling update with a batch size of 25%, to ensure that 75% of your servers remain available at any time.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","title":"Elastic Beanstalk Deployment Options"}],"answers":[{"id":"d5b066eef81dedf1d0352f27d2128586","text":"All at once","correct":false},{"id":"ff2713a6181db42fded101c670bbd0dd","text":"Rolling with additional batch","correct":false},{"id":"f4920797afb92022a9c6608efcd86317","text":"Rolling","correct":true},{"id":"11efd9ae6f76e706e3f1b34d97584ebc","text":"Immutable","correct":false}]},{"id":"802be8c8-07cc-48a7-94c8-21d785d18f5a","domain":"deployment","question":"Your organization is developing a CI/CD environment to improve software delivery of your applications. It has already adopted a plan to execute the various phases of the CI/CD pipeline from continuous integration to continuous deployment. There are now discussions around restructuring the team make-up to implement a CI/CD environment. How would you recommend creating developer teams as a best practice to support this change in the long run?","explanation":"AWS recommends organizing three developer teams for implementing a CI/CD environment: an application team, an infrastructure team, and a tools team. This organization represents a set of best practices that have been developed and applied in fast-moving startups, large enterprise organizations, and in Amazon itself. The teams should be no larger than groups that two pizzas can feed, or about 10-12 people. This follows the communication rule that meaningful conversations hit limits as group sizes increase and lines of communication multiply. Hiring an external consulting firm will not be beneficial in the long run. Setting up a single team is not best practice. AWS CodePipeline is a continuous integration and continuous delivery service for fast and reliable application and infrastructure updates and not used for team structuring.","links":[{"url":"https://d0.awsstatic.com/whitepapers/DevOps/practicing-continuous-integration-continuous-delivery-on-AWS.pdf","title":"Practicing Continuous Integration and Continuous Delivery on AWS"}],"answers":[{"id":"b943ddf4265197477c4036cdd230b033","text":"Hire an external consulting firm to build and manage the pipeline. Provide them with the proper IAM roles to access your AWS environment.","correct":false},{"id":"d163f1cc494b3cde77122207a42d9de1","text":"Set up one team to own an operate all components of the CI/CD pipeline to consolidate tasks and improve efficiency.","correct":false},{"id":"f3054a7a017a533ace8f081538d0b664","text":"Set up an application team to develop applications. Set up an infrastructure team to create and configure the infrastructure to run the applications. Set up a tools team to build and manage the CI/CD pipeline.","correct":true},{"id":"3e514092970cfe2b9a3ea7331a0828cf","text":"Use CodePipeline to manage your CI/CD environment and assign team members to own different phases within your CodePipeline.","correct":false}]},{"id":"51d0eac3-d55e-4a50-aa5b-c133add86037","domain":"refactoring","question":"A content publishing organization runs its own platform, which uses DynamoDB as its data store. A bug report has come in from the content team. They say that when two editors are working on the same content they frequently overwrite each other's changes.\n\nWhat DynamoDB feature would prevent the most number of overwrite bug reports?","explanation":"Using a condition-expression we can perform a conditional update to an item. The condition must evaluate to true; otherwise, the update operation fails. We can use this feature to make sure the content of an article has not changed since it was last read, before we update it.\n\nacid-expression is incorrect because there is no such expression.\n\nDynamoDB TTL is incorrect because it is for deleting items from DynamoDB after a given duration, not creating a lock.\n\nCalling GetItem immediately before calling UpdateItem would help mitigate the issue, but still leaves a small race condition where condition-expression does not. It is, therefore, not the best solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ConditionExpressions.html","title":"Condition Expressions in DynamoDB"}],"answers":[{"id":"9d2d53ddaae2b905e48ea3705529a19c","text":"Apply a time-limited lock to the item while an author is editing it using a DynamoDB TTL.","correct":false},{"id":"058706dd0f32f05aa73a515774a5dc2d","text":"Call GetItem immediately before calling UpdateItem to ensure the item has not changed.","correct":false},{"id":"ddb55880d9b1b331207bcb38cebd6dbf","text":"Include an acid-expression in the UpdateItem command.","correct":false},{"id":"b1d92ca8c7500f89cffdf0057251aec1","text":"Include a condition-expression in the UpdateItem command.","correct":true}]},{"id":"8e61dab4-571e-4a97-a6a7-bcbfddddd867","domain":"deployment","question":"You are using CloudFront to serve static website content to users based in multiple locations across the USA, Africa, India and the Middle East. You recently made some significant updates to the website, but users are complaining that they can only see the original content. What can you do you make sure the latest version of the website is being served by CloudFront?","explanation":"If you need to remove a file from CloudFront edge caches before it expires, you can do one of the following: Invalidate the file from edge caches. The next time a viewer requests the file, CloudFront returns to the origin to fetch the latest version of the file. Use file versioning to serve a different version of the file that has a different name.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Invalidation.html","title":"Invalidating Files in CloudFront"}],"answers":[{"id":"1215948dd7c3245305713d0ec57cae6f","text":"Update the file in the original location and reset the cache timestamp","correct":false},{"id":"cf938fcfef89105b2dc2d97975c87b22","text":"Wait for the cache to expire","correct":false},{"id":"6d72e9895d437372eba948f57e50610f","text":"Delete the file from the original location and replace it with a new version","correct":false},{"id":"78eef0aaf2d58aea70bfd13a7d03df31","text":"Invalidate the file from the CloudFront edge cache","correct":true}]},{"id":"7bd7a103-821e-40af-9665-7695fac3de16","domain":"deployment","question":"AWS recommends that you use Multipart Upload for files larger than _____.","explanation":"","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html","title":"Uploading Objects Using Multipart Upload"}],"answers":[{"id":"6df47862fbfbd67605dc294d3f41925a","text":"100MB","correct":true},{"id":"84fb7b98e6e50302bf6cc709c92a6192","text":"5TB","correct":false},{"id":"0be25e5b91d25f9db3b4d3dcaf2cfd1f","text":"5GB","correct":false},{"id":"208b4367cf771ded0e29ff6f9282442e","text":"1GB","correct":false}]},{"id":"d4258c06-e769-46cc-b5ab-1571ea57879b","domain":"development","question":"You are pair programming with another senior developer in your team and you have been tasked with writing a number of different Lambda functions. Your colleague recommends that you separate the Lambda handler from the core business logic of your code. What is the rationale for this?","explanation":"At the time you create a Lambda function, you specify a handler, which is a function in your code, that AWS Lambda can invoke when the service executes your code. Separating the handler from the core business logic is best practice as it enables code re-use as well as making unit testing easier. See the URL below for best practices for developing Lambda functions.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html","title":"Best Practices for Working with AWS Lambda Functions"}],"answers":[{"id":"0f56edddb67c69aafb238d531d6abdfb","text":"To reduce the size of your deployment package","correct":false},{"id":"79c80a290b9838caa5e24e1f96a2a8f7","text":"To make the code easier to re-use","correct":true},{"id":"1763988c31a85fbf689902e6d3e1a185","text":"To reduce complexity caused by dependencies","correct":false},{"id":"6a5519ec7f0685c57d611a5c6731c5a4","text":"To improve function performance","correct":false}]},{"id":"32d5da0f-0ed7-436c-98cf-a16053badf54","domain":"development","question":"Your application runs on Lambda and you would like to enable your functions to communicate with EC2 instances in your private subnet. How can you enable this?","explanation":"In order to enable Lambda to communicate with your private VPC, you need to add VPC config information. You do not need to add a NAT or Internet gateway and it is not possible to launch a Lambda function inside your own VPC or subnet. - Please be aware that in September 2019, AWS announced that they are simplifying VPC networking for Lambda functions, with changes planned to be rolled out on a per region basis. However the exams do generally run at least 6-12 months behind any new updates or announcements, so unfortunately, you may still see exam questions referring to the old way of doing things.","links":[{"url":"https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/","title":"Announcing improved VPC networking for AWS Lambda functions"}],"answers":[{"id":"a8f43c529989f897c2749cb29caeb890","text":"Add a NAT gateway to the subnet","correct":false},{"id":"d77b6ba1a84152571b9b01b57aa78774","text":"Add an internet gateway to your VPC","correct":false},{"id":"9b7ce49759154447fc7d7666f84adf68","text":"Launch the Lambda function in the same subnet as your EC2 instances","correct":false},{"id":"4f2ebe62076f1314a2b7ece1aae5f495","text":"Update your Lambda function with the relevant VPC config information","correct":true}]},{"id":"f7fd0d7a-5d45-4f72-aa8e-d9a65270360f","domain":"refactoring","question":"You are developing an online hotel booking application which makes an number of requests to different back end applications to get quotes for travel related add-on services. You are using API gateway handle all the API calls and you notice that the majority of requests are for the same 5 or 6 services. How can you optimize the configuration to ensure the best performance for your application?","explanation":"You can enable API caching to cache your endpoint's responses, this reduces the number of calls made to your endpoint and improves the latency of requests to your API.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html","title":"API Caching"}],"answers":[{"id":"b255bca6117b1096664ab7b1415fae80","text":"Add an ElastiCache cluster in front of your database to cache the most frequently accessed data","correct":false},{"id":"59a69a5bb20a3dbe9214ef93c38041f7","text":"Configure auto-scaling for the API Gateway","correct":false},{"id":"336a729744a0b4682222e3a4a1cdc750","text":"Implement API Caching to cache the endpoint's response for the most popular requests","correct":true},{"id":"9a86454fefc71c7430655ce2e18ac716","text":"Configure a CloudFront CDN in front of the API Gateway to cache the most frequent HTTP requests","correct":false}]},{"id":"5cf3b6d4-9a0e-4602-8dab-26e687207049","domain":"development","question":"Which of the following platforms are supported in ElasticBeanstalk?","explanation":"Elastic beanstalk supports common platforms like including Tomcat, Passenger, Puma and Docker","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html","title":"Elastic Beanstalk Supported Platforms"}],"answers":[{"id":"7345f7045e4668138112c100f25517a4","text":"JBoss","correct":false},{"id":"bf2528a296adb62d041a7519aa77f248","text":"Passenger","correct":true},{"id":"c5fd214cdd0d2b3b4272e73b022ba5c2","text":"Docker","correct":true},{"id":"8f72e28063c30c7468fb6af4653f4f9c","text":"Tomcat","correct":true}]},{"id":"c1271c56-09c1-44e0-9e24-840abbf8ad96","domain":"development","question":"You are deploying a new version of your application using a CodeDeploy In-Place upgrade. At the end of the deployment you test the application and discover that something has gone wrong. You need to roll back your changes as quickly as possible. What do you do?","explanation":"With an In-Place upgrade you will need to redeploy the original version. Only a Blue / Green upgrade allows you to keep the original instances and roll back by routing all requests to the original instances","links":[{"url":"https://docs.aws.amazon.com/codedeploy/latest/userguide/deployments-rollback-and-redeploy.html#deployments-rollback-and-redeploy-manual-rollbacks","title":"CodeDeploy Rollback and Redeploy"}],"answers":[{"id":"d2949de6ed3d3a5197775436b9302635","text":"Point all incoming requests to your development environment while you fix the problem with the failed deployment","correct":false},{"id":"63d25b1e978fde1df3b91bb3d47c31a6","text":"Use CodeDeploy to redeploy the previous version of the application","correct":true},{"id":"f7d2972260a5229eaad04f071022e255","text":"Use the CodeDeploy roll back feature to seamlessly roll back to the previous version","correct":false},{"id":"079d9ac5765ea898c4d08a65d8e35c53","text":"Configure your load balancer to send all incoming requests to the original instances running the old version of the application","correct":false}]},{"id":"86b9ada2-ae5a-450b-8a69-88ffc0c65ee6","domain":"mon-trb","question":"A recent increase in the amount of users of an application hosted on an EC2 instance that you manage has caused the instances OS to run out of CPU resources and crash. The crash caused several users' unsaved data to be lost and your supervisor wants to know how this problem can be avoided in the future. Which of the following would you NOT recommend?","explanation":"Frequent snapshots are not recommended, as they can result in performance degradation. Additionally, these snapshots will not capture users' unsaved data that lives in the instance's memory.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"EBS Snapshots"}],"answers":[{"id":"e990838c77c787b8156a1101cebec36e","text":"Take frequent snapshots of the EBS volume during business hours to ensure users' data is backed up.","correct":true},{"id":"65d5964c0293f901c37f0a8b00d46369","text":"Create an auto-scaling group to add more servers when demand is high.","correct":false},{"id":"02f0b48391d2df79b37ab3fe6fed3bbe","text":"Take a snapshot of the EBS volume and re-deploy as a larger instance type.","correct":false},{"id":"641a29c3ebde27a5fa880ae928ae6462","text":"Rewrite the application so that users' unsaved data is frequently written to disk.","correct":false}]},{"id":"34846cde-4c2d-11ea-b77f-2e728ce88125","domain":"mon-trb","question":"Elastic Beanstalk uses the color grey as one of the status descriptions for web server environment health. Which of the following statuses applies to this color?","explanation":"Elastic Beanstalk uses the color grey to indicate that the web server environment is being updated. It uses green when the environment has passed the most recent health check, yellow when it has failed one or more health checks, and red when it has failed three or more health checks.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.healthstatus.html","title":"Basic Health Reporting"}],"answers":[{"id":"d543d408773a2b391b87ee20607ffede","text":"The environment is being updated.","correct":true},{"id":"758f6434d66c70a2bfbb567601559057","text":"The environment has failed three or more health checks.","correct":false},{"id":"125becf999b8e3c30fa0041ee8348ada","text":"The environment has failed one or more health checks.","correct":false},{"id":"9b2bdc63485515ac852959f9d35fdb96","text":"The environment has passed the most recent health check.","correct":false}]},{"id":"764c68cc-0596-485a-b5a0-4bb272444d02","domain":"deployment","question":"Which of the following services enables you to automatically build, test and release new software whenever a developer makes an update to their code?","explanation":"CodeBuild only builds your code, it won't deploy it to your environment. CloudFormation is used to deliver Infrastructure As Code. CodeCommit manages your source code. CodeDeploy can be used to deploy code, but in isolation, it cannot create an automated release process. CodePipeline automates the build, test, and can be used to deploy phases of your release process every time there is a code change, based on the release model you define.","links":[{"url":"https://aws.amazon.com/codepipeline/","title":"AWS CodePipeline"}],"answers":[{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":false},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"5f6f48261d96567b3014b43c23382021","text":"CodePipeline","correct":true},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":false},{"id":"56c20df941e069e1a35a1871f662298a","text":"CodeCommit","correct":false}]}]}}}}
