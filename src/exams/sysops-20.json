{"data":{"createNewExamAttempt":{"attempt":{"id":"90e95e9e-bb05-4c2f-a956-aac1906dc1b0"},"exam":{"id":"aa06884d-f418-4162-a005-e59d7cc2c7f4","title":"AWS Certified SysOps Administrator - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"cc89c061-ab6b-4cb4-8809-12daecdbc5b4","domain":"networking","question":"A SaaS company has an existing web application set up in the AWS Singapore Region. The company created a new web application setup in the Tokyo Region. The company decided to host an active-active setup with the traffic evenly distributed between the Singapore region setup and the Tokyo region setup. The company currently uses Route 53 to manage the routing policies. How can the company accomplish this?","explanation":"Route 53 Weighted Routing Policy can distribute traffic evenly between two application environments. The Failover routing policy is only used for routing requirements involving a primary setup and a backup / failover setup. Creating and adding load balancers in the architecture will not solve the problem.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Route 53 - Routing Policy"}],"answers":[{"id":"71053c311ca592ed50fdc7ec6c5a98f5","text":"Create an Application Load Balancer in the Singapore Region. Register the two web application environments in the Application Load Balancer. Point the Route 53 record set to the Application Load Balancer.","correct":false},{"id":"ad3851f2c1fb167d0adcff683b66ac90","text":"Use the Route 53 Weighted Routing Policy","correct":true},{"id":"b050fdf9ffd82093c1a184237e0849ca","text":"Create a Network Load Balancer in the Singapore Region. Register the two web application environments in the Network Load Balancer. Point the Route 53 record set to the Network Load Balancer.","correct":false},{"id":"c6c1e82d29d79462db966c3f61ab6b84","text":"Use the Route 53 Failover Routing Policy","correct":false}]},{"id":"9f4a3688-de11-407f-99a7-f332ade4066e","domain":"dep-prov","question":"You are running an EC2 instance and have created and attached an EBS volume with default settings. You notice that the volume status check for the volume has failed and the instance can no longer access the volume. How can you access the information on the volume?","explanation":"When Amazon EBS determines that a volume's data is potentially inconsistent, it disables I/O to the volume from any attached EC2 instances by default. This causes the volume status check to fail, and creates a volume status event that indicates the cause of the failure. Switching on Enable Volume IO will allow the instance to access the volume. Switching on Auto-Enabled IO will also achieve the same outcome automatically but this is disabled by default. All other options are incorrect.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html#work_volumes_impaired","title":"Working with an Impaired Volume"}],"answers":[{"id":"bf737cfd17a3b913cb405f896e5e9b7d","text":"Switch on Enable Volume IO","correct":true},{"id":"8daa3d585fbafd5057d0e3bf2af521e0","text":"The volume can no longer be accessed","correct":false},{"id":"628b701156eef0c168e27dc6d58a9d15","text":"Switch off Auto-Enabled IO","correct":false},{"id":"7de363a9824728f9b2e5c0a8efd8c6c3","text":"Switch off Enable Volume IO","correct":false}]},{"id":"a73df876-d426-4e85-8387-ebcb549a678c","domain":"dep-prov","question":"To register targets and correctly route requests, the Application Load Balancer's listeners need a rule that specifies a ________ .","explanation":"You register targets with a target group. To route requests to the targets in a target group, specify the target group in a rule for one of the listeners for your load balancer.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-target-group.html","title":"Creating a Target Group"}],"answers":[{"id":"1f6a4e9b062bf087b6ef57465c893d58","text":"Target Group","correct":true},{"id":"67f9cd8e61172174cf748a9b4c4c64f3","text":"Routing Configuration","correct":false},{"id":"e91131f524dfb0d7ef8c247be493d660","text":"Registered Target","correct":false},{"id":"b682dc481b1877dbaaec615eaed0b7d8","text":"Target Type","correct":false}]},{"id":"ff1ea769-7316-4292-9cb6-efc556c4af5d","domain":"networking","question":"You have an application running on an EC2 instance using IPv4. The EC2 instance is in a public subnet with a route to an Internet Gateway with target 0.0.0.0/0. As a SysOps Administrator you've been tasked with editing the network to accommodate an upgrade to the application. The upgrade adds an IPv6 address to the instance and it requires only outbound Internet access. What changes would you make?","explanation":"If you have an existing VPC that supports IPv4 only, and resources in your subnet that are configured to use IPv4 only, you can enable IPv6 support for your VPC and resources. Your VPC can operate in dual-stack mode â€” your resources can communicate over IPv4, or IPv6, or both. IPv4 and IPv6 communication are independent of each other. An egress-only Internet Gateway is a horizontally scaled, redundant, and highly available VPC component that allows outbound communication over IPv6 from instances in your VPC to the Internet, and prevents the Internet from initiating an IPv6 connection with your instances. You cannot use a NAT instance nor a NAT Gateway using the IPv6 protocol; you can only use an egress-only Internet Gateway.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html","title":"Egress-Only Internet Gateways"}],"answers":[{"id":"453bf5bd268d1213b9aa8e0d45ba876a","text":"This is not possible. You will need to create a new VPC that supports IPv6.","correct":false},{"id":"e83dc6bf30ada297b10ae6b7d524fb08","text":"Set up a NAT Gateway. Create a route from your public subnet to the NAT Gateway.","correct":false},{"id":"754f95d8f4bb6371c0314ad0727947ff","text":"Create an egress-only Internet gateway and associate it to your subnet. Specify ::/0 in the destination box and select the egress-only Internet Gateway ID in the Target list.","correct":true},{"id":"ed594610a3ab11624c962c4b7b60381c","text":"Set up a NAT instance and place it in the public subnet. As the NAT instance is in the same subnet as your EC2 instance, no route changes are necessary.","correct":false}]},{"id":"2a16f1cd-530d-4e30-ad08-d89afae34484","domain":"mon-rep","question":"You create a new DynamoDB table with the provisioned read and write capacity units set to 5. The auto scaling feature is enabled for both read and write. And the target utilization is set as 70%. After monitoring the table for some time, you notice that there are two CloudWatch alarms related to the table. The description of one alarm is \"ConsumedWriteCapacityUnits < 150 for 15 datapoints within 15 minutes\". Which action do you need to take to address the alarm?","explanation":"DynamoDB manages the throughput capacities automatically with the auto scaling feature. The alarms are used for the feature and no action is required. There is no need to disable the feature or modify the provisioned capacities.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html","title":"Manage throughput capacity automatically with DynamoDB Auto Scaling"}],"answers":[{"id":"2131aeffdfb01948cc4943432a680327","text":"You need to adjust the provisioned read and write capacities to a higher value such as 10.","correct":false},{"id":"3a5208c005673a46313dce67b9e2dd57","text":"You should disable the auto scaling feature for the table.","correct":false},{"id":"252cd5486e4ae9685450c3e9ad208b05","text":"No action is required as the alarms are used for auto scaling for the DynamoDB table.","correct":true},{"id":"859412aa0d0666ab4c2b8d20707c8f41","text":"They are fake alarms. You can manually delete them from the console.","correct":false}]},{"id":"762031fb-db4e-4e09-bab4-09bf0fc50472","domain":"high-avail","question":"You run a very popular fashion blog and during a major event your wordpress site struggles immensely with the amount of traffic that you are receiving. The wordpress site sits across a fleet of EC2 instances in an autoscaling group which scales based on CPU utilization. You notice from your CloudWatch metrics that your webservers appear fine, however your back end Aurora database is running at 100% CPU Utilization. What can you do to alleviate the situation?","explanation":"Aurora Replicas are independent endpoints in an Aurora DB cluster, best used for scaling read operations and increasing availability","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html","title":"Aurora Read Replicas"}],"answers":[{"id":"e38c819297b357216e3ddc63cecd22ec","text":"Migrate from Aurora to MySQL RDS instance with multi-AZ turned on to better handle the load","correct":false},{"id":"98a15d02b2c6ead5dff3036e99269acd","text":"Place the Aurora database in to a the same Autoscaling group as the EC2 instances and configure the launch configuration to deploy new Aurora instances whenever a node capacity reaches 80% for 5 minutes","correct":false},{"id":"10239931e046b099c14736b5b9c422d0","text":" Place the Aurora database in to a separate Autoscaling group and configure the launch configuration to deploy new Aurora instances whenever a node capacity reaches 80% for 5 minutes","correct":false},{"id":"f663aa878eb8286dbadf97aa0f95be56","text":"Add additional Aurora Read Replica Nodes and update your connection string on the webservers to point to the new nodes to spread the load","correct":true}]},{"id":"y895ku45-wsg2-9rye-087a-zdmu2wd7qtr8","domain":"mon-rep","question":"Which AWS service can be used to log API calls from the AWS console, the EC2 CLI, the AWS CLI, or the AWS SDKs.","explanation":"CloudTrail captures API calls and delivers the log files to an Amazon S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/APIReference/using-cloudtrail.html","title":"Logging API Calls Using AWS CloudTrail"}],"answers":[{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false}]},{"id":"eab3e224-a279-4865-a746-4595551b4cfb","domain":"security-comp","question":"As a systems administrator, it's your job to grant IAM access to your entire development team as your company transitions to AWS. What's the best strategy in doing this?","explanation":"Instead of defining permissions for individual IAM users, it's usually more convenient to create groups that relate to job functions (administrators, developers, accounting, etc.). Next, define the relevant permissions for each group. Finally, assign IAM users to those groups. All the users in an IAM group inherit the permissions assigned to the group.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#use-groups-for-permissions","title":"Using Groups to Assign IAM Permissions"}],"answers":[{"id":"58d601b0c64e419e78ca3f11a589b34a","text":"Create groups based on the relevant permissions for that job function and assign each user to the appropriate group.","correct":true},{"id":"f070e391c12dea8466645d67cc18ef12","text":"Use the default access provided by your identity provider.","correct":false},{"id":"d07d419ef9a8d5dfbaa087cd534554de","text":"Create IAM access specific to each user's needs.","correct":false},{"id":"5ed32311b773a2bfca008d3086a7bd62","text":"Use Active Directory and copy its permissions.","correct":false}]},{"id":"571b9603-45b6-45b1-aa47-68849ac814bb","domain":"automation","question":"A big-box retailer runs their in-store point-of-sale system on EC2 linux instances. All of the infrastructure is managed as part of a CloudFormation stack. The web servers are part of an Auto Scaling Group. The application only needs to be available during business hours from 9:00am until 6:00pm. What would be the best way to scale the web servers cost efficiently based on demand?","explanation":"Authoring the CloudFormation template to include an AutoScaling:ScheduledAction resource to increase the Auto Scaling Group's MinSize and MaxSize values at 9:00am, and another AutoScaling:ScheduledAction resource to decrease the Auto Scaling Group's MinSize and MaxSize values at 6:00pm will save costs for the retailer during non-business hours. CloudFormation conditions control whether certain resources are created or whether certain resource properties are assigned a value during stack creation or update, but don't control the actions of an Auto Scaling Group. Using an Auto Scaling Group scheduled action provides more streamlined automation than using a Lambda function. CloudFormation mappings are key/value pairs that can be used to specify conditional parameter values, but they have no impact on the Auto Scaling Group unless they are used to create a resource.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"What is AWS CloudFormation?"},{"url":"https://s3-us-west-2.amazonaws.com/cloudformation-templates-us-west-2/AutoScalingScheduledAction.template","title":"Cloud Formation Sample Template for Time-based Auto Scaling"}],"answers":[{"id":"765dccb8332e2036eb70a0b6276e7285","text":"Use CloudWatch Events to trigger a Lambda function at business opening and closing that adjusts the Auto Scaling Group's MinSize and MaxSize accordingly","correct":false},{"id":"a0f99978bb65910b10b75a32e1b92a2a","text":"Create AutoScaling:ScheduledAction conditions in the CloudFormation template that change Maxsize and MinSize values based on business hours","correct":false},{"id":"725933a9f7ea7ef281e2decf6cefadae","text":"Configure AutoScaling:ScheduledAction mappings in the CloudFormation template with Maxsize, MinSize, and Recurrence values based on business hours","correct":false},{"id":"0db6203397832efddcbca893f96ba1b6","text":"Include AutoScaling:ScheduledAction resources in the CloudFormation template that change Maxsize, MinSize, and Recurrence values based on business hours","correct":true}]},{"id":"c51ec258-f289-41da-9ffe-77c296f5998f","domain":"data-man","question":"A company is reaching capacity with its on-premises SAN storage.  It has started to build-out a cloud presence and already has a Direct Connect from its Data Center to AWS.  A new application server is being deployed on-premises, but the company is unsure what the storage requirements might be for the application - they could quite quickly outgrow the remaining capacity of the data center.  What AWS service could be used in order to present an NFS mount point to the server, but store the files in the Cloud?","explanation":"The file gateway enables you to store and retrieve objects in Amazon S3 using file protocols, such as NFS. Objects written through file gateway can be directly accessed in S3.  Although Volume and Tape Gateway both push your data to S3 as a back-end, they both provide iSCSI or Virtual Tape devices, and do not provide an NFS or SMB mount point in order to work from S3 as if it was a local file store.  S3 Gateway is not a service provided by AWS.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html","title":"What Is AWS Storage Gateway"}],"answers":[{"id":"7ab2d24d1894cccf8593c88513473aa9","text":"AWS Storage Gateway - Volume Gateway","correct":false},{"id":"1461208499456e0ec38b4c464e8c8035","text":"AWS Storage Gateway - Tape Gateway","correct":false},{"id":"316d2e201514c4d952cfdd81c270e9c1","text":"AWS Storage Gateway - S3 Gateway","correct":false},{"id":"daf71e62fcf30c944e8792f733eb9324","text":"AWS Storage Gateway - File Gateway","correct":true}]},{"id":"af9e096c-e1b0-4f1e-9102-84dac1fab349","domain":"dep-prov","question":"You are trying to delete an EBS volume with the volume ID of vol-129df77122c4d7208 using the AWS CLI. You need to make sure that you have the required permissions before you perform the delete action. Which of the following commands will achieve this?","explanation":"The '--dry-run' parameter checks whether you have the required permissions for the action, without actually making the request, and provides an error response. If you have the required permissions, the error response is DryRunOperation. Otherwise, it is UnauthorizedOperation. The '--generate-cli-skeleton' parameters prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value 'input', it prints a sample input JSON that can be used as an argument for the '--cli-input-json' flag. '--dryrun' and '--perform-action no' are not valid parameters.","links":[{"url":"https://docs.aws.amazon.com/cli/latest/reference/ec2/delete-volume.html","title":"EC2 CLI documentation: delete-volume"}],"answers":[{"id":"21a0e55daf1816e8554b456fd8f16f9d","text":"aws ec2 delete-volume --volume-id vol-129df77122c4d7208 --dryrun","correct":false},{"id":"7b8ce5990ccec3f3375d86cb12a57fa4","text":"aws ec2 delete-volume --volume-id vol-129df77122c4d7208 --generate-cli-skeleton","correct":false},{"id":"153993f9bb7a685925820e05c073cffd","text":"aws ec2 delete-volume --volume-id vol-129df77122c4d7208 --perform-action no","correct":false},{"id":"efbae1a8e8a0b8190dfd2fcc000acff5","text":"aws ec2 delete-volume --volume-id vol-129df77122c4d7208 --dry-run","correct":true}]},{"id":"4a2b50c3-b064-4235-a27f-e6a57dab2536","domain":"automation","question":"A non-emergency medical transport provider receives their AWS bill and would like to reduce their monthly spend. Upon investigation, they discover they are paying for many orphaned EBS volumes not attached to EC2 instances. As they dig deeper, they determine that none of the volumes are needed any longer. They'd like to automate the removal process for these volumes and any others that become orphaned for more than ninety days. Which solution will keep them from paying for unneeded EBS volumes in the future?","explanation":"A periodically scheduled Lambda function can be written to determine how long an EBS volume has been orphaned by looking at CloudTrail actions. Instructions for how to create snapshots and delete EBS volumes can be found in the EC2 API Reference. Passing the volume's ARN as an AWS Systems Manager Automation resolution target will not create a snapshot and delete a volume. You can use Amazon CloudWatch Events to automate the monitoring of Trusted Advisor activity, but not CloudWatch Logs. AWS Data Pipeline is used to move and process data between different services, not to manage EBS resources.","links":[{"url":"https://aws.amazon.com/ebs/","title":"Amazon Elastic Bock Store"},{"url":"https://aws.amazon.com/blogs/mt/controlling-your-aws-costs-by-deleting-unused-amazon-ebs-volumes/","title":"Controlling your AWS costs by deleting unused Amazon EBS volumes"}],"answers":[{"id":"92788951cb2a5d4a2d4d91fb8c19fe27","text":"Create an AWS Systems Manager workflow to examine EBS volumes. For volumes not attached to EC2 instances for over ninety days, pass the volume's ARN as a resolution target to the automation's execution logic to create a snapshot and delete the volume.","correct":false},{"id":"628e11e6d88eb8d10d63cd3f003d04a2","text":"Schedule an AWS Data Pipeline workflow that leverages the AWS-provided pre-condition for orphaned EBS volumes. Pass it a time threshold parameter value of ninety days, and assign actions to create a snapshot and delete the volume.","correct":false},{"id":"855c39931a8bd19bfec582fd45fb7334","text":"Schedule an AWS Lambda function to run periodically via Amazon CloudWatch Events. Have the Lambda function read AWS CloudTrail actions to identify detached EBS volumes in an available state for over ninety days. Create a snapshot of the volume and delete it using EBS APIs.","correct":true},{"id":"9dfd7bacb72bcd7c38c22bb76dbd0321","text":"Detect changes in AWS Trusted Advisor checks for underutilized EBS volumes with Amazon CloudWatch Logs. For volumes identified as underutilized for over ninety days, invoke an AWS Lambda function to create a snapshot of the volume and delete it using EBS APIs.","correct":false}]},{"id":"46d872a7-bf30-4880-9cbd-3a63c50fb75e","domain":"mon-rep","question":"You need to enable a CloudWatch alarm to alert you if an EC2 instance which holds a key customers database goes over 100% CPU Utilization for more than two minutes. Which service should you use?","explanation":"Detailed Monitoring collects data at 1 minute intervals, whereas Basic or Standard Monitoring is every 5 minutes. Artifact allows you to check which industry and regulatory compliance standards AWS adheres to.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html","title":"CloudWatch Detailed Monitoring"}],"answers":[{"id":"af64135daff929ae7e26207cfae5e24a","text":"CloudWatch Standard Monitoring","correct":false},{"id":"96778f7d823daef4c612d60aa5bf2312","text":" CloudWatch Detailed Monitoring","correct":true},{"id":"3d3e141cae28c035547bafe32dea1423","text":"CloudTrail Expedite","correct":false},{"id":"60b018772cea138af5a8c452ed694734","text":"AWS Artifact","correct":false}]},{"id":"795314ba-4e90-418a-af2c-ee9d66f916d8","domain":"data-man","question":"An engineer has been instructed to design and build an application that processes and stores summary reports of financial transactions daily. The CTO has mandated that these reports are protected from accidental deletion when reports with the same name are generated and stored. How can the engineer accomplish this?","explanation":"Using the versioning feature of S3, accidental deletions are prevented as delete markers are just placed for deleted versions of objects. Kinesis automatically deletes records after 7 days and is not used to store critical data. The EC2 instance store and the ElastiCache clusters are not persistent storage options as well.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"S3 Versioning"}],"answers":[{"id":"8cfcc5e04e55c8460deac0663173053b","text":"Store the reports as JSON documents in Amazon Kinesis.","correct":false},{"id":"e524707a83030888491be6ca959ec580","text":"Store the reports as JSON documents in an ElastiCache cluster.","correct":false},{"id":"92a6d1a8e51989a926f98031621f78c6","text":"Store the reports inside an S3 bucket and enable versioning.","correct":true},{"id":"a198447d96a130961d8a3f7c3f73d325","text":"Store the reports inside an EC2 instance store. Use a proper naming convention to prevent reports from being overwritten.","correct":false}]},{"id":"dc1b5bc1-79d0-49ab-9c2f-e0dea66f0361","domain":"dep-prov","question":"You are helping to migrate a customer from their on-premise data center to AWS. The customer has over 1,000 users in their Active Directory service and wants to be able to using their existing on-premise directory to quickly and easily log into AWS. The customer wants to be able to continue using Microsoft Active Directory with AWS. How would you configure this set up for the customer?","explanation":"AD Connector helps connect your on-premises Microsoft Active Directory to the AWS cloud. AD Connector is designed to give you an easy way to establish a trust relationship between your Active Directory and AWS. With AD Connector, you can streamline identity management by sourcing and managing all your user identities from Active Directory. It also enables you to reuse your existing Active Directory security policies such as password expiration, password history, and account lockout policies. Also, your users will no longer need to remember yet another user name and password combination. SimpleAD does not connect existing on-premises AD to AWS. SimpleAD is a Microsoft Active Directory compatible directory from AWS Directory Service and supports common features of an active directory. AWS Directory Service for Microsoft AD is an AWS managed service that is hosted on the AWS cloud, it does not connect your AD with AWS. Creating IAM users, groups, and roles would not be feasible with 1,000 users and is not best practice.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/active-directory-ds/architecture.html","title":"Deployment Scenarios and Architecture"}],"answers":[{"id":"63140d266692d56af00a75ac1e583ff5","text":"Use AWS Directory Service for Microsoft AD to connect the on-premise Microsoft Active Directory to AWS.","correct":false},{"id":"59dc56b1ea5b335ecde98e0658573ae3","text":"Use SimpleAD to connect the on-premise Microsoft Active Directory to AWS.","correct":false},{"id":"3d15e64aa60139df5f0cd74532823f6f","text":"Create IAM users, groups, and roles based on the current on-premise users to mirror their permissions on AWS.","correct":false},{"id":"2b121dea9ea29a83bc210acdacd096e4","text":"Use AD Connector to connect the on-premise Microsoft Active Directory to AWS.","correct":true}]},{"id":"89d55a3e-4442-4e1a-9700-ca84f89c2bd2","domain":"security-comp","question":"As a consultant, many of your AWS clients come to you for answers regarding security on AWS. One client is concerned about data confidentiality and security running on their EC2 instances. The client has learned that the same instance host is shared between multiple AWS customers. She has asked you if sharing the resource would make it easy to hack into her resource to obtain confidential data. Which of the below responses would ease your client's concerns?","explanation":"256-bit AES is used for encrypting the data. Ensuring the isolation of the VMs running on a hypervisor is not the purpose of AES-256. CMKs are also used for encrypting data but have no part in securing underlying hardware. IAM permissions have nothing to do with the isolation of the VMs running on a hypervisor. The shared responsibility model for infrastructure services, such as Amazon Elastic Compute Cloud (Amazon EC2) for example, specifies that AWS manages the security of the following assets: Facilities, Physical security of hardware, Network infrastructure, Virtualization infrastructure.","links":[{"url":"https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf","title":"AWS Security Best Practices"}],"answers":[{"id":"74a2e39c263c57894c9cd11a70b72db8","text":"EC2 instances running on the same physical host are isolated from each other via IAM permissions per AWS account.","correct":false},{"id":"5a474b0ed68df81d57c5bddfb611f66c","text":"EC2 instances running on the same physical host are isolated from each other via Customer Master Keys (CMKs) under KMS policies that you own and manage.","correct":false},{"id":"748cb8264234b20c598b5ca25cfed5a2","text":"EC2 instances running on the same physical host are isolated from each other via 256-bit Advanced Encryption Standard (AES-256).","correct":false},{"id":"3341fae60e0212eff137abdf4602fa85","text":"EC2 instances running on the same physical host are isolated from each other via the hypervisor.","correct":true}]},{"id":"eba4823a-9cb9-440a-99cd-38f38ed3c10d","domain":"mon-rep","question":"An IoT company is producing a large stream of records and events and aims to store the event records in a persistent storage service of AWS. The CTO of the company has instructed the Solutions Architect of the IoT company to provide a solution that has the least amount of work required to set up and manage the data stream setup. How can the Solutions Architect accomplish this?","explanation":"Out of all the options, S3 will have the least storage costs and can easily be integrated with AWS Kinesis Firehose as a target destination of event records. The AppSync real-time support is for web and mobile applications. For an event bridge requirement that processes logs and event records from IoT sources, the Kinesis family of services is the primary option for handling realtime data streaming requirements. Given the amount of records to be stored, EBS is not a reliable solution and is also not a target destination for Kinesis.","links":[{"url":"https://aws.amazon.com/blogs/big-data/persist-streaming-data-to-amazon-s3-using-amazon-kinesis-firehose-and-aws-lambda/","title":"Amazon Kinesis Firehose"}],"answers":[{"id":"5ced4482b5eafc08a6df5d246887a232","text":"Use AWS Kinesis Firehose for the real-time data streaming service and AWS EBS for the storage.","correct":false},{"id":"cd4cace18ffdaa97f0968c443e1ffd16","text":"Use AWS Kinesis Firehose for the real-time data streaming service and S3 for the storage.","correct":true},{"id":"532a348bf03c7431c7f01baea9a4e380","text":"Use AWS Lambda and API Gateway for the real-time data streaming service and S3 for the storage.","correct":false},{"id":"03c8bfac94e1e7b5ad38f4d55bdb2f6b","text":"Use AWS AppSync and Lambda for the real-time data streaming service and DynamoDB for the storage.","correct":false}]},{"id":"17885db5-c61d-4edf-b0e3-e9d449d8e618","domain":"mon-rep","question":"Which of the following EC2 instance metrics are sent to Amazon CloudWatch by default? Select three.","explanation":"CPU utilization, disk I/O and network traffic are visible to the hypervisor running the instance and are sent to CloudWatch by default. For the others, you would need to install CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html","title":"Available CloudWatch Metrics for Your Instances"}],"answers":[{"id":"fb8326e1edbd06b1bf6ea0332e089055","text":"CPU utilization","correct":true},{"id":"2105454033539f83d3b07265aac88d7a","text":"The amount of swap space currently in use","correct":false},{"id":"b4e5bb2b6842990e919682b3d6d5726c","text":"Volume of incoming and outgoing network traffic","correct":true},{"id":"613b1188dd73dfdb768f39cfad3cc9a3","text":"Memory utilization","correct":false},{"id":"ec1e54ae04652319df5c011f228c07ac","text":"Free disk space","correct":false},{"id":"c4903df1e41e0ba0b4636e753d8c7661","text":"Disk read and write operations","correct":true}]},{"id":"0260f2a1-85f9-489c-b235-461207089452","domain":"networking","question":"You are a network administrator for your organization and have been tasked to address a recent security threat to your application that sits in a subnet. VPC flow logs show that malicious activity has been coming from a specific IP address source. You need to add an extra layer of security to control traffic coming into your VPC from that IP address. How would go about making your application secure from the malicious IP source?","explanation":"You can associate a network ACL with multiple subnets; however, a subnet can be associated with only one network ACL at a time. When you associate a network ACL with a subnet, the previous association is removed. Amazon WAF is not applied at the subnet level. AWS Config will only set your AWS resources as compliant to rules you set, but it won't prevent any external traffic from accesses your resources. As best practice, start by creating rules for your NACL in increments (for example, increments of 10 or 100) so that you can insert new rules where you need to later on.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"03bb7768562d89b49c918ae64b4183f9","text":"Configure an AWS Config rule to detect traffic originating from the malicious source. Configure a Lambda function to block the IP address whenever the Config rule is triggered.","correct":false},{"id":"cd96a1230ce2e15c29f01e30180e1d67","text":"Associate another NACL to the subnet holding the application. Add rule as the lowest number to the second NACL that explicitly denies traffic from the malicious IP source.","correct":false},{"id":"e81b37b199479422fa7a10cb981356d9","text":"Activate the WAF with your VPC flow log. Add the malicious IP source address to the WAF's blacklist.","correct":false},{"id":"b78c14382f6b1586c4a8016924d49783","text":"Add a rule to the NACL to explicitly deny traffic coming from the malicious IP source. Insert the rule as a lower number from the desired traffic from the same port.","correct":true}]},{"id":"3f14908a-fb13-4a6a-a777-7eeb6722447d","domain":"dep-prov","question":"You are running a legacy application on an EC2 instance and have created and attached an EBS volume with default settings. The volume occasionally encounters data consistency errors making the EBS volume inaccessible to the instance. How can this be prevented?","explanation":"When Amazon EBS determines that a volume's data is potentially inconsistent, it disables I/O to the volume from any attached EC2 instances by default. This causes the volume status check to fail, and creates a volume status event that indicates the cause of the failure. Switching on Enable Volume IO will allow the instance to access the volume. Switching on Auto-Enabled IO will also achieve this outcome automatically when enabled. All other options are incorrect.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html#work_volumes_impaired","title":"Working with an Impaired Volume"}],"answers":[{"id":"65e65e38f33598416e8a272b6ad29b2a","text":"This cannot be prevented","correct":false},{"id":"628b701156eef0c168e27dc6d58a9d15","text":"Switch off Auto-Enabled IO","correct":false},{"id":"bf737cfd17a3b913cb405f896e5e9b7d","text":"Switch on Enable Volume IO","correct":true},{"id":"1775e91227da79ae13b5522ccf280ca0","text":"Switch on Auto-Consistency IO","correct":false},{"id":"58bcefbd4466f36f955a0383bd253082","text":"Switch on Auto-Enabled IO","correct":true}]},{"id":"84adda98-8315-454d-b0c1-b6478c5c0d98","domain":"mon-rep","question":"You are performing an update to all of your application servers, however some of your applications are failing following the upgrade and you notice that this seems to only be affecting servers with a specific application profile. How can you easily identify which of your systems are likely to be affected?","explanation":"AWS Config is a service that enables you to assess, audit and evaluate the configurations of your AWS resources.","links":[{"url":"https://aws.amazon.com/config/faq/","title":"AWS Config FAQs"}],"answers":[{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"055f466b265e26667e0bb23ddffc7970","text":"Run Command","correct":false},{"id":"9deb03cd21d41a691cdc24bfaab2820c","text":"Inspector","correct":false},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false}]},{"id":"6eb6dee0-9456-492e-afc7-b7c860b04c92","domain":"mon-rep","question":"You have a fleet of EC2 webservers behind an application load balancer. Your web application had some down time which involved some 5XX errors during a very important time in your business 1 week ago. Although you maintain application logs on individual EC2 instances, you do not store these logs anywhere central and unfortunately the EC2 instances that experienced the downtime have since been terminated. How could you review this log data?","explanation":"Elastic Load Balancing provides access logs that capture detailed information about requests sent to your load balancer. Each log contains information such as the time the request was received, the client's IP address, latencies, request paths, and server responses. These logs are encrypted and stored in S3.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html","title":"Application Load Balancer Access Logs"}],"answers":[{"id":"c13c66278433ebb606e21e9c9f5250fd","text":"Create a new AWS inspector job to pull the snapshots of the EC2 instances from S3 and run a report in conjuction with AWS Athena.","correct":false},{"id":"d53665e5cde1c8f661130ca2882d789a","text":"Open the AWS artifact service. Create a new artifact job and point the AWS artifact agents at the terminated EC2 instances. Download the metrics and review in CloudWatch.","correct":false},{"id":"ae59c599efa75d438daecb43cc08ad41","text":"Use AWS X-ray to restore the logs from the terminated EC2 instances","correct":false},{"id":"49774faac3030c4425f2aa345cb89dc0","text":"If access logs is turned on for your application load balancer you could review this data by reviewing the logs in S3.","correct":true}]},{"id":"1a37a76e-3c69-4ae6-8ae3-5b0db850807c","domain":"mon-rep","question":"You need to monitor memory utilization of an EC2 instance. How could you achieve this?","explanation":"Monitoring memory utilization requires the installation of the CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html","title":"Collecting Metrics and Logs from Amazon EC2 Instances and On-Premises Servers with the CloudWatch Agent"}],"answers":[{"id":"c5d4aec73235f6dc0fda6738ef7c93f9","text":"Install CloudWatch Agent on the instance and have it collect memory utilization metrics.","correct":true},{"id":"e1771db5f560892163019427b6f3742c","text":"From the CloudWatch console, enable memory ulitization metric for the instance.","correct":false},{"id":"8b901f2e0a6136525aaf5ffcb881b223","text":"EC2 instance memory utilization is monitored by default.","correct":false},{"id":"30041d2fc11ea9b43497c2fe847b6461","text":"From the EC2 console, enable memory ulitization metric for the instance.","correct":false}]},{"id":"aa8af241-5322-486d-bd34-12b2d348b2ce","domain":"data-man","question":"A security officer needs to know when IAM keys in his companyâ€™s AWS Accounts have been around for more than three months.  Which service will easily help him with this?","explanation":"Trusted Advisor will give you details of IAM access key rotation.","links":[{"url":"https://aws.amazon.com/blogs/mt/query-for-the-latest-windows-ami-using-systems-manager-parameter-store/","title":"Query for the Latest Windows AMI using Systems Manager Parameter Store"}],"answers":[{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":true},{"id":"8db02bec6e61573a2849575f23459da0","text":"AWS IAM Inspector","correct":false},{"id":"49e614cc047c88063f1780aa1c1e7c0a","text":"AWS CloudWatch Sentinel","correct":false},{"id":"1f530f3e77a170663f032cffb98d0f26","text":"AWS Security Advisor","correct":false}]},{"id":"0ac7251e-689e-4cd6-bfb9-992628fb3e3c","domain":"mon-rep","question":"There has been a major outage of S3 in US-East-1 where many of your companyâ€™s AWS assets are. Your boss wants to know what effect this will have on your organization. What dashboard can you use to help diagnose how this will affect your individual organisation?","explanation":"AWS Personal Health Dashboard provides alerts and remediation guidance when AWS is experiencing events that may impact you. Inspector is an automated security assessment service. AWS X-Ray helps developers analyze and debug production, distributed applications.","links":[{"url":"https://aws.amazon.com/premiumsupport/phd/","title":"AWS Personal Health Dashboard"}],"answers":[{"id":"cf4db9f312542c8284a6ccdefcd98544","text":"Personal Health Dashboard","correct":true},{"id":"0863526e514d88cd2d00b39f8dda0920","text":"X-Ray","correct":false},{"id":"3473fa31769f9b170662878d3f67fc8c","text":"AWS Inspector Dashboard","correct":false},{"id":"6bd8c280d2d212f5f6338714620001a4","text":"AWS Service Dashboard","correct":false}]},{"id":"29e51c05-d93d-4868-9c14-8c7940bf9d4c","domain":"security-comp","question":"The CFO has raised concerns about rising AWS costs and has asked you to look into this potential issue. When you look at CloudTrail logs you notice that certain IAM Users in multiple AWS accounts within your organization are using AWS services without discretion, and these services are not relevant to their business functions. How would you implement security policies to limit which AWS services these users can access in the most effective way?","explanation":"Creating IAM policies for each IAM User is not best practice and can become an administrative burden. AWS GuardDuty does not provide IAM-related services, and thus is irrelevant. It is not possible to view CloudTrail logs at the OU level. The best solution is to use Service Control Policies (SCPs) to govern use of the AWS environment at the OU level.","links":[{"url":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html","title":"AWS Organizations: Service Control Policies (SCPs)"}],"answers":[{"id":"633fa64e9f9d9f6b601b4400d9ca6b30","text":"Identify the IAM Users within each Organizational Unit. Attach IAM policies to each user to restrict access based on each users' job function.","correct":false},{"id":"93faedb0826b3c6a97423da318c0b775","text":"Use AWS GuardDuty to detect and monitor each IAM Users' activity to document unauthorized behavior.","correct":false},{"id":"5b2ff64d8adf96a19f7dc89c3b3d76ef","text":"Attach a Service Control Policy at the Organization Unit to blacklist AWS Services that all Accounts under the OU shouldn't use.","correct":true},{"id":"c6d620763c9f148cf7eaab8ef0467d62","text":"Send CloudTrail logs at the Organizational Units' level to CloudWatch Events. Use Lambda to change IAM permission to DENY any AWS service if users attempt to use non-business critical services.","correct":false}]},{"id":"988e212c-6400-4c9d-8e9b-25ce5413256b","domain":"dep-prov","question":"If you use an IAM user to copy an instance-store-backed AMI, the user must have which of the following Amazon S3 permissions?","explanation":"If you use an IAM user to copy an instance-store-backed AMI, the user must have the following Amazon S3 permissions: s3:CreateBucket, S3:GetObject, S3:PutObject, s3:GetBucketAcl, s3:ListAllMyBuckets and s3:PutObjectAcl.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/creating-an-ami-instance-store.html","title":"Creating an Instance Store-Backed Linux AMI"}],"answers":[{"id":"3d48378493503b3c7c04da8400942853","text":"s3:DeleteBucket","correct":false},{"id":"7002b8d843e69183ff3fcc03410db0ad","text":"s3:GetObjectAcl","correct":false},{"id":"d0e4bee632dc55607e492853b76d8194","text":"s3:CreateBucket","correct":true},{"id":"8e0864f8129f5d2b658668b9103e83a5","text":"s3:PutObject","correct":true},{"id":"53cfd5032381d05f65cbc6d64e0004f5","text":"s3:GetObject","correct":true},{"id":"28e5f48e9f12d4928897b706c15e527a","text":"s3:RestoreObject","correct":false}]},{"id":"f0b349fc-e132-4c8a-be92-502a0e9295d7","domain":"dep-prov","question":"Your organization runs an application on AWS EC2 for your customers. The application runs steadily, and needs to be readily available for at least the next 10 months. What is the most cost-effective solution to run your application?","explanation":"Reserved instances are the most appropriate, cost-effective solution in this case. Spot instances may be a cheaper option but workloads on Spot can be interrupted if AWS requires capacity back. Since customers use the application regularly, Spot would not be a dependable solution. On-demand instances are less cost-effective than reserved instances. A Dedicated Host is expensive and would not be a cost-effective solution.","links":[{"url":"https://aws.amazon.com/ec2/pricing/reserved-instances/","title":"EC2 Reserved Instances"}],"answers":[{"id":"84243f7ccace747dfe8baa62b3874b2b","text":"Run your application on Spot instances. Configure a Lambda function to automate provisioning of spot fleets when demand increases.","correct":false},{"id":"3d8c0de67ef97a56a55d0e2bfc942ed3","text":"Purchase a Dedicated Host to run your application.","correct":false},{"id":"85803b258addc23096677302acf5c2e5","text":"Purchase a standard, 1-year reserved instance to run your application.","correct":true},{"id":"70446568a1bdbc2b55d792a820c55442","text":"Run your application on-demand. Turn off your servers on the weekend when demand is low to save costs.","correct":false}]},{"id":"3f043cde-54b2-42c7-9a19-7153fe5b6e95","domain":"high-avail","question":"Your customer has asked about cost-savings opportunities with AWS. They've noted that their EC2 instances are on most, if not all, the time but metrics show that aggregate CPU utilization is low. Demand for their application is also unpredictable. They want to cut costs around their EC2 fleet. Which of the below suggestions would you recommend to your customer to maximize savings?","explanation":"AWS Auto Scaling monitors your applications and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost. AWS Auto Scaling makes scaling simple with recommendations that allow you to optimize performance, costs, or balance between them. With auto scaling you can scale-out Amazon EC2 instances seamlessly and automatically when demand increases, shed unneeded Amazon EC2 instances automatically and save money when demand subsides, and scale dynamically based on your Amazon CloudWatch metrics, or predictably according to a schedule that you define. Purchasing reserved instances, although cheaper than on-demand, would not necessarily cut costs. Since demand is unpredictable you may be purchasing a commitment that you may not use. There is no indication that the application will be running for at least a year. This is true even after right-sizing. Storing snapshots of EBS in S3 is indeed cheaper than storing EBS volumes but that does not address the issue of the EC2 instances themselves.","links":[{"url":"https://aws.amazon.com/autoscaling/","title":"AWS Auto Scaling"}],"answers":[{"id":"99040729979583a2eb85e3502b484989","text":"Purchase convertible reserved instances for your EC2 fleet. They will experience up to 66% savings compared to on-demand costs and will have the option to change their instance types if the application needs change.","correct":false},{"id":"76a2f03f07c2ade7d896075a501c6bc5","text":"Utilize auto scaling groups for the EC2 fleet. Set up a scaling policy that will launch EC2 instances when CUP utilization is above a threshold, and release instances when CPU utilization is below a threshold.","correct":true},{"id":"89a84b7404990525469a3025ab3b5116","text":"Decrease the instance sizes for those instances with low CPU utilization. Purchase standard reserved instances after right-sizing the instances.","correct":false},{"id":"a8dd2caf5c16147c7b1b6bd321b6558d","text":"Take snapshots of the EBS volumes attached to the EC2 instances and store them in S3. Delete the EBS volumes as storing in S3 is a cheaper alternative than EBS storage costs.","correct":false}]},{"id":"e8355e44-b357-48de-b17b-b2373c316edd","domain":"networking","question":"An organization runs a website on an Autoscaling Group behind an Application Load Balancer (ALB). During deployments the application team creates a new ASG and Load Balancer. Which DNS service can you use to flip between the two environments in a Blue/Green manner and direct all users to the new environment?","explanation":"Route53 allows various routing policies to direct users to one or more resources.  In this case all users must be directed from one Load Balancer to another.  A simple routing policy would fulfil this requirement as it will completely replace the DNS pointer from the 'blue' load balancer with the 'green'. All other routing policies perform more complicated routing based on other variables such as healthchecks or country of origin which is not needed here.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-simple","title":"Amazon Route 53 Simple Routing"}],"answers":[{"id":"1844cecdf015b88aef8e88746b321731","text":"Use Route53 latency routing","correct":false},{"id":"ebeefbe1e321377375eb3065b4a2fc20","text":"Use Route53 failover routing","correct":false},{"id":"816c21d5068061f198f8df28aaf61e0d","text":"Use Route53 multi-answer routing","correct":false},{"id":"3299777a46e7aa18ad281b2a40bf2894","text":"Use Route53 simple routing","correct":true}]},{"id":"5ba4b098-ba54-49c0-9bd4-84461f4b7f77","domain":"security-comp","question":"An IT company has several AWS accounts that are part of an AWS Organization. The root account and all linked accounts have configured Service Control Policies (SCPs) to help restrict access to unneeded resources and manage governance for the Organization. If a user in one of the linked accounts wants to enable VPC Flow Logs to monitor IP traffic coming in/out of their VPC, what policy conditions would allow the user to do so?","explanation":"An SCP policy at the root account cascades down to all linked accounts under it. Therefore the child account only has permissions permitted by the parent above it. In this case, the IAM User would only be able to enable VPC Flow Logs if the SCP for the root account and linked account, and the IAM policy attached to the user ALL allow access to enabling VPC Flow Logs. Remember, an explicit deny always trumps an explicit allow.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_evaluation-logic.html","title":"Policy Evaluation Logic"}],"answers":[{"id":"6b8c1e7d84f5dbdb40a33a7c3b65cb35","text":"The SCP for the root account and the SCP for the linked account permit enabling VPC Flow Logs. The IAM User policy allows the user to enable VPC Flow Logs.","correct":true},{"id":"cfe34960caff96755d23848fae9707b1","text":"The SCP for the root account permits actions with the default AWSFullAccess policy. The SCP for the linked account does not permit enabling VPC Flow Logs. The IAM User policy allows the user to enable VPC Flow Logs.","correct":false},{"id":"0cf5189bcdacb3696d3bda3e43512f31","text":"The SCP for the root account does not allow enabling VPC Flow Logs. The SCP for the linked account does not permit enabling VPC Flow Logs. The IAM User policy allows the user to enable VPC Flow Logs.","correct":false},{"id":"c692b032c5024821ef739e00f1f7605e","text":"The SCP for the root account and the SCP for the linked account do not permit enabling VPC Flow Logs. The IAM User policy explicitly allows the user to enable VPC Flow Logs.","correct":false}]},{"id":"67817330-582a-439c-878c-4f490334cfad","domain":"high-avail","question":"The web development team of an chatbot machine learning startup has migrated their on-premise application to AWS. The on-premise application uses a custom load balancer which was replaced by an Application Load Balancer in the new architecture setup in AWS. The customers have reported that their chat sessions are lost from time to time and they are forced to sign in again. The new architecture setup uses Route 53, Application Load Balancer, EC2 instances, and DynamoDB for the web application tier. How can the team resolve this issue?","explanation":"Instead of disabling sticky sessions, enabling sticky sessions in the Application Load Balancer would solve the requirement of having an EC2 instance stick to an existing session similar to the scenario provided. Replacing DynamoDB with RDS instances would not solve the stickiness issues. Stickiness is not handled by Route53 routing policies. Replacing the Application Load Balancer with a Classic Load Balancer would not solve the stickiness issue.","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/","title":"ELB Features"}],"answers":[{"id":"ebb04e35ab1c5519bfe7dc876f414406","text":"Replace the Application Load Balancer with a Classic Load Balancer.","correct":false},{"id":"93cb25a136afcc3b5e255daab59500f5","text":"Enable sticky sessions in the Route 53 routing policy.","correct":false},{"id":"ca8c07a031edb56f0a44f9d891ebaa8a","text":"Enable sticky sessions in the Application Load Balancer.","correct":true},{"id":"7a83fce81dc2bab71c72499c7076e2d4","text":"Replace DynamoDB with RDS instances.","correct":false}]},{"id":"c5bc5186-77bf-47ff-86b0-a493d3d5f79e","domain":"security-comp","question":"Which of the following names is not a valid name for an IAM server certificate?","explanation":"Names of users, groups, roles, policies, instance profiles, and server certificates must be alphanumeric, including the following common characters: plus (+), equal (=), comma (,), period (.), at (@), underscore (_), and hyphen (-). cert#company.name is therefore not an acceptable server certificate name.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_iam-limits.html","title":"Limitations on IAM Entities and Objects"}],"answers":[{"id":"50720e862209ce24ecae4c6b1a483523","text":"cert=Company.Name","correct":false},{"id":"fcac63bd07e8b093f02e341d42d24e5d","text":"Certificate-CompanyName","correct":false},{"id":"bacefe00cb2a7a91e03569ee24b503a8","text":"certificate,,companyname","correct":false},{"id":"9f60f06229708587864e4896426180c2","text":"cert@companyname","correct":false},{"id":"946270e321436de010ee43f1baaf703b","text":"Certificate_CompanyName","correct":false},{"id":"88f1b3c406c7b70cdc2ffdd948270841","text":"cert#company.name","correct":true}]},{"id":"524af9a6-94c5-4c0b-a6d1-8c29011045df","domain":"automation","question":"Which AWS service allows you to consolidate billing across multiple AWS accounts, automate account creation and control access to AWS services?","explanation":"AWS Organizations offers policy-based management for multiple AWS accounts as well as consolidated billing. Personal Health Dashboard provides alerts when AWS is experiencing outages and other events that may impact you. Inspector is used for vulnerability scanning of applications running on EC2. IAM is used for policy based access control for users under a single AWS account","links":[{"url":"https://aws.amazon.com/organizations/","title":"AWS Organizations"}],"answers":[{"id":"cf4db9f312542c8284a6ccdefcd98544","text":"Personal Health Dashboard","correct":false},{"id":"b1820ee1cf68e2e65f263ff7bb207626","text":"AWS Organizations","correct":true},{"id":"41dff7155cc7aeb11c06434f6a450bb3","text":"IAM","correct":false},{"id":"9deb03cd21d41a691cdc24bfaab2820c","text":"Inspector","correct":false}]},{"id":"3ea0783e-5a48-462d-868c-4a7ffd40b78e","domain":"security-comp","question":"You have a application running on EC2 that needs to add metadata to images stored in an S3 bucket. What is the best way for the application to access the files in the S3 bucket?","explanation":"Macie is a security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS. It is not best practice to embed security credentials or access keys within an application. Creating a Lambda function to download and re-upload objects is an administrative burden. The best solution is to attach an IAM role to the EC2 instance with the proper permissions.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html","title":"IAM Roles for EC2"}],"answers":[{"id":"3ebc23969d82ab8f19ecddaf5d0189fc","text":"Create an IAM role that has a policy granting access to the S3 bucket. Attach this role to the EC2 instance running the application.","correct":true},{"id":"9aa2921b541790bb7d7f66e434891602","text":"Create a Lambda function that will download the S3 objects to the EC2 instance where the application can add metadata. Have the application re-uploaded the processed files to S3.","correct":false},{"id":"6ff9077debdc73b41993ca879b10d482","text":"Integrate the EC2 instance with Macie. Macie using NLP can apply metadata to the objects in S3.","correct":false},{"id":"7b204f66d6a87082d7d09be75dbce21b","text":"Create a new IAM User for the developer of the application. Provider the developer access keys and secret access keys to the account owning the S3 bucket. Encrypt the access keys and embed them in the appplication for security purposes.","correct":false}]},{"id":"9f2d0dd1-cac2-4cff-9166-005b4746f186","domain":"networking","question":"Your developers are coming to you for advice on how to make their website content better available to customers in Asia. There is a growing customer base in Asia Pacific (Singapore) but customers are complaining about poor latency. You discover that customers in Asia are being directed to an S3 endpoint in EU (Ireland). What would you do to ensure customers are directed to the appropriate region to improve performance?","explanation":"Geolocation routing lets you choose the resources that serve your traffic based on the geographic location of your users, meaning the location that DNS queries originate from. This would be the best way to improve latency. Creating a customer domain name is not relevant to the question. Amazon WAF is a web application firewall that would serve no purpose toward performance improvement. An ELB cannot span regions.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"3f2402f6feb904363b29958f853b0b75","text":"Configure a custom domain name by creating a new DHCP option set.","correct":false},{"id":"d2964a2b6eb3dadd409e8e4870f8e686","text":"Configure an Elastic Load Balancer to direct traffic to instances located in the Asia Pacific (Singapore) region to improve performance.","correct":false},{"id":"aea00e8d5238909a0f741554d4179219","text":"Configure a geolocation routing policy in Amazon Route 53 to route traffic based on the location of your users.","correct":true},{"id":"e691592cfcfc0a33ddeac2529c433659","text":"Configure Amazon WAF to only allow traffic from the Asia Pacific (Singapore) region to filter out unnecessary traffic to improve performance.","correct":false}]},{"id":"fe87b3bd-e952-4f75-9b0e-3583fe879ad6","domain":"data-man","question":"Your manager has informed you that due to compliance issues, all data stored in company S3 buckets must be encrypted as soon as possible.  What is the quickest way to ensure all of this data is encrypted to meet the requirements?","explanation":"The easiest and quickest way to encrypt data in a bucket is to use Server Side Encryption, because Client Side Encryption will encrypt the files before sending to S3 and therefore will only work on newly uploaded files, we can discount any Client Side Encryption options first.  Of the remaining Server Side Encryption options, we can remove any method of managing keys ourselves, as this creates an overhead, so using S3 Managed Keys (SSE-S3) will be the quickest way to encrypt objects in a bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Server-Side Encryption"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Client-Side Encryption"}],"answers":[{"id":"1a4d7384bee05f19390352598fbc5fb6","text":"Enable Server-Side Encryption with Customer-Provided Keys on each S3 bucket","correct":false},{"id":"873764e12ed3764f29ba07e9fcdb622a","text":"Enable Server-Side Encryption with S3-Managed Keys on each S3 bucket","correct":true},{"id":"d16f34464ccb19afe4b04ca69703c59e","text":"Encrypt new data using AWS KMSâ€“Managed Customer Master Key and add to S3 bucket","correct":false},{"id":"56f875bcb7f1ca2bd789c15f1cdc5c37","text":"Enable Server-Side Encryption with AWS KMS-Managed Keys on each S3 bucket","correct":false}]},{"id":"b5cf6800-4ce3-4d24-8eaa-a1279c1c6409","domain":"mon-rep","question":"An insurance company has a monolithic application hosted in an EC2 instance and a serverless application hosted in AWS Lambda. After a few months of running the application, the customers have raised multiple delays and performance issues from the applications. The Operations Engineer responsible has mentioned that the latency issues might have been caused by code-level performance issues and the Head of Operations has instructed the team to add code-level monitoring support. How can the team accomplish this?","explanation":"X-Ray can be used for adding code tracing support for both monolithic application code (e.g. a large Django monolithic project) and serverless (Lambda function) code. CloudTrail is used for auditing API call logs. CloudWatch is used for monitoring resource usage and metrics. X-Ray is a distributed tracing system.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html","title":"AWS X-Ray"}],"answers":[{"id":"2eb097422fa45d569c37d094428d9a9d","text":"Use AWS CloudWatch for the monolithic application code. Use AWS X-Ray for the serverless application code.","correct":false},{"id":"ab066c8d1096ed9b7b49b4637589b201","text":"Use AWS X-Ray for the monolithic application code. Use AWS CloudTrail for the serverless application code.","correct":false},{"id":"7d3a7bc0301958a4e3ad624f70b462d4","text":"Use AWS CloudTrail for the monolithic application code. Use AWS X-Ray for the serverless application code.","correct":false},{"id":"359f4dd3d7689aca37514e23a8781431","text":"Use AWS X-Ray for both the monolithic application code and the serverless application code.","correct":true}]},{"id":"6ef01959-f96f-4529-91e6-fd45696273ef","domain":"networking","question":"You are a SysOps Administrator setting up secure access for IAM users in your organization to an S3 bucket. You do not want any traffic to leave the AWS Network. How would you implement a cost-effective solution?","explanation":"A gateway endpoint is a gateway that you specify as a target for a route in your route table for traffic destined to a supported AWS service. S3 and DyanamoDB are the only two AWS services supported by gateway endpoints. A gateway endpoint would allow you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. An interface endpoint is not supported for S3. A Direct Connect connection is costly and unnecessary for this case. Connecting a NAT device to S3 is not possible.","links":[{"url":"https://docs.aws.amazon.com/en_pv/vpc/latest/userguide/vpc-endpoints.html","title":"VPC Endpoints"}],"answers":[{"id":"29139880aac3b4d667b356b282ea87b9","text":"Configure a NAT device to the S3 bucket. Route all traffic to the S3 bucket through this NAT device.","correct":false},{"id":"3164bfcf2b95e5e90ebd10a622eb7797","text":"Configure a Direct Connect connection between your data center and AWS. Have users access AWS through this Direct Connect connection.","correct":false},{"id":"2baf6dcd64a5aac39aeb30d6e25605ac","text":"Configure a gateway endpoint to the S3 bucket. Specify the endpoint as a target for a route in your route table.","correct":true},{"id":"5d03cf7506e8692659007c4cc2be9114","text":"Configure an interface endpoint to the S3 bucket. Specify the IP range of allowable traffic.","correct":false}]},{"id":"4871ce12-9da0-4e28-b1e4-373560dbdffa","domain":"automation","question":"A telecommunications company sends out monthly bills to their customers. Usage is accumulated during the month by nightly batch jobs that process call details. The company is in the process of migrating the billing system to AWS to reduce costs. What approach will provide them with the most cost effective solution for the compute portion of their nightly batch runs?","explanation":"AWS Batch provides allocation strategies to consider capacity and throughput in addition to cost when provisioning instances for jobs. This is a newer feature that provides more flexibility than the previous scheme that chose an instance that was the best fit based on vCPU, memory, and GPU requirements. Creating a pool of EC2 Reserved Instances might result in unused capacity if workload requirements change. Lambda is not currently available as a compute resource for AWS Batch.","links":[{"url":"https://aws.amazon.com/batch/","title":"AWS Batch"},{"url":"https://aws.amazon.com/blogs/compute/optimizing-for-cost-availability-and-throughput-by-selecting-your-aws-batch-allocation-strategy/","title":"Optimizing for cost, availability and throughput by selecting your AWS Batch allocation strategy"}],"answers":[{"id":"8633cd86b6633324660fa073362c2f98","text":"Schedule jobs with AWS Batch into a pool of EC2 Reserved Instances that contains enough servers for the minimum number of jobs that will be run on any one night. Use an Auto Scaling Group to provision Spot Instances to handle any additional demand.","correct":false},{"id":"3220afaa7c6fd31e7a8d35ce1e2df1fa","text":"Configure AWS Batch to choose an instance type for each job based on vCPU, memory, and GPU requirements at the lowest cost.","correct":false},{"id":"0bb4d60773589240e55a5a506ee84275","text":"Use AWS Batch allocation strategies to define capacity, throughput, and cost priorities for instance type provisioning.","correct":true},{"id":"96ef18a4d93470acb7dbd558eb666ca3","text":"Specify AWS Lambda as the compute resource for AWS Batch. Invoke the appropriate Lambda functions for each job.","correct":false}]},{"id":"cb89f655-931a-4755-a01c-07b9abf46363","domain":"data-man","question":"Your payment processing system stores 300 GB of data in an Amazon RDS database and 1 TB of data in an Amazon Elastic File System (EFS). A human error incident occurs resulting in files being mistakenly deleted from the EFS. With no backup of the files, the data needs to be reconstructed from other sources. You're tasked with ensuring that future recoveries from unintentional corruptions and deletions from the EFS can be accomplished in a more expeditious manner. Which solution will provide the most efficient recovery capability?","explanation":"AWS DataSync makes it simple and fast to move large amounts of data between on-premises storage, S3, and EFS. A DataSync agent on an EC2 instance can access a source file system and write the data to a target EFS file system. AWS DataSync performs transfers much faster than open source tools like rsync. EFS currently does not provide a snapshot capability. The EFS API doesn't currently provide the capability to read file system directories.","links":[{"url":"https://aws.amazon.com/datasync/","title":"AWS DataSync"},{"url":"https://aws.amazon.com/about-aws/whats-new/2019/05/aws-datasync-now-supports-efs-to-efs-transfer/","title":"AWS DataSync Now Supports EFS-to-EFS Transfer"}],"answers":[{"id":"d358ff9f00701597b983db08178191be","text":"Implement an Amazon CloudWatch event to periodically invoke an AWS Lambda function. Have the Lambda function read the primary file system's directory via the EFS API and write updated files from the primary file system to a backup file system. Have the Lambda function also write details about the backup to an Amazon DynamoDB table, and send backup logs to Amazon S3","correct":false},{"id":"f0aa146fd12f8b90653556e359f3a5a5","text":"Implement an Amazon CloudWatch event to periodically invoke an AWS Lambda function. Have the Lambda function create an EC2 Linux instance that uses rsync to write files from the primary file system to a backup file system. Have the EC2 instance also write details about the backup to an Amazon DynamoDB table, and send backup logs to Amazon S3","correct":false},{"id":"c008c80d4f7240b74aa18b5301bd2f80","text":"Install an AWS DataSync agent on an EC2 instance and mount the primary EFS file system. Implement an Amazon CloudWatch event to periodically publish a message to an Amazon Simple Notification Service topic. Have a script on the EC2 instance receive the notification and invoke DataSync to update a backup EFS file system","correct":true},{"id":"d14180fd4210358f6de8f3e00fa219b9","text":"Configure EFS snapshots for the file system. In the EFS management console, designate when the snapshots will run and what the retention time frame should be","correct":false}]},{"id":"cf072a65-cda4-492e-b42a-7ee7305bb9b6","domain":"high-avail","question":"You have a web application with the front end hosted on EC2 and the database hosted on RDS in a single Availability Zone. You notice that when backups are taken from your RDS instance, your applications performance is severely degraded. Your boss asks you to fix the issue. What should you do?","explanation":"You should create a multi-AZ RDS instance and migrate your DB to it. This way, when the backups are taken, they will be taken from the secondary -- not the primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"Multi-AZ RDS"}],"answers":[{"id":"ebcb098cff009244307167ae9489e2b1","text":"Create a multi-AZ RDS instance and migrate your DB to it. This way, when the backups are taken, they will be taken from the secondary -- not the primary.","correct":true},{"id":"531a46711a70d61a60f10cf29f31171b","text":"Move your RDS instance to an in-house SQL server that has Netbackup installed.","correct":false},{"id":"82ca3fd61d44001c088391d1a6af1442","text":"Upgrade your RDS instance to an instance that has better disk IO. This way, the IO suspension from the back up will be \"equaled out\" by the increase in the new IO from the upgraded instance.","correct":false},{"id":"ff7e77cc465d1a0285e8ea4c236bee2c","text":"Turn off backups for RDS. This will fix the performance issue immediately.","correct":false}]},{"id":"8f2d3d61-092d-429c-a109-69ab00fa4065","domain":"mon-rep","question":"AWS Cost Management encompasses a number of services to help you to organize, control and optimize your AWS costs and usage.  Which of the following Cost Management related tools gives you the ability to set alerts when costs or usage are exceeded?","explanation":"The correct answer is AWS Budgets.  AWS Cost Explorer lets you visualize, understand, and manage your AWS costs and usage over time. AWS Cost & Usage Report lists AWS usage for each service category used by an account and its IAM users and finally, Reserved Instance Reporting provides a number of RI-specific cost management solutions to help you better understand and manage RI Utilization and Coverage.","links":[{"url":"https://aws.amazon.com/aws-cost-management/aws-budgets/","title":"AWS Budgets"}],"answers":[{"id":"e32a801c8e0beab6abb9361e937365be","text":"AWS Budgets","correct":true},{"id":"c7f176d72688fd87853e31b84159d541","text":"AWS Cost Explorer","correct":false},{"id":"eef79d956328d5e4ec426d448cc53c74","text":"Reserved Instance Reporting","correct":false},{"id":"824fd559c917b4ae56f36787b886eb81","text":"AWS Cost & Usage Report","correct":false}]},{"id":"88d422b1-765f-4919-b83d-91b1b862b26f","domain":"networking","question":"You need a load balancer with support for SSL offloading, cross-zone load balancing and Path-Based Routing. What load balancer should you choose?","explanation":"Path Load balancer isn't a real thing. Application Load balancer, Network Load Balancer and Classic Load Balancer all support SSL offloading and cross-zone load balancing. However, only Application Load Balancer supports Path-Based Routing.","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/","title":"Elastic Load Balancing features"}],"answers":[{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":false},{"id":"682b66281be2437eb8d29a051355963d","text":"Path Load balancer","correct":false},{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false},{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":true}]},{"id":"bff7e3f1-155b-475f-b05d-04a051ab9325","domain":"dep-prov","question":"You are experiencing issues with an Application Load Balancer that has been updated in the past week by another member of your team. Access logging is enabled on the ALB. You need to determine what configuration changes have been made. Which is the most appropriate monitoring tool to use?","explanation":"You can use AWS CloudTrail to capture detailed information about the calls made to the Elastic Load Balancing API for configuration and store them as log files in Amazon S3. You can use these CloudTrail logs to determine which calls were made, the source IP address where the call came from, who made the call, when the call was made, and so on. Amazon CloudWatch can be used to retrieve statistics about data points for your load balancers and targets as an ordered set of time-series data, known as metrics. You can use these metrics to verify that your system is performing as expected but they do not provide information about configuration changes. Access Logs capture detailed information about requests sent to your load balancer from clients, but are also not relevant to configuration. You can use request tracing to track HTTP requests but this does not provide additional configuration information.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-monitoring.html","title":"Monitor Your Application Load Balancers"}],"answers":[{"id":"50ed91980adb1dac23689554eb719277","text":"CloudWatch metrics","correct":false},{"id":"8c6ded942a243b91e65d037ab4e21f7d","text":"CloudTrail logs","correct":true},{"id":"6a292fdb897093b64ef80b39e7db0a4a","text":"Request tracing","correct":false},{"id":"6c5c81f47915de5f03d2577e8fae1c34","text":"Access logs","correct":false}]},{"id":"a9593b23-49e7-4831-b16d-b7618fd07bfd","domain":"mon-rep","question":"Which of the following ELB response Codes indicates a normal, successful response from the registered instances.","explanation":"A HTTPCode_Backend_2XX  indicates a normal, successful response from the registered instances.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-cloudwatch-metrics.html#loadbalancing-metrics-clb","title":"CloudWatch Metrics for Your Classic Load Balancer"}],"answers":[{"id":"4cbb9bc9e8892ec2b03ce9300089bbae","text":"HTTPCode_Backend_2XX","correct":true},{"id":"ed7ec39cbf617481ed14efc52061f350","text":"HTTPCode_Backend_5XX","correct":false},{"id":"e7415e6c2943791d842013f7aba6c120","text":"HTTPCode_Backend_4XX","correct":false},{"id":"e12e4cbddc5e0433d4f8b642c591b631","text":"HTTPCode_Backend_3XX","correct":false}]},{"id":"3xre6hrv-j02a-kj8k-nkyn-5951wwipzpzd","domain":"automation","question":"Which service can you use to enable configuration management using Chef or Puppet?","explanation":"OpsWorks is a configuration management service that provides managed instances of Chef and Puppet. Config allows you to record and evaluate configuration but doesn't use Chef or Puppet, Systems Manager is an operational insights tool and Athena is used to run SQL queries on data held in S3.","links":[{"url":"https://aws.amazon.com/opsworks/","title":"OpsWorks"}],"answers":[{"id":"582ca45acfd3e21caca8b786c1413850","text":"Athena","correct":false},{"id":"c42aaccedc51aac929c8ae313066f320","text":"OpsWorks","correct":true},{"id":"fa535ffb25e1fd20341652f9be21e06e","text":"Config","correct":false},{"id":"8e75b153e61c22a8ea4e14aadc7cb4ee","text":"Systems Manager","correct":false}]},{"id":"a633d884-fccf-4ab0-bdff-72974f6fe06c","domain":"networking","question":"You have launched an EC2 instance into the public subnet of your custom VPC. The VPC's internet gateway is properly specified in the default route table and the instance's security group allows SSH traffic over port 22. However, you are still unable to SSH into your instance. Which of the following could explain this?","explanation":"To communicate with your instance, it must have either a public IP or an Elastic IP.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html","title":"AWS Elastic IP"}],"answers":[{"id":"780a0b2b6809da8bfafa8cc49a2d62e3","text":"Your instance doesn't have an Elastic IP.","correct":true},{"id":"0111365d729d1d299458b0a3069b9a25","text":"Your EC2 instance doesn't have a public IP address.","correct":true},{"id":"62c19bb64f03bcc2aa277034eca8fa21","text":"You have the Internet Gatweway specified as the destination in the Route Table.","correct":false},{"id":"3376ac0efb861775fb39e3946d485331","text":"The security group isn't properly connected to the Internet Gateway.","correct":false}]},{"id":"066a63c9-1a0c-454f-8eeb-628657c4b7b3","domain":"security-comp","question":"As a security administrator for your company, the development team has asked for your advice on protecting their web product running on AWS against SQL injection attacks. Recently, there have been several cases where attackers have tried to insert certain malicious SQL queries to extract data from a database that stores confidential customer data. The development team manages and runs the database on EC2 running behind a load balancer. What advice would you give to the team to proactively protect against these kinds of attacks?","explanation":"There are several firewall services that AWS has provided including AWS WAF, AWS Shield, and AWS Firewall Manager. But in this case an ACL with WAF would be the most appropriate. AWS Firewall Manager simplifies your administrative and maintenance tasks across multiple accounts and resources for AWS WAF. AWS WAF is a web application firewall that lets you monitor the HTTP and HTTPS requests that are forwarded to a load balancer. You can block/allow all requests except the ones your specify. AWS Shield Advanced would protect against DDOS attacks. AWS Config would only provide notifications and thus would be a reactive solution to attacks.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html","title":"What Are AWS WAF, AWS Shield, and AWS Firewall Manager?"}],"answers":[{"id":"c84b52c0e32a45fc862e101beb233230","text":"Activate AWS Shield Advanced. Although costly, it will protect the application with a 24/7 response team from AWS, and full system and financial restoration after an attack.","correct":false},{"id":"5cfd6d4faff387749033b7f3e493f870","text":"Create a WAF Access Control List (ACL) with a rule to explicitly block the SQL injection attacks. Attach the ACL to the load balancer.","correct":true},{"id":"3e1ffae7dc069fcf4bdce431a89b4792","text":"Create a rule in AWS Firewall Manager to explicitly block the IP addresses that were listed as the attackers.","correct":false},{"id":"3b888c9ab75dfc1fd31b6fdcec298c41","text":"Use AWS Config to monitor the application. Set a rule to notify the development team when a malicious attack occurs.","correct":false}]},{"id":"ac509f33-b7fd-483a-a610-b5744bc89943","domain":"automation","question":"An organization wants to understand when the infrastructure it is deploying from CloudFormation has been manually changed by a rogue developer in the team.  Which three services would help to detect changes and determine who performed the change?","explanation":"AWS CloudFormation Drift detection allows for you to identify changes over time of resources, when compared to the Cloudformation stack which created them.  The AWS Config managed rule 'cloudformation-stack-drift-detection-check' allows for a drift check to be initiated.  Any stacks with drift can be flagged as a non-compliant stack.  AWS Config can also provide you with a timeline of modified resources, along with the associated CloudTrail event that caused the configuration to change.. including which IAM role or user performed the change.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2018/11/aws-cloudformation-now-supports-drift-detection/","title":"AWS CloudFormation Now Supports Drift Detection"},{"url":"https://aws.amazon.com/about-aws/whats-new/2018/11/aws-config-launches-a-new-aws-config-rule-to-support-aws-cloudformation-stack-drift-detection/","title":"AWS Config Launches a New AWS Config Rule to Support AWS CloudFormation Stack Drift Detection"}],"answers":[{"id":"3c4dbfbe3fe821153b16f5a7b3e98a96","text":"AWS CloudFormation Drift","correct":true},{"id":"7c1c0a0eb09dcbcd9acf3ade0b16cb91","text":"AWS Guard Duty","correct":false},{"id":"b00e2e3d5e092e8527268afe49e5a5e2","text":"AWS CloudFormation Change Sets","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"28408acf54ab04fe847fd24957e528d9","text":"AWS CloudWatch Logs","correct":false},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":true}]},{"id":"b44c9f0b-805c-4de9-8ae7-71a6c2885b76","domain":"mon-rep","question":"Which of the following can you use to monitor API usage in AWS?","explanation":"CloudTrail logs all API calls within your account, CloudWatch monitors performance metrics, RunCommand is a Systems Manager feature which lets you run a command simultaneously on multiple instances, Trusted Advisor makes security, performance and cost optimization recommendations.","links":[{"url":"https://aws.amazon.com/cloudtrail/faqs/","title":"CloudTrail FAQs"}],"answers":[{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"64d231d79e9f7640a4572f7ae75aa226","text":"RunCommand","correct":false}]},{"id":"ed2ywbaa-95e6-2i0x-jzmq-kdvksdj16nxi","domain":"security-comp","question":"As an administrator, which of the following IAM tasks are *critical* to the security of your AWS environment?","explanation":"While all of these things are important, it's critical that you delete the root access keys, activate MFA on the root account and create an IAM password policy.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html","title":"IAM Best Practices"}],"answers":[{"id":"18ca1c0dbfc5485da49fcec4853501ee","text":"The use of groups to assign permissions","correct":false},{"id":"d4f7829d16d41ce16ff31c2d31aeba6a","text":"The creation of individual IAM users","correct":false},{"id":"c436360232888720d87f4d9d3b2a8147","text":"The activation of MFA on the root account","correct":true},{"id":"5911b1e6aadb27a95ade3c5e00f03ea8","text":"The application of an IAM password policy","correct":true},{"id":"878a3402611421642a5100d0177d21fb","text":"The deletion of root access keys","correct":true}]},{"id":"3f2da740-c544-4f1e-91c5-82a11619c457","domain":"automation","question":"An engineer has been instructed to generate a CloudFormation template that creates an ElastiCache cluster automatically when in production mode. How should the engineer accomplish this?","explanation":"This use case involves the use of a parameter (input) and a condition that changes the behavior of the template depending on the parameter. With the use of CloudFormation conditions, only one template is used instead of multiple similar templates","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/conditions-section-structure.html","title":"CloudFormation - Conditions Section Structure"}],"answers":[{"id":"944e9640a5444863d4993d2e7da7719e","text":"Use nested CloudFormation stacks with one stack creating an ElastiCache resource and another without the ElastiCache resource.","correct":false},{"id":"59d4d9c4627999c1d25bf01e7b161b6b","text":"Create two templates. One for the production template with the ElastiCache cluster and another without the ElastiCache cluster.","correct":false},{"id":"778d1401e9dd6d35d4355b56d7c12d3f","text":"Use a parameter for the environment. Add a condition in the CloudFormation template to create the ElastiCache resource only when environment = production.","correct":true},{"id":"7c59d26f19f71a761bc0b00e8194713f","text":"Use SAM templates instead of CloudFormation templates to manage the differences between environments.","correct":false}]},{"id":"4c7fb750-0ec0-4c9f-8dc6-378122edf97a","domain":"automation","question":"The engineering team of a digital marketing company has a lot of AWS Lambda functions directly created and managed using the AWS Console. The CTO has mandated that the code and the deployments are managed using templates and the code is stored in a code repository to enable proper version control processes. How can the team achieve this?","explanation":"SAM templates and CloudFormation templates can be used to manage the Lambda function code. Out of all the options, only CodeCommit can be used directly as a managed service for a code repository. S3 buckets are not used directly as a code repository.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"What is SAM"}],"answers":[{"id":"b670d764967a3aa65a1424279e37291c","text":"Use SAM templates to manage the lambda function code. Use S3 buckets for the code repository.","correct":false},{"id":"f33ec453646a2074aa930a61f466fc1a","text":"Use CloudFormation templates to manage the lambda function code. Use ECR for the code repository.","correct":false},{"id":"c5fe89ee64d944e98f26b2db3fa7cea2","text":"Use SAM templates to manage the lambda function code. Use CodeCommit for the code repository.","correct":true},{"id":"a85a26cd33fe99adb584452fa780dce2","text":"Use CloudFormation templates to manage the lambda function code. Use S3 buckets for the code repository.","correct":false}]},{"id":"8dade21b-c268-4ccd-af0a-18c01cd2c638","domain":"automation","question":"You check the last bill of your AWS account and find that the storage of EBS snapshots charges a lot. A large number of EBS snapshots are very old and can be deleted. You want to keep 10 snapshots for an EBS volume and old snapshots are deleted automatically. The strategy should also help you to create a snapshot every 24 hours. Which is the best way of implementing this strategy?","explanation":"The Amazon EBS Snapshot Lifecycle can automate the creation, retention, and deletion of EBS snapshots. You only need to configure a lifecycle policy in the Lifecycle Manager. You do not need to configure a Lambda Function or a Cron job in an EC2 instance to implement the same policy.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html","title":"Automating the Amazon EBS Snapshot Lifecycle"}],"answers":[{"id":"e711537d471732823f103b6f63ab96c2","text":"Configure a Cloudwatch Event rule to execute every 24 hours. The target is a Lambda Function that creates a new snapshot and deletes the old one.","correct":false},{"id":"6e23ea86e4cf4e8929aa5b846a7e5ad4","text":"Create a Snapshot Lifecycle Policy to automatically create new snapshots and delete old snapshots.","correct":true},{"id":"ac159fa50438475f44d25f96b6a2bea4","text":"Configure a Lambda Function that runs every 24 hours to create a snapshot and delete the old snapshot.","correct":false},{"id":"630f293528bb790c603b2f77b266a56d","text":"Use a Cron job that runs in an T2.micro EC2 instance. The job creates a new snapshot and deletes the old one every day.","correct":false}]},{"id":"947a7303-9a09-41cc-ae76-6e7fe32a8dc4","domain":"data-man","question":"Autoscaling has been terminating your EC2 instances which has resulted in losing application logs. Where could you store the logs so that they exist independently from the life of the EC2 instances?","explanation":"Amazon CloudWatch is a monitoring service for AWS cloud resources and the applications you run on AWS. You can use Amazon CloudWatch to collect and track metrics, collect and monitor log files, and set alarms.","links":[{"url":"https://aws.amazon.com/cloudwatch/","title":"CloudWatch"}],"answers":[{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":true},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"9deb03cd21d41a691cdc24bfaab2820c","text":"Inspector","correct":false}]},{"id":"50aa4157-f34a-4783-a384-54a3d6a01a56","domain":"security-comp","question":"According to the AWS shared responsibility model for abstracted services such as Amazon S3 and Amazon DynamoDB, what is the customer responsible for? Choose two.","explanation":"For abstracted services, such as Amazon S3 and Amazon DynamoDB, AWS operates the infrastructure layer, the operating system, and platforms, and customers access the endpoints to store and retrieve data. Customers are responsible for managing their data and configuring the service to match their use case.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"f085213d0eb85dba2852d4806d44c8d8","text":"Using IAM to apply the appropriate permissions.","correct":true},{"id":"ff0cec3b4483d0f78461e26f53e22b1e","text":"Provisioning the underlying infrastructure.","correct":false},{"id":"c664130f5b6e5a24cd61a355e8b97540","text":"High availability of the endpoints","correct":false},{"id":"e027059be4bd1474a9b38c65eb31e483","text":"Operating system patches.","correct":false},{"id":"45701a6f69581c386f76dc415b5f9c4e","text":"Managing the data (including encryption options).","correct":true}]},{"id":"44323aa9-db88-4c8e-8594-5af3edab91b8","domain":"networking","question":"You're consulting for a consumer electronics company that markets its products globally. A new customer-facing application will be deployed in seven AWS Regions worldwide. Business logic will be handled by microservices deployed on EC2 instances in each region. The data layer will be hosted on Amazon Aurora in a single AWS Region. Which architecture will provide the highest performing solution for end users?","explanation":"A Route 53 latency routing policy will send requests to the destination with the lowest latency, generally resulting in the best performance. A Route 53 geolocation routing policy will probably not provide better performance than a latency routing policy. Even though targets may be physically closer, they may involve more network hops. Geolocation policies are generally used to serve localized content. Application Load Balancers work well for microservice architectures since targets can be registered as a specific port on an EC2 instance. CloudFront path patterns are for routing different file types, not for distinguishing origins in different regions.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html","title":"What Is an Application Load Balancer?"}],"answers":[{"id":"8f8597399845c09e57ce08b6791b3ab0","text":"Deploy the EC2 instances behind an ELB Network Load Balancer in each region and set each one up as an Amazon CloudFront origin. Create path patterns to route all requests to the load balancer in the desired region","correct":false},{"id":"9a5a8c536cd4c0209770d8e9b9897abd","text":"Create an Amazon Route 53 record set for the application with a latency routing policy. Deploy an ELB Application Load Balancer in front of the EC2 instances in each region","correct":true},{"id":"562b2939dfd8d3940e82593f75d73725","text":"Implement an Amazon Route 53 record set for the application with a geolocation routing policy. Use an ELB Network Load Balancer in front of the EC2 instances in each region","correct":false},{"id":"915fca3a9a0bf0eaf51de3fe684ef9e0","text":"Configure an Amazon Route 53 record set for the application with a geolocation routing policy. Implement an ELB Application Load Balancer in front of the EC2 instances in each region","correct":false}]},{"id":"466da628-4a01-43da-bb82-90215f555b37","domain":"automation","question":"A development team wants to deploy an application to AWS infrastructure using CloudFormation. They have code which copies files from the Internet in order to install their application on launch.  The team finds that whilst the stack deploys, it shows CREATE_COMPLETE, before the application is available.  What changes can they make to their solution in order for the Create Stack to only show as CREATE_COMPLETE when the application has finished deploying?","explanation":"The stack is changing to CREATE_COMPLETE because CloudFormation does not wait for userdata to complete by default. By adding a 'creation policy', you are able to tell CloudFormation to wait for the 'all-clear' from a given resource that it has complete its setup. The 'all-clear' signal is sent back to CloudFormation via the cfn-signal tool.  In addition to a creation policy, the development team could consider creating their own customised AMIs which contain the large downloads from the Internet already. By launching from these AMIs you can considerably cut down on installation time. Thirdly if you store the files in S3, the file download operations will likely be much faster and reliable than using the Internet.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-signal.html","title":"cfn-signal"},{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/enable-fast-bootstrapping-of-your-auto-scaled-instances-using-dynamically-created-images/","title":"Speed up instance bootstrapping by using dynamically created images"}],"answers":[{"id":"b39b6b36b224e633a0f7ce72a9061c61","text":"Use a nested stack with a dependency so that the parent stack only completes when the nested (application server) stack create has completed","correct":false},{"id":"affa2b51c754c18df43f666b47e9a3bc","text":"Use a cfn-signal and a creation policy in the stack to remain at CREATE_IN_PROGRESS during installation and then send a web call back to CloudFormation to mark the resource as complete once the download and install has finished","correct":true},{"id":"4feec8f08e82e321dd29bddaca27eac1","text":"Use a custom lambda to change the stack status to 'CREATE_PENDING' whilst the install is running and set to 'CREATE_COMPLETE' once the application is installed","correct":false},{"id":"489ada34b3c1a06eb7099396dd7b87ee","text":"Add the downloaded files to Systems Manager Parameter store as a large binary and pull from there on launch","correct":false},{"id":"6ddb94842ea46b76f66e976e3a13c912","text":"Customise their AMI to pre-install the software from the Internet to speed-up deployment time","correct":true},{"id":"deecec189f6b1db2dc2f46b389124e5f","text":"Store the downloaded files in S3 and update the userdata to perform a s3 cp instead of downloading from the Internet","correct":false}]},{"id":"3f8d157d-c9a7-4e65-81ca-23495248c13a","domain":"high-avail","question":"Which of the following is part of the failover process for a Multi-Availability Zone RDS instance","explanation":"The DNS record for the RDS endpoint is changed from primary to standby.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"The Multi-AZ Failover Process"}],"answers":[{"id":"837a3731c4c25be7e91a8d02984a08fd","text":"A new DB instance is created in the standby availability zone.","correct":false},{"id":"d0bb9a7c3d4da6a24f1f7d977b81210c","text":"The IP of the primary DB instance is switched to the standby DB instance.","correct":false},{"id":"7150d3c0aa88b4f548178e7ee6748ce3","text":"The failed RDS DB instance reboots.","correct":false},{"id":"aa56a93d275a00fbbc67b186e8b7683c","text":"The DNS record for the RDS endpoint is changed from primary to standby.","correct":true}]},{"id":"f77c40bd-922a-4bd5-8688-355a24e5b7f4","domain":"mon-rep","question":"As a SysOps Administrator you are auditing the patches across all the RDS instances within the us-east-1 Region of your AWS environment. You need to check the OS of the instances to ensure that the latest patches are installed and that the proper security requirements are being met. What AWS service could you use to complete your task?","explanation":"You can view whether a maintenance update is available for your DB instance by using the RDS console, the AWS CLI, or the Amazon RDS API. If an update is available, it is indicated in the Maintenance column for the DB instance on the Amazon RDS console. You can use Amazon Inspector service to create and run security assessments for your Amazon EC2 instances. AWS Artifact is used for gathering central compliance-related information that matters to you. Trusted Advisor online tool that provides you real time guidance to help you provision your resources following AWS best practices and would not necessarily provide OS patching related recommendations. These are best viewed directly in the RDS console.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Maintenance.html","title":"Maintaining a DB Instance"}],"answers":[{"id":"289e4c4b17e574f33583898b34a8f37a","text":"Check maintenance of the instances on the Amazon RDS console.","correct":true},{"id":"d289311b7f2b2249f93a154c2a78e69a","text":"Use the AWS Trusted Advisor dashboard to view recommendations.","correct":false},{"id":"af6beaf0a652352efd6b43acbef87765","text":"Check AWS Artifact to view the patch requirements of the instances in your AWS environment.","correct":false},{"id":"f5182b63a0b85cdb1fba4efaac2c38d6","text":"Use Amazon Inspector to run a report that shows the current security status of your RDS instances.","correct":false}]},{"id":"a6f0b148-f08b-4a0e-bf13-791fe0af285e","domain":"security-comp","question":"You have a new manager who would like to introduce automated security assessments to allow you to test all of your applications running on EC2. Which AWS tool do you recommend?","explanation":"Inspector allows you to perform automated vulnerability assessments on applications running on EC2, Trusted Advisor can help you reduce cost, increase performance and improve security by optimizing your AWS environment, AWS Shield provides DDOS protection, Systems Manager is an Operational Management tool","links":[{"url":"https://aws.amazon.com/inspector/faqs/","title":"Inspector"}],"answers":[{"id":"9deb03cd21d41a691cdc24bfaab2820c","text":"Inspector","correct":true},{"id":"8e75b153e61c22a8ea4e14aadc7cb4ee","text":"Systems Manager","correct":false},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"637d82e8a7206e87344161109cf7112d","text":"AWS Shield","correct":false}]},{"id":"9ad79f24-9def-4d1e-9419-2037fdeda2cf","domain":"data-man","question":"In your company, in order to meet compliance requirements, production files in all S3 buckets need to be replicated into S3 buckets in a different region. These files already have a prefix of PROD. Other files without this prefix should not be copied. Which of the following is the fastest and most cost-efficient way to achieve this requirement?","explanation":"Users can easily configure Cross-Region Replication to copy S3 objects to a bucket in another region. In the replication rule, the source can be the entire bucket, a prefix or tags. The solution of using the EC2 instance is not cost-efficient. The Lambda function should only copy files with the PROD prefix. The \"aws s3 cp\" command cannot replicate new or updated files to the target.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html","title":"S3 Cross-Region Replication"}],"answers":[{"id":"b4d89a58bd92a685500e925adf4d68d6","text":"Create a T2.micro EC2 instance. Set up a cron job to sync production files to the target S3 buckets every 10 minutes.","correct":false},{"id":"d786d6ad7df12da04c1096d758233df6","text":"Use a Lambda function to copy all objects in S3 buckets to another region. Then delete the files that do not have the PROD prefix.","correct":false},{"id":"e0c7b585219f6c9ec9213169d6c29f23","text":"Use AWS CLI command \"aws s3 cp s3://sourceBucket/PROD/* s3://targetBucket/PROD/* --recursive\" to replicate production files.","correct":false},{"id":"db95dac10149c21840a7dd4c3e6694b2","text":"Configure a Cross-Region Replication rule in S3 buckets. Only replicate the objects with the prefix of PROD to the target S3 buckets in another region.","correct":true}]},{"id":"fcccd90f-956b-41b6-b618-bc81dade5d80","domain":"security-comp","question":"You have an EC2 instance in a private subnet. You connect to this instance via SSH using a bastion host in a public subnet. You notice from the logs that other SSH connections are being made from other private IP addresses, which is strange because only the bastion host should be able to connect to this instance. The private IP address of the bastion host is 10.0.1.117. You review the security group, which of the following rules could be causing the unauthorised SSH connections?;","explanation":"By allowing access to port 22 for SGXXXXXXXX this allows any host configured with this security group to access the instance using SSH","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups"}],"answers":[{"id":"80fb1a7299d4a1135830c6f51a49fe82","text":" SSH 22 10.0.1.117/32","correct":false},{"id":"b0172715fbf8cb2b18f5db13e284ca91","text":"SSH 22  SGXXXXXXXX","correct":true},{"id":"c3b35087d573e2c25bc7f358f1bf77d0","text":"MySQL 1433 10.0.1.117/32","correct":false},{"id":"f7bc2e53005e98bab5ea06b5b23bfcf7","text":" HTTP 80 10.0.1.117/32","correct":false}]},{"id":"2729f0e9-af70-412f-b6bb-388bd9f0af12","domain":"dep-prov","question":"You application needs to send data to DynamoDB, but you donâ€™t want the application to have to wait for acknowledgment from the database to continue sending data. In decoupling this application, which AWS service might you use.","explanation":"SQS is a fully-managed queuing service that allows you to decouple components of a cloud application.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/Welcome.html","title":"About SQS"}],"answers":[{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":false},{"id":"f62772d94b939126ee608465cf5e0881","text":"SWF","correct":false},{"id":"8513f757701b24dbadad3df74e817df5","text":"SES","correct":false},{"id":"ef4ba2f338cdf4b615ed280ff0b2777d","text":"SQS","correct":true}]}]}}}}
