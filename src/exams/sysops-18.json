{"data":{"createNewExamAttempt":{"attempt":{"id":"37810e60-ccdd-44c6-b561-cc0c5c95aedb"},"exam":{"id":"65e595b2-99e4-42ed-a2b3-bc9ba8dfc268","title":"AWS Certified SysOps Administrator - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"3eaf9c7f-ec35-42cb-af59-f26b9b358432","domain":"automation","question":"Which of the following sections is required for a CloudFormation template to be valid?","explanation":"The Resources section is the only required section. It specifies the stack resources and their properties, such as an Amazon Elastic Compute Cloud instance or an Amazon Simple Storage Service bucket.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/resources-section-structure.html","title":"CloudFormation - Resources"}],"answers":[{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"229eb04083e06f419f9ac494329f957d","text":"Conditions","correct":false},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false}]},{"id":"55e3410c-cf36-4a46-948a-95e2440003fd","domain":"mon-rep","question":"You are running an Application Load Balancer (ALB) in front for a fleet of web servers running on EC2. These servers are in a public subnet. Your customers connect to the ELB domain name to access web servers using HTTP. You want to know your customers' IP addresses to gain metrics into where your customers are located. This information will be helpful for improving your application based on the location of your customers. How would you collect log data for your ELB?","explanation":"The X-Forwarded-For request header helps you identify the IP address of a client when you use an HTTP or HTTPS load balancer. Because load balancers intercept traffic between clients and servers, your server access logs contain only the IP address of the load balancer. Elastic Load Balancing stores the IP address of the client in the X-Forwarded-For request header and passes the header to your server. If you were using TCP protocol (rather than HTTP), no additional configuration would be needed. CloudTrail is not appropriate as it only shows data regarding API requests sent within your AWS account. CloudWatch and Lambda would be an administrative burden and are not necessary.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html","title":"HTTP Headers and Classic Load Balancers"}],"answers":[{"id":"c790427146d378ddfcfb7c4e0821a00c","text":"No additional configuration is needed. The proxy protocol will pass the client IP automatically, and you can check the ELB logs to find this information.","correct":false},{"id":"0fcaa257260dc2e705852935fcc43979","text":"Modify the application code to pull the client IP into the X-Forwarded-For header so the web servers can parse the information.","correct":true},{"id":"db95fed268eaf12b5b9c069f8256be2f","text":"Enable CloudTrail on your ELB and push the logs to an S3 bucket. Search the logs using Athena or download them as a CSV to identify the IP addresses of your customers.","correct":false},{"id":"ee23873239420b48da4e1d7e54294f34","text":"Enable CloudWatch logs for your application and push the logs to a custom CloudWatch metric. Use Lambda to parse through the log files to search and extract the client IP addresses into a DynamoDB table.","correct":false}]},{"id":"8c1dec5f-627d-4f25-af24-119b092ca2ef","domain":"high-avail","question":"A client asks you how they can make their current database running on AWS highly available. The client is running a MySQL RDS database in us-west-1. The client does not currently have a Multi-AZ deployment. The client wants to know what the benefits are with a Multi-AZ deployment as it would incur additional costs to their AWS bill. How would you explain the benefits to the customer?","explanation":"Amazon RDS Multi-AZ deployments provide enhanced availability and durability for databases. When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone. In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby. It does not lower latencies nor does it increase read performance. It cannot tolerate the failure of a single AWS Region as failure of a Region would implicate failure of all the Availability Zones within that Region.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"Amazon RDS Multi-AZ Deployments"}],"answers":[{"id":"4983004598ef3be1bb46819c748a09ab","text":"Multi-AZ tolerates the failure of a single Availability Zone. It also allows higher availability during maintenance tasks.","correct":true},{"id":"aa4c2ced080ae70c33f36fe825b972ce","text":"Multi-AZ lowers latencies for application servers when they are accessing the database in multiple Availability Zones.","correct":false},{"id":"6772f4dc3173a8dd298656b65d2b6efa","text":"Multi-AZ makes it faster for application servers to access the database by reading data at a quicker rate.","correct":false},{"id":"834345e14f96992b8d4b2e785595f697","text":"Multi-AZ tolerates the failure of a single Region. It also allows higher availability during maintenance tasks.","correct":false}]},{"id":"04595a27-6a9a-413a-aac3-bfa950ff8a84","domain":"networking","question":"You need to enable internet access to your EC2 instances in a private subnet, what is the most secure way to provide egress only internet access?","explanation":"A NAT gateway provides egress (outgoing) internet access for hosts in a Private subnet, you will also need to add a route to the internet via the NAT Gateway. Internet gateways allow ingress and egress internet traffic for hosts attached to Public subnets","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","title":"NAT Gateways"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html","title":"Internet Gateways"}],"answers":[{"id":"0beea13fa9f8b9da7131d1dff9d7cdd6","text":"Configure a Public IP address or Elastic IP for the hosts which need internet access","correct":false},{"id":"e61b3a55a64158231956847ef848272f","text":"Configure a NAT gateway and add a route to the internet via the NAT in your route table","correct":true},{"id":"5f748ece0d81aee4b596a0065b82c992","text":"Move the instances which need internet access to a Public subnet","correct":false},{"id":"d60b4e40b731d4c21b78e8a35b139cc9","text":"Add an Internet Gateway to the Private Subnet","correct":false}]},{"id":"6fd27cf3-e84d-4a26-875c-7695a786a998","domain":"networking","question":"Two EC2 instances in two VPCs cannot ping each other. Both instances are located in private subnets. Which of the following would help you troubleshoot the problem? Select two.","explanation":"You can only peer VPCs, not individual subnets. There must also exist a route between the peered VPCs. Subnet security policy isn't a real thing although Network ACLs could be considered as such. VPC endpoint policy controls access to S3 or DynamoDB, not to a peered VPC.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html","title":"What is VPC Peering?"}],"answers":[{"id":"088c1791b9d25f53b479820769d14995","text":"Check that there is a peering connection between the VPCs","correct":true},{"id":"19b59f579598d8721b6507a457658f92","text":"Check that a subnet security policy allows ping","correct":false},{"id":"e88fa7d7390ad4d45912151c4e94b106","text":"Check that a VPC endpoint policy allows ping","correct":false},{"id":"d6d0388ad6ed9fa8508ce01fce126328","text":"Check that there is a peering connection between the subnets","correct":false},{"id":"b60b61736af41d60dfcadf8fde5d83b6","text":"Check that a route exists between the VPCs","correct":true}]},{"id":"86596bb1-b46e-449f-889d-b5d830ca4f2e","domain":"dep-prov","question":"The development team in your company has finished developing a proof-of-concept of a new Ruby web application. The management wants to show it to a customer quickly, so they ask you to deploy it as soon as possible. You choose to use Elastic Beanstalk. What are the steps required to deploy the application with it?","explanation":"The benefit of deploying with Elastic Beanstalk is that you don't have to worry about provisioning and managing the infrastructure and application stack. You don't have to create EC2 instances or load balancers. Elastic Beanstalk does it all for you. You simply upload your code.","links":[{"url":"https://aws.amazon.com/elasticbeanstalk/faqs/","title":"AWS Elastic Beanstalk FAQs"}],"answers":[{"id":"4cefa75ab7d2e02f84528f56fe7b9646","text":"Provision an EC2 instance and an Elastic Load Balancer. Upload your code.","correct":false},{"id":"4bc0f60972b5b7a69a1cca6e12facb39","text":"Provision an EC2 instance. Upload your code.","correct":false},{"id":"5057183b7131b6d33dab6404e3169e16","text":"Upload your code.","correct":true},{"id":"845d1a709577cc630a50cd331d24103c","text":"Provision an Elastic Load Balancer. Upload your code.","correct":false}]},{"id":"095bed19-081d-4865-acff-d6f9bc29eb7c","domain":"automation","question":"Which of the following is the only required component of a CloudFormation template?","explanation":"As the primary purpose of CloudFormation is to create a collection of related AWS resources, the Resources section is the only required section of a CloudFormation template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"}],"answers":[{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"7df96b18c230f90ada0a9e2307226338","text":"Templates","correct":false},{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false}]},{"id":"4a4c6ce8-b38c-4905-8705-d5bbfb0ee4b2","domain":"mon-rep","question":"You have an Auto Scaling group resource in your AWS account. The desired number of instances has been changed from 2 to 0 recently and all instances were terminated because of it. You want to know when and how the resource was created and who modified the desired number. Which service can help you to quickly get the information?","explanation":"You can quickly get the configuration history in the AWS Config configuration timeline including who and when the resource was created or modified. A new CloudTrail does not help as it only records new events. Athena may work however it is not as easy as AWS Config. CloudWatch metrics cannot provide the required configuration information.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/view-manage-resource-console.html","title":"Viewing configuration details in AWS Config"}],"answers":[{"id":"8d084da5294ed862175582c9670af840","text":"Create a new CloudTrail and save the events to CloudWatch Logs. Search for the Auto Scaling group resource in the logs.","correct":false},{"id":"9a2b6d3211e9c6531d8bf6f6ff2e8351","text":"Save all CloudTrail events to an S3 bucket. Perform SQL queries in the bucket via Athena.","correct":false},{"id":"25787092d8b6523e05e0155400bcc0bf","text":"Check the Auto Scaling group resource in AWS Config and inspect the configuration timeline for the resource.","correct":true},{"id":"65d77f35794d925b20ff78961bb4c1df","text":"Check the CloudWatch metrics for the Auto Scaling group resource. CloudWatch metrics can record the data for 6 weeks.","correct":false}]},{"id":"b5cf6800-4ce3-4d24-8eaa-a1279c1c6409","domain":"mon-rep","question":"An insurance company has a monolithic application hosted in an EC2 instance and a serverless application hosted in AWS Lambda. After a few months of running the application, the customers have raised multiple delays and performance issues from the applications. The Operations Engineer responsible has mentioned that the latency issues might have been caused by code-level performance issues and the Head of Operations has instructed the team to add code-level monitoring support. How can the team accomplish this?","explanation":"X-Ray can be used for adding code tracing support for both monolithic application code (e.g. a large Django monolithic project) and serverless (Lambda function) code. CloudTrail is used for auditing API call logs. CloudWatch is used for monitoring resource usage and metrics. X-Ray is a distributed tracing system.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html","title":"AWS X-Ray"}],"answers":[{"id":"ab066c8d1096ed9b7b49b4637589b201","text":"Use AWS X-Ray for the monolithic application code. Use AWS CloudTrail for the serverless application code.","correct":false},{"id":"7d3a7bc0301958a4e3ad624f70b462d4","text":"Use AWS CloudTrail for the monolithic application code. Use AWS X-Ray for the serverless application code.","correct":false},{"id":"359f4dd3d7689aca37514e23a8781431","text":"Use AWS X-Ray for both the monolithic application code and the serverless application code.","correct":true},{"id":"2eb097422fa45d569c37d094428d9a9d","text":"Use AWS CloudWatch for the monolithic application code. Use AWS X-Ray for the serverless application code.","correct":false}]},{"id":"6eb6dee0-9456-492e-afc7-b7c860b04c92","domain":"mon-rep","question":"You have a fleet of EC2 webservers behind an application load balancer. Your web application had some down time which involved some 5XX errors during a very important time in your business 1 week ago. Although you maintain application logs on individual EC2 instances, you do not store these logs anywhere central and unfortunately the EC2 instances that experienced the downtime have since been terminated. How could you review this log data?","explanation":"Elastic Load Balancing provides access logs that capture detailed information about requests sent to your load balancer. Each log contains information such as the time the request was received, the client's IP address, latencies, request paths, and server responses. These logs are encrypted and stored in S3.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html","title":"Application Load Balancer Access Logs"}],"answers":[{"id":"49774faac3030c4425f2aa345cb89dc0","text":"If access logs is turned on for your application load balancer you could review this data by reviewing the logs in S3.","correct":true},{"id":"ae59c599efa75d438daecb43cc08ad41","text":"Use AWS X-ray to restore the logs from the terminated EC2 instances","correct":false},{"id":"d53665e5cde1c8f661130ca2882d789a","text":"Open the AWS artifact service. Create a new artifact job and point the AWS artifact agents at the terminated EC2 instances. Download the metrics and review in CloudWatch.","correct":false},{"id":"c13c66278433ebb606e21e9c9f5250fd","text":"Create a new AWS inspector job to pull the snapshots of the EC2 instances from S3 and run a report in conjuction with AWS Athena.","correct":false}]},{"id":"d1f23ad4-6255-449e-ba3e-93f4ea692185","domain":"dep-prov","question":"You encounter problems while detaching an EBS volume through the Amazon EC2 console. What can help you diagnose the issue?","explanation":"The 'describe-volumes' CLI command can be used to gather further information to help with diagnosing volume issues and is therefore the most appropriate. The 'detach-volume --force' CLI command forces detachment if the previous detachment attempt did not occur cleanly (for example, logging into an instance, unmounting the volume, and detaching normally). This option can lead to data loss or a corrupted file system. Use this option only as a last resort to detach a volume from a failed instance. The 'Dismount-EC2Volume' PowerShell command will perform the same action as the EC2 console and will therefore not help with additional diagnosis. The 'fix-volumes' command is not a valid CLI command.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-detaching-volume.html","title":"Detaching an Amazon EBS Volume from an Instance"}],"answers":[{"id":"75f13dd600a356952c8f887bd5bcb626","text":"Run the 'Dismount-EC2Volume' PowerShell command.","correct":false},{"id":"8f52ce0a3a674b594aaed05357a3d828","text":"Run the 'detach-volume --force' CLI command.","correct":false},{"id":"6dab4100f13c64be47fc0b254385f5ab","text":"Run the 'describe-volumes' CLI command.","correct":true},{"id":"8f6461e3ace3c5f5cab7f6c269e12420","text":"Run the 'fix-volumes' CLI command.","correct":false}]},{"id":"ca3638f9-91ac-4667-9241-b4e3015691b5","domain":"data-man","question":"Your company's legal department needs to be able to retrieve customer transactions during litigation activities from seven years of historical data. Transactional archives are stored on Amazon S3, and file sizes range from 50 MB to 8 GB. The files are stored in different formats due to being written by separate departments, one third in GZIP compressed YAML format, one third in RZIP compressed CSV format, and one third in BZIP2 compressed JSON format. Which retrieval scheme will provide the best performance at the least cost?","explanation":"S3 Select provides the capability to filter the contents of S3 objects using SQL. S3 Select works on objects stored in CSV, JSON, and Parquet format, and it works with objects that are compressed with GZIP and BZIP2 compression, as well as server side encrypted objects. Due to lack of support for RZIP compression and YAML formatted files, any answer using S3 Select to retrieve the CSV or YAML files is not valid.","links":[{"url":"https://aws.amazon.com/blogs/aws/s3-glacier-select/","title":"S3 Select and Glacier Select – Retrieving Subsets of Objects"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/selecting-content-from-objects.html","title":"Selecting Content from Objects"}],"answers":[{"id":"37f4b5267a8be86e5b80ad0fb6ee1b55","text":"Retrieve full objects and extract the desired records programatically from the YAML and CSV files. Use Amazon S3 Select to retrieve only the desired records from the JSON files","correct":true},{"id":"1aa1c17b6e1fe36065a076d92aec97ca","text":"Use Amazon S3 Select to retrieve only the desired records from all files regardless of format","correct":false},{"id":"21c1e971f9150a4c6b3c3ecf5665cb9c","text":"Retrieve full objects and extract the desired records programatically from the YAML and JSON files. Use Amazon S3 Select to retrieve only the desired records from the CSV files","correct":false},{"id":"74d1424680f4ddebfe0cf92e16d5f99b","text":"Retrieve full objects and extract the desired records programatically from the YAML files. Use Amazon S3 Select to retrieve only the desired records from the CSV and JSON files","correct":false}]},{"id":"1e148869-35dd-465b-962c-780c6d32b8b8","domain":"security-comp","question":"Your main application currently stores its credentials as a text file on an EC2 server.  Your Manager has informed you that this is an insecure practice and has told you to store these credentials in an AWS managed service instead.  AWS Systems Manager Parameter Store and AWS Secrets Manager can be used for the secure storage of credentials.  Of the below features, which apply to both Secrets Manager and Parameter Store?","explanation":"Many aspects of Parameter Store and Secrets Manager appear very similar, but Secrets Store charges you for storing each secret and also provides a secret rotation service whereas Parameter Store does not.  Therefore these are the only two answers related to both services.","links":[{"url":"https://aws.amazon.com/systems-manager/faq/#Parameter_Store","title":"AWS Systems Manager FAQs"},{"url":"https://aws.amazon.com/secrets-manager/faqs/","title":"AWS Secrets Manager FAQs"}],"answers":[{"id":"a6c8669080382c473c6c3331a4d3e832","text":"Supports encryption at rest using customer-owned KMS keys","correct":true},{"id":"5a6c9e66d676a1b933ff0f18e23874d1","text":"Can store credentials in hierarchical form","correct":true},{"id":"12697ea16ebbdb808c191988acdbecba","text":"Manages rotation and lifecycle of credentials","correct":false},{"id":"c954aba0b83727b5f6892234e837686d","text":"Integrated with Identity and Access Management","correct":true},{"id":"da5f35495ba99b6d624c0dadf1bd7626","text":"Available at no additional charge providing you store less than 10,000 credentials","correct":false}]},{"id":"44b4605e-3e4b-4762-8db1-29f4d8bdadb1","domain":"data-man","question":"Your team has come to you for advice on finding the best storage solution on AWS. Your team's application runs on a load balanced pool of web servers and needs to store frequently changing data like buffers, caches, and other interim data. What AWS storage solution would you recommend to maximize performance and minimize costs?","explanation":"An instance store provides temporary block-level storage for your instance. This storage is located on disks that are physically attached to the host computer. Instance store is ideal for temporary storage of information that changes frequently, such as buffers, caches, scratch data, and other temporary content, or for data that is replicated across a fleet of instances, such as a load-balanced pool of web servers. Amazon Instance Store is best used for temporary storage. The other options would incur additional storage costs.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","title":"Amazon EC2 Instance Store"}],"answers":[{"id":"270fcb785810d0206945029bb05f4e97","text":"Amazon S3","correct":false},{"id":"e2b73d2522b2b07ac67d36de7ac51b75","text":"Amazon EC2 Instance Store","correct":true},{"id":"e58f9c51d5656ba7cd0d4796730248a7","text":"Amazon EBS. Read contents on the EBS volume to improve performance.","correct":false},{"id":"f7b96044a16becafecad63df1725e9c8","text":"Amazon EFS","correct":false}]},{"id":"ac509f33-b7fd-483a-a610-b5744bc89943","domain":"automation","question":"An organization wants to understand when the infrastructure it is deploying from CloudFormation has been manually changed by a rogue developer in the team.  Which three services would help to detect changes and determine who performed the change?","explanation":"AWS CloudFormation Drift detection allows for you to identify changes over time of resources, when compared to the Cloudformation stack which created them.  The AWS Config managed rule 'cloudformation-stack-drift-detection-check' allows for a drift check to be initiated.  Any stacks with drift can be flagged as a non-compliant stack.  AWS Config can also provide you with a timeline of modified resources, along with the associated CloudTrail event that caused the configuration to change.. including which IAM role or user performed the change.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2018/11/aws-cloudformation-now-supports-drift-detection/","title":"AWS CloudFormation Now Supports Drift Detection"},{"url":"https://aws.amazon.com/about-aws/whats-new/2018/11/aws-config-launches-a-new-aws-config-rule-to-support-aws-cloudformation-stack-drift-detection/","title":"AWS Config Launches a New AWS Config Rule to Support AWS CloudFormation Stack Drift Detection"}],"answers":[{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"b00e2e3d5e092e8527268afe49e5a5e2","text":"AWS CloudFormation Change Sets","correct":false},{"id":"3c4dbfbe3fe821153b16f5a7b3e98a96","text":"AWS CloudFormation Drift","correct":true},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":true},{"id":"7c1c0a0eb09dcbcd9acf3ade0b16cb91","text":"AWS Guard Duty","correct":false},{"id":"28408acf54ab04fe847fd24957e528d9","text":"AWS CloudWatch Logs","correct":false}]},{"id":"4a2b50c3-b064-4235-a27f-e6a57dab2536","domain":"automation","question":"A non-emergency medical transport provider receives their AWS bill and would like to reduce their monthly spend. Upon investigation, they discover they are paying for many orphaned EBS volumes not attached to EC2 instances. As they dig deeper, they determine that none of the volumes are needed any longer. They'd like to automate the removal process for these volumes and any others that become orphaned for more than ninety days. Which solution will keep them from paying for unneeded EBS volumes in the future?","explanation":"A periodically scheduled Lambda function can be written to determine how long an EBS volume has been orphaned by looking at CloudTrail actions. Instructions for how to create snapshots and delete EBS volumes can be found in the EC2 API Reference. Passing the volume's ARN as an AWS Systems Manager Automation resolution target will not create a snapshot and delete a volume. You can use Amazon CloudWatch Events to automate the monitoring of Trusted Advisor activity, but not CloudWatch Logs. AWS Data Pipeline is used to move and process data between different services, not to manage EBS resources.","links":[{"url":"https://aws.amazon.com/ebs/","title":"Amazon Elastic Bock Store"},{"url":"https://aws.amazon.com/blogs/mt/controlling-your-aws-costs-by-deleting-unused-amazon-ebs-volumes/","title":"Controlling your AWS costs by deleting unused Amazon EBS volumes"}],"answers":[{"id":"855c39931a8bd19bfec582fd45fb7334","text":"Schedule an AWS Lambda function to run periodically via Amazon CloudWatch Events. Have the Lambda function read AWS CloudTrail actions to identify detached EBS volumes in an available state for over ninety days. Create a snapshot of the volume and delete it using EBS APIs.","correct":true},{"id":"9dfd7bacb72bcd7c38c22bb76dbd0321","text":"Detect changes in AWS Trusted Advisor checks for underutilized EBS volumes with Amazon CloudWatch Logs. For volumes identified as underutilized for over ninety days, invoke an AWS Lambda function to create a snapshot of the volume and delete it using EBS APIs.","correct":false},{"id":"92788951cb2a5d4a2d4d91fb8c19fe27","text":"Create an AWS Systems Manager workflow to examine EBS volumes. For volumes not attached to EC2 instances for over ninety days, pass the volume's ARN as a resolution target to the automation's execution logic to create a snapshot and delete the volume.","correct":false},{"id":"628e11e6d88eb8d10d63cd3f003d04a2","text":"Schedule an AWS Data Pipeline workflow that leverages the AWS-provided pre-condition for orphaned EBS volumes. Pass it a time threshold parameter value of ninety days, and assign actions to create a snapshot and delete the volume.","correct":false}]},{"id":"739bcd50-ad59-4cbe-a911-17cff575b80d","domain":"security-comp","question":"You have been asked by your company's CISO to create and manage an S3 bucket with highly confidential company information. Only two business-critical individuals within the company should have read and write access to the bucket. All other personnel should not have access. How would you go about ensuring the security and confidentiality of the bucket in the most efficient manner?","explanation":"Bucket policies provide centralized access control to buckets and objects based on a variety of conditions, including Amazon S3 operations, requestors, resources, and aspects of the request (for example, IP address). The policies are expressed in the access policy language and enable centralized management of permissions. The permissions attached to a bucket apply to all of the objects in that bucket. AWS Config would only report on if buckets are in compliance to any rules set. An explicitly deny for all IAM users would work but it isn't the most efficient solution. Bucket access control lists apply to bucket objects, not the bucket itself.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Bucket Policies"}],"answers":[{"id":"ebf041183040a34a7220734ce5497478","text":"Create an IAM policy for all non-business-critical individuals that explicitly denies access to the bucket.","correct":false},{"id":"06899090182266f944ef7ff8a34750ed","text":"Create an AWS Config rule that denies access to the S3 bucket except for the business-critical users. Set an alarm whenever someone attempts to access the bucket.","correct":false},{"id":"48f34a3e8e8a95fcbe3abee586e0f775","text":"Create a bucket access control list to explicitly grant access to the two individuals.","correct":false},{"id":"fdadf86a8030fc5cbfd2cdb0b16b95f6","text":"Create a bucket policy explicitly granting access to the two principals.","correct":true}]},{"id":"4553a766-ae3d-4a15-a0cd-8f7617510415","domain":"security-comp","question":"You work at a pharmaceutical company who has just deployed a new web application in to their development environment. The webapp sits inside a single Availability Zone inside a public subnet and runs on PHP. It connects in to an RDS instance which is in a private subnet running MySQL. You load the webapp’s DNS address in your browser and you get the following error “Database Connection Error” what might be the cause of the problem?","explanation":"You need to configure the Security Group to allow ingress access to allow inbound connections to the RDS instance","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups"}],"answers":[{"id":"c9f3da4211e1e93ebb9d49ee8c2a0bd6","text":"The security group for the Webserver does not allow egress SSH access to the instance","correct":false},{"id":"4cbe0aae95d4b87bb274b250394fcd6c","text":"The security group for the Webserver does not allow ingress SSH access to the instance","correct":false},{"id":"c343ffd845f05787efb4ada77e096f99","text":"The security group for the RDS instance does not allow egress access to the RDS instance","correct":false},{"id":"30e5bf736c605d975c83d2bc39ba2e63","text":" The security group for the RDS instance does not allow ingress access to the RDS instance","correct":true}]},{"id":"ab86f355-ca8c-4f03-bc21-bd2b6add379f","domain":"high-avail","question":"You need to deploy a DynamoDB table in the production environment for an application. The read and write traffic is low during weekdays. On weekends, the traffic becomes much higher due to the increasing number of users. The traffic pattern is very predictable and there is no unexpected spike. Which kind of capacity mode would you configure for the DynamoDB table?","explanation":"In this scenario, DynamoDB Auto Scaling should be used as the pattern is predictable. On-demand mode is more suitable for unknown workloads and development environments. Reserved capacity would cause a waste of resources. And users cannot configure a schedule to automatically adjust the capacity in DynamoDB.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html","title":"DynamoDB read/write capacity mode"}],"answers":[{"id":"35ba3d07134765e8d2b001befc79e653","text":"Reserved capacity that is able to cover the high traffic on weekends.","correct":false},{"id":"4fdafc1c54632989128146ba919a0e07","text":"Provisioned capacity with auto scaling.","correct":true},{"id":"fe576b38a59cfeaa466623938285521e","text":"Provisioned capacity on weekdays with a schedule to automatically increase the capacity on weekends.","correct":false},{"id":"b799c024f6af20489d00692976f1bfd1","text":"On demand mode without the need to configure the capacity.","correct":false}]},{"id":"1a37a76e-3c69-4ae6-8ae3-5b0db850807c","domain":"mon-rep","question":"You need to monitor memory utilization of an EC2 instance. How could you achieve this?","explanation":"Monitoring memory utilization requires the installation of the CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html","title":"Collecting Metrics and Logs from Amazon EC2 Instances and On-Premises Servers with the CloudWatch Agent"}],"answers":[{"id":"30041d2fc11ea9b43497c2fe847b6461","text":"From the EC2 console, enable memory ulitization metric for the instance.","correct":false},{"id":"e1771db5f560892163019427b6f3742c","text":"From the CloudWatch console, enable memory ulitization metric for the instance.","correct":false},{"id":"8b901f2e0a6136525aaf5ffcb881b223","text":"EC2 instance memory utilization is monitored by default.","correct":false},{"id":"c5d4aec73235f6dc0fda6738ef7c93f9","text":"Install CloudWatch Agent on the instance and have it collect memory utilization metrics.","correct":true}]},{"id":"46d872a7-bf30-4880-9cbd-3a63c50fb75e","domain":"mon-rep","question":"You need to enable a CloudWatch alarm to alert you if an EC2 instance which holds a key customers database goes over 100% CPU Utilization for more than two minutes. Which service should you use?","explanation":"Detailed Monitoring collects data at 1 minute intervals, whereas Basic or Standard Monitoring is every 5 minutes. Artifact allows you to check which industry and regulatory compliance standards AWS adheres to.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html","title":"CloudWatch Detailed Monitoring"}],"answers":[{"id":"96778f7d823daef4c612d60aa5bf2312","text":" CloudWatch Detailed Monitoring","correct":true},{"id":"3d3e141cae28c035547bafe32dea1423","text":"CloudTrail Expedite","correct":false},{"id":"60b018772cea138af5a8c452ed694734","text":"AWS Artifact","correct":false},{"id":"af64135daff929ae7e26207cfae5e24a","text":"CloudWatch Standard Monitoring","correct":false}]},{"id":"694223e9-400f-46d9-b113-d770e9d509b8","domain":"dep-prov","question":"Your organization provides a service using an Application Load Balancer with both HTTP and HTTPS listeners. The business no longer needs to provide the service so you attempt to delete the ALB via the AWS CLI. What will happen to the listeners?","explanation":"You can delete a listener at any time. When you delete a load balancer, all its listeners are deleted.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/delete-listener.html","title":"Delete a Listener for Your Application Load Balancer"}],"answers":[{"id":"104a10917908f00eeccd5369b1ac85da","text":"It is not possible to delete an ALB with active listeners attached","correct":false},{"id":"c9e9a56599d874c979dc81169f0eb659","text":"The ALB and both listeners will be deleted","correct":true},{"id":"8eaee7de96060692c6500d1043fae9d5","text":"The ALB will be deleted but both listeners will remain","correct":false},{"id":"3a830da2fbcf5c10870200329e2a0bdc","text":"The ALB will be deleted but the HTTPS listener will remain","correct":false}]},{"id":"5d1249a6-960b-4540-8631-50875e04850d","domain":"mon-rep","question":"A company is using a site-to-site AWS VPN connection with static routing to allow connectivity between its corporate office and a VPC in AWS. The SysOps Administrator wants to get notified if the connection goes down. What’s the most effective way to accomplish this?","explanation":"AWS support won't do this for you. The other options would work, however, creating a CloudWatch alarm is the simplest option.","links":[{"url":"https://docs.aws.amazon.com/vpn/latest/s2svpn/monitoring-cloudwatch-vpn.html","title":"Monitoring VPN Tunnels Using Amazon CloudWatch"}],"answers":[{"id":"759ca4c838619fc5548932dc516de2cf","text":"Create a CloudWatch alarm to track the TunnelState metric and send an SNS notification if necessary.","correct":true},{"id":"4ca2750b50a6661dbeff47ae8524ff24","text":"Set up a cron job in an EC2 instance to confirm the TunnelState metric every minute and send an SNS notification if necessary.","correct":false},{"id":"a05514224184194909112ecdabb8b939","text":"Write a Lambda function to check the TunnelState metric every minute and send an SNS notification if necessary.","correct":false},{"id":"b9f0b72860ab9c76417cf3f4c3ec6c98","text":"Ask AWS support to monitor the connection and send an SNS notification if necessary.","correct":false}]},{"id":"7b724c4c-726d-4da7-9021-59e459427ecd","domain":"networking","question":"Placement Groups can either be of the type 'Cluster', 'Spread', or 'Partition'.  Choose options from below which are only specific to Spread Placement Groups.","explanation":"There is only one answer that is specific to Spread Placement Groups.  Whilst some of these answers are correct for either Cluster Placement Groups only, or for both Cluster and Spread Placement Groups, the question stated that only options specific to Spread Placement Groups should be chosen, which would rule out two options as they are true for both Spread & Cluster type placement groups.  The Logical grouping of instances within a single Availability Zone is only true of Cluster Placement Groups and is also incorrect.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"Placement Groups"}],"answers":[{"id":"0156cb85707daf221315fb25ac1bb505","text":"An instance can be launched in one placement group at a time and cannot span multiple placement groups.","correct":false},{"id":"2ce403ef492eb181bff27c45219186ad","text":"A spread placement group is a logical grouping of instances within a single Availability Zone","correct":false},{"id":"bb229a2ce0bd114f2e002f94923618d2","text":"A spread placement group is a group of instances that are each placed on distinct underlying hardware","correct":true},{"id":"5e91fe627c2bd0613378a96fab7f8bc3","text":"Spread placement groups require a name that is unique within your AWS account for the region","correct":false}]},{"id":"0a54c671-954d-4e52-8a46-83eadcf029cd","domain":"mon-rep","question":"Which of the following are valid alarm statuses in CloudWatch?","explanation":"The three alarm statuses are OK, INSUFFICIENT_DATA and ALARM.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html","title":"About CloudWatch Alarms"}],"answers":[{"id":"9de6d0a670ae5a0dee31a6318aa00e8d","text":"ALARM","correct":true},{"id":"320f86f60f25459ba5550e000b2c3929","text":"ALERT","correct":false},{"id":"f5d0aa0db6ffc40d938f1412b89d946c","text":"INSUFFICIENT_DATA","correct":true},{"id":"e0aa021e21dddbd6d8cecec71e9cf564","text":"OK","correct":true}]},{"id":"ed2ywbaa-95e6-2i0x-jzmq-kdvksdj16nxi","domain":"security-comp","question":"As an administrator, which of the following IAM tasks are *critical* to the security of your AWS environment?","explanation":"While all of these things are important, it's critical that you delete the root access keys, activate MFA on the root account and create an IAM password policy.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html","title":"IAM Best Practices"}],"answers":[{"id":"5911b1e6aadb27a95ade3c5e00f03ea8","text":"The application of an IAM password policy","correct":true},{"id":"878a3402611421642a5100d0177d21fb","text":"The deletion of root access keys","correct":true},{"id":"18ca1c0dbfc5485da49fcec4853501ee","text":"The use of groups to assign permissions","correct":false},{"id":"c436360232888720d87f4d9d3b2a8147","text":"The activation of MFA on the root account","correct":true},{"id":"d4f7829d16d41ce16ff31c2d31aeba6a","text":"The creation of individual IAM users","correct":false}]},{"id":"9a336e95-d0f5-4b79-904b-f0618496cc2f","domain":"networking","question":"You have created a new VPC with the CIDR block of 10.0.0.0/16. You create 2 subnets: 10.0.1.0/24 and 10.0.2.0/24. 10.0.1.0 will be a public subnet and 10.0.2.0 will be a private subnet. You deploy a NAT gateway with the name i-7c1507ab into 10.0.1.0 and assign it a public IP address. You now need to update your route table to complete the setup. Which of the following is the correct route table listing?","explanation":"Destination: 0.0.0.0/0 Target:i-7c1507ab is correct.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#WorkWithRouteTables","title":"Working With route Tables"}],"answers":[{"id":"5b62777103d2e471ec99428f0453f132","text":"Destination: 0.0.0.0/0 Target:i-7c1507ab","correct":true},{"id":"7540f0e829de47c0b695dae438a647d0","text":"Destination: 10.0.2.0/24 Target:i-7c1507ab","correct":false},{"id":"eee0734b451befed6d35d25ecd8b7e00","text":"Destination:10.0.1.0/16 Target:i-7c1507ab","correct":false},{"id":"c4362c9a78985f2334fe591db6c45c50","text":"Destination: 10.0.0.0/16 Target:i-7c1507ab","correct":false}]},{"id":"8938dba3-4740-4cfa-9226-f27006233c27","domain":"security-comp","question":"You work for a large multi-national corporation who has literally 100’s of AWS accounts. Some of these accounts belong to subsidiary companies, some to departments and some to individual teams. You need to implement a strategy so that when a new account is created you can lock down which AWS services are available to that account on an account by account basis. What is the easiest way to do (and manage) this?","explanation":"SCPs enable you to restrict, at the account level of granularity, what services and actions the users, groups, and roles in those accounts can do.","links":[{"url":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html","title":"Service Control Policies"}],"answers":[{"id":"55006bb8960ca3bd15aedc34fc19c9fe","text":"Using AWS Organizations Service Control Policies (SCP)","correct":true},{"id":"55b133327fbc344978b0c06c0821cf5f","text":"Using AWS Inspector with Lambda Integration in to Athena","correct":false},{"id":"27f329a839e5b524103723898c84aaf4","text":" Using AWS Cognito","correct":false},{"id":"74765eedd0b4460b44e6233fb940b347","text":"Using IAM Policies within each individual AWS account","correct":false}]},{"id":"41260d7b-e3b1-4ba3-81e2-f8f441b798e6","domain":"security-comp","question":"When providing mobile apps with temporary security credentials for access to AWS services, which of the following methods is best?","explanation":"AWS strongly recommends that you do not embed or distribute long-term AWS credentials with apps that a user downloads to a device, even in an encrypted store. Instead, build your app so that it requests temporary AWS security credentials dynamically when needed using web identity federation. The supplied temporary credentials map to an AWS role that has only the permissions needed to perform the tasks required by the mobile app.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html","title":"About Web Identity Federation"}],"answers":[{"id":"9d5170dbe7d5ca2ce9011d9234fc376a","text":"Web Identity Federation with Cognito","correct":true},{"id":"d6b9a7c9c7e8cd3c41fd1ebeae2fa4ef","text":"IAM credentials alone","correct":false},{"id":"0bcfd08b38a1d0c297fd1f4dc597a81a","text":"Active Directory with IAM","correct":false},{"id":"d48ff95a8acfcaabeb2f6a3f070af924","text":"LDAP with IAM","correct":false}]},{"id":"bd76b805-8568-4083-a962-3eebb610d4fc","domain":"dep-prov","question":"You've been given the responsibility for creating an automated deployment approach to provision EC2 instances for every application in your department's portfolio. Each application requires a different set of software libraries, and all EC2 instances are members of Auto Scaling Groups. Deployments must complete within a limited time window as part of the department's overall DevOps strategy, and AWS CloudFormation will be used for infrastructure-as-code. Which architecture will provide for the fastest deployments in the most operationally efficient manner?","explanation":"Creating an AMI at the time of CloudFormation stack creation or update helps to ensure that the latest binaries are included in an Auto Scaling Launch Configuration while avoiding potentially long waits for Auto Scaling instances to be provisioned. Bootstrapping software downloads during Auto Scaling instance launch will potentially result in long wait times. Using CloudFormation metadata to indicate which software binaries need to be used in Auto Scaling Launch Configurations is not supported functionality. Not automatically keeping the AMIs up to date means that a significant level of effort will be needed to keep AMIs current with new software releases in each EC2 instance configuration.","links":[{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/enable-fast-bootstrapping-of-your-auto-scaled-instances-using-dynamically-created-images/","title":"Speed up instance bootstrapping by using dynamically created images"}],"answers":[{"id":"ff704c3738fe0246d98c17f8a497e999","text":"Create an EC2 instance for each application's full software configuration. For each application, have CloudFormation invoke an AWS Lambda function that creates an Amazon Machine Image for the EC2 instance. Include the AMI in the Auto Scaling Group Launch Configuration specified by CloudFormation","correct":true},{"id":"02bf56251e14a50de6e835ecd38ab66a","text":"Create complete Amazon Machine Images for each application's EC2 configuration. Configure a CloudFormation Stack for each application that creates Auto Scaling Groups for each instances corresponding AMI","correct":false},{"id":"d53fd253be12fb9ac6c1f9d04b0590f3","text":"Create base Amazon Machine Images for each application's EC2 configuration. Use CloudFormation to specify that the Auto Scaling Launch Configuration use the base AMIs, and bootstrap software downloads from public sources for each application at the time of instance launch","correct":false},{"id":"df623f37652f3a2b4441a7c1de625ab8","text":"Create base Amazon Machine Images for each application's EC2 configuration. Use CloudFormation to specify that the Auto Scaling Launch Configuration use the base AMIs, and use CloudFormation metadata to indicate which software binaries need to be used in Auto Scaling Launch Configurations during CloudFormation stack creations and updates","correct":false}]},{"id":"fa06cd79-3e11-4410-b67d-078ff338c946","domain":"automation","question":"A FinTech company has been aggressively managing their AWS resources using CloudFormation templates. The company has started using a new AWS service that is not yet available in CloudFormation. The engineering team has been given the strict compliance requirement of making sure that all resources need to be deployed and orchestrated automatically. The engineering manager has also been instructed to ensure that the team does not over-engineer or over-complicate the solution. How can the team accomplish this?","explanation":"Given that CloudFormation may not necessarily support new AWS resources and products right away, CloudFormation custom resources will allow CloudFormation to use another resource such as AWS Lambda to create resources on its behalf and continue the processing of the template after the Lambda function has completed its execution. AppSync is not used to generate new AWS service resources and is used primarily for hosting GraphQL powered APIs. Generating an Elastic Beanstalk environment would over-complicate the solution. Using nested stacks would not solve the unsupported service issue of CloudFormation.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html","title":"AWS CloudFormation - Template Custom Resources"}],"answers":[{"id":"4eb557d837b6a756dabf8724f0237688","text":"Use custom resources in CloudFormation to generate the new AWS service resource","correct":true},{"id":"19a39cb24cfb7593d023becd2b712ec3","text":"Generate an Elastic Beanstalk environment in CloudFormation that generates the new AWS service resource","correct":false},{"id":"1c3eb64e993a1f308aa47da24cfd0143","text":"Use nested stacks in CloudFormation to generate the new AWS service resource","correct":false},{"id":"97ebd9f4402ff1438c34af60ee4997f2","text":"Generate an AppSync resource in CloudFormation that generates the new AWS service resource","correct":false}]},{"id":"d3ba2fd5-b275-4485-a2c3-12c264fdd9ff","domain":"dep-prov","question":"You are trying to SSH into your EC2 instance and you get a \"Permission denied (publickey)\" error. Which of the following are the most likely causes of this error?","explanation":"If you connect to your instance using SSH and get any of the following errors, \"Host key not found in [directory]\", \"Permission denied (publickey)\", or \"Authentication failed, permission denied\", verify that you are connecting with the appropriate user name for your AMI *and* that you have specified the proper private key (.pem) file for your instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html","title":"Troubleshooting: Connecting to Your Instance"}],"answers":[{"id":"334acb0dcf7f1f56bc449066c8cab4b6","text":"The instance's security group is misconfigured.","correct":false},{"id":"51ba58459b06a9c8a6e1d38f220f5d65","text":"You have supplied an invalid or otherwise improper private key (.pem) file.","correct":true},{"id":"99e7bf54cfff54e73272a9034be64f6c","text":"There is an issue with the AWS infrastructure.","correct":false},{"id":"eb07107df739e65e6a8f465acdc3a501","text":"You have provided an incorrect username for your AMI type.","correct":true}]},{"id":"4e911348-5056-4ece-a91d-ce96b619578f","domain":"automation","question":"The DevOps team of an insurance company has been instructed to use CloudFormation to manage the different environments of the company. Due to the size of the templates prepared exceeding the limit, the CloudFormation service rejected the processing of the template. How can the DevOps team resolve this issue?","explanation":"Due to the size of the templates exceeding the limit, dividing the CloudFormation template into smaller subparts is the solution. With this in mind, CloudFormation nested stacks will yield to the same template behavior but will involve different files","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html","title":"Using CloudFormation Nested Stacks"}],"answers":[{"id":"f163f3aff96f7db10bfa4b93ed9a0a67","text":"Use CloudFormation wait handlers","correct":false},{"id":"d4838aa62aeb5717c4100906a75dea2d","text":"Use CloudFormation nested stacks","correct":true},{"id":"1d75dba4b52318bdc075c815a7690e4c","text":"Use CloudFormation custom resources","correct":false},{"id":"e29c7f5b3439e3e8355a1e6bede51fa1","text":"Minify the CloudFormation template","correct":false}]},{"id":"6ef01959-f96f-4529-91e6-fd45696273ef","domain":"networking","question":"You are a SysOps Administrator setting up secure access for IAM users in your organization to an S3 bucket. You do not want any traffic to leave the AWS Network. How would you implement a cost-effective solution?","explanation":"A gateway endpoint is a gateway that you specify as a target for a route in your route table for traffic destined to a supported AWS service. S3 and DyanamoDB are the only two AWS services supported by gateway endpoints. A gateway endpoint would allow you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. An interface endpoint is not supported for S3. A Direct Connect connection is costly and unnecessary for this case. Connecting a NAT device to S3 is not possible.","links":[{"url":"https://docs.aws.amazon.com/en_pv/vpc/latest/userguide/vpc-endpoints.html","title":"VPC Endpoints"}],"answers":[{"id":"29139880aac3b4d667b356b282ea87b9","text":"Configure a NAT device to the S3 bucket. Route all traffic to the S3 bucket through this NAT device.","correct":false},{"id":"5d03cf7506e8692659007c4cc2be9114","text":"Configure an interface endpoint to the S3 bucket. Specify the IP range of allowable traffic.","correct":false},{"id":"3164bfcf2b95e5e90ebd10a622eb7797","text":"Configure a Direct Connect connection between your data center and AWS. Have users access AWS through this Direct Connect connection.","correct":false},{"id":"2baf6dcd64a5aac39aeb30d6e25605ac","text":"Configure a gateway endpoint to the S3 bucket. Specify the endpoint as a target for a route in your route table.","correct":true}]},{"id":"0260f2a1-85f9-489c-b235-461207089452","domain":"networking","question":"You are a network administrator for your organization and have been tasked to address a recent security threat to your application that sits in a subnet. VPC flow logs show that malicious activity has been coming from a specific IP address source. You need to add an extra layer of security to control traffic coming into your VPC from that IP address. How would go about making your application secure from the malicious IP source?","explanation":"You can associate a network ACL with multiple subnets; however, a subnet can be associated with only one network ACL at a time. When you associate a network ACL with a subnet, the previous association is removed. Amazon WAF is not applied at the subnet level. AWS Config will only set your AWS resources as compliant to rules you set, but it won't prevent any external traffic from accesses your resources. As best practice, start by creating rules for your NACL in increments (for example, increments of 10 or 100) so that you can insert new rules where you need to later on.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"e81b37b199479422fa7a10cb981356d9","text":"Activate the WAF with your VPC flow log. Add the malicious IP source address to the WAF's blacklist.","correct":false},{"id":"b78c14382f6b1586c4a8016924d49783","text":"Add a rule to the NACL to explicitly deny traffic coming from the malicious IP source. Insert the rule as a lower number from the desired traffic from the same port.","correct":true},{"id":"cd96a1230ce2e15c29f01e30180e1d67","text":"Associate another NACL to the subnet holding the application. Add rule as the lowest number to the second NACL that explicitly denies traffic from the malicious IP source.","correct":false},{"id":"03bb7768562d89b49c918ae64b4183f9","text":"Configure an AWS Config rule to detect traffic originating from the malicious source. Configure a Lambda function to block the IP address whenever the Config rule is triggered.","correct":false}]},{"id":"0cd21180-3ac0-45e5-859c-8a439c58b4fc","domain":"networking","question":"An organization runs a website on an Autoscaling Group behind an Application Load Balancer (ALB). During deployments the application team creates a new ASG and Load Balancer. Which DNS service can you use to route 10% of users to your new environment and the remaining 90% to your existing servers?","explanation":"Route53 allows various routing policies to direct users to one or more resources.  In this case for every ten users querying our DNS we want to send nine users to the existing infrastructure and one of the ten to our new servers. Route53 weighted routing allows us to do this by setting a weight of 1 for the new load balancer and 9 for the existing load balancer.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-weighted","title":"Amazon Route 53 Weighted Routing"}],"answers":[{"id":"ebeefbe1e321377375eb3065b4a2fc20","text":"Use Route53 failover routing","correct":false},{"id":"816c21d5068061f198f8df28aaf61e0d","text":"Use Route53 multi-answer routing","correct":false},{"id":"3299777a46e7aa18ad281b2a40bf2894","text":"Use Route53 simple routing","correct":false},{"id":"b2900db4eb2c71497f4b1817819797bc","text":"Use Route53 weighted routing","correct":true}]},{"id":"z43ur61l-age6-mxal-w90h-oxgkf0r1rqdm","domain":"data-man","question":"You've been tasked with storing petabytes of non-critical data. It might never be accessed and you'll have 24 hours to get it back if you do need it. What is the most cost-effective storage solution in this scenario?","explanation":"Glacier is the most cost-effective option here.","links":[{"url":"https://docs.aws.amazon.com/amazonglacier/latest/dev/introduction.html","title":"About Glacier"}],"answers":[{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":false},{"id":"248c1b0bcb74394beb4a08030c4a6847","text":"EBS","correct":false},{"id":"9d4c23c2bbecbcde969cff9721fd18f5","text":"S3-IA","correct":false}]},{"id":"6b54e986-f59f-4e75-9c40-c6bc649fab55","domain":"dep-prov","question":"You need to create a new trail in AWS CloudTrail service. You want the new trail to capture all management events through AWS API or console. The trail should also capture the data events that are performed within the resources. Which types of resources can be configured in the trail for the data events? (Select TWO.)","explanation":"With CloudTrail, you can collect data events that happen within the resources of S3 or Lambda Function. Data events are disabled by default. You can explicitly add the supported resource types when configuring a trail.","links":[{"url":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-management-and-data-events-with-cloudtrail.html?icmpid=docs_cloudtrail_console#logging-data-events","title":"Logging Data and Management Events for Trails"}],"answers":[{"id":"acb5990f113ecf1bd53980965afac0d2","text":"RDS instances","correct":false},{"id":"5480a17f5758c852bd04b2f161ff0292","text":"S3 buckets.","correct":true},{"id":"789e00e8a87626604884b3f6914ef4af","text":"EC2 EBS volumes.","correct":false},{"id":"cebb61de76a9f200611a3ba82b466b74","text":"Lambda Functions.","correct":true},{"id":"38a35b30a2aefbe82c671f0441c0fd5b","text":"DynamoDB tables.","correct":false}]},{"id":"b4ca6c23-e1b7-4e8d-970b-9799a990126e","domain":"automation","question":"What happens when one of the resources in a CloudFormation stack cannot be created successfully?","explanation":"By default, the “automatic rollback on error” feature is enabled. This will cause all AWS resources that AWS CloudFormation created successfully for a stack up to the point where an error occurred to be deleted. This feature enables you to rely on the fact that stacks are either fully created, or not at all, which simplifies system administration and layered solutions built on top of AWS CloudFormation.","links":[{"url":"https://aws.amazon.com/cloudformation/faqs/","title":"What happens when one of the resources in a stack cannot be created successfully?"}],"answers":[{"id":"98b3aa08dc4c9826ee43acd20f3d400f","text":"CloudFormation will rollback the creation of the resource that failed.","correct":false},{"id":"03c1a80b2ab11433c3c6468b8fefec72","text":"The \"automatic rollback on error\" feature is enabled, deleting all resources created up to the point of the failure.","correct":true},{"id":"8d79a78919c954fac95764cd824334ca","text":"CloudFormation will stop the stack creation process and request manual intervention.","correct":false},{"id":"c951223fd02f1849373afe7edde6a1dc","text":"CloudFormation will simply continue, then ask you to create the resource manually.","correct":false}]},{"id":"6afb3149-0215-4a56-871a-ba55ad07fa07","domain":"security-comp","question":"To meet the security compliance, all the EBS volumes in your AWS account need to be encrypted. The encryption key should have the key material imported from a local server. And the key material is required to be maintained outside of AWS. Which of the below options should you choose?","explanation":"By using Customer Managed Key in KMS, you can import your own key material into the CMK. Then the key can be used to encrypt EBS volumes. You cannot modify the key material for AWS Managed Keys such as aws/ebs.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys.html","title":"Importing key material in AWS Key Management Service (AWS KMS)"}],"answers":[{"id":"18d880df394bfc8553f32d13907972d2","text":"Configure a Customer Key Store with imported key material in KMS to encrypt the EBS volumes.","correct":false},{"id":"4b7aa43955ca963689c5753479d1d2d5","text":"Use a Customer Managed Key with imported key material to encrypt the EBS volumes.","correct":true},{"id":"c9d513eb9767845d56d1808f962eae22","text":"Configure a custom key with imported key material in AWS ACM to encrypt all EBS volumes.","correct":false},{"id":"6252a38ce08f0db1b36876f30b0fe352","text":"Use the AWS Managed Key (aws/ebs) with imported key material for the encryption.","correct":false}]},{"id":"8b30bb8d-7142-4b59-8d3c-4d5033f31a8f","domain":"mon-rep","question":"You are working for a company which is migrating all of its data into S3, the migration is underway but your Security Architect is concerned that not all buckets are secure and wants you identify all buckets which allow public read or write. Which service can you use to find out?","explanation":"AWS Config allows gives you a view of the configuration of your AWS infrastructure and compares it for compliance against rules you can define","links":[{"url":"https://aws.amazon.com/blogs/aws/aws-config-update-new-managed-rules-to-secure-s3-buckets/","title":"AWS Config Rules to Secure S3"}],"answers":[{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":false},{"id":"7c90c8f2a24f3a1a28525f19fb2c75ab","text":"AWS Inspector","correct":false}]},{"id":"e7703705-dc16-4a4f-a8d3-98e3577e942a","domain":"data-man","question":"You plan to deploy a MySQL 5.6 database in AWS RDS and you have some specific database parameter settings that must be applied, such as: AUTOCOMMIT, which should be disabled on the RDS instance. You may need to create additional DB instances with the same settings in the future. Which method would you use to configure the parameters?","explanation":"As there are specific parameters that need to be modified, the best way is to create a customized parameter group. You can associate any additional DB instances you launch with this parameter group so ensure they have a consistent configuration. You should not change the default parameter group as it may affect other existing or new instances unexpectedly. Creating and maintaining a JSON file for launching a DB instance via the AWS CLI adds unnecessary complexity. Systems Manager Run Command is used for EC2 instances instead of RDS DB instances.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithParamGroups.html","title":"RDS parameter groups"}],"answers":[{"id":"168989a72a2725d264ca14b78d381d73","text":"Create a JSON file with customized DB parameters. Pass in the JSON file as an option when creating the DB instance via AWS CLI.","correct":false},{"id":"41b0cd4c9b1c355a7119f0645ce643b9","text":"Modify the default MySQL 5.6 parameter group and all MySQL 5.6 DB instances will update parameters automatically.","correct":false},{"id":"1c4b963beae658001b275abdaf38f116","text":"Create a custom parameter group for MySQL 5.6. Modify parameters accordingly and associate the parameter group with a DB instance.","correct":true},{"id":"44708ac216e24969b934ef95be540000","text":"In AWS Systems Manager Run Command, execute the AWS-ConfigureDBParameter command to customize the DB parameters.","correct":false}]},{"id":"4871ce12-9da0-4e28-b1e4-373560dbdffa","domain":"automation","question":"A telecommunications company sends out monthly bills to their customers. Usage is accumulated during the month by nightly batch jobs that process call details. The company is in the process of migrating the billing system to AWS to reduce costs. What approach will provide them with the most cost effective solution for the compute portion of their nightly batch runs?","explanation":"AWS Batch provides allocation strategies to consider capacity and throughput in addition to cost when provisioning instances for jobs. This is a newer feature that provides more flexibility than the previous scheme that chose an instance that was the best fit based on vCPU, memory, and GPU requirements. Creating a pool of EC2 Reserved Instances might result in unused capacity if workload requirements change. Lambda is not currently available as a compute resource for AWS Batch.","links":[{"url":"https://aws.amazon.com/batch/","title":"AWS Batch"},{"url":"https://aws.amazon.com/blogs/compute/optimizing-for-cost-availability-and-throughput-by-selecting-your-aws-batch-allocation-strategy/","title":"Optimizing for cost, availability and throughput by selecting your AWS Batch allocation strategy"}],"answers":[{"id":"8633cd86b6633324660fa073362c2f98","text":"Schedule jobs with AWS Batch into a pool of EC2 Reserved Instances that contains enough servers for the minimum number of jobs that will be run on any one night. Use an Auto Scaling Group to provision Spot Instances to handle any additional demand.","correct":false},{"id":"96ef18a4d93470acb7dbd558eb666ca3","text":"Specify AWS Lambda as the compute resource for AWS Batch. Invoke the appropriate Lambda functions for each job.","correct":false},{"id":"0bb4d60773589240e55a5a506ee84275","text":"Use AWS Batch allocation strategies to define capacity, throughput, and cost priorities for instance type provisioning.","correct":true},{"id":"3220afaa7c6fd31e7a8d35ce1e2df1fa","text":"Configure AWS Batch to choose an instance type for each job based on vCPU, memory, and GPU requirements at the lowest cost.","correct":false}]},{"id":"daab371e-09f1-4d56-ae18-ac01147c8d31","domain":"automation","question":"Your organisation is growing their AWS footprint and wants to build a dashboard for their hybrid infrastructure.  They use a mix of on-premises Linux and Windows machines, and new AWS EC2 instances. There are around 1500 on-premises VMs which your CTO ambitiously wants to manage with a centralised configuration tool.  How can your organization simplify the management of the patching and inventory of both the on-premises and cloud instances from one central AWS account?","explanation":"Microsoft patching is only available for on-premises instances under the 'advanced-instances' tier of Systems Manager.  The standard Systems Manager tier also only enables you to register a maximum of 1,000 servers per AWS account per AWS Region. If you need to register more than 1,000 servers or VMs in a single account and Region, then you need to use the advanced-instances tier. Since there are over 1,000 servers, and a mix of Windows and Linux workloads, the organisation needs to enable Systems Manager Advanced-Instances before it can perform inventory and patching of the whole hybrid fleet using SSM.","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-managedinstances.html","title":"Setting Up AWS Systems Manager for Hybrid Environments"}],"answers":[{"id":"b99a0eb336123271439fdc9e65a6eace","text":"You can patch on-premises Linux VMs using AWS Systems Manager, however patching of on-premises Windows instances is not supported using AWS Systems Manager.","correct":false},{"id":"dc3a64c07de1193f3276dfd13990fbc3","text":"Enable AWS Systems Manager Enterprise to inventory and patch instances via the SSM agent.","correct":false},{"id":"59d2c9186d25dac05a2935b57bd9c708","text":"Enable AWS Systems Manager Advanced-Instances and use Systems Manager to inventory and patch the instances via the SSM agent.","correct":false},{"id":"34c2b7a9390e3561fd7641103bc12575","text":"Use AWS Systems Manager Managed Instances to inventory and patch instances via the SSM agent.","correct":true}]},{"id":"6b5ed706-afce-4eda-8d2c-dc54e1741a8e","domain":"dep-prov","question":"You are running a WordPress site on an EC2 instance. The site gets visitors from all over the world and they are sometimes complaining about slow page load times. To serve content to your visitors faster, what could you do?","explanation":"S3 static web hosting only supports static websites, not dynamic sites like WordPress. Changing the tenancy won't change the instance specs. Scaling up the instance might help in another scenario, but here the issue is latency and transfer speed. A CloudFront distribution would cache your content close to your visitors and resolve the slow load times. As an added benefit, the caching would also take some load off the instance.","links":[{"url":"https://aws.amazon.com/cloudfront/","title":"CloudFront"}],"answers":[{"id":"fea505586259520090752b2fb572d489","text":"Change the tenancy to a dedicated instance to get more CPU power","correct":false},{"id":"333dd3e9883af7f7cc6ece108e9ffe30","text":"Scale up the instance to a one with more CPU power","correct":false},{"id":"29db6de8b90b19b898fa59f6320deba7","text":"Place a CloudFront distribution in front of the instance","correct":true},{"id":"e393aadc6f1e8478bfc3cc962b86e18c","text":"Move the site to S3 static web hosting","correct":false}]},{"id":"64058244-581f-4354-9a9a-76108a5da03e","domain":"data-man","question":"A developer with the proper IAM permissions on your team is attempting to list objects from Amazon Glacier. The objects in Amazon Glacier are offsite enterprise information that were archived using Amazon S3 lifecycle policies. The developer only has Programmatic access to AWS but when attempting to use the Amazon Glacier API, she can't see the objects as archives in the Amazon Glacier vault. What would you do to remedy the situation?","explanation":"Note that when using Amazon Glacier as a storage class in Amazon S3 you use the Amazon S3 API, and when using “native” Amazon Glacier you use the Amazon Glacier API. For example, objects archived to Amazon Glacier using Amazon S3 lifecycle policies can only be listed and retrieved by using the Amazon S3 API or the Amazon S3 console. You can’t see them as archives in an Amazon Glacier vault. You cannot unlock a vault once the Vault Lock has been activated after the 24 hour validation period. Management Console access would not help. The 3-5 hour retrieval time is expected when retrieving objects from Amazon Glacier but not for listing objects.","links":[{"url":"https://d0.awsstatic.com/whitepapers/AWS%20Storage%20Services%20Whitepaper-v9.pdf & https://docs.aws.amazon.com/amazonglacier/latest/dev/amazon-glacier-accessing.html","title":"Amazon S3 Glacier"}],"answers":[{"id":"3560f5083a7d4cce9b3e658f2190f274","text":"Inform the developer to use the Amazon S3 API.","correct":true},{"id":"0a03188271930e5829e002258dac4ffe","text":"Provide the developer the Vault Lock access keys to first unlock the vault.","correct":false},{"id":"be52886c7c2a9deee49a5931fdb158f9","text":"Grant the developer AWS Management Console access.","correct":false},{"id":"7726f2f0aca541c8ab9a1d55a6e42ad1","text":"Inform the developer to wait 3-5 hours to view the objects.","correct":false}]},{"id":"947a7303-9a09-41cc-ae76-6e7fe32a8dc4","domain":"data-man","question":"Autoscaling has been terminating your EC2 instances which has resulted in losing application logs. Where could you store the logs so that they exist independently from the life of the EC2 instances?","explanation":"Amazon CloudWatch is a monitoring service for AWS cloud resources and the applications you run on AWS. You can use Amazon CloudWatch to collect and track metrics, collect and monitor log files, and set alarms.","links":[{"url":"https://aws.amazon.com/cloudwatch/","title":"CloudWatch"}],"answers":[{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"9deb03cd21d41a691cdc24bfaab2820c","text":"Inspector","correct":false},{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":true}]},{"id":"5660d734-c8d8-404c-b683-3d43db3c17e1","domain":"mon-rep","question":"You are a SysOps Administrator for your company. Your CFO notices that costs have increased steadily for the past year, and tasks you with analyzing cost and usage of the company’s AWS environment based on tagged resources. What is the most effective way to analyze your company’s AWS spend?","explanation":"Choose Cost Explorer to track and analyze your AWS usage. Cost Explorer is free for all accounts and can filter by Region, purchase option, tags, among other things. Trusted Advisor provides areas to optimize costs but doesn't provide cost and budget reports. Developing a Lambda function to calculate spend would be an administrative burden, and so would comparing different AWS Config environments. Both would require manual efforts to leverage AWS' pricing API. It's much more efficient to utilize AWS' free Cost Explorer with built-in reporting functionality.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-getting-started.html","title":"AWS Billing and Cost Management"}],"answers":[{"id":"dbbdf8cec2b6f9217bcf2d39ad3ac859","text":"Create a Lambda function that is invoked for every CloudTrail Event. Have the Lambda function calculate spend based on each AWS services’ API calls using the tag key.","correct":false},{"id":"343d6ae3fa3cd5f44bce786dbe8e8b8b","text":"Use AWS Config to evaluate the configuration of your AWS environment last year. Create a custom rule to analyze by tag. Compare last year’s configuration to this year's and calculate the difference in spend.","correct":false},{"id":"c307cf10883e9081648ee198aebeb387","text":"Download cost optimization and budgeting reports from Trusted Advisor as a CSV. Filter downloaded data by tags.","correct":false},{"id":"b1204a52a0664ddd8a75b740204e6b88","text":"Enable the Cost Explorer tool to track and analyze your AWS usage. Filter spend by tags.","correct":true}]},{"id":"17885db5-c61d-4edf-b0e3-e9d449d8e618","domain":"mon-rep","question":"Which of the following EC2 instance metrics are sent to Amazon CloudWatch by default? Select three.","explanation":"CPU utilization, disk I/O and network traffic are visible to the hypervisor running the instance and are sent to CloudWatch by default. For the others, you would need to install CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html","title":"Available CloudWatch Metrics for Your Instances"}],"answers":[{"id":"ec1e54ae04652319df5c011f228c07ac","text":"Free disk space","correct":false},{"id":"c4903df1e41e0ba0b4636e753d8c7661","text":"Disk read and write operations","correct":true},{"id":"613b1188dd73dfdb768f39cfad3cc9a3","text":"Memory utilization","correct":false},{"id":"b4e5bb2b6842990e919682b3d6d5726c","text":"Volume of incoming and outgoing network traffic","correct":true},{"id":"2105454033539f83d3b07265aac88d7a","text":"The amount of swap space currently in use","correct":false},{"id":"fb8326e1edbd06b1bf6ea0332e089055","text":"CPU utilization","correct":true}]},{"id":"113a7914-1249-4e12-a748-03392c0570e8","domain":"high-avail","question":"You are a Security Administrator for your company. Your CIO wants to ensure that company data is highly available in multiple AWS Regions. What would you suggest to your CIO as the most effective approach?","explanation":"Deploying a multi-AZ RDS instance would only make it fault tolerant between Availability Zones, and not AWS Regions. Creating a Lambda function and creating/deploying EBS snapshots into different AWS Regions would both be an administrative and operational burden. The easiest, most effective, way is to utilize S3 Cross Region Replication","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 Cross Region Replication"}],"answers":[{"id":"f876473fb6289d5a1e3e6d449713b0e7","text":"Copy the company data to an RDS instance. Deploy a multi-AZ configuration for your RDS instance to make it highly available.","correct":false},{"id":"fbde7989c5f0da5bb91bb5593f9c8e4e","text":"Create a Lambda function that downloads data from your S3 Bucket and executes a PUT operation to upload copied objects into a new bucket in a new Region.","correct":false},{"id":"6e22da724261694b4ecf8fa105ef5174","text":"Enable Cross-Region Replication on your bucket to copy objects to a destination bucket in another AWS Region.","correct":true},{"id":"a4ca2ada50730e36dd0f3302f60ab0dc","text":"Create multiple snapshots of your company data on EBS volumes. Deploy those EBS volumes on EC2 instance in different AWS Regions.","correct":false}]},{"id":"3f14908a-fb13-4a6a-a777-7eeb6722447d","domain":"dep-prov","question":"You are running a legacy application on an EC2 instance and have created and attached an EBS volume with default settings. The volume occasionally encounters data consistency errors making the EBS volume inaccessible to the instance. How can this be prevented?","explanation":"When Amazon EBS determines that a volume's data is potentially inconsistent, it disables I/O to the volume from any attached EC2 instances by default. This causes the volume status check to fail, and creates a volume status event that indicates the cause of the failure. Switching on Enable Volume IO will allow the instance to access the volume. Switching on Auto-Enabled IO will also achieve this outcome automatically when enabled. All other options are incorrect.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html#work_volumes_impaired","title":"Working with an Impaired Volume"}],"answers":[{"id":"1775e91227da79ae13b5522ccf280ca0","text":"Switch on Auto-Consistency IO","correct":false},{"id":"628b701156eef0c168e27dc6d58a9d15","text":"Switch off Auto-Enabled IO","correct":false},{"id":"58bcefbd4466f36f955a0383bd253082","text":"Switch on Auto-Enabled IO","correct":true},{"id":"65e65e38f33598416e8a272b6ad29b2a","text":"This cannot be prevented","correct":false},{"id":"bf737cfd17a3b913cb405f896e5e9b7d","text":"Switch on Enable Volume IO","correct":true}]},{"id":"83fd057a-07f2-4372-a889-abf74e907806","domain":"data-man","question":"You own and manage an S3 bucket with which you have PUT request access to select users in various regions and countries. Users have recently complained about long upload lengths and poor latency. How would you improve the upload performance for your users?","explanation":"Amazon S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and an S3 bucket. Transfer Acceleration takes advantage of Amazon CloudFront’s globally distributed edge locations. As the data arrives at an edge location, data are routed to Amazon S3 over an optimized network path. Multipart upload can be used in conjunction with Transfer Acceleration but will not itself solve the issue. Buckets are universal and cannot be replicated in other regions. Geo-location routing policy applies to Route 53.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html#transfer-acceleration-requirements","title":"Amazon S3 Transfer Acceleration"}],"answers":[{"id":"42bc9efd5b2b629ef42ae7e808d66fa2","text":"Configure a geo-location routing policy to route the object upload based on the location of the user to reduce latency.","correct":false},{"id":"edda60f4b576cd518abc4e1430e86a30","text":"Replicate the bucket in multiple Regions so that users can upload the objects to the Region closest to them.","correct":false},{"id":"3d973493e7cdf70d033fb8c92c83b75f","text":"Use S3 Transfer Acceleration to minimize the effect of distance on throughput.","correct":true},{"id":"61ae8ec9b582ff4ea402f7ca1b7e5cba","text":"Edit the bucket policy to require Multipart upload for any PUT requests for objects greater than 100 megabytes in size.","correct":false}]},{"id":"daf6b2b4-fed3-47fd-a6c8-7fce838a6543","domain":"security-comp","question":"What is the name of the API call used to request temporary security credentials from the AWS platform when federating with Active Directory?","explanation":"AssumeRoleWithSAML provides a set of temporary security credentials for users who have been authenticated via a SAML authentication response.","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithSAML.html","title":"AssumeRoleWithSAML"}],"answers":[{"id":"d6db28cc32e24b1d1c39831f43e5d8b8","text":"GetSAMLRole","correct":false},{"id":"e19dc096230f8dc3a7e2b56f94d309a2","text":"AssumeRoleWithSAML","correct":true},{"id":"9c7a6a871dd64a673837a44ccfdecf49","text":"ShowMeTheSAML","correct":false},{"id":"92379b50a98b2cd0366ee58621f3d4a4","text":"CovertRoleToSAML","correct":false}]},{"id":"b4e4d4f8-b9af-47da-9f90-2b63cab25ddf","domain":"automation","question":"As a SysOps Administrator you are managing your company's infrastructure as code. You have a number of CloudFormation templates that automate the provisioning of AWS resources for disaster recovery purposes. Your CISO have asked you for additional insights into the changes that teams are making to the CloudFormation templates in order to see when templates are updated with what changes. How would you build a solution that fulfills the CISO's ask?","explanation":"Change sets allow you to preview how proposed changes to a stack might impact your running resources. For example, whether your changes will delete or replace any critical resources, AWS CloudFormation makes the changes to your stack only when you decide to execute the change set, allowing you to decide whether to proceed with your proposed changes or explore other changes by creating another change set. Config and Lambda would be complicated to configure and unnecessary as you would be able to directly do this using change sets. Amazon Inspector is used for EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html","title":"Updating Stacks Using Change Sets"}],"answers":[{"id":"00c32ce29ae8b3d7291d321ea5a8c6ba","text":"Run Amazon Inspector report periodically to identify changes made to a CloudFormation stack. Forward these reports to your CISO.","correct":false},{"id":"a4e164938d62b8c500a3c3bc4680f546","text":"Create a change set by submitting changes against the stack you want to update.","correct":true},{"id":"44fab4e192c83f7e36b2143702b9958e","text":"Configure an AWS Config rule to detect changes to a CloudFormation stack. Send an SNS notification to the CISO for any changes.","correct":false},{"id":"a374362c79930669cc8b737ca45f03cb","text":"Create a Lambda function that parses through CloudWatch logs for any changes made to a CloudFormation stack. Ensure CloudFormation has a role assigned that sends logs to CloudWatch.","correct":false}]},{"id":"3a6ecc9f-2e62-4807-b2f7-0d4f0e032cc3","domain":"networking","question":"You're configuring an Elastic Load Balancer. What can you do to ensure that a user request always goes to the same server?","explanation":"You can use the sticky session feature (also known as session affinity) to enable the load balancer to bind a user's session to a specific instance. This ensures that all requests from the user during the session are sent to the same instance.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html","title":"Sticky Sessions for Your Classic Load Balancer"}],"answers":[{"id":"4ff5c8a41331ce8a8718cf02c632ff5d","text":"Enable sticky sessions","correct":true},{"id":"fe11d265f3c285c0d795d272a9eff45a","text":"Use Multi-Zone Load Balancing","correct":false},{"id":"6586c5993a69b3d3955cc5bf228a0792","text":"Enable Connection Draining","correct":false},{"id":"55c493073aa412bee5b26fa084e13092","text":"Enable Zonal Failover","correct":false}]},{"id":"67817330-582a-439c-878c-4f490334cfad","domain":"high-avail","question":"The web development team of an chatbot machine learning startup has migrated their on-premise application to AWS. The on-premise application uses a custom load balancer which was replaced by an Application Load Balancer in the new architecture setup in AWS. The customers have reported that their chat sessions are lost from time to time and they are forced to sign in again. The new architecture setup uses Route 53, Application Load Balancer, EC2 instances, and DynamoDB for the web application tier. How can the team resolve this issue?","explanation":"Instead of disabling sticky sessions, enabling sticky sessions in the Application Load Balancer would solve the requirement of having an EC2 instance stick to an existing session similar to the scenario provided. Replacing DynamoDB with RDS instances would not solve the stickiness issues. Stickiness is not handled by Route53 routing policies. Replacing the Application Load Balancer with a Classic Load Balancer would not solve the stickiness issue.","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/","title":"ELB Features"}],"answers":[{"id":"ebb04e35ab1c5519bfe7dc876f414406","text":"Replace the Application Load Balancer with a Classic Load Balancer.","correct":false},{"id":"ca8c07a031edb56f0a44f9d891ebaa8a","text":"Enable sticky sessions in the Application Load Balancer.","correct":true},{"id":"93cb25a136afcc3b5e255daab59500f5","text":"Enable sticky sessions in the Route 53 routing policy.","correct":false},{"id":"7a83fce81dc2bab71c72499c7076e2d4","text":"Replace DynamoDB with RDS instances.","correct":false}]},{"id":"27109f2b-2906-43cb-90b4-3e2bcfad7ab8","domain":"high-avail","question":"You are a consultant working for a global company. They are hosting their companies CRM web application on-premise across servers in three different countries. Amazon Route 53 is being used as their DNS Provider. When the servers in one of the countries goes down, traffic starts to drop instead of being redirected to the two working sites. Corporate policies prohibit client data being stored or transferred through a Public Cloud Provider. What would the simplest solution be to their issue?","explanation":"Multivalue Answer Routing will perform simple health checks on IP addresses before sending traffic to them. This has advantages over a simple routing, where an outage of one of the IP Addresses would result in failures to connect. Corporate policies prohibit in this scenario the storage or transfer of client data from the CRM through a Public Cloud Provider. This effectively rules out the migration to EC2, or the use of CloudFront as a CDN. Transferring DNS to an on-premise service may allow for more flexibility and abilities to write special health checks, but it would certainly not be the most simple option","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Amazon Route 53 Routing Policies"}],"answers":[{"id":"abb8f1f2096c4f271cf6c11ab4be0ab4","text":"Implement CloudFront as a CDN for their website, ensuring global fault tolerance","correct":false},{"id":"dcfd51b6eec1175ce379fb23d19ec48f","text":"Transfer their DNS Zone to on-premise DNS servers to allow administrators more power to respond to outages","correct":false},{"id":"bad6a2c2cd6a244c640ffb67243421bd","text":"Migrate the servers to EC2 in three different regions to prevent outages in local datacentres","correct":false},{"id":"1ed8875652253a24ebf466592454a1be","text":"Use a Multivalue Answer Routing Policy on their Route 53, including the Health Checks to detect outages","correct":true}]},{"id":"723a6cb2-65a0-454f-b391-8647401fa54d","domain":"networking","question":"A photo sharing application is growing in popularity.  The application uses S3 to store photographs. Your boss has asked you how you can improve the upload and download times for your end users?","explanation":"S3 upload and download times can be improved by enabling Transfer Acceleration. This leverages Points of Presents (PoPs) in the CloudFront network to provide connection points closer to users, thereby improving transfer speeds.  Disabling Object Versioning or enabling Intelligent Tiering would not affect upload or transfer speeds.  Lastly, BitTorrent support is for publicly-available files and is designed to increase availability of files and reduce S3 costs but does not improve upload and download times from the S3 service itself.","links":[{"url":"https://docs.aws.amazon.com/en_pv/AmazonS3/latest/dev/transfer-acceleration.html","title":"Amazon S3 Transfer Acceleration"}],"answers":[{"id":"5c6679012efaeb73c2123036ba676303","text":"Enable S3 Transfer Acceleration on your buckets","correct":true},{"id":"26b2f3dfb7078bf49a2aafd952d45a13","text":"Disable S3 Object Versioning","correct":false},{"id":"792c81205244e2382feec0be4a8a8716","text":"Enable S3 BitTorrent support","correct":false},{"id":"3992a5af710f81ade0226fff00fedf2d","text":"Enable S3 Intelligent Tiering","correct":false}]},{"id":"0ac7251e-689e-4cd6-bfb9-992628fb3e3c","domain":"mon-rep","question":"There has been a major outage of S3 in US-East-1 where many of your company’s AWS assets are. Your boss wants to know what effect this will have on your organization. What dashboard can you use to help diagnose how this will affect your individual organisation?","explanation":"AWS Personal Health Dashboard provides alerts and remediation guidance when AWS is experiencing events that may impact you. Inspector is an automated security assessment service. AWS X-Ray helps developers analyze and debug production, distributed applications.","links":[{"url":"https://aws.amazon.com/premiumsupport/phd/","title":"AWS Personal Health Dashboard"}],"answers":[{"id":"cf4db9f312542c8284a6ccdefcd98544","text":"Personal Health Dashboard","correct":true},{"id":"3473fa31769f9b170662878d3f67fc8c","text":"AWS Inspector Dashboard","correct":false},{"id":"6bd8c280d2d212f5f6338714620001a4","text":"AWS Service Dashboard","correct":false},{"id":"0863526e514d88cd2d00b39f8dda0920","text":"X-Ray","correct":false}]},{"id":"fae36faf-783b-4c76-83ed-511f56063f62","domain":"mon-rep","question":"A MySQL database is created in AWS RDS. The DB instance stores sensitive customer data and its running status needs to be closely monitored. You want to use the Amazon Simple Notification Service (SNS) to receive notifications whenever there is a configuration change for the instance such as when the master password for the DB instance has been reset. How would you meet this requirement?","explanation":"Amazon RDS uses the Amazon SNS to provide notifications. You can create an event subscription and subscribe to specific event categories. RDS does not have streams and you cannot register a DB instance in an AWS Config rule. Lambda function makes things complicated and is not as simple as Event Subscription in RDS.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html#USER_Events.Messages","title":"Using Amazon RDS event notification"}],"answers":[{"id":"80e872148df53129ffa1664bafab3bdd","text":"Enable the RDS streams to save the configuration events. Configure an SNS topic to receive notifications.","correct":false},{"id":"29c262e90545613cde223c6ace0c200a","text":"Create a Lambda function to monitor the configuration change events for the DB instance. Send a notification to an SNS topic whenever such an event happens.","correct":false},{"id":"6321b05f3e9c6a31e5173e1e87d3aa62","text":"Configure an event subscription in RDS and subscribe to the “configuration change” event category. Use an SNS topic to receive notifications.","correct":true},{"id":"a70af04178c8de89d82a07fef3eb2d30","text":"Register the RDS instance in an AWS Config rule. Whenever there is a configuration change, the rule triggers a notification to an SNS topic.","correct":false}]},{"id":"e6e97329-0325-41bb-99cd-95f73d8cbf7b","domain":"security-comp","question":"You are running a public facing website which is hosted on 6 EC2 instances across 2 AZs. Your security team have identified some suspicious traffic originating from a public IP address outside your organisation, and you have been asked to block this IP from your public website. What is the quickest and simplest way to achieve this?","explanation":"Of all the options, using subnet NACLs is the quickest and easiest. Security Groups do not allow block rules so can be discounted. AWS Firewall Manager is used to manage multiple instances of AWS WAF and Shield Advanced, and neither of those are mentioned in this scenario. Although using iptables would work for linux EC2 instances, it adds unneeded complexity to the issue.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"AWS Network Access List"}],"answers":[{"id":"fd8b9b77d42ae65ac062f3da9516a18c","text":"Add a block rule to AWS Firewall Manager","correct":false},{"id":"e4603e8c6c15ef19dd3adf7da6725d16","text":"Use the System Manager to run the \"iptables -A INPUT -s <IP-ADDRESS> -j DROP\" on all the servers,","correct":false},{"id":"672072a1bc5bd9c47eb8de77e500d285","text":"Add a block rule to the security group of your web EC2 instances","correct":false},{"id":"a1286c8d10d0d6ae23294cfd877c9f5b","text":"Add a block rule to the NACLs on the public subnets","correct":true}]},{"id":"066a63c9-1a0c-454f-8eeb-628657c4b7b3","domain":"security-comp","question":"As a security administrator for your company, the development team has asked for your advice on protecting their web product running on AWS against SQL injection attacks. Recently, there have been several cases where attackers have tried to insert certain malicious SQL queries to extract data from a database that stores confidential customer data. The development team manages and runs the database on EC2 running behind a load balancer. What advice would you give to the team to proactively protect against these kinds of attacks?","explanation":"There are several firewall services that AWS has provided including AWS WAF, AWS Shield, and AWS Firewall Manager. But in this case an ACL with WAF would be the most appropriate. AWS Firewall Manager simplifies your administrative and maintenance tasks across multiple accounts and resources for AWS WAF. AWS WAF is a web application firewall that lets you monitor the HTTP and HTTPS requests that are forwarded to a load balancer. You can block/allow all requests except the ones your specify. AWS Shield Advanced would protect against DDOS attacks. AWS Config would only provide notifications and thus would be a reactive solution to attacks.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html","title":"What Are AWS WAF, AWS Shield, and AWS Firewall Manager?"}],"answers":[{"id":"3b888c9ab75dfc1fd31b6fdcec298c41","text":"Use AWS Config to monitor the application. Set a rule to notify the development team when a malicious attack occurs.","correct":false},{"id":"3e1ffae7dc069fcf4bdce431a89b4792","text":"Create a rule in AWS Firewall Manager to explicitly block the IP addresses that were listed as the attackers.","correct":false},{"id":"5cfd6d4faff387749033b7f3e493f870","text":"Create a WAF Access Control List (ACL) with a rule to explicitly block the SQL injection attacks. Attach the ACL to the load balancer.","correct":true},{"id":"c84b52c0e32a45fc862e101beb233230","text":"Activate AWS Shield Advanced. Although costly, it will protect the application with a 24/7 response team from AWS, and full system and financial restoration after an attack.","correct":false}]},{"id":"4fa7de17-2f03-4b83-a519-e00b011ca644","domain":"security-comp","question":"You are a SysOps Administrator for your organzation. The organization has one AWS account that all users share. You are asked by the CISO to make access to AWS secure and manageable. What would be the best solution?","explanation":"AWS Single Sign-On makes it easy to centrally manage access to all of your AWS accounts. It supports Security Assertion Markup Language (SAML) 2.0 so you don't have to create IAM users for every individual in your organization. The other solutions would be an administrative and unnecessary burden, while encrypted login credentials using KMS is not used for AWS access.","links":[{"url":"https://docs.aws.amazon.com/en_pv/singlesignon/latest/userguide/iam-auth-access.html &https://docs.aws.amazon.com/cli/latest/reference/sts/assume-role-with-saml.html","title":"AWS Single Sign-On"}],"answers":[{"id":"678d5bab1e8e14c5f9a7055f83d2aa56","text":"Set up an AWS Organization to manage accounts and apply permissions boundaries. Set up IAM users and group them in the appropriate OU.","correct":false},{"id":"48371df9efaa3423dc8c9153f0af03c3","text":"Group Active Directory users and mirror their permissions with IAM policies. Create IAM users in AWS and group them into IAM groups that correspond to the Active Directory Group.","correct":false},{"id":"0949ef9615ffc62f343f10d27d0bea2e","text":"Encrypt Active Directory logins using AWS KMS. Store encrypted logins in an RDS table. When users access AWS, set up permissions to decrypt the credentials to securely access AWS resources.","correct":false},{"id":"b18f21a1b9a12f45b180d3ba09d175a0","text":"Configure a SAML federation between AWS and your organization's Active Directory. Set up Active Directory groups with AWS IAM groups to manage user permissions.","correct":true}]},{"id":"edaeeffd-65ec-4d45-8f2d-f37d50773681","domain":"dep-prov","question":"You create an Oracle database in AWS RDS for an application. As the database instance needs to integrate with an S3 bucket, you want to configure an IAM role for the database to read and write the bucket objects. You already have an IAM role for EC2 and the EC2 instance can use the role to transfer files from and to the bucket properly. However, when you try to add the same role to the database, the role cannot be found. What is the reason and how to fix it?","explanation":"The trust entity of the IAM role must include rds.amazonaws.com for a RDS database to assume it. The existing role only contains the trust entity of ec2.amazonaws.com so it cannot be used for RDS. The resource and action parts of the role should be good as EC2 can work with S3 properly. Policies of an IAM role do not have the “principal” part.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-s3-integration.html","title":"RDS integrates with S3"}],"answers":[{"id":"edb854c1df5fa32a6d19c322a736f525","text":"The permissions of the IAM role do not list the resource of the S3 bucket.","correct":false},{"id":"d0d2809faf6ff80ea9807995d483b3e0","text":"For the RDS database to assume the role, the IAM policy should allow the action of \"rds:*\".","correct":false},{"id":"d87fa6b85878f5af177443f4c2aa638f","text":"The trust entity of the role is the service of EC2 instead of RDS. You should create a new role for the RDS service to assume.","correct":true},{"id":"9b1ce3b64821b8efb42f867e68acfbae","text":"The IAM role needs to add a principal of RDS so that any RDS instance can assume the role to integrate with S3.","correct":false}]},{"id":"281dba1d-32b8-4e19-a324-72e004b2f7c6","domain":"mon-rep","question":"The Jet Engine Division of Consolidated Aerospace Corporation would like to centralize monitoring of both their on-premises systems and their AWS servers in the AWS cloud. On-premises operating systems include Red Hat, Debian, AIX, and Windows. EC2 operating systems used include Red Hat and Windows. Which architecture will provide the most robust monitoring and alerting solution?","explanation":"The CloudWatch agent is supported on Red Hat, Debian, and Windows operating systems for writing to CloudWatch Logs for both on-premises and EC2 systems. The agent is not supported for AIX, so writing those log messages to an EC2 instance for forwarding to CloudWatch Logs will work. Configuring CloudWatch metric filters will result in numerical metrics for graphing or alarming. CloudWatch alarms perform actions based on CloudWatch metrics, so setting up the metric filters needs to happen first","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html","title":"What Is Amazon CloudWatch Logs?"},{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringLogData.html","title":"Searching and Filtering Log Data"},{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/install-CloudWatch-Agent-on-premise.html","title":"Installing the CloudWatch Agent on On-Premises Servers"}],"answers":[{"id":"b506e93e4197e20db1193673763fa6b9","text":"Install the CloudWatch agent on the EC2 systems. Write on-premises logs to an EC2 instance which sends log messages to CloudWatch Logs. Configure CloudWatch alarms to alert on error messages in the logs.","correct":false},{"id":"1247cb867a2d6b15f0e4e149aee44e02","text":"Install the CloudWatch agent on the Red Hat, Debian, and Windows systems, both on-premises and EC2. Write AIX logs to an EC2 instance which sends messages to CloudWatch Logs. Set up CloudWatch metric filters to alarm on potential issues.","correct":true},{"id":"150fdd86d9a864feb197592ccedbeee3","text":"Install the CloudWatch agent on the Red Hat and Windows systems, both on-premises and EC2. Write Debian and AIX logs to an EC2 instance which sends messages to CloudWatch Logs. Configure CloudWatch alarms to alert on error messages in the logs.","correct":false},{"id":"4a3ae3aa58ce592572b629601964f7bf","text":"Install the CloudWatch agent on the EC2 systems. Write on-premises logs to an EC2 instance which sends log messages to CloudWatch Logs. Set up CloudWatch metric filters to alarm on potential issues.","correct":false}]}]}}}}
