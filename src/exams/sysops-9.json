{"data":{"createNewExamAttempt":{"attempt":{"id":"1766f497-9df2-4d8e-974c-6c83112f7e8c"},"exam":{"id":"fb4658a4-1f89-40dc-88b9-ee7cb1b4cc5c","title":"AWS Certified SysOps Administrator - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"7fc0d8c0-5fc9-463e-94ff-54f852f1d819","domain":"data-man","question":"An S3 bucket stores some files for an application. As the files need to be read from users on the internet, the bucket should have Public Access. However when you modify the Bucket Policy to be public in AWS console, the operation is blocked with an \"Access denied\" error. Your IAM user has enough permissions to modify Bucket Policies. How would you troubleshoot the issue?","explanation":"Users can configure S3 buckets to block public access. When users try to enable the public access through Access Control Lists or Bucket Policies, the operation is denied. In this scenario, you should check if the public access through Bucket Policy is blocked.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/block-public-access.html","title":"Block Public Access to S3 Buckets"}],"answers":[{"id":"92ffb0eb54566b1970433d74106174e3","text":"Use AWS CLI s3api put-bucket-policy to modify the Bucket Policy.","correct":false},{"id":"416e41b2d06f37e643dd26b55ea9bc53","text":"Check the syntax of Bucket Policy and ensure that the Action field only contains s3:GetObject and the Principal field is a wildcard.","correct":false},{"id":"ba324e78ebf4d884332673942ca4bee0","text":"Check the bucket public access settings to see if the public access through Bucket Policy is blocked. Make sure the public access is not blocked by the settings.","correct":true},{"id":"2e51a73ed0e5f8cf18b5f4047b358a94","text":"User should configure the public access in S3 Access Control List rather than Bucket Policy. In ACL, enable the read access to the group of Everyone.","correct":false}]},{"id":"2db1ee7d-fe0a-4556-ad28-5731b36c2eca","domain":"networking","question":"You need a load balancer with support for TCP connections and preserving the source IP address. What load balancer should you choose?","explanation":"Proxy Load balancer isn't a real thing. Network Load Balancer and Classic Load Balancer both support TCP connections. However, only Network Load Balancer supports preserving the source IP address. ","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/","title":"Elastic Load Balancing features"}],"answers":[{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false},{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":true},{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":false},{"id":"898665d0778b0435cd2b64ff8a8512c2","text":"Proxy Load balancer","correct":false}]},{"id":"ba52dee8-0d6c-4faf-9121-0e64c18bbf1a","domain":"high-avail","question":"Your website is evenly distributed across 10 EC2 instances in 5 AWS regions. How could you configure your site to maintain high-availability with minimum downtime if one of the 5 regions was to lose network connectivity for an extended period of time?","explanation":"If you are designing to check for loss of contact with the instances you need to use \"Evaluate Target Health\" to confirm connectivity.  The Latency policy will eventually detect the unavailability; however it is not a real-time test.","links":[{"url":"http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html","title":"How Health Checks Work in Complex Amazon Route 53 Configurations"}],"answers":[{"id":"0e2faa25f8eb6371b513d8d442513b10","text":"Create a Route 53 Latency-based Routing Record Set that resolves to Elastic Load Balancers in each region and has the Evaluate Target Health flag set to \"True\".","correct":true},{"id":"dc1f9d897e82bca789bb2983fa7ce22d","text":"Create a Route 53 Latency-based Routing Record Set that resolves to an Elastic Load Balancer in each region. Set an appropriate health check on each ELB.","correct":false},{"id":"90875d19db265ba7b3931ecbd5a5d813","text":"Establish VPN Connections between the instances in each region. Rely on BGP to failover in the case of a region-wide connectivity outage.","correct":false},{"id":"b5494c49d052d62119e11eab7d8499c7","text":"Create an Elastic Load Balancer to place in front of each EC2 instance. Set an appropriate health check on each ELB.","correct":false}]},{"id":"694223e9-400f-46d9-b113-d770e9d509b8","domain":"dep-prov","question":"Your organization provides a service using an Application Load Balancer with both HTTP and HTTPS listeners. The business no longer needs to provide the service so you attempt to delete the ALB via the AWS CLI. What will happen to the listeners?","explanation":"You can delete a listener at any time. When you delete a load balancer, all its listeners are deleted.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/delete-listener.html","title":"Delete a Listener for Your Application Load Balancer"}],"answers":[{"id":"8eaee7de96060692c6500d1043fae9d5","text":"The ALB will be deleted but both listeners will remain","correct":false},{"id":"c9e9a56599d874c979dc81169f0eb659","text":"The ALB and both listeners will be deleted","correct":true},{"id":"104a10917908f00eeccd5369b1ac85da","text":"It is not possible to delete an ALB with active listeners attached","correct":false},{"id":"3a830da2fbcf5c10870200329e2a0bdc","text":"The ALB will be deleted but the HTTPS listener will remain","correct":false}]},{"id":"a085468f-b362-451e-a53b-2a027f39f4b4","domain":"security-comp","question":"Your team has a new web application in AWS that has customers in different countries. As the service needs to be highly available, it must be well protected from common DDoS attacks such as SYN floods. When the web site is under attack, you can get instant support to assist you in mitigating the issue. Which option is the most suitable to achieve this requirement?","explanation":"When the AWS Shield Advanced feature is activated, you can get support from the DDoS response team. The team helps you to analyze the suspicious activity and fix the issue. AWS Shield Standard or AWS WAF do not have this service. AWS Enterprise Support plan is not cost-efficient. As there is only one web application that needs to be protected from DDoS attacks, AWS Shield Advanced is enough.","links":[{"url":"https://docs.aws.amazon.com/en_pv/waf/latest/developerguide/shield-chapter.html","title":"AWS Shield"}],"answers":[{"id":"2f94e6d78605c4eef8c11c646aab2420","text":"Activate the AWS Shield Advanced feature.","correct":true},{"id":"3bb0eac221e4844f28e6ad4ea5db5f86","text":"Enable AWS WAF rules to protect the application from DDoS attacks.","correct":false},{"id":"2d4b07f7063adc3f7d26742bd531f447","text":"Enable the AWS Enterprise Support plan.","correct":false},{"id":"f3573cee21c8731886863e4c267344fe","text":"Activate the AWS Shield Standard service.","correct":false}]},{"id":"de2610da-0b20-4258-b215-146e96c134d3","domain":"automation","question":"Which section of a CloudFormation template allows you to set up differing instance types based on environment type (e.g. 'Production' or 'QA')?","explanation":"","links":[{"url":"http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"}],"answers":[{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false},{"id":"229eb04083e06f419f9ac494329f957d","text":"Conditions","correct":true},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":false},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false}]},{"id":"1c5e58d5-4d5a-4680-9b38-139079a8a31d","domain":"data-man","question":"You are a SysOps Administrator analyzing S3 costs for your organization as directed by the CFO. A number of objects in the S3 bucket are in the Intelligent_Tiering storage class. After careful analysis you realize some objects in that storage class that are 36kb are being charged for more than their size. How would you explain this to the CFO?","explanation":"The INTELLIGENT_TIERING storage class is suitable for objects larger than 128 KB that you plan to store for at least 30 days. If the size of an object is less than 128 KB, it is not eligible for auto-tiering. Smaller objects can be stored, but they are always charged at the frequent access tier rates in the INTELLIGENT_TIERING storage class. Bucket policies do not affect S3 pricing. There is no time delay for when Intelligent_Tiering applies. This is not an AWS issue, but a pricing mechanism explicitly stated in AWS Documentation.","links":[{"url":"https://docs.aws.amazon.com/en_pv/AmazonS3/latest/dev/storage-class-intro.html","title":"Amazon S3 Storage Class"}],"answers":[{"id":"1849c59d612f3d9a745f0ca2e881eab9","text":"This is an AWS issue. Contact AWS Support by opening a Support Case in the Management Console.","correct":false},{"id":"33064ab5af6c994f9f1121aa0e703cb9","text":"Check the bucket policy. Ensure you have proper policy permissions to access the Intelligent_Tiering storage class.","correct":false},{"id":"f7b1bf34e76110780b27b7e489769c4d","text":"There is no issue. You are being charged properly per S3 pricing.","correct":true},{"id":"01c9a3e0268f90a8c1f87735185a3197","text":"Intelligent_Tiering applies after 30 days. Wait 30 days for the charges to properly reflect.","correct":false}]},{"id":"fcccd90f-956b-41b6-b618-bc81dade5d80","domain":"security-comp","question":"You have an EC2 instance in a private subnet. You connect to this instance via SSH using a bastion host in a public subnet. You notice from the logs that other SSH connections are being made from other private IP addresses, which is strange because only the bastion host should be able to connect to this instance. The private IP address of the bastion host is 10.0.1.117. You review the security group, which of the following rules could be causing the unauthorised SSH connections?;","explanation":"By allowing access to port 22 for SGXXXXXXXX this allows any host configured with this security group to access the instance using SSH","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups"}],"answers":[{"id":"f7bc2e53005e98bab5ea06b5b23bfcf7","text":" HTTP 80 10.0.1.117/32","correct":false},{"id":"80fb1a7299d4a1135830c6f51a49fe82","text":" SSH 22 10.0.1.117/32","correct":false},{"id":"b0172715fbf8cb2b18f5db13e284ca91","text":"SSH 22  SGXXXXXXXX","correct":true},{"id":"c3b35087d573e2c25bc7f358f1bf77d0","text":"MySQL 1433 10.0.1.117/32","correct":false}]},{"id":"2f757d58-833a-40ab-9eb6-2a981fb6b79f","domain":"security-comp","question":"Under the AWS shared responsibility model which of the following would be your responsibility as a customer?","explanation":"The shared Responsibility Model states that you are responsible for configuring the security of your EC2 instances, VPCs and S3 buckets as well as any guest Operating Systems, application and database security settings. AWS is responsible for patching RDS instances and software platforms provided by Elastic Beanstalk","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"96785b9a477bb691ff03d686c919e1cf","text":"Antivirus for EC2 instances","correct":true},{"id":"ceb259f9a51f0549f076e847bf207781","text":"Application level patching for RDS","correct":false},{"id":"fa7989aaf9918b210db642de0de21650","text":"OS level patching for EC2 instances","correct":true},{"id":"e4e2b01049a70752d94080ef404f35cf","text":"OS level patching for RDS instances","correct":false},{"id":"b71690da3d36c4e2b8fe168de0e70b84","text":"PHP patching for applications using Elastic Beanstalk","correct":false}]},{"id":"08b69906-407e-4ec7-9995-849fef7431a3","domain":"dep-prov","question":"Your organization provides a service using an Application Load Balancer with 3 EC2 instances as registered targets. The organization no longer needs to provide the service so you attempt to delete the ALB via the AWS CLI. What will happen?","explanation":"Deleting a load balancer does not affect its registered targets. For example, your EC2 instances continue to run and are still registered to their target groups. The command will not fail as it is possible to delete an ALB registered targets.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-delete.html","title":"Delete an Application Load Balancer"}],"answers":[{"id":"af18f004917f3bcc9a1a8dc6b867b1f0","text":"The command will fail because there are instances attached to the ALB","correct":false},{"id":"c9e00101dcbdd43dd5940309daf0b02f","text":"The ALB will be removed and the target instances will be terminated","correct":false},{"id":"2f4978a4d0f6296a0c354b89adb25f86","text":"The ALB will be deleted but the instances will still be running","correct":true},{"id":"2a4e55639f55031ca059e7173f17bc5b","text":"It is not possible to delete an ALB using the CLI","correct":false}]},{"id":"466da628-4a01-43da-ba82-90215f555b37","domain":"data-man","question":"A mobile application which runs its backend data storage and processing in AWS experienced an outage last night.  According to AWS there was scheduled maintenance on a number of EC2 instances in your VPC.  You should have caught this but you did not.. Your company recently invested in Business Support for your Production account.  As a SysOps engineer you have been asked to ensure that planned maintenance on AWS services that affect you, as well as known outages in the region, are logged into your IT department ticketing system.  The notifications should be in a human-readable format.  Which services will help you to do this in an efficient manner?","explanation":"AWS Health is an API service which provides programmatic access to AWS health events for Business and Enterprise Support customers.  CloudWatch Events allows you to intercept AWS Health events, and has the ability to convert a Health event into human-readable format by performing transforms on the properties of the Health event.  AWS SNS allows the transformed events to be delivered to a variety of destinations including HTTP endpoints, or via email in order to integrate into your ticketing systems.","links":[{"url":"https://docs.aws.amazon.com/health/latest/ug/what-is-aws-health.html","title":"What is AWS Health?"},{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/CloudWatch-Events-Input-Transformer-Tutorial.html","title":"Tutorial: Use Input Transformer to Customize What is Passed to the Event Target"}],"answers":[{"id":"f9118d24e7ab0d46eccea1c43f5db58d","text":"AWS Personal Health Dashboard, CloudTrail and AWS Lambda","correct":false},{"id":"c500e0084c698c714d39fa45e73c194f","text":"AWS Health, CloudTrail and AWS Simple Notification Service","correct":false},{"id":"ab911b3e904a12c5461f69cab52931d4","text":"AWS Health, CloudWatch Events and AWS Simple Notification Service","correct":true},{"id":"cb52f85bdee5c92ebdded1c692c43685","text":"AWS System Status, CloudTrail and SES","correct":false}]},{"id":"17b1cb9e-6c30-4cb5-8122-ac0799b51470","domain":"mon-rep","question":"Your team uses a CloudFormation template to configure a CloudWatch dashboard. The dashboard includes metrics of a classic load balancer such as HTTPCode_Backend_5XX and HTTPCode_ELB_5XX. The development team changes the type of the load balancer to network load balancer. However, after you recreate the CloudFormation stack, the metrics in the CloudWatch dashboard do not report any data. What is the cause of it?","explanation":"CloudFormation uses the resource type AWS::CloudWatch::Dashboard to create a CloudWatch dashboard. And the resource configures the metrics names in the DashboardBody. Metrics: HTTPCode_Backend_5XX and HTTPCode_ELB_5XX are valid only for the Classic Load Balancer, and are not supported in the Network Load Balancer (NLB), since NLBs operate in layer 4. The DashboardBody in the template needs to be modified to include the appropriate NLB metrics.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-cloudwatch-metrics.html","title":"CloudWatch Metrics for network load balancer"}],"answers":[{"id":"0c719bf2f29ec9b673c0092df8426d3c","text":"The target groups of the network load balancer are unhealthy so that they do not report any data.","correct":false},{"id":"fee717ce407145a9caf9135e8b046e55","text":"Network load balancers do not support reporting metrics to CloudWatch dashboard. Only Classic load balancers do.","correct":false},{"id":"fb1a3d94cf187bb86bd85a8a4d584c4d","text":"It takes longer time for the network load balancer to send metrics data to the CloudWatch dashboard. Wait at least half an hour.","correct":false},{"id":"959ff1c7a797aea82688e7a5b2468b64","text":"The selected metrics: HTTPCode_Backend_5XX and HTTPCode_ELB_5XX are not supported in a network load balancer.","correct":true}]},{"id":"e105d8a7-6333-48d8-9610-7c2f9ad73991","domain":"mon-rep","question":"There has been a steady rise in costs with your AWS bill, and the security team has noticed that there has been an increase in the number of requests, even though the number of IAM users has decreased due to employee turnover and down-sizing. The CISO has tasked you with identifying whether recent requests to the AWS account's environment were made with temporary security credentials for a role or federated user. How would you go about identifying this?","explanation":"A trail enables CloudTrail to deliver log files to an Amazon S3 bucket. By default, when you create a trail in the console, the trail applies to all AWS Regions. The trail logs events from all Regions in the AWS partition and delivers the log files to the Amazon S3 bucket that you specify. Additionally, you can configure other AWS services to further analyze and act upon the event data collected in CloudTrail logs. The userIdentity element contains details about the type of IAM identity that made the request, and which credentials were used. If temporary credentials were used, the element shows how the credentials were obtained. Identify Federation is used for access to an account. Config will not log API activity. Lambda cannot scrape an entire account; it needs to access an S3 bucket of CloudTrail logs to take any action.","links":[{"url":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-user-identity.html","title":"CloudTrail userIdentity Element"},{"url":"https://docs.aws.amazon.com/config/latest/developerguide/log-api-calls.html","title":"Logging AWS Config API Calls with AWS CloudTrail"}],"answers":[{"id":"97ddb7778b0f9f5decefb8013df4d710","text":"Set up Identity Federation with SAML. Create IAM roles and create policies for employees to assume with the correct permissions. Log all requests using the Credential report.","correct":false},{"id":"41e73582d973a777c1838270973c1a5a","text":"Create a Lambda function that is triggered daily that scrapes the account for requests from any assumed roles. Have the Lambda function revoke access if any requests are non-compliant.","correct":false},{"id":"4ffef50c6af5fe0e395fb58ca8319f05","text":"Record all ongoing events in the AWS account using AWS Config. Create a CloudWatch alarm to send an SNS topic when an identity under AssumeRole makes a request to the account.","correct":false},{"id":"73e4bf9add9c239534c52f8a03fb95fb","text":"Create a CloudTrail log to deliver files to an Amazon S3 bucket. Use Amazon Athena to query the logs to search for the userIdentity element.","correct":true}]},{"id":"3eaf9c7f-ec35-42cb-af59-f26b9b358432","domain":"automation","question":"Which of the following sections is required for a CloudFormation template to be valid?","explanation":"The Resources section is the only required section. It specifies the stack resources and their properties, such as an Amazon Elastic Compute Cloud instance or an Amazon Simple Storage Service bucket.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/resources-section-structure.html","title":"CloudFormation - Resources"}],"answers":[{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"229eb04083e06f419f9ac494329f957d","text":"Conditions","correct":false}]},{"id":"e9a2a106-8596-4e7c-bd0b-7a274c9b65f1","domain":"mon-rep","question":"Your organization is growing and your CISO is concerned with the increasing risk of users accessing resources they shouldn't have permissions for. What is the most effective solution to track requests for access to S3 buckets?","explanation":"To track requests for access to your bucket, you can enable access logging. Each access log record provides details about a single access request, such as the requester, bucket name, request time, request action, response status, and error code, if any. Access log information can be useful in security and access audits. AWS Config does not collect logs. AWS CloudWatch aggregates logs into one place. You could collect AWS CloudTrail logs for API calls to an S3 bucket but the most effective method is to turn on access logging for the bucket.","links":[{"url":"https://d0.awsstatic.com/whitepapers/AWS%20Storage%20Services%20Whitepaper-v9.pdf","title":"Amazon Storage Services Overview"}],"answers":[{"id":"ff1f340f3014857175b4708e7eefa686","text":"Turn on AWS Config access for the bucket","correct":false},{"id":"5e65dc82f972821c704a45d2cb78368e","text":"Turn on AWS CloudTrail for the bucket","correct":false},{"id":"aa39a2d244d1792f0833837683ceaba8","text":"Turn on AWS CloudWatch logs on the bucket","correct":false},{"id":"dcd1426526e6edaa4108cf53b54f5886","text":"Turn on access logging for the bucket","correct":true}]},{"id":"4a4c6ce8-b38c-4905-8705-d5bbfb0ee4b2","domain":"mon-rep","question":"You have an Auto Scaling group resource in your AWS account. The desired number of instances has been changed from 2 to 0 recently and all instances were terminated because of it. You want to know when and how the resource was created and who modified the desired number. Which service can help you to quickly get the information?","explanation":"You can quickly get the configuration history in the AWS Config configuration timeline including who and when the resource was created or modified. A new CloudTrail does not help as it only records new events. Athena may work however it is not as easy as AWS Config. CloudWatch metrics cannot provide the required configuration information.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/view-manage-resource-console.html","title":"Viewing configuration details in AWS Config"}],"answers":[{"id":"25787092d8b6523e05e0155400bcc0bf","text":"Check the Auto Scaling group resource in AWS Config and inspect the configuration timeline for the resource.","correct":true},{"id":"9a2b6d3211e9c6531d8bf6f6ff2e8351","text":"Save all CloudTrail events to an S3 bucket. Perform SQL queries in the bucket via Athena.","correct":false},{"id":"65d77f35794d925b20ff78961bb4c1df","text":"Check the CloudWatch metrics for the Auto Scaling group resource. CloudWatch metrics can record the data for 6 weeks.","correct":false},{"id":"8d084da5294ed862175582c9670af840","text":"Create a new CloudTrail and save the events to CloudWatch Logs. Search for the Auto Scaling group resource in the logs.","correct":false}]},{"id":"b4ca6c23-e1b7-4e8d-970b-9799a990126e","domain":"automation","question":"What happens when one of the resources in a CloudFormation stack cannot be created successfully?","explanation":"By default, the “automatic rollback on error” feature is enabled. This will cause all AWS resources that AWS CloudFormation created successfully for a stack up to the point where an error occurred to be deleted. This feature enables you to rely on the fact that stacks are either fully created, or not at all, which simplifies system administration and layered solutions built on top of AWS CloudFormation.","links":[{"url":"https://aws.amazon.com/cloudformation/faqs/","title":"What happens when one of the resources in a stack cannot be created successfully?"}],"answers":[{"id":"03c1a80b2ab11433c3c6468b8fefec72","text":"The \"automatic rollback on error\" feature is enabled, deleting all resources created up to the point of the failure.","correct":true},{"id":"98b3aa08dc4c9826ee43acd20f3d400f","text":"CloudFormation will rollback the creation of the resource that failed.","correct":false},{"id":"8d79a78919c954fac95764cd824334ca","text":"CloudFormation will stop the stack creation process and request manual intervention.","correct":false},{"id":"c951223fd02f1849373afe7edde6a1dc","text":"CloudFormation will simply continue, then ask you to create the resource manually.","correct":false}]},{"id":"3a6adeef-2a94-4d25-964d-a153e860782a","domain":"dep-prov","question":"One of your company's applications experienced a sudden spike in users after a new feature was launched. The increase in traffic caused the EC2 instances to run out of CPU and your application lost a number of servers. As a result, some of your users' data was lost. Out of the following, what is the best recommendation to prevent this from happening again in the future?","explanation":"You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots. Snapshots are incremental backups, which means that only the blocks on the device that have changed after your most recent snapshot are saved. This minimizes the time required to create the snapshot and saves on storage costs by not duplicating data. Deploying the instances in an autoscaling group will not ensure data durability. Auto Scaling would only ensure that that at least one (or minimum number of) instance(s) would be running to run the application. If any data is stored on the instances that scale down, the data would be lost. Data on EC2 instance store is lost when the instance is terminated. Redeploying the instance on a larger instance size could work temporarily but will not solve the issue in the long run. If load increases beyond the capability of the C5.8xlarge, then there's a chance that the failure happens again. The core issue is retaining data, and this is best addressed using EBS snapshots of the choices provided.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"Amazon EBS Snapshots"}],"answers":[{"id":"bd81e4f1da2f8d673179b1efd85a81ff","text":"Deploy the instances in an autoscaling group to ensure additional servers are launched when load becomes high.","correct":false},{"id":"5a55606a43ae21c632a718926f08550b","text":"Terminate the current instances, and redeploy your application on a larger instance size. Use a compute-optimized instance like the C5.8xlarge to maximize CPU performance.","correct":false},{"id":"1560444e669aaf0ae63f9f8cacec5089","text":"Redeploy your application on instance store instances to ensure your application experiences the best IOPS performance for your users.","correct":false},{"id":"b9aa2e73596fcf8ba661d5ed4a4e85ea","text":"Create a CloudWatch Events CRON job to take regular snapshots of your instances during non-business hours to ensure user data are backed up.","correct":true}]},{"id":"571b9603-45b6-45b1-aa47-68849ac814bb","domain":"automation","question":"A big-box retailer runs their in-store point-of-sale system on EC2 linux instances. All of the infrastructure is managed as part of a CloudFormation stack. The web servers are part of an Auto Scaling Group. The application only needs to be available during business hours from 9:00am until 6:00pm. What would be the best way to scale the web servers cost efficiently based on demand?","explanation":"Authoring the CloudFormation template to include an AutoScaling:ScheduledAction resource to increase the Auto Scaling Group's MinSize and MaxSize values at 9:00am, and another AutoScaling:ScheduledAction resource to decrease the Auto Scaling Group's MinSize and MaxSize values at 6:00pm will save costs for the retailer during non-business hours. CloudFormation conditions control whether certain resources are created or whether certain resource properties are assigned a value during stack creation or update, but don't control the actions of an Auto Scaling Group. Using an Auto Scaling Group scheduled action provides more streamlined automation than using a Lambda function. CloudFormation mappings are key/value pairs that can be used to specify conditional parameter values, but they have no impact on the Auto Scaling Group unless they are used to create a resource.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"What is AWS CloudFormation?"},{"url":"https://s3-us-west-2.amazonaws.com/cloudformation-templates-us-west-2/AutoScalingScheduledAction.template","title":"Cloud Formation Sample Template for Time-based Auto Scaling"}],"answers":[{"id":"765dccb8332e2036eb70a0b6276e7285","text":"Use CloudWatch Events to trigger a Lambda function at business opening and closing that adjusts the Auto Scaling Group's MinSize and MaxSize accordingly","correct":false},{"id":"725933a9f7ea7ef281e2decf6cefadae","text":"Configure AutoScaling:ScheduledAction mappings in the CloudFormation template with Maxsize, MinSize, and Recurrence values based on business hours","correct":false},{"id":"0db6203397832efddcbca893f96ba1b6","text":"Include AutoScaling:ScheduledAction resources in the CloudFormation template that change Maxsize, MinSize, and Recurrence values based on business hours","correct":true},{"id":"a0f99978bb65910b10b75a32e1b92a2a","text":"Create AutoScaling:ScheduledAction conditions in the CloudFormation template that change Maxsize and MinSize values based on business hours","correct":false}]},{"id":"a8410bf2-3c51-49cc-8e44-ca3a1241eff2","domain":"dep-prov","question":"A developer has a monolithic Python application which is being migrated and refactored to use a microservice architecture. The developer has decided to use multiple AWS Lambda functions to run the Python code. During the preparation of the Lambda functions, the developer has noticed that the code requires several third party dependencies which are not part of the standard library. What needs to be done to ensure that the Lambda function code referencing the third party libraries can be executed properly?","explanation":"In order for a Lambda function to run scripts that involve third party libraries, a deployment package needs to be generated in a Lambda-like environment and uploaded to the Lambda or an S3 bucket. This is automatically done by tools like the SAM CLI. Third party libraries are not stored in EFS, ECR, or AppSync.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html","title":"Lambda Python - How to Create a Deployment Package"}],"answers":[{"id":"e45dd8b567270f7faf25f4111f41fa9e","text":"Generate a deployment package containing the code and the third party libraries.","correct":true},{"id":"d3ae725bd59d297fd27e71f3db582c01","text":"Store the third party libraries in ECR and link the Lambda function to the ECR repo.","correct":false},{"id":"b41396a5bc20297186c72b266cf8be9e","text":"Use AppSync to manage and store the third party libraries.","correct":false},{"id":"de93e97f2545dd02641eecd1a42fba8d","text":"Store the third party libraries in EFS and link the Lambda function to the EFS store.","correct":false}]},{"id":"b439f1df-a83a-47d6-96a0-c14944daeaff","domain":"networking","question":"A UK company is building its presence in India. It has decided to deploy dedicated infrastructure in India for the local market.  How can the company seamlessly route its Indian users to the load balancer located in ap-south-1 instead of the UK?","explanation":"Route53 geolocation routing is the only answer here which will return a different DNS record based on the source IP address of the DNS request.  The other answers would not route users correctly based on their country.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/geolocation-routing-policy/","title":"How do I direct traffic to specific resources or AWS regions based on the query's geographic location?"}],"answers":[{"id":"ebeefbe1e321377375eb3065b4a2fc20","text":"Use Route53 failover routing","correct":false},{"id":"816c21d5068061f198f8df28aaf61e0d","text":"Use Route53 multi-answer routing","correct":false},{"id":"055d83107cd15485df5c1f48c53f1758","text":"Use Route53 geolocation routing policy","correct":true},{"id":"1844cecdf015b88aef8e88746b321731","text":"Use Route53 latency routing","correct":false}]},{"id":"31081113-ca90-46fd-b9de-b0d861af38ab","domain":"automation","question":"A sports company has migrated systems to AWS but has not implemented any patching policy. A SysOps administrator has been hired to understand the current state of patching and help plan remediation. Which service can they use to understand the patch level of the EC2 instances?","explanation":"AWS Systems Manager provides a centralised location to view patching status of all Managed EC2 and on-prem instances. AWS Inspector, AWS Config and Macie are not services that can provide patch status reports.","links":[{"url":"https://docs.aws.amazon.com/en_pv/systems-manager/latest/userguide/systems-manager-patch.html","title":"AWS Systems Manager Patch Manager"}],"answers":[{"id":"fefa18704e871eb671528fd4b7bc6ca2","text":"AWS Macie","correct":false},{"id":"113b1ad9ce6cdc3a37ad8475bc9bb2b2","text":"AWS Systems Manager","correct":true},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":false},{"id":"7c90c8f2a24f3a1a28525f19fb2c75ab","text":"AWS Inspector","correct":false}]},{"id":"1db48074-bc12-4a56-92ce-865f2766c080","domain":"dep-prov","question":"You are running an application where you need to bring your own licenses for your AWS EC2 instances. To maintain the license compliance, the instances should be consistently deployed to the same physical servers over time. And the number of sockets and physical cores used in EC2 need to be well controlled. Which instance purchasing option would you choose?","explanation":"In this scenario, it is required that the instances are always deployed to the same physical hosts. Dedicated hosts should be chozen and this option also supports Bring Your Own License (BYOL). Dedicated instances are dedicated to a single customer, however it is not guaranteed that they are deployed to the same physical servers. Both scheduled reserved and reserved instances are incorrect because they are not dedicated to the same machines.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-hosts-overview.html","title":"Dedicated hosts"}],"answers":[{"id":"9d6afa7b92408e486a11a7f9b3179f8f","text":"Dedicated hosts","correct":true},{"id":"82595be34ecee78fa9be27b7d108b98b","text":"Scheduled reserved instances","correct":false},{"id":"46c8b5c0c6ebe7840383ec6b058d0394","text":"Dedicated instances","correct":false},{"id":"bcc129e8d9496a05a331c903d4c5bcb0","text":"Reserved instances","correct":false}]},{"id":"wprzr3tn-okej-0h4b-ndf8-ap946jyfvo5r","domain":"automation","question":"Your company has moved to AWS so it can use \"scripted infrastructure\". You would like to apply version control to your infrastructure, so that you can roll back infrastructure to a previous stable version if needed. You would also like to quickly deploy testing and staging environments in multiple regions. What services should you use to achieve this?","explanation":"CloudFormation, plus a version control system such as GitHub, would be the correct choice if the goal was to employ infrastructure-as-code.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"About CloudFormation"}],"answers":[{"id":"0fe9a555daecf33ab759c807a79e3027","text":"Opsworks, plus a version control system such as GitHub.","correct":false},{"id":"3944bd95d89aa956870cc4058a727391","text":"CloudFormation, plus a version control system such as GitHub.","correct":true},{"id":"a9b7ffe77958257f25106e8512657c4c","text":"CloudWatch, plus a version control system such as GitHub.","correct":false},{"id":"9c90a68675503a6fe9fa5d118c48fa11","text":"Elastic BeanStalk, plus a version control system such as GitHub.","correct":false}]},{"id":"7d7ac6a5-ba31-4418-9d4c-6da76657dbf2","domain":"networking","question":"You are designing a network with a bastion host (jump box) for security. Your network admins will SSH in to the bastion host and then on to other EC2 instances in a private subnet. You need your bastion host to be highly available. How should you build this environment?","explanation":"There has been is a much discussion about resilient Bastion design. The ELB does not add much value in this situation. Although you can get around it the ELB session timeouts will cause an SSH session to become disconnected if idle.  The answer with two AZs is a trap of the type you will see on the exam.  While 2x AZs would be ideal, the WHOLE answer must be correct, not just part of it. You should never use an ELB IP address for business as it is ephemeral and may change at any time.  DNS convectional round-robin will achieve the resiliency needed, as would an R53 Failover policy. The answer with two subnets does not exclude 2x AZs even though it does not stipulate it. Another design option you might see is EC2 Auto-Recovery or an Autoscaling group of Max=1 & Min=1 so that if the Bastion Host fails it is recreated automatically. ","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html","title":"Bastion Hosts on AWS - Architecture"},{"url":"https://en.wikipedia.org/wiki/Round-robin_DNS","title":"DNS convectional round-robin"},{"url":"hhttps://aws.amazon.com/blogs/aws/new-auto-recovery-for-amazon-ec2/","title":"Auto Recovery for Amazon EC2"}],"answers":[{"id":"cb402e295d67552ab9dfcffabcfb0dcb","text":"Create 1 Bastion EC2 instance in a private subnet. Connect to this EC2 instance using a site to site VPN. Configure your router to automatically reconnect if the VPN is dropped.","correct":false},{"id":"d5cfd03aad43f4cb7329ceb07c3b288d","text":"Create 2 Bastion EC2 instances in the same subnet. Create a DNS entry in Route53 which uses Round Robin DNS and points to each instance. Tell your SysAdmins to connect using the new DNS entry.","correct":false},{"id":"01a3b5d266f7455e0d0cfc25070de365","text":"Create 2 Bastion EC2 instances in separate availability zones. Place these instances behind an elastic load balancer, and ask your SysAdmins to connect to the ELB's public IP Address.","correct":false},{"id":"c87a02a4d83b0d5310563e4b700e303a","text":"Create 2 Bastion EC2 instances in different subnets. Create a DNS entry in Route53 which uses Round Robin DNS and points to each instance. Tell your SysAdmins to connect using the new DNS entry.","correct":true}]},{"id":"55cd4e20-346b-4ab5-920b-bf4720db7ee5","domain":"automation","question":"You are working as a SysOps Administrator for your company and are working on writing a CRON job on an application running on EC2. The CRON expression requires the instance to provide its public IP address to pass to another application running on a second EC2 instance. How would you obtain the IP address?","explanation":"Because your instance metadata is available from your running instance, you do not need to use the Amazon EC2 console or the AWS CLI. This can be helpful when you're writing scripts to run from your instance. For example, you can access the local IP address of your instance from instance metadata to manage a connection to an external application. User data are the parameters you specify when configuring your instance. Instance store is a type of instance and the AMI does not contain the IP address.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html","title":"Instance Metadata and User Data"}],"answers":[{"id":"6544d86f167272ed59ebf831074f047f","text":"From the instance store data using the curl command.","correct":false},{"id":"263ce3ebb0453f2bf28edc6a6d3bbf05","text":"From the instance user data using the curl command.","correct":false},{"id":"6248d35cdbd86a27a1dd1517a621d1d2","text":"From the instance AMI data.","correct":false},{"id":"45dbd3d67172bc00ea7cf86e81faf0f5","text":"From the instance metadata using the curl command.","correct":true}]},{"id":"4672c614-c5ab-464a-9de0-5ef85a8d081e","domain":"automation","question":"You are a SysOps Administrator for your company. The company's CIO was on vacation and didn't know that there was an AWS Region outage during her time off. She returned having no idea of the impact and wants to be alerted the next time an outage occurs whether or not she is on vacation. How would you implement a solution?","explanation":"You can use Amazon CloudWatch Events to detect and react to changes in the status of AWS Personal Health Dashboard (AWS Health) events. Then, based on the rules that you create, CloudWatch Events invokes one or more target actions when an event matches the values that you specify in a rule. Depending on the type of event, you can send notifications, capture event information, take corrective action, initiate events, or take other actions. Creating a Lambda function may be possible but is overly complicated. An AWS Config rule may also work but is not as efficient as using AWS Health directly. Amazon Inspector is used to assess security for applications deployed on EC2 and is not appropriate for this case.","links":[{"url":"https://docs.aws.amazon.com/health/latest/ug/cloudwatch-events-health.html","title":"Monitoring AWS Health Events with Amazon CloudWatch Events"}],"answers":[{"id":"74245b5d3f6507fb9fbf04a80d0edc0a","text":"Send custom text or SMS notifications to the CIO with Amazon SNS when an AWS Health event happens by using Lambda and CloudWatch Events.","correct":true},{"id":"0825ebcd89b98147868bbea3888611bd","text":"Use Amazon Inspector to assess service health. Have Amazon Inspector produce reports for you to review and forward these reports to the CIO for those containing outages.","correct":false},{"id":"d34ecb714b1da223e3ec16bc80d4193b","text":"Configure an AWS Config rule that checks to see if any Regions are suffering outages. Have the configure trigger a Lambda function that will send an email to the CIO.","correct":false},{"id":"984716f59e8039a5c670fd67e008a4e7","text":"Create a Lambda function that parses through the AWS Service Health Dashboard to identify outages in certain Regions. Have the Lambda function email the CIO using SES.","correct":false}]},{"id":"557a8cbf-ffb7-492a-b24a-7662b95c6269","domain":"automation","question":"A startup is planning to migrate their existing on-premise application to AWS. The company is already using Chef as the configuration management tool to manage their on-premise application and is looking to continue using Chef to manage their AWS resources. In addition to this, the team is looking to use a managed service to reduce the overhead of managing its PostgreSQL databases. How can the team accomplish this?","explanation":"OpsWorks is a managed service for Chef and Puppet and can easily be used to deploy and manage resources utilizing the Chef recipes already prepared. CloudFormation uses AWS's own engine to process and convert JSON or YAML templates to AWS resources. For requirements involving Chef and Puppet, OpsWorks is the primary (and only) managed service. For managed database service requirements, Aurora, RDS, and DynamoDB can be used as the managed database.","links":[{"url":"https://aws.amazon.com/opsworks/","title":"OpsWorks"}],"answers":[{"id":"378e25243c4a87f77553aed4ddbb2808","text":"Use ECS for the configuration management requirements. Use Athena for the database management requirements.","correct":false},{"id":"ce66fcb736d2db75172e1c56777a36e1","text":"Use CloudFormation for the configuration management requirements. Use Aurora for the database management requirements.","correct":false},{"id":"5b18a2364c2c69356af48e23e5347e81","text":"Use Elastic Beanstalk for the configuration management requirements. Use DynamoDB for the database management requirements.","correct":false},{"id":"33b2bf9a830d2dddb0570706a774902f","text":"Use OpsWorks for the configuration management requirements. Use RDS for the database management requirements.","correct":true}]},{"id":"8c197177-2b38-41eb-9b6c-d7c52de0808c","domain":"security-comp","question":"Which of the following statements is correct?","explanation":"AWS is responsible for physical controls, you are responsible for patching and updating your own operating systems","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"0f245a67bb96c5c2cfe2a8892b81a868","text":"AWS is responsible for patching and updates of any Operating System you install on your EC2 instances","correct":false},{"id":"d891cc198c4681e4512d4855f795f22e","text":"AWS is responsible for the hardware, software, networking and facilities that run AWS Cloud services","correct":true},{"id":"25147b4a8382ebb44937e157a61975fc","text":"You are responsible for Physical and Environmental controls for your AWS infrastructure","correct":false},{"id":"be49b24b55936f276a5224988013f961","text":"You are responsible for the security configuration and management tasks for any VPCs, EC2 instances and S3 buckets you create","correct":true}]},{"id":"46d872a7-bf30-4880-9cbd-3a63c50fb75e","domain":"mon-rep","question":"You need to enable a CloudWatch alarm to alert you if an EC2 instance which holds a key customers database goes over 100% CPU Utilization for more than two minutes. Which service should you use?","explanation":"Detailed Monitoring collects data at 1 minute intervals, whereas Basic or Standard Monitoring is every 5 minutes. Artifact allows you to check which industry and regulatory compliance standards AWS adheres to.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html","title":"CloudWatch Detailed Monitoring"}],"answers":[{"id":"af64135daff929ae7e26207cfae5e24a","text":"CloudWatch Standard Monitoring","correct":false},{"id":"60b018772cea138af5a8c452ed694734","text":"AWS Artifact","correct":false},{"id":"3d3e141cae28c035547bafe32dea1423","text":"CloudTrail Expedite","correct":false},{"id":"96778f7d823daef4c612d60aa5bf2312","text":" CloudWatch Detailed Monitoring","correct":true}]},{"id":"fa8987c8-41e8-43a5-b9d3-1446dce8e0ca","domain":"security-comp","question":"Your Security Architect would like to perform Penetration Testing on your entire AWS environment. They would like to schedule this as soon as possible, how should you approach this?","explanation":"Penetration Testing is allowed with prior approval from AWS","links":[{"url":"https://aws.amazon.com/security/penetration-testing/","title":"Pen Testing in AWS"}],"answers":[{"id":"530b142692a4e704a1565e00789ad493","text":"You are free to perform Penetration Testing on your own environment any time you like","correct":false},{"id":"ddf28d1bf64dae2b0a151350c25ca26e","text":"There is no need to perform Penetration Testing because AWS automatically runs regular tests on your behalf and provides any security recommendations in the Trusted Advisor console","correct":false},{"id":"2e72d2d8a44bb5d14dd29d0fd1e97d65","text":"Penetration Testing is not supported at any time as it can be disruptive in a multi-tenant environment","correct":false},{"id":"7be6630643492a9ae03b1911fb54573a","text":"This will depend on the service and the type of test you want to perform - some will require permission","correct":true},{"id":"f61573848ecce2f46433c0841355646d","text":"You need to request approval before you can perform Penetration Testing in AWS","correct":false}]},{"id":"d584866c-4884-40ad-a263-94eaad98f894","domain":"mon-rep","question":"AWS Config is a managed service which is part of the AWS Management & Governance portfolio of services.  Which of the following options are functions of the AWS Config service?","explanation":"AWS Config is a service that provides access to resource configuration history, an inventory of resources and alerts on any configuration changes, however it doesn't log API calls as this is the function of CloudTrail.","links":[{"url":"https://aws.amazon.com/config/faq/","title":"AWS Config FAQs"}],"answers":[{"id":"b3a15d8a30c303c913c4b2976f61f5c7","text":"Provides an inventory of all AWS resources","correct":true},{"id":"77eef0aefcbae3f15cc5ce086d0bff63","text":"Provides access to resource configuration history","correct":true},{"id":"46057f48c99511ac9dfb7fe92df1aefa","text":"Provides notification of configuration item changes","correct":true},{"id":"511bc797ffd63fd0702e8632fb5156db","text":"Provides a log of all configuration related API calls","correct":false}]},{"id":"f0c663f6-c133-4064-93f1-5a68ec604f86","domain":"networking","question":"A company is developing a software product on AWS. The product requires some dependencies on an external software application developed by another company. In order for the product to run properly, it must connect with the external software that has a configured AWS PrivateLink to run some tasks. Both companies want the connection between the product and the external application to be secured privately and not over the open Internet. How would you configure this connection?","explanation":"An interface VPC endpoint is required to use AWS PrivateLink. In this case, since the external software application has configured a PrivateLink, connecting the interface VPC endpoint to the PrivateLink will provide private connectivity. A VPN connection and Direct Connect are best suited for connectivity between AWS and an on-premise data center. A VPC endpoint is more appropriate in this case. Cross account access would not apply in this case.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html#what-is-privatelink","title":"What Is Amazon VPC?"}],"answers":[{"id":"396ed1524965dd42f15a5584a5df2111","text":"Set up a VPN connection between a gateway endpoint on your VPC and a customer gateway in the external company's VPC. Encrypt the IPSec tunnel to ensure private connectivity.","correct":false},{"id":"125e90bd89dd9a655f80754756185ade","text":"Put the product within a VPC and configure a VPC endpoint for the external application. Use the elastic network interface in the subnet with a private IP address.","correct":true},{"id":"a295a681bdc68fccdefa0245a0f3cb22","text":"Create a IAM role for the product. Enable cross account access for the product to communicate with the external software application to run its dependencies.","correct":false},{"id":"82d6bd6a8ad9b046abc832a10aab46ec","text":"Configure a Direct Connect connection between your software product and the external software application's VPC. Data traversed over this connection will be private.","correct":false}]},{"id":"594aa1e8-45f7-4cc9-a4d9-0241868d6e47","domain":"high-avail","question":"Your company has an application running on Amazon EC2 instances behind an Elastic Load Balancer (ELB). The instances are in an Auto Scaling group that spans multiple Availability Zones. You are a SysOps Administrator and as your check the health of your Auto Scaling group you notice that instances that are failing the Load Balancer health checks are not being replace. How would you remedy this situation?","explanation":"If you attached a load balancer or target group to your Auto Scaling group, you can configure the group to mark an instance as unhealthy when Elastic Load Balancing reports it as OutOfService. If you configure your Auto Scaling group to use the Elastic Load Balancing health checks, Amazon EC2 Auto Scaling determines the health status of the instances by checking both the EC2 status checks and the Elastic Load Balancing health checks. After an instance has been marked unhealthy because of an Amazon EC2 or Elastic Load Balancing health check, it is almost immediately scheduled for replacement. Re-creating an Auto Scaling group or launching new instance types would not solve the issue. HTTPS port 443 will also have no impact.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html","title":"Health Checks for Auto Scaling Instances"}],"answers":[{"id":"a26b5f88aff4c163eb6d9cad25ac904e","text":"Ensure that HTTPS port 443 is open on all the security groups attached to these instances.","correct":false},{"id":"c4cb9c892c467fcccbff0e8640bd4d5b","text":"Delete the Auto Scaling group and re-create a new one using the same configuration.","correct":false},{"id":"d28a2bf653d5f98af3ed710e025e87a1","text":"Configure the Auto Scaling group to determine health status using ELB health checks.","correct":true},{"id":"0cc2395369502a58ef4d3168644555f6","text":"Save the AMIs of the instances and terminate the existing instances. Re-launch the AMIs with new instances under the latest generation instance type (i.e. m4 to m5).","correct":false}]},{"id":"c9f0e61e-627b-421e-8a57-0d04983c25c4","domain":"security-comp","question":"You are a consultant working for a company who has recently completed their migration from an on-premise data centre to AWS. Most of the migration has been for EC2 instances, which have been sized to match the specifications they were originally using on-premise (CPU, memory, etc.). They have setup a Business Support plan with AWS. The technical manager is unhappy with the high costs, and wants to find ways to reduce them. What would the simplest way be to find ways to reduce their AWS costs in the short-term?","explanation":"This is a very common scenario for businesses migrating to the cloud, and discovering the operational expenditure (OPEX) costs of AWS. AWS Trusted Advisor has a lot of simple and effective recommendations for Cost Optimization. Some may not be applicable in your case, but it is a very easy way to find potential options for reducing your costs. These features are unlocked with the AWS Support Plans of Business or Enterprise. CloudWatch metrics can be very useful for right-sizing your instances (aligning the needs of the application workload with the instance specifications), but CloudWatch will also automate this to an extent as well by finding under-utilized instances. Reducing your support plan is usually an unwise move for production workloads, despite their cost, as they can be very important when outages are experienced. Advocating for a transition to PaaS and SaaS is definitely a strategic cost-saving measure, but it forms part of a long term business strategy, since it involves significant resources, both in time and money","links":[{"url":"https://aws.amazon.com/premiumsupport/technology/trusted-advisor/","title":"AWS Trusted Advisor"},{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Cost-Optimization-Pillar.pdf","title":"AWS Whitepaper - Cost Optimization Pillar"}],"answers":[{"id":"52107942e028b953519341a78f6815ca","text":"Inspect the CloudWatch metrics to better right-size the instances","correct":false},{"id":"39788d9f10797f3b8c876dbe95022c0d","text":"Advocate a transition to more cost-effective PaaS and SaaS solutions","correct":false},{"id":"55af961ef2471aec130c45657098b110","text":"Investigate recommendations from AWS Trusted Advisor's automated checks","correct":true},{"id":"b4e67747b2a23a55a53554b964d1ab9b","text":"Reduce the expensive AWS Support Plan to lower costs","correct":false}]},{"id":"bc639267-4b1b-4a5e-820e-27495782af83","domain":"data-man","question":"You have a mobile gaming application that uses an RDS MySQL database. The allocated storage of the database instance is 100GiB. As users are adopting rapidly, the available database storage is also rapidly decreasing, and will soon lead to performance issues if additional storage capacity is not added soon. Which of the following statements is correct in terms of addressing this database storage issue?","explanation":"You can manually scale up the storage. There is no outage during scaling and the performance of the server is not degraded. When the storage is modified, the change can be applied immediately. You can also enable auto scaling to automatically adjust the storage.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html","title":"Working with storage for Amazon RDS DB instances"}],"answers":[{"id":"bea16cc246ddc8340245b09063aeb7e8","text":"The database has an outage for a short period when the storage is being modified.","correct":false},{"id":"7a4336887970da0724cffecb782ab21f","text":"You can enable the RDS Storage Autoscaling feature to avoid manually scaling up the database storage.","correct":true},{"id":"528fd2301cd5c616abc137beeb7755e9","text":"The database status is \"degrading\" when you scale up the storage.","correct":false},{"id":"65998a26d3cbe450d273182cc29db11d","text":"You have to wait until the next scheduled maintenance window to apply the change.","correct":false}]},{"id":"a7e0b35e-a0a9-43fb-86a8-4677970f57ae","domain":"mon-rep","question":"Your Auto-Scaling group is configured to launch a new EC2 instance whenever it detects an unhealthy instance in your Auto-Scaling group. However, you wish to be notified when this happens. Which of the following AWS services would you join with Auto-Scaling to achieve this?","explanation":"When you use Auto Scaling to scale your applications automatically, it is useful to know when Auto Scaling is launching or terminating the EC2 instances in your Auto Scaling group. Amazon SNS coordinates and manages the delivery or sending of notifications to subscribing clients or endpoints. You can configure Auto Scaling to send an SNS notification whenever your Auto Scaling group scales.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/ASGettingNotifications.html","title":"SNS Notifications With Auto Scaling"}],"answers":[{"id":"f62772d94b939126ee608465cf5e0881","text":"SWF","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"ef4ba2f338cdf4b615ed280ff0b2777d","text":"SQS","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":true}]},{"id":"8a1eae53-9489-4424-904d-6cf15dc1a0a0","domain":"security-comp","question":"The R&D group at your company has begun developing on AWS. Most applications have a short lifespan due to initiatives either not moving forward or entering a product life cycle in another department. Security policy dictates that AWS IAM roles be used for authentication and authorization of AWS services used by all applications. Policy also requires the removal of IAM roles that have had no activity for sixty days. Which solution will provide the most operationally efficient way to identify roles that don't comply with security policy?","explanation":"The IAM API provides information about when a role has last been used. A Lambda function invoked by an AWS Config custom rule can cycle through IAM roles to identify which are compliant and which are non-compliant. Trusted Advisor doesn't provide a check for inactive IAM roles. CloudWatch Alarm metrics don't exist for IAM role activity. Filtering CloudTrail events will miss non-compliant roles that have no API records written.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_develop-rules.html","title":"AWS Config Custom Rules"},{"url":"https://aws.amazon.com/blogs/security/continuously-monitor-unused-iam-roles-aws-config/","title":"Continuously monitor unused IAM roles with AWS Config"}],"answers":[{"id":"2799421eb19492036b61a12bcb8445d4","text":"Create an AWS Config custom rule that invokes an AWS Lambda function to identify IAM roles that have been inactive for sixty days or more. Have the Lambda function write compliance status back to AWS Config.","correct":true},{"id":"444fe0024cfc19432a6f4acf80e90d76","text":"Configure an Amazon CloudWatch Alarm to publish metrics to an Amazon Simple Notification Service topic when the role last used date exceeds the sixty-day compliance threshold for role activity.","correct":false},{"id":"08d10e1bbf40689f1b82d560dabddbbc","text":"Employ AWS CloudTrail to publish to Amazon CloudWatch Logs. Filter the logs for IAM role activity and publish metrics which will alarm whenever a role hasn't been accessed for sixty days or more.","correct":false},{"id":"d7ec8812d614132d00b53e4d6ae7e537","text":"Regularly invoke a Lambda function to refresh AWS Trusted Advisor security checks. Create Amazon CloudWatch Events rules that monitor the Trusted Advisor checks and send status events to an Amazon Simple Notification Service topic when a role is no longer compliant.","correct":false}]},{"id":"88d422b1-765f-4919-b83d-91b1b862b26f","domain":"networking","question":"You need a load balancer with support for SSL offloading, cross-zone load balancing and Path-Based Routing. What load balancer should you choose?","explanation":"Path Load balancer isn't a real thing. Application Load balancer, Network Load Balancer and Classic Load Balancer all support SSL offloading and cross-zone load balancing. However, only Application Load Balancer supports Path-Based Routing.","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/","title":"Elastic Load Balancing features"}],"answers":[{"id":"682b66281be2437eb8d29a051355963d","text":"Path Load balancer","correct":false},{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":false},{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false},{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":true}]},{"id":"f5213e28-c41d-4552-810a-7aa8f5ba2a1c","domain":"networking","question":"A Developer is unable to connect to an EC2 instance in a VPC. A SysOps Administrator investigates the connectivity issue. Going through a troubleshooting checklist, which conditions should be checked? Select two.","explanation":"Internet gateways allow all traffic and that cannot be configured. EC2 instances always have a private IP but a public IP is required for internet access. Security groups are stateful so only an allow rule for incoming traffic is required.","links":[{"url":"","title":""}],"answers":[{"id":"692e30da816ea07b3744e393cbbd28cd","text":"The instance has a private IP address.","correct":false},{"id":"50be1cda181093d2df7e72aed5f80ab8","text":"The instance has a public IP address.","correct":true},{"id":"578d4a14aed3e21944a0f081460e32af","text":"The security group has an allow rule for outgoing traffic.","correct":false},{"id":"f9b2c3489abcbefefb1b289a51e33ccb","text":"The internet gateway associated with the VPC allows incoming traffic.","correct":false},{"id":"8b476944980fce87668c22d0c40470e9","text":"The internet gateway associated with the VPC allows outgoing traffic.","correct":false},{"id":"08eefee7811ea91e42e46ba287ff5d6a","text":"The security group has an allow rule for incoming traffic.","correct":true}]},{"id":"1de9eb98-4b61-4178-b30f-68d5d6422439","domain":"mon-rep","question":"You need to monitor application-specific events every 10 seconds. How can you configure this?","explanation":"you need to configure a custom metric to handle application specific events and if you want to monitor at 10 second intervals, you need to use high-resolution metrics. Detailed monitoring reports metrics at 1 minute intervals.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html","title":"CloudWatch Custom Metrics"}],"answers":[{"id":"da902bf148db5983868bf3383162183a","text":"Select high-resolution metrics in CloudWatch","correct":false},{"id":"f3e15ffbefd8415dda26321a2912dca1","text":"Select detailed monitoring in CloudWatch","correct":false},{"id":"8625460160031630c52a466b7a91f16b","text":"configure a high-resolution custom metric in CloudWatch","correct":true},{"id":"886f04b8880657a2d07a12c6355639a7","text":"Configure the application to send notifications using SNS every 10 seconds","correct":false}]},{"id":"b44c9f0b-805c-4de9-8ae7-71a6c2885b76","domain":"mon-rep","question":"Which of the following can you use to monitor API usage in AWS?","explanation":"CloudTrail logs all API calls within your account, CloudWatch monitors performance metrics, RunCommand is a Systems Manager feature which lets you run a command simultaneously on multiple instances, Trusted Advisor makes security, performance and cost optimization recommendations.","links":[{"url":"https://aws.amazon.com/cloudtrail/faqs/","title":"CloudTrail FAQs"}],"answers":[{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"64d231d79e9f7640a4572f7ae75aa226","text":"RunCommand","correct":false},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false}]},{"id":"a7cf4a98-8f6b-4000-8a95-39daf4c49350","domain":"security-comp","question":"What does the following snippet from an IAM policy do: {\"Effect\": \"Allow\", \"Action\": \"*\", \"Resource\": \"S3\"}","explanation":"This snippet from an IAM policy allows this user or group full access to all S3 actions.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html","title":"Overview of IAM Policies"}],"answers":[{"id":"d993ee846a8102e296072f7fff8f49ce","text":"It allows this user or group full access to all S3 actions.","correct":true},{"id":"4e7df242da046f347738cbbda30e35fe","text":"It allows this user or group no access to all S3 actions.","correct":false},{"id":"89faecec5b9b3852e1d2bf648268abb0","text":"It allows this user or group full access to certain S3 actions.","correct":false},{"id":"ee5803adff59a49957351bdf7a3be9ad","text":"It allows this user or group full access to all AWS actions.","correct":false}]},{"id":"43f0527f-8ffc-49c2-8dd8-f55203c05f15","domain":"data-man","question":"A company has a local data center that stores satellite images and the company plans to migrate the image files to AWS S3 or Glacier. The total amount of data is about 100TB. The local network speed is slow so it is not applicable to transfer the files over the internet. Which of the provided options is the best to migrate the data to AWS?","explanation":"AWS Snowball is a recommended data transport solution that accelerates moving terabytes to petabytes of data to AWS. AWS Transfer for SFTP uses the internet so it is eliminated. VPN also relies on the network connection and it cannot accelerate the data transfer. AWS Storage File Gateway is a storage service to integrate with on-premises server. It is not used to migrate data to AWS.","links":[{"url":"https://docs.aws.amazon.com/whitepapers/latest/aws-overview/migration-services.html#aws-snowball","title":"Migration and Transfer solutions"}],"answers":[{"id":"d21889436bedfa9ee6bd66e73efdc3f0","text":"Configure the AWS Transfer for SFTP service to seamlessly migrate files to AWS S3 or Glacier.","correct":false},{"id":"49088421573ec1c3f93f7588fb78704f","text":"Create an AWS Snowball job and transfer files to the Snowball hardware. After the device is shipped back, AWS is in charge of storing data in S3 or Glacier.","correct":true},{"id":"4713a94f713bbca5a4e46d58447eb1cf","text":"Configure the VPN direct connection from the local data center to AWS VPC. Copy over the files using the high speed intranet.","correct":false},{"id":"8ebed8f00ea6cd51a35c7bfbc4a1b000","text":"Create a high speed AWS Storage File Gateway to map all the local files to S3 or Glacier.","correct":false}]},{"id":"f253314b-765f-471a-a5de-bc5f6095164a","domain":"dep-prov","question":"An application server running in an autoscaling group is terminating and relaunching every few minutes. What is the most likely cause?","explanation":"When an instance is seen to be terminating and relaunching regularly (commonly known as 'flapping' or 'thrashing'), the most likely cause is that the Autoscaling group is marking the instance as unhealthy to trigger a replacement.  This can be caused if the Load Balancer health check has been improperly configured- for instance if a missing security group rules means the ALB cannot perform health checks. or the health check too aggressively marks instances as unhealthy before launch has completed (i.e. before userdata has finished.  Termination of an autoscaling instance when using Spot fleet is common, but to see the regular launch and termination would suggest this is health-check related rather than due to spot price changes.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html#health-check-grace-period","title":"EC2 AutoScaling - Replacing Unhealthy Instances"}],"answers":[{"id":"22b774b395936efd71fe7ddaf41a3f8a","text":"The autoscaling health check is marking the instance as unhealthy before it has time to initalise fully.","correct":false},{"id":"18d69cdccb048f832573792064f79345","text":"There is a temporary outage in the AWS Autoscaling service in that region.","correct":false},{"id":"ceb2643dc2123b2807f446e103bad7ff","text":"The price for the EC2 spot instance has increased to above the maximum price for your autoscaling group Launch Configuration.","correct":false},{"id":"ef10fce024d97295098b2e7c8b9de34e","text":"The Launch Configuration is using an unsupported AMI for your Availability Zone.","correct":true}]},{"id":"2ed81e01-78af-4ca1-8cc9-2ecfeeff8984","domain":"data-man","question":"Which of the following is not a use case for read replicas?","explanation":"Providing greater redundancy via automatic failovers is not a use case for read replicas. They're not useful in this case.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.Overview","title":"Overview: Read Replicas"}],"answers":[{"id":"61cb6fc4fb9c00d23b126d6e5c0d8905","text":"Scaling beyond the compute or I/O capacity of a single DB Instance for read-heavy database workloads. This excess read traffic can be directed to one or more read replicas.","correct":false},{"id":"865c6a9aca74af0e2c37ab4e50ca6013","text":"Providing greater redundancy via automatic failovers.","correct":true},{"id":"82d85c0b4a19e372bf779bb4908cd64a","text":"Business reporting or data warehousing scenarios; you may want business reporting queries to run against a read replica, rather than your primary DB Instance.","correct":false},{"id":"5224fa97bf0d7d77ee80e90a695f1e40","text":"Serving read traffic while the source DB instance is unavailable. If your source DB Instance cannot take I/O requests (e.g. due to I/O suspension for backups or scheduled maintenance), you can direct read traffic to your read replicas.","correct":false}]},{"id":"3a6ecc9f-2e62-4807-b2f7-0d4f0e032cc3","domain":"networking","question":"You're configuring an Elastic Load Balancer. What can you do to ensure that a user request always goes to the same server?","explanation":"You can use the sticky session feature (also known as session affinity) to enable the load balancer to bind a user's session to a specific instance. This ensures that all requests from the user during the session are sent to the same instance.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html","title":"Sticky Sessions for Your Classic Load Balancer"}],"answers":[{"id":"fe11d265f3c285c0d795d272a9eff45a","text":"Use Multi-Zone Load Balancing","correct":false},{"id":"6586c5993a69b3d3955cc5bf228a0792","text":"Enable Connection Draining","correct":false},{"id":"4ff5c8a41331ce8a8718cf02c632ff5d","text":"Enable sticky sessions","correct":true},{"id":"55c493073aa412bee5b26fa084e13092","text":"Enable Zonal Failover","correct":false}]},{"id":"066a63c9-1a0c-454f-8eeb-628657c4b7b3","domain":"security-comp","question":"As a security administrator for your company, the development team has asked for your advice on protecting their web product running on AWS against SQL injection attacks. Recently, there have been several cases where attackers have tried to insert certain malicious SQL queries to extract data from a database that stores confidential customer data. The development team manages and runs the database on EC2 running behind a load balancer. What advice would you give to the team to proactively protect against these kinds of attacks?","explanation":"There are several firewall services that AWS has provided including AWS WAF, AWS Shield, and AWS Firewall Manager. But in this case an ACL with WAF would be the most appropriate. AWS Firewall Manager simplifies your administrative and maintenance tasks across multiple accounts and resources for AWS WAF. AWS WAF is a web application firewall that lets you monitor the HTTP and HTTPS requests that are forwarded to a load balancer. You can block/allow all requests except the ones your specify. AWS Shield Advanced would protect against DDOS attacks. AWS Config would only provide notifications and thus would be a reactive solution to attacks.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html","title":"What Are AWS WAF, AWS Shield, and AWS Firewall Manager?"}],"answers":[{"id":"c84b52c0e32a45fc862e101beb233230","text":"Activate AWS Shield Advanced. Although costly, it will protect the application with a 24/7 response team from AWS, and full system and financial restoration after an attack.","correct":false},{"id":"5cfd6d4faff387749033b7f3e493f870","text":"Create a WAF Access Control List (ACL) with a rule to explicitly block the SQL injection attacks. Attach the ACL to the load balancer.","correct":true},{"id":"3e1ffae7dc069fcf4bdce431a89b4792","text":"Create a rule in AWS Firewall Manager to explicitly block the IP addresses that were listed as the attackers.","correct":false},{"id":"3b888c9ab75dfc1fd31b6fdcec298c41","text":"Use AWS Config to monitor the application. Set a rule to notify the development team when a malicious attack occurs.","correct":false}]},{"id":"6afb3149-0215-4a56-871a-ba55ad07fa07","domain":"security-comp","question":"To meet the security compliance, all the EBS volumes in your AWS account need to be encrypted. The encryption key should have the key material imported from a local server. And the key material is required to be maintained outside of AWS. Which of the below options should you choose?","explanation":"By using Customer Managed Key in KMS, you can import your own key material into the CMK. Then the key can be used to encrypt EBS volumes. You cannot modify the key material for AWS Managed Keys such as aws/ebs.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys.html","title":"Importing key material in AWS Key Management Service (AWS KMS)"}],"answers":[{"id":"18d880df394bfc8553f32d13907972d2","text":"Configure a Customer Key Store with imported key material in KMS to encrypt the EBS volumes.","correct":false},{"id":"6252a38ce08f0db1b36876f30b0fe352","text":"Use the AWS Managed Key (aws/ebs) with imported key material for the encryption.","correct":false},{"id":"c9d513eb9767845d56d1808f962eae22","text":"Configure a custom key with imported key material in AWS ACM to encrypt all EBS volumes.","correct":false},{"id":"4b7aa43955ca963689c5753479d1d2d5","text":"Use a Customer Managed Key with imported key material to encrypt the EBS volumes.","correct":true}]},{"id":"39376479-c045-4faf-a0b1-6dfddce09dba","domain":"mon-rep","question":"Which of the following is a valid AWS namespace?","explanation":"CloudWatch namespaces are containers for metrics.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/aws-namespaces.html","title":"AWS Namespaces"}],"answers":[{"id":"be6132c54d50d8ce33a982685bcdb6fd","text":"CUSTOM/KMS","correct":false},{"id":"96f49c22a5ef2aba5cfdcdf4d4c7cce1","text":"AWS/DynamoDB","correct":true},{"id":"15b7736c9e06de8c034b67c82b7bee1b","text":"AMAZON/EC2","correct":false},{"id":"f7986f757fc3e62f5d2152aafbb2dde0","text":" AWS/ApiGateway","correct":true}]},{"id":"6397b5f5-49ec-41f3-82da-1cac6fd6128e","domain":"dep-prov","question":"You are a SysOps engineer with a large self-help company.  Your website has just launched for your Yoga programme \"Yoga: Noob to Guru\" which your company is very excited about.  The application is deployed to web servers in an autoscaling group which are behind an AWS Application Load Balancer.  Your team is proud of the work they have done in just a short amount of time.  Unfortunately today, on the day of launch, your CEO tried the website and received an error: 504 Gateway Timeout.  What is the likely cause of this error and how should you proceed??","explanation":"The 5xx error codes indicate a problem on the server-side of a web request.  Gateway Timeout could indicate an issue between the load balancer which is serving the request to the CEO, and the web servers which the load balancer is trying to forward requests to.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-troubleshooting.html","title":"Troubleshooting Your Application Load Balancer"}],"answers":[{"id":"495fdf22664eed25be9c8e2d3631d9fd","text":"There is a problem between your Load Balancer and the web servers, your engineering team need to check the health of the web servers","correct":true},{"id":"4e94dcfe6494fd181c00b19e94d6701a","text":"The CEO entered the incorrect URL and the page was not found, he should try the correct URL","correct":false},{"id":"27529e162c1316a6e7403e428c6ee8a5","text":"Your website's SSL certificate is expired and needs to be replaced","correct":false},{"id":"1243ac6ffa178c8f5deab05f9499b796","text":"Your CEO has encountered an HTCPCP error, he should make a cup of coffee and try later","correct":false}]},{"id":"5b71bc80-b7ef-4fde-86f0-1a73d1d63e4c","domain":"high-avail","question":"You are an AWS administrator and have set up an Elastic Load Balancer inside a VPC. The ELB spans several Availability Zones. The ELB sits in front of a web application running on Amazon EC2. You notice that incoming traffic is not being evenly distributed across the AZs. How would you solve this issue?","explanation":"Traffic not evenly distributed across the instances in multiple AZs means the traffic is going to only specific EC2 instances. This happens when either the instances which are not receiving the traffic are unhealthy, or the instances that are receiving the traffic are holding on to the session. Since there is no mention of unhealthy instances, disabling sticky sessions on the ELB is the best answer. Increasing the number of subnets and/or instances will not solve the problem as users will remain stuck to the original instance. Increasing the frequency of health checks will have no impact to force even distribution of traffic.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html","title":"Configure Sticky Sessions for Your Classic Load Balancer"}],"answers":[{"id":"d532ac3048a69a5902a79b51bc219bd3","text":"Increase the number of EC2 instances behind the ELB.","correct":false},{"id":"c0d9e44a3e92d6d91864058257e9922c","text":"Add additional subnets within your ELB and configure your ELB to span the new subnets.","correct":false},{"id":"b7116d2a43d8462c83e8b93fda085c71","text":"Disable sticky sessions on the ELB.","correct":true},{"id":"e23eea1cecbc63f7423de00e65f29614","text":"Increase the frequency of the health checks to the EC2 instances running your application.","correct":false}]},{"id":"84adda98-8315-454d-b0c1-b6478c5c0d98","domain":"mon-rep","question":"You are performing an update to all of your application servers, however some of your applications are failing following the upgrade and you notice that this seems to only be affecting servers with a specific application profile. How can you easily identify which of your systems are likely to be affected?","explanation":"AWS Config is a service that enables you to assess, audit and evaluate the configurations of your AWS resources.","links":[{"url":"https://aws.amazon.com/config/faq/","title":"AWS Config FAQs"}],"answers":[{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"055f466b265e26667e0bb23ddffc7970","text":"Run Command","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"9deb03cd21d41a691cdc24bfaab2820c","text":"Inspector","correct":false}]},{"id":"113a7914-1249-4e12-a748-03392c0570e8","domain":"high-avail","question":"You are a Security Administrator for your company. Your CIO wants to ensure that company data is highly available in multiple AWS Regions. What would you suggest to your CIO as the most effective approach?","explanation":"Deploying a multi-AZ RDS instance would only make it fault tolerant between Availability Zones, and not AWS Regions. Creating a Lambda function and creating/deploying EBS snapshots into different AWS Regions would both be an administrative and operational burden. The easiest, most effective, way is to utilize S3 Cross Region Replication","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 Cross Region Replication"}],"answers":[{"id":"6e22da724261694b4ecf8fa105ef5174","text":"Enable Cross-Region Replication on your bucket to copy objects to a destination bucket in another AWS Region.","correct":true},{"id":"f876473fb6289d5a1e3e6d449713b0e7","text":"Copy the company data to an RDS instance. Deploy a multi-AZ configuration for your RDS instance to make it highly available.","correct":false},{"id":"a4ca2ada50730e36dd0f3302f60ab0dc","text":"Create multiple snapshots of your company data on EBS volumes. Deploy those EBS volumes on EC2 instance in different AWS Regions.","correct":false},{"id":"fbde7989c5f0da5bb91bb5593f9c8e4e","text":"Create a Lambda function that downloads data from your S3 Bucket and executes a PUT operation to upload copied objects into a new bucket in a new Region.","correct":false}]},{"id":"3714015f-1a0e-4b58-b904-42d21b082ce4","domain":"dep-prov","question":"You are running an EC2 instance with an attached EBS volume. Which of the following applies to EBS volumes?","explanation":"You cannot create snapshots from EBS volumes when hibernation is enabled on an instance. You can take a snapshot of an attached root volume, however this is not recommended as it may result in data inconsistency. If a snapshot is taken of an encrypted volume, it is automatically encrypted. Encrypted snapshots can be shared with other users of specific AWS accounts. For others to use your shared, encrypted snapshot, you must also share the CMK key that was used to encrypt it. Users with access to your encrypted snapshot must create their own personal copy of it and then use that copy to restore the volume.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html","title":"Creating Amazon EBS Snapshots"}],"answers":[{"id":"be7cc695163e3cfbe4fce331a5431ffe","text":"Snapshots that are taken from encrypted volumes are automatically encrypted.","correct":true},{"id":"f1854d1c449a2c9492159c401571eb3e","text":"You can create snapshots from instances for which hibernation is disabled.","correct":true},{"id":"ce3d4a8b603387b4c447b51080ecb934","text":"Encrypted snapshots cannot be shared with other users.","correct":false},{"id":"615c6b61cf777a5a029a4d97f7e0d897","text":"You cannot take a snapshot of an attached root volume.","correct":false},{"id":"d433815b2c570bc61e97ae01aad4e24c","text":"You can create snapshots from instances for which hibernation is enabled.","correct":false}]},{"id":"64ee23de-9703-4090-983d-d36552dac361","domain":"networking","question":"You are a SysOps Administrator running security checks throughout your AWS environment. One of your tasks is to clean up the environment and remove any idle resources that are no longer in use. You identify a VPC that was configured and used by a team that no longer works at the company and you are looking to delete the VPC. The VPC has a few running instances, a route table, a NAT Gateway, and an Internet Gateway. When you try to delete the VPC you get an error. How would you troubleshoot this situation?","explanation":"In AWS, you will get the following error if you attempt to delete the VPC with a network interface in-use: 'The VPC contains one or more in-use network interfaces, and cannot be deleted until those network interfaces have been deleted. View in-use network interfaces in the VPC.' Moreover, you cannot delete a subnet that has instances in it. The best answer would be to terminate the instances before deleting the VPC. There is no need to take snapshots before deleting a VPC (unless for backup purpose), and detaching the Internet Gateway is unnecessary as well. Assuming the role of the VPC creator is unnecessary if you already have the proper IAM permissions to do so.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html","title":"VPCs and Subnets"}],"answers":[{"id":"4fd6f1d4acf6323fa52621653e2a6150","text":"Take a snapshot of the EBS volumes before deleting the VPC. Upload the snapshots into S3 and proceed deleting the VPC.","correct":false},{"id":"dc869ce95aa68ff14f2265e56e10d33d","text":"Stop and terminate the running instances. Delete all the resources in the VPC before deleting the VPC itself.","correct":true},{"id":"bdba6bd2f5a22439d78f3ae5512c9213","text":"Detach the Internet Gateway from the VPC. Delete the Internet Gateway to restrict public traffic into the VPC. Delete the VPC.","correct":false},{"id":"64ab90b44ef9b90a49072f93bb50a615","text":"Assume the role of the creator of the VPC. The credentials for the VPCs creator is required to delete the VPC.","correct":false}]},{"id":"8473f19c-c3f7-4f2b-93a5-55ed10d99f83","domain":"mon-rep","question":"You run a hybrid environment with some servers in AWS and other Servers on Premise. Your boss has been impressed with your CloudWatch dashboard which shows the performance of all your EC2 instances around the world, however it does not show any metrics for your on premise servers. What could you do to rectify this?","explanation":"AWS Systems Manager Agent (SSM Agent) is Amazon software that runs on your Amazon EC2 instances and your hybrid instances that are configured for Systems Manager (hybrid instances). You can manually install SSM Agent on servers or virtual machines in your on-premises environment","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html","title":"SSM Agent"}],"answers":[{"id":"5aa17ac5ff5e522d0cbd19818e8b854d","text":"It is not yet possible to monitor on premise servers using AWS CloudWatch","correct":false},{"id":"02a9311d5b1ac89de02acaf3c528c90a","text":"Install a third party monitoring agent and export performance data to the third party platform. Use AWS datapipeline to create a pipeline of this data from the third parties platform, in to CloudWatch","correct":false},{"id":"38763eaec7d5f8126a56abeb236b9d27","text":"Install and run the SSM agent on your on premise servers. Once finished, install and run the CloudWatch agent on the on premise servers. Create the required role in IAM and verify that the agent is publishing data to CloudWatch. Add the widget for the on premise tools","correct":true},{"id":"2b914a41bdba2bd7ceb93d6306696cd4","text":"Use AWS Storage Gateway and configure Gateway Monitoring Mode. Publish the monitoring statistics to S3 and use AWS Datapipeline to import this data in to CloudWatch","correct":false}]},{"id":"8c1dec5f-627d-4f25-af24-119b092ca2ef","domain":"high-avail","question":"A client asks you how they can make their current database running on AWS highly available. The client is running a MySQL RDS database in us-west-1. The client does not currently have a Multi-AZ deployment. The client wants to know what the benefits are with a Multi-AZ deployment as it would incur additional costs to their AWS bill. How would you explain the benefits to the customer?","explanation":"Amazon RDS Multi-AZ deployments provide enhanced availability and durability for databases. When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone. In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby. It does not lower latencies nor does it increase read performance. It cannot tolerate the failure of a single AWS Region as failure of a Region would implicate failure of all the Availability Zones within that Region.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"Amazon RDS Multi-AZ Deployments"}],"answers":[{"id":"834345e14f96992b8d4b2e785595f697","text":"Multi-AZ tolerates the failure of a single Region. It also allows higher availability during maintenance tasks.","correct":false},{"id":"aa4c2ced080ae70c33f36fe825b972ce","text":"Multi-AZ lowers latencies for application servers when they are accessing the database in multiple Availability Zones.","correct":false},{"id":"4983004598ef3be1bb46819c748a09ab","text":"Multi-AZ tolerates the failure of a single Availability Zone. It also allows higher availability during maintenance tasks.","correct":true},{"id":"6772f4dc3173a8dd298656b65d2b6efa","text":"Multi-AZ makes it faster for application servers to access the database by reading data at a quicker rate.","correct":false}]},{"id":"466da628-4a01-43da-bb82-90215f555b37","domain":"automation","question":"A development team wants to deploy an application to AWS infrastructure using CloudFormation. They have code which copies files from the Internet in order to install their application on launch.  The team finds that whilst the stack deploys, it shows CREATE_COMPLETE, before the application is available.  What changes can they make to their solution in order for the Create Stack to only show as CREATE_COMPLETE when the application has finished deploying?","explanation":"The stack is changing to CREATE_COMPLETE because CloudFormation does not wait for userdata to complete by default. By adding a 'creation policy', you are able to tell CloudFormation to wait for the 'all-clear' from a given resource that it has complete its setup. The 'all-clear' signal is sent back to CloudFormation via the cfn-signal tool.  In addition to a creation policy, the development team could consider creating their own customised AMIs which contain the large downloads from the Internet already. By launching from these AMIs you can considerably cut down on installation time. Thirdly if you store the files in S3, the file download operations will likely be much faster and reliable than using the Internet.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-signal.html","title":"cfn-signal"},{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/enable-fast-bootstrapping-of-your-auto-scaled-instances-using-dynamically-created-images/","title":"Speed up instance bootstrapping by using dynamically created images"}],"answers":[{"id":"6ddb94842ea46b76f66e976e3a13c912","text":"Customise their AMI to pre-install the software from the Internet to speed-up deployment time","correct":true},{"id":"4feec8f08e82e321dd29bddaca27eac1","text":"Use a custom lambda to change the stack status to 'CREATE_PENDING' whilst the install is running and set to 'CREATE_COMPLETE' once the application is installed","correct":false},{"id":"deecec189f6b1db2dc2f46b389124e5f","text":"Store the downloaded files in S3 and update the userdata to perform a s3 cp instead of downloading from the Internet","correct":false},{"id":"b39b6b36b224e633a0f7ce72a9061c61","text":"Use a nested stack with a dependency so that the parent stack only completes when the nested (application server) stack create has completed","correct":false},{"id":"489ada34b3c1a06eb7099396dd7b87ee","text":"Add the downloaded files to Systems Manager Parameter store as a large binary and pull from there on launch","correct":false},{"id":"affa2b51c754c18df43f666b47e9a3bc","text":"Use a cfn-signal and a creation policy in the stack to remain at CREATE_IN_PROGRESS during installation and then send a web call back to CloudFormation to mark the resource as complete once the download and install has finished","correct":true}]},{"id":"6da1a2f4-4dc6-48be-8e42-c838e3815602","domain":"data-man","question":"Your CTO wants to store company data in the Cloud. The full migration plan includes moving 500 TB of data to Amazon S3. What would be the fastest, and most cost-effective way to move this amount of data to AWS?","explanation":"Snowball is a strong choice for data transfer if you need to more securely and quickly transfer terabytes to many petabytes of data to AWS. As a rule of thumb, if it takes more than one week to upload your data to AWS using the spare capacity of your existing Internet connection, then you should consider using Snowball. If you have a 100 Mb connection that you can solely dedicate to transferring your data and need to transfer 100 TB of data, it takes more than 100 days to complete data transfer over that connection. You can make the same transfer by using multiple Snowballs in about a week. Direct Connect would take longer and is more expensive, and there would be no need for the connection after moving the 500 TB. VPN is faster to set up than Direct Connect but would take even longer. Storage Gateway would have the same issues and is ideally meant to be used as a hybrid cloud storage service.","links":[{"url":"https://aws.amazon.com/snowball/faqs/","title":"AWS Snowball FAQs"}],"answers":[{"id":"49d1df753d0b6625015b1b5a57b60b6a","text":"Set up a VPN connection between your on-premise data center and AWS. Transfer the data over IPSec Tunnel using encryption.","correct":false},{"id":"4d4f0e9f5d90bedd7d63f07e5d7102a7","text":"Transfer your data with multiple instances of Snowball. Install the Snowball client on multiple workstations and transfer data to the Snowball devices.","correct":true},{"id":"37724cf12ad7358208dd202bd2037e64","text":"Use AWS Storage Gateway using file gateway and copy the data to S3 using the file gateway mount point.","correct":false},{"id":"6459fb2dead422bbe8c534a859c17e67","text":"Set up a Direct Connection connection between your on-premise data center and AWS. Transfer the data over the Direct Connect connection.","correct":false}]},{"id":"5d1249a6-960b-4540-8631-50875e04850d","domain":"mon-rep","question":"A company is using a site-to-site AWS VPN connection with static routing to allow connectivity between its corporate office and a VPC in AWS. The SysOps Administrator wants to get notified if the connection goes down. What’s the most effective way to accomplish this?","explanation":"AWS support won't do this for you. The other options would work, however, creating a CloudWatch alarm is the simplest option.","links":[{"url":"https://docs.aws.amazon.com/vpn/latest/s2svpn/monitoring-cloudwatch-vpn.html","title":"Monitoring VPN Tunnels Using Amazon CloudWatch"}],"answers":[{"id":"759ca4c838619fc5548932dc516de2cf","text":"Create a CloudWatch alarm to track the TunnelState metric and send an SNS notification if necessary.","correct":true},{"id":"b9f0b72860ab9c76417cf3f4c3ec6c98","text":"Ask AWS support to monitor the connection and send an SNS notification if necessary.","correct":false},{"id":"4ca2750b50a6661dbeff47ae8524ff24","text":"Set up a cron job in an EC2 instance to confirm the TunnelState metric every minute and send an SNS notification if necessary.","correct":false},{"id":"a05514224184194909112ecdabb8b939","text":"Write a Lambda function to check the TunnelState metric every minute and send an SNS notification if necessary.","correct":false}]},{"id":"983c6fbc-20eb-4389-a91f-491d1f1e230b","domain":"networking","question":"You have a simple VPC with a single public subnet and a security group that allows access from source 0.0.0.0/0. Although you have both an Internet Gateway and Elastic IP specified for your instance, you are still unable to reach the instance via SSH. What have you forgotten to do?","explanation":"For the outside world to be able to communicate with your instance, you must allow inbound traffic on both the Security Group and the Route Table.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#AddRemoveRoutes","title":"Adding and Removing Routes from a Route Table"}],"answers":[{"id":"9c4da4b8220f1bcf509bc4cd3ccd943f","text":"You forgot to associate the Security Group with the Route Table.","correct":false},{"id":"93b61a7d33d3f54dee0f2c7dfd033254","text":"You haven't associated the Internet Gateway with the Security Group.","correct":false},{"id":"cb7394a526c29652c88dc22d58ad386a","text":"You have failed to associate the Internet Gateway with the custom Route Table.","correct":true},{"id":"1e8881ac02fb21089d364fb6f88436a7","text":"You have forgotten to associate the Elastic IP with the private IP.","correct":false}]},{"id":"9de05324-9d1a-4252-a6ed-c8bc6e732afe","domain":"dep-prov","question":"You use a launch template to create an Auto Scaling group for an application. You need to ensure a number of EC2 instances are always online to meet minimum capacity requirements and also use lower priced instances when scaling up. Which of the following instance combinations would be the most cost effective solution to use in the Auto Scaling group?","explanation":"A combination of on-demand instances and spot instances should be launched to meet the target capacity that you specified in the spot fleet request. The on-demand instances ensure the minimum capacities are met and the spot instances provide extra capacity as the application scales up. The other options without the spot instances are not cost-efficient. And scheduled reserved instances do not run continuously and should not be selected.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html","title":"How spot fleet works"}],"answers":[{"id":"8f81bfbb0090b9ecba50b69be972ec7b","text":"Dedicated instances + on-demand instances","correct":false},{"id":"eeea48d3cb7324682811fe139fd30093","text":"Scheduled reserved instances + spot instances","correct":false},{"id":"da8d4ca080444c6f36c71ed68a3c9a8f","text":"Reserved instances + on-demand instances","correct":false},{"id":"853ea21196f8eeabab96ee1faf8cb4bf","text":"On-demand instances + spot instances","correct":true}]},{"id":"0aec7415-8b29-457e-b3f1-155c5bb8cb86","domain":"security-comp","question":"A company is developing a photo sharing application. The frontend and backend are hosted on EC2 instances managed by Auto Scaling groups. The instances reside in a customer VPC. An Amazon Aurora database is created in RDS for the application. The DB instance is put in the same customer VPC and should only allow inbound traffic from the backend servers. Which method would you use to control the access for the database?","explanation":"RDS instances use VPC security groups to control the inbound and outbound access. You can configure a rule by specifying the backend server VPC security group as the source. You cannot attach a network control list to an RDS instance. An EC2 security group is associated with an EC2 instance and cannot be attached in an RDS database.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.RDSSecurityGroups.html","title":"Controlling access with security groups for RDS"}],"answers":[{"id":"a0fe13c612a2532365d4ef7cc72df516","text":"Attach a network control list to the RDS database. In the NCL, allow inbound traffic from the backend network control list.","correct":false},{"id":"38d438dc12bb1dc8fcf3ecd2cab2b66f","text":"Configure an EC2 security group and attach it to the database. The inbound rule allows the IP range used by the backend EC2 instances.","correct":false},{"id":"c9d929435a86501ae9e08194715efb79","text":"Configure a VPC security group in the DB instance and the inbound rule allows the security group of the backend server.","correct":true},{"id":"b0d35520a9a26c27b68a88876f158ee2","text":"Set up a network control list in the RDS instance. Only allow the inbound traffic from the backend Auto Scaling group.","correct":false}]},{"id":"c7e5ebf3-7eae-45bf-a02b-28bc06a6d575","domain":"mon-rep","question":"You have several CloudWatch Log Groups and Lambda Functions send logs to them. You need to use a tool to quickly search and analyze the log data in the log streams. The tool should automatically discover information in the Lambda logs such as the timestamp, max memory used and execution duration. It should also help you to perform the query using simple and pre-built query languages. Which tool is the best one for you to choose?","explanation":"CloudWatch Logs Insights is the most suitable tool to perform pre-build queries on CloudWatch Logs. Users do not need to transfer or transform the log streams. The log fields contained in the Lambda logs are automatically discovered. AWS Athena only performs queries on S3 objects. For Amazon ElasticSearch or Kinesis stream, extra configuration steps are required.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html","title":"Analyze log data with CloudWatch Logs Insights"}],"answers":[{"id":"7edc1b3e500b915d821d4db1db01280c","text":"Use CloudWatch Logs Insights to select the log groups and perform queries.","correct":true},{"id":"2c4abdd6514dcf68f6bace3f1a769e4f","text":"Stream the log data to an Amazon Kinesis stream and perform real time queries or analysis in the stream.","correct":false},{"id":"01551b4fd4b50ed9ceb2be1d0e338932","text":"Use AWS Athena to run queries on the log streams. The query language of Athena is based on SQL.","correct":false},{"id":"79930c2280cb2398212ed1465b34b81e","text":"Export the log data to an Amazon ElasticSearch Service. Use ElasticSearch to perform queries or analysis.","correct":false}]}]}}}}
