{"data":{"createNewExamAttempt":{"attempt":{"id":"ae0c9846-63f2-46a4-b6fc-a16e6e2db771"},"exam":{"id":"d7b8be8f-d65c-4490-a74f-6078929a5aa7","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"655aca00-21a4-11ea-978f-2e728ce88125","domain":"Performant","question":"A wealth intelligence software company currently uses Oracle 12c as its database solution. However, it wants to move its databases to the AWS Cloud. Which of the following services will accommodate the migration?","explanation":"The hint to the answer lies in the company’s current database software. Oracle 12c is a relational database solution, which is what Amazon RDS is. The company can run its Oracle databases using RDS instances. Amazon DynamoDB is a non-relational DB solution and Amazon Redshift is for Big Data and Data Warehouse solutions. Amazon ElastiCache is used to increase DB performance through caching DB data to improve application performance.","links":[{"url":"https://aws.amazon.com/rds/oracle/","title":"Amazon RDS for Oracle"}],"answers":[{"id":"ecafbaed9f41dac736e496a7cd234ce4","text":"Amazon DynamoDB","correct":false},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false},{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":true},{"id":"f7415e33f972c03abd4f3fed36748f7a","text":"Amazon Redshift","correct":false}]},{"id":"52cf0185-4629-47ac-8779-4ec4ffd9cc06","domain":"SecureSolutions","question":"You have an EC2 instance with a Security Group attached. This security group is configured to only allow inbound traffic from 192.168.0.0/24. A collegue has also configured a NACL on the subnet that the instance resides on, and this NACL is configured to block all traffic, except where the source or destination is in 192.168.0.0/24. What will happen when an instance with an IP of 192.168.1.12 tries to connect to your instance on port 80?","explanation":"With inbound traffic, NACLs are evaluated before Security Groups. As the NACL is configured to only allow traffic from 192.168.0.0/24 and the IP 192.168.1.12 does not fall within that range, it will be blocked by the NACL before reaching the Security Groups.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"c885215eb76a3baac02ca8ea6da9a7b4","text":"The NACL will block the traffic before it is evaluated by the security group","correct":true},{"id":"d3d7c67e2cf8c1d1cb89971fd90c2b72","text":"The security group will block the traffic before it is evaluated by the NACL","correct":false},{"id":"5298f0866dac220c6bbad6d2da2163d8","text":"The traffic will be allowed as it is still within a private range","correct":false},{"id":"eb5d4be456a62dd4f884a4b47c45fd46","text":"The traffic will be blocked simultaneously by the Security Group and NACL","correct":false}]},{"id":"c6a3e070-265a-11ea-978f-2e728ce88125","domain":"Performant","question":"An SEO company collects data based on disparate search engine optimization metrics and stores it in a DynamoDB database. The company wants to create an extra copy of the database tables as a form of disaster recovery. Which of the following AWS services can do that?","explanation":"True to its naming, AWS Backup is the service that you can use to back up the DynamoDB database tables. It also works for RDS databases.","links":[{"url":"https://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html","title":"What Is AWS Backup?"}],"answers":[{"id":"ce52d2cff6e50f2e74505e0c70d072b3","text":"AWS Backup","correct":true},{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":false},{"id":"df346128c45efa43efc29607224fc716","text":"Amazon Simple Storage Service (S3)","correct":false},{"id":"ce1a41ee0352cee512475ef6a6233963","text":"Amazon Elastic Compute Cloud (EC2)","correct":false}]},{"id":"57ee57eb-5b47-45ff-8c95-42b35bb8e719","domain":"ResilientDesign","question":"A Multi-AZ RDS deployment will automatically fail-over as a result of which two of the following?","explanation":"Amazon RDS detects and automatically recovers from the most common failure scenarios for Multi-AZ deployments so that you can resume database operations as quickly as possible without administrative intervention. Amazon RDS automatically performs a failover in the event of any of the following: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, Storage failure on primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"Failover Process for Amazon RDS"}],"answers":[{"id":"7ecc550bc4f7f4c4d01c334d359bb0d9","text":"Loss of availability in standby Availability Zone","correct":false},{"id":"215b7e6d7f48e4225c06a3c50bf400d2","text":"Loss of availability in primary Availability Zone","correct":true},{"id":"8851c500044adfe0ba4a247acdb86eda","text":"Loss of network connectivity to the Primary","correct":true},{"id":"7b75b57dbe879950151e7a40cf0aed41","text":"A region-wide loss of service","correct":false}]},{"id":"eba390fe-7699-47c0-b51f-f38cbc948112","domain":"CostOptimized","question":"What is the 'first-byte' latency when retrieving data from Glacier?","explanation":"You should expect data retrieval latency of 3-5 hours when retrieving data from Glacier.","links":[{"url":"https://aws.amazon.com/glacier/faqs/#dataretrievalpolicies","title":"Glacier Data Retrieval Policies"}],"answers":[{"id":"b86a4270946442f3b17bd51e3aa226ce","text":"> 5 hours","correct":false},{"id":"72ab9d0304d3e84c6aa2dd15eda282f2","text":"1 hour","correct":false},{"id":"6619a70f8ab8877e4131643fb8ded723","text":"2 hours","correct":false},{"id":"99d888e6893ac480abd21ecb8a18e060","text":"3-5 hours","correct":true}]},{"id":"ce9877b8-de12-428e-8ff5-9900b8e817f2","domain":"Performant","question":"You have some EC2 instances in a private subnet that need access to an S3 bucket.  There is a requirement that traffic does not traverse the Internet. Which of the following can be used to achieve this?","explanation":"A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html","title":"VPC Endpoints"},{"url":"https://aws.amazon.com/blogs/aws/aws-privatelink-update-vpc-endpoints-for-your-own-applications-services/","title":"Private link announcement"}],"answers":[{"id":"8f9d3edc1ed25845346d7d64e087edbe","text":"NAT Instance","correct":false},{"id":"a0b2b99d905954d58da91017a81d3059","text":"VPC Gateway Endpoint","correct":true},{"id":"8ca0f1328403ec0d05ed995272d74715","text":"NAT Gateway","correct":false},{"id":"3fdc04800c36e2177d81c4431616f533","text":"Internet Gateway","correct":false}]},{"id":"acf9a198-cda6-48ea-9c6b-a9252be9629c","domain":"SecureSolutions","question":"You have a subnet in your VPC that contains VMs with only private IP addresses in the 10.0.1.0/24 range. Where should this subnet's default route point to in order to allow the instances access to the internet?","explanation":"Instances with private IP addresses will need to route their internet-bound traffic through a NAT gateway or NAT Instance to be able to reach the internet, meaning the Nat Gateway option is the only correct one in the list.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","title":"NAT Gateways"}],"answers":[{"id":"f6d32b11f585cc7f427bfc00d81e5818","text":"The IP Address 10.0.1.1","correct":false},{"id":"a68a4add38339b1ccca0bc64939ac112","text":"The VPC's Internet Gateway","correct":false},{"id":"6922e39a5f1d9929421a1a6f9c957d57","text":"The NAT Gateway","correct":true},{"id":"20bfe770b8c1b0ba4fef59dcd797ff92","text":"The Default Gateway","correct":false}]},{"id":"aad18b7b-a805-45b3-9b77-66eecf097e97","domain":"CostOptimized","question":"Your AWS environment contains several on-demand, EBS-backed EC2 instances dedicated to a project that has just been canceled. Your supervisor does not want to incur charges for these on-demand instances, but also does not want to lose the data just yet because there is a chance the project may be revived in the next few days. What should you do to minimize charges for these instances in the meantime?","explanation":"Stopping an EBS-backed on-demand instance will stop the charges and preserve the data.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html","title":"Stopping and Starting Your Instances"}],"answers":[{"id":"3e9091dfa36a1ab60c68658d5b630b61","text":"Terminate the instances.","correct":false},{"id":"1c1cacea035822ccf211f7f588b085fe","text":"Stop the instances as soon as possible.","correct":true},{"id":"bcf45b66b85859c34f9a1bc2e2e3d537","text":"Explain your situation to AWS Support and ask them to hold your instances for you.","correct":false},{"id":"ad806d84c4f630fa88693a83dc990289","text":"Take snapshots of the EBS volumes and sell the instances on the In-Demand Instance Marketplace.","correct":false}]},{"id":"5fac4bb4-d450-440d-bc31-62fd409b5bee","domain":"ResilientDesign","question":"A company has an LNMP (Linux, Nginx, MySQL, PHP) stack application deployed to AWS. The availability requirements for their backend database specify automatic failover in case of disaster recovery. What is the optimal solution that meets this requirement?","explanation":"Since the scenario calls for MySQL, we must choose a relational database for the backend database. This means that DynamoDB is not a correct option. With RDS Multi-AZ deployment, a primary DB instance is automatically and synchronously replicated to a secondary RDS instance in a different availability zone (AZ). In case of a disaster causing primary instance failure, RDS performs automatic failover to the secondary standby RDS instance. During the failover, the database endpoint remains the same. RDS Read-Replica provide secondary RDS instances that are asynchronous replicated from the primary. RDS read-replicas have different endpoints and do not provide automatic failover. Additionally, they only provide read (not write) operations. It is possible to use Route53 with Health-check and DNS failover configurations to route traffic to multiple RDS instances. However, this solution does not provide automatic data synchronization between instances.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"High Availability (Multi-AZ) for Amazon RDS"}],"answers":[{"id":"9e445d25eaf3cc7b2f2412dbf19e6e4b","text":"RDS with Read-Replica deployment.","correct":false},{"id":"8a8d90b530fbd9c90820ca63425401b5","text":"Deploy multiple RDS instances. Use Route53 with Health-Check and DNS failover configured.","correct":false},{"id":"23f694af0e449b15b6fb26401d12eb0e","text":"DynamoDB with Global Tables deployment.","correct":false},{"id":"f38116f4410ef57b5ffc6e17d11b1721","text":"RDS with Multi-AZ deployment.","correct":true}]},{"id":"15c91139-c33f-4583-8864-dba8207c73a0","domain":"Performant","question":"Your organisation is running a business critical application with a backend MySQL DB that has been experiencing performance issues due to an increase in customers hitting the website. Management are concerned that the existing solution will not handle the anticipated customer growth over the next 12 months and any outages could lead to a loss in potential revenue.\\n You’ve been asked to develop a suitable AWS cloud based solution that will best meet the requirements of the organisation and require minimal operational overhead. Which AWS DB service will be most suitable for your organisation?","explanation":"Aurora natively maintains 2 copies of your data in each availability zone (3 AZs x 2 = 6 copies) within a region providing the highly available solution needed for this scenario. It also supports storage autoscaling and CPU and Memory scaling. Aurora also provides up to 5 times improved performance over a traditional DB installation.  MySQL and PostgreSQL support multi-AZ deployments and read replicas, but this requires additional configuration. CPU, memory and storage scaling is not automated and requires additional configuration and design consideration. Redshift does not support Multi-AZ deployments.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/","title":"Amazon Aurora FAQs"}],"answers":[{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":true},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"f52a9d91766886fb3a524dd06d1581cb","text":"Redshift","correct":false},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false}]},{"id":"15025340-2278-430c-befc-70d80f9a2544","domain":"ResilientDesign","question":"Your company stores confidential data in S3. To comply with regulations, the data needs to be made available in a different geographical location. What steps would you take to be within compliance?","explanation":"This is a specific use case for S3 Cross-Region Replication. Comply with compliance requirements—Although Amazon S3 stores your data across multiple geographically distant Availability Zones by default, compliance requirements might dictate that you store data at even greater distances. Cross-region replication allows you to replicate data between distant AWS Regions to satisfy these requirements.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html#crr-scenario","title":"Cross-Region Replication - When to Use CRR"}],"answers":[{"id":"866cffef4a3a5d96498ba8d57616d6f4","text":"Enable Cross-Region Replication for the S3 bucket.","correct":true},{"id":"26b572d8c2fcaa2928ad8d9c685b0f4e","text":"Copy the data to an EBS volume in another region.","correct":false},{"id":"62515dd9616b3f1afcfdc0686d8a5759","text":"Apply Multi-AZ for the S3 bucket.","correct":false},{"id":"7ec7b008897371370d957669d36a1956","text":"Create a snapshot of the S3 bucket and copy it to another region.","correct":false}]},{"id":"1ad4b101-8078-4f3c-86bf-2f865ee09a54","domain":"CostOptimized","question":"A government agency has a regulatory mandate that all archived data must be preserved exclusively in a non-rewriteable and non-erasable format. What solution satisfies this requirement in the most cost-effective way?","explanation":"Amazon S3 versioning does not protect object versions from being deleted and is therefore an incorrect solution. Amazon S3 bucket policies do not satisfy the requirement and is not the correct solution. Amazon S3 bucket policies can be changed, thus removing protection on the objects. Implementing Amazon S3 Object Locks is incorrect because it is not the most cost-effective solution. The question specifically asks about archived data. Storing archived data in Amazon S3 Glacier is more cost-effective than Amazon S3. Amazon S3 Glacier is the most cost-effective storage solution for archive data. Amazon S3 Glacier Vault Lock can be used to implement a 'Write-Once-Read-Many' archive storage solution.","links":[{"url":"https://docs.aws.amazon.com/amazonglacier/latest/dev/vault-lock.html","title":"Amazon S3 Glacier Vault Lock"},{"url":"https://aws.amazon.com/blogs/aws/glacier-vault-lock/","title":"Create Write-Once-Read-Many Archive Storage with Amazon Glacier"}],"answers":[{"id":"1430bbbd409858a9a820458c0f311d39","text":"Enable Amazon S3 Object Lock.","correct":false},{"id":"6a730079c6c38844cd80386edd5634f3","text":"Enable Amazon S3 Versioning.","correct":false},{"id":"554acd3f3712f630497b0180dbb5124c","text":"Implement Amazon S3 Glacier Vault Lock.","correct":true},{"id":"c367faed034f6f722c499e129d8ca5dd","text":"Implement Amazon S3 Bucket Policy with deny statements for object delete operations.","correct":false}]},{"id":"bee3fc3a-4738-4c3f-b6ad-e6f25e600772","domain":"Performant","question":"Which of the following are types of virtualization available on AWS?","explanation":"The two different types of virtualization available are Hardware Virtual Machine (HVM) & Paravirtual Machine (PVM)","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#instance-virtualization-type","title":"EC2 Virtualization Types"}],"answers":[{"id":"4b796a884a8b85e9857127deafecc5e7","text":"Hardware Virtual Machine (HVM)","correct":true},{"id":"5136698bc5a65f152fe16da0719dd612","text":"Paravirtual Machine (PV)","correct":true},{"id":"fc9184bf07a56c1342576d092d7cdf15","text":"Physical Virtual Machine (PVM)","correct":false},{"id":"e526c533a9df6aff264b1313a0908f9d","text":"Cloud Virtual Machine (CVM)","correct":false}]},{"id":"86d55e8e-2438-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"To optimize the security and performance of its cloud environment, your company recently expressed interest in upgrading to an AWS Support plan that provides the full set of Trusted Advisor checks and recommendations. Which of the following support plans will provide that?","explanation":"Since each AWS account comes with Basic Support, Basic is not the answer. And the Developer Support plan offers seven core Trusted Advisor checks, but not the full suite. You will need to go with either the Business or the Enterprise plan to get the full set of Trusted Advisor checks and recommendations.","links":[{"url":"https://console.aws.amazon.com/support/plans/home?#/","title":"AWS Support Plans"}],"answers":[{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":true},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false}]},{"id":"e8d01592-5b1f-418e-84e9-fcc23e15ae0d","domain":"Performant","question":"You need to store files as objects in Amazon S3. Which AWS service provides that ability?","explanation":"You will need to go with Storage Gateway, which gives you the option of creating a file gateway so that S3 can support files. EFS provides file storage, but without the compatibility with S3. True to its naming, EBS is a block-level storage service. And RDS is for creating relational databases, not file gateways.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html","title":"What Is AWS Storage Gateway?"}],"answers":[{"id":"9155453f43b8a6472df0b8ffa5b5a028","text":"Amazon Elastic Block Storage (EBS)","correct":false},{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":false},{"id":"d2a6652ddeb631da029d1f2806e11fdc","text":"Amazon Elastic File System (EFS)","correct":false},{"id":"5ba49687f2f5ade4cd1c756a7e9024e3","text":"AWS Storage Gateway","correct":true}]},{"id":"28221b23-1edf-4afd-bf2e-0c681d53ce7d","domain":"ResilientDesign","question":"Which of the following statements about an Amazon SQS standard queue is true?","explanation":"Understand the fundamental differences between Standard and FiFo, and the volume or capacity differences.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html","title":"SQS Standard Queues"}],"answers":[{"id":"3c41b0e4131dbb7da1914721523b42c0","text":"SQS will deliver your message at least once in FIFO order.","correct":false},{"id":"5178787674f59478ee4f9e034cbd5609","text":"SQS will deliver your message at least once, but cannot guarantee that it will not create duplicates of that message.","correct":true},{"id":"dc88f4345d4040dc97b69e420b6710f6","text":"SQS will deliver your message at least once, and guarantees that it will not create duplicates of that message.","correct":false},{"id":"323f27bf40546901f5d6900427b43fdf","text":"SQS will deliver your message at least once, but cannot guarantee the order in which the messages will be delivered.","correct":true}]},{"id":"d4a0aea7-cf85-460c-a913-abe2fd9ed769","domain":"Performant","question":"You need a network interface to connect your Amazon Elastic Compute Cloud (EC2) instances to file systems created with the Amazon Elastic File System (EFS) service. What is the name of this interface?","explanation":"The network interface needed to be created for mounting an EFS file system on an EC2 instance is called a mount target. After the system is mounted, you can work with the files and directories it contains. An Internet gateway is for enabling communication between instances in your VPC and the Internet; it is not for connecting EC2 instances to EFS file systems. Customer gateways are for providing information to AWS about your Customer Gateway Device, which is a software application or physical device on your side of a Site-to-Site VPN connection. An endpoint is the URL of the entry point for the EC2 service, rather than the connection to file systems.","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/accessing-fs.html#create-mount-target-console","title":"Creating Mount Targets"}],"answers":[{"id":"29cc9d1ad76c71d91e4848bfd8dd9458","text":"Mount target","correct":true},{"id":"2a6ba72e93aa7fa676d07973ed2716bb","text":"Endpoint","correct":false},{"id":"4ea1ba703d8df561d96054c53dafcbaf","text":"Customer gateway","correct":false},{"id":"4bfc6473ca81dac7a8a86b539c366c02","text":"Internet gateway","correct":false}]},{"id":"9d65d585-d756-42e0-83bb-d8a7f4c83e82","domain":"ResilientDesign","question":"You need to take a snapshot of an EBS volume.  You are concerned about the volume and instance becoming unavailable until the snapshot is complete.  Which of these statements best describe the facts that will allow you to assess the duration of the outage?","explanation":"in General terms a snapshot has two parts; the snapshot catalogue, and the copy off of the data.  Sometimes called 'the snapshot'.  During the catalogue phase all changed files and blocks are catalogued, locked, and a change log is started.  This is a relatively fast process for most disk file systems and is the only part of the process during which the disk cannot be accessed.  the 2nd phase is the slow part during which the data is copied to the backup system.  The system is not locked during this phase. The actual duration when the system is unavailable is most closely related to how many files or blocks have changed since the last backup as this is the only portion of the data that is relevant to the incremental backup (snapshot).","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"Amazon EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html","title":"Creating an Amazon EBS Snapshot"},{"url":"https://help.acloud.guru/hc/en-us/search?utf8=%E2%9C%93&query=ebs+snapshot","title":"EBS Snapshot KBs"},{"url":"https://aws.amazon.com/blogs/aws/new-lifecycle-management-for-amazon-ebs-snapshots/","title":"New – Lifecycle Management for Amazon EBS Snapshots"}],"answers":[{"id":"c18929ab2ad2fc22f4c285962aaa39c8","text":"The duration of the outage is determined by the number of files on the disk.","correct":false},{"id":"3ac42d808544b4ab0806225881c0e525","text":"The duration of the outage is determined by the number of files changed since the last backup.","correct":true},{"id":"071b64034823256c8ea3bb0048764787","text":"The duration of the outage is only related to the initial cataloguing phase.","correct":true},{"id":"0462d5d8fc0d1947c3ed97376ea2ceba","text":"The duration of the outage is the time it takes to copy all the files from the disk to the backup.","correct":false},{"id":"aae5747a54a5f12a114ff2d92fd668c7","text":"The duration of the outage is determined by the number of files changed since the server was commissioned.","correct":false},{"id":"6e2f1ca114ad32c09d2c423450ab61e5","text":"The duration of the outage is determined by the size of the server.","correct":false},{"id":"26583a3f6db686ba6c478f8ee3badf00","text":"The duration of the outage is determined by the age of the server.","correct":false}]},{"id":"d2453a9d-7b6d-4147-814e-5c4d465f2f39","domain":"ResilientDesign","question":"You are using a classic elastic load balancer for a small website in order to save money. The classic load balancer is deployed in US-EAST-1A and it is supposed to distribute traffic to 3 EC2 instances, each in different Availability Zones. However when you check the logs you notice that only the EC2 instance in US-East-1A is receiving traffic. What could be the cause?","explanation":"For the Classic ELB, cross zone load balancing is a option.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-disable-crosszone-lb.html","title":"Cross-Zone Load Balancing for the ELB"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/how-elastic-load-balancing-works.html","title":"Availability Zones and Load Balancer nodes"},{"url":"https://aws.amazon.com/elasticloadbalancing/features/#Product_comparisons","title":"ELB - product comparison"}],"answers":[{"id":"43aac55ac9817dd52215b223ab1f3f6e","text":"The site is operating on Layer 4 and needs a static IP address, therefore you should upgrade your load balancer to a Network Load Balancer.","correct":false},{"id":"ee179e41685578f3421f0d789bc5081d","text":"You need to enable cross zone load balancing.","correct":true},{"id":"1428d2163a199fd9185cb5abe9a1c7dc","text":"The load balancing algorithm needs content meta-data. You should upgrade the load balancer to an application load balancer in order to get layer 7 visibility.","correct":false},{"id":"615a2767ab662bd6c9d4701ebbb0c212","text":"You need to enable sticky sessions.","correct":false}]},{"id":"b864406d-be60-4f6a-82dc-9160d5585ca0","domain":"SecureSolutions","question":"Your manager has noticed that some members of your team are using the AWS Account Root User to undertake certain tasks.  They have asked you to confirm when is it correct procedure to use the Root User.  Choose from the correct options.","explanation":"You cannot use policies within your account to explicitly deny access to the Root user. However, if an IAM user accidentally revokes their own permissions, you can sign in as the Root user to edit policies and restore those permissions.  All other options are valid uses of the AWS Account Root User.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html","title":"The AWS Account Root User"},{"url":"https://docs.aws.amazon.com/general/latest/gr/aws_tasks-that-require-root.html","title":"AWS Tasks That Require AWS Account Root User Credentials"}],"answers":[{"id":"d0623de1aeb9bae95ad7fd9df219e156","text":"Submitting a Request to perform an external penetration test that isn't a permitted service","correct":true},{"id":"fe713e15c6b90a9c07f22b8fd92d6f70","text":"Using IAM policies to deny Root account access","correct":false},{"id":"e7e875a434ddf25dfe250989b53ca2ce","text":"Move the level of your AWS Support Plan from Business to Enterprise","correct":true},{"id":"767fe082a112680443e319c832c4f06f","text":"Create a CloudFront Key Pair","correct":true},{"id":"5799714fbea5ac62293b5ace786552dd","text":"Closing an AWS Account","correct":true}]},{"id":"952a1ff3-9e44-4ea3-99ba-886bca88a621","domain":"SecureSolutions","question":"You plan to consolidate the two AWS accounts that you currently have so that you can protect them and their resources centrally against common web exploits and attacks. Which of the following combinations of AWS services can do that for you?","explanation":"You need AWS Organizations for consolidating your accounts, so this automatically rules out WAF and Shield as the right answer. While WAF protects your resources against web exploits and AWS Shield protects them against web attacks, neither tool is a centralizing protection service. Rather, it is Firewall Manager that will simplify your WAF and AWS Shield tasks by providing a single point of control. Notably, your AWS accounts being in an organization is one of the prerequisites for using Firewall Manager.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/fms-chapter.html","title":"AWS Firewall Manager"}],"answers":[{"id":"cf658332aeff3680485add6485a734ac","text":"AWS Organizations and AWS Firewall Manager","correct":true},{"id":"8421d513e178656de832265230613532","text":"AWS Web Application Firewall (WAF) and AWS Shield","correct":false},{"id":"886aafc053322ceac05e481b60abf924","text":"AWS Organizations and AWS Shield","correct":false},{"id":"32a8ea3869fee49bca61f4cabbfac398","text":"AWS Organizations and AWS WAF","correct":false}]},{"id":"8dea5b5e-453e-4dda-883d-e390d14a8c83","domain":"ResilientDesign","question":"You have chosen to use S3-RRS with your cloud application. Which limitations have you considered in doing so?","explanation":"The use of RRS is being phased out. In exchange for a significant cost savings, RRS offers only 99.99% durability.","links":[{"url":"https://aws.amazon.com/s3/reduced-redundancy/","title":"About S3-RRS"}],"answers":[{"id":"da6d1d0f493d75bccd625f920a3b8b35","text":"RRS offers only 99.99% durability, so you have to design your application to re-create any objects that may be lost.","correct":true},{"id":"7e2b64603db15867a5b488818ec6d9f3","text":"RRS has a 4-hour data recovery time.","correct":false},{"id":"83091b498f26985700b51b43e93fb462","text":"RRS requires supplementary Access Control Lists.","correct":false},{"id":"07f7d94a1360ae1987207ba589182e55","text":"RRS  is available only in the US-STANDARD region.","correct":false},{"id":"7ae25c780e69aeb7ac28e7b25b79873f","text":"RRS is not recommended for new projects in some AWS regions.","correct":true}]},{"id":"232e5218-23ae-49a3-b865-c44f4aa3c430","domain":"SecureSolutions","question":"You have just created a new IAM role called US-S3-Access using the GUI at \"https://console.aws.amazon.com/iam/home?region=us-east-1#/roles\". This role grants access to the a bucket called ec2-temp-storage254 which was created in the us-east-1 region. One of your colleagues wants their EC2 instance in us-east-2 region to access this bucket - how can this be accomplished","explanation":"IAM is a global service, and therefore objects created in one region are available in all regions. Although S3 buckets are created and stored in a specific region, they are accessible globally - therefore the correct answer is to attach the existing role to the instance - this will grant the instance access to the bucket. There is no need to create a new role, and there is no such setting as multi-region access on roles.","links":[{"url":"https://aws.amazon.com/iam/faqs/","title":"IAM FAQ"}],"answers":[{"id":"057599d3b676dc5e3f4a5284f641c5ca","text":"Create a new role in the us-east-2 region that grants access to the bucket, and attach it to the instance","correct":false},{"id":"dedf1276f190146139ebc76212f15edb","text":"Enable multi-region use for the role, attach it to the instance","correct":false},{"id":"320c9d5e32dfe1dce4ea215892e1d7fe","text":"This cannot be done as the EC2 instance and S3 bucket are in different regions","correct":false},{"id":"1a108ea83cc5a71b33fe8e2455e7fd37","text":"Attach the existing role to the EC2 instance","correct":true}]},{"id":"8d478f70-2e57-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"Your company wants the on-premises network of its nearby branch office to securely connect with the instances launched into the Amazon virtual private cloud (VPC) environment of its headquarters. Which of the following proposed solutions is the correct one?","explanation":"To establish a secure connection between the company’s branch office and the Amazon VPC of its headquarters, you will need to create a site-to-site VPN. This process includes creating a customer gateway for the branch office and a virtual private gateway for the headquarters, so responses A and C only provide part of the answer. Although you can establish a connection with AWS Direct Connect, the connection depends on the headquarters being a Direct Connect location for it to work.","links":[{"url":"https://docs.aws.amazon.com/vpn/latest/s2svpn/how_it_works.html","title":"What is AWS Site-to-Site VPN?"}],"answers":[{"id":"1c83b0f1e61bd1a6e279dfd7f53aa406","text":"Create an AWS site-to-site VPN connection","correct":true},{"id":"db905221240144105178d58376e68624","text":"Create a virtual private gateway and attach it to the headquarters VPC.","correct":false},{"id":"6fc0482bf91e864524eeb8b99b8b1df9","text":"Create a virtual private gateway and a customer gateway and attach them to the headquarters VPC and the branch office on-premises network, respectively.","correct":false},{"id":"572a700c620a728ee9f12b0d7d4601fc","text":"Use AWS Direct Connect to create a connection.","correct":false}]},{"id":"126e898c-dd73-4447-b5a7-59701a16a92d","domain":"ResilientDesign","question":"You are reviewing Change Control requests and you note that there is a proposed change designed to reduce errors due to S3 Eventual Consistency by updating the 'DelaySeconds' attribute. What does this mean?","explanation":"Poor timing of SQS processes can significantly impact the cost effectiveness of the solution.","links":[{"url":"http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"6e5b2857717c8cf5b2722dc270183515","text":"While processing a message, a consumer instance can reset the message visibility by restarting the preset timeout counter.","correct":false},{"id":"4b46d6ad9dd090f0143cc40fecbad7b5","text":"When a new message is added to the SQS queue, it will be hidden from consumer instances for a fixed period.","correct":true},{"id":"464400e5333b3beab1128b1b1f7cedf7","text":"While processing a message, a consumer instance can amend the message visibility counter by a fixed amount.","correct":false},{"id":"f170b98804f18cb00b57e135f0a3f116","text":"When the consumer instance polls for new work, the consumer instance will wait a certain time until it has a full workload before closing the connection.","correct":false}]},{"id":"daa2b1cf-f863-4a75-9b5c-bcd93b27ea18","domain":"Performant","question":"The users of your company's sales lead tracking system are reporting slow response times. Upon investigation, you find that the application's Amazon RDS MySQL database has become memory constrained due to increased transaction volumes. Most of the application's recent activity involves writing new lead records and updating existing lead records. How will you best scale the database to satisfy the increase in business opportunities?","explanation":"You can scale the compute resources for an RDS database by migrating to a larger DB Instance class through the Management Console, the RDS API, or the AWS CLI. RDS currently doesn't support horizontal DB Instance scaling, but Amazon Aurora offers multi-master capabilities. Read Replicas will probably not solve the slow response time issue since most of the application transactions involve write activity. Sharding data across multiple RDS databases will increase operational maintenance.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html","title":"Choosing the DB Instance Class"}],"answers":[{"id":"22072b591b511c34f793b93c492a2a67","text":"Add another compute instance to scale the RDS MySQL cluster horizontally","correct":false},{"id":"9b0d0b1a68e122afa3452e2820fdf2e7","text":"Modify the RDS DB Instance class to vertically scale the primary instance's CPU and memory allocation","correct":true},{"id":"885fbaedd6d0804dc01bca26777afada","text":"Deploy RDS Read Replicas and redirect read transactions to the replicas to offload the primary RDS instance","correct":false},{"id":"d93c105d76b90210dd755f35daf0995b","text":"Create another RDS MySQL database and shard the data between the two databases","correct":false}]},{"id":"f1715a54-ef4a-4912-9093-e8e36698b0c9","domain":"CostOptimized","question":"Your company needs to run several monthly workloads that will each take several hours to complete. Although critical, these workloads can be stopped and restarted without adversely affecting the outcome of the job. Which pricing model would you use to deliver the most economical solution?","explanation":"Spot instances are a cost-effective choice if you can be flexible about when your applications run and if your applications can be interrupted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html","title":"About Spot Instances"}],"answers":[{"id":"026db7f2265667575c05772f32778b8a","text":"Spot Instances","correct":true},{"id":"29068f6044e3fedf44165e646a2d2bb1","text":"Reserved Instances","correct":false},{"id":"de53d38fe38e0fce729f15c292a59891","text":"Free-Tier Instances","correct":false},{"id":"c658c72ec41cc513ad91a3f3e6d2c060","text":"On-demand Instances","correct":false}]},{"id":"487042c6-27f3-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"One of your clients wants an AWS Support plan that provides around-the-clock access to Cloud Support Engineers when needed, as well as access to the seven core Trusted Advisor checks. Which of the following is the most cost-effective choice?","explanation":"Basic Support is included with each AWS account, and it includes access to the seven core Trusted Advisor checks to guide your client in increasing performance and improving security of AWS resources. However, it does not include the around-the-clock access to Cloud Support Engineers for technical assistance. You will need to upgrade your client to the Business Support plan to do so. Indeed, the client will get the full set of Trusted Advisor checks, instead of just the seven core ones. However, it is less expensive than the top-tier Enterprise, which also has those features; thus, the Business plan is the more cost-effective of the two.","links":[{"url":"https://aws.amazon.com/premiumsupport/plans/","title":"AWS Support Plans"}],"answers":[{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":false},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":true}]},{"id":"3f41cb1e-265b-11ea-978f-2e728ce88125","domain":"Performant","question":"You are setting up the properties of an S3 bucket created for storing monthly pie charts. You want to use a template that will serve as the pie chart for the month of January, and for making alterations corresponding with subsequent months. All charts will be stored in the same bucket. Which of the following options should you select to allow that to happen?","explanation":"Enabling the Versioning feature will enable you to keep multiple versions of the pie chart in the S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/enable-versioning.html","title":"Enable Versioning"}],"answers":[{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":true},{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false},{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":false},{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":false}]},{"id":"3252d84d-08d9-4bde-a8e7-d716502d1855","domain":"Performant","question":"You have a very heavily-trafficked WordPress blog that has approximately 95% read traffic and 5% write traffic. You notice that the blog is getting slower and slower. You discover that the bottleneck is in your RDS instance. Which of the following answers can improve your WordPress blog's performance?","explanation":"You should use a combination of Read Replicas and ElastiCache to help offload the traffic.","links":[{"url":"https://aws.amazon.com/elasticache/","title":"About ElastiCache"}],"answers":[{"id":"e94a05a7348f87c7b9c4f7036d632a9c","text":"Use ElastiCache to cache the most commonly read posts of your WordPress blog.","correct":true},{"id":"1af32ee0c62b109e45b92828dbc33f2d","text":"Create a secondary Multi-AZ database and run the queries off the secondary Multi-AZ database.","correct":false},{"id":"fdc556bb3ab9b5da3b290c181aaefb3c","text":"Create a number of read replicas and update the connection string on your EC2 instances so that traffic is evenly shared amongst these new RDS instances.","correct":true},{"id":"1c551a09129057627b3b75fb70e6f527","text":"Export the database to DynamoDB which has push button scalability.","correct":false}]},{"id":"f30c65af-6476-4a69-87ac-1e8e1bf69df8","domain":"ResilientDesign","question":"A company's SOC is implementing a system to perform real-time analysis of CloudTrail logs to enhance their security. What option would enable them to receive logs from CloudTrail in real-time in the most optimal way?","explanation":"CloudTrail can be configured to send notifications to an SNS topic. SQS Queue can be configured to subscribe to the SNS topic so that messages can be processed programmatically. S3 notifications do not have ability to send messages to Kinesis Streams, so this is not a valid option. Likewise, CloudTrail does not have ability to send notification to Kinesis Streams. Using CloudWatch Events rules as a trigger is not an operationally optimal solution since CloudTrail has native notification capability.","links":[{"url":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/configure-sns-notifications-for-cloudtrail.html","title":"Configuring Amazon SNS Notifications for CloudTrail"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-subscribe-queue-sns-topic.html","title":"Tutorial: Subscribing an Amazon SQS Queue to an Amazon SNS Topic"}],"answers":[{"id":"cd0e5b49f050ae2342a147f66f2a9f10","text":"Configure CloudWatch Events rule that is triggered when new logs are written to CloudTrail. Implement a Lambda function to analyse the event. Configure the Lambda function as the CloudWatch Event target.","correct":false},{"id":"f9aeb59c8eacbc153e39c069dbe71d3a","text":"Create a Kinesis Stream. Configure the CloudTrail trail to send notifications to the Kinesis Stream. Use Kinesis Data Analytics to perform analysis on the data.","correct":false},{"id":"ac8b34a41e5e43b017a506c82a4ad0b5","text":"Create an SNS Topic. Configure the CloudTrail trail to send notifications to the SNS Topic. Configure SQS Queue to subscribe to the SNS Topic.","correct":true},{"id":"074f8c98d1aa39441f8f17d8ea7f72d5","text":"Create a Kinesis Stream. Configure the CloudTrail S3 bucket notifications with the Kinesis stream as the message destination. Implement a Lambda function to process messages from the Kinesis Stream.","correct":false}]},{"id":"7dd78d8f-4ef3-4d55-941a-c6e865c5ab7c","domain":"Performant","question":"Using the AWS Server Migration Service, what's the maximum number of volumes that can be attached to a VMs during a SMS migration job?","explanation":"At this writing, a VM can only have 22 virtual volumes during the SMS replication job.","links":[{"url":"https://aws.amazon.com/server-migration-service/faqs/","title":"AWS Server Migration Service - FAQ"},{"url":"https://docs.aws.amazon.com/server-migration-service/latest/userguide/prereqs.html","title":"AWS Server Migration Service - limits"}],"answers":[{"id":"6364d3f0f495b6ab9dcf8d3b5c6e0b01","text":"32","correct":false},{"id":"c74d97b01eae257e44aa9d5bade97baf","text":"16","correct":false},{"id":"0cae09dcea866a75f21e4e0d07a2ebc5","text":"only limited by the OS","correct":false},{"id":"b6d767d2f8ed5d21a44b0e5886680cb9","text":"22","correct":true}]},{"id":"2a2db64e-2e02-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You wish to set up a WordPress website consisting of 4 webpages for your client, who recently founded a logo creation business. Based on the client’s specifications, you will create one webpage that gives a summary of the company and its services, a second one that provides a brief professional biography of the founder, a third one that showcases the business owner’s portfolio, and a fourth one that serves as the contact information page and simply contains an email and phone number. Three of the four webpages will include images which the client doesn’t expect will change much, if at all. Using the EC2 service to set up the website, which of the following instance types would be the most cost-effective choice?","explanation":"Based on the client’s specifications, it doesn’t seem like this website requires an elevated level of compute, memory, storage, or networking power. So, a general purpose instance would be the most cost-effective choice.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types"}],"answers":[{"id":"3da02f3f7a678b5e2c167fb35dcea8f5","text":"General purpose","correct":true},{"id":"4e8e31d149d66214d0c06fd9ee8b877b","text":"Compute optimized","correct":false},{"id":"b4820282379b9534539d339e1d898f2b","text":"Storage optimized","correct":false},{"id":"e65781ecdb4e2c3e7af2864d7b875e57","text":"Accelerated computing","correct":false},{"id":"a97bdc2a34beb1500a16c5a5f41d3234","text":"Memory optimized","correct":false}]},{"id":"db72323e-0c43-4542-9f6b-cd6136b5dcd8","domain":"ResilientDesign","question":"You have a production website for a car insurance company running on AWS. One of the important KPI’s for the company is the number of users on the website at any given time and you have been asked to track this. The website runs on a fleet of EC2 instances behind an application load balancer. What is the simplest way to track this metric.","explanation":"Be clear in yor own mind about the difference between CloudWatch & CloudTrail. An ELB is a service, you cannot install anything onto an ELB.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-cloudwatch-metrics.html","title":"CloudWatch Metrics for your ALB"}],"answers":[{"id":"0ea85fc826488c41b0f86072ac7fd0ad","text":"Install the CloudTrail agent on the Application Load Balancer. In CloudTrail look for the “ActiveConnectionCount” metric.","correct":false},{"id":"dd97365a376f41ec276427520159fbd4","text":"Install the CloudWatch agent on the Application Load Balancer. After the agent is installed, look for the “ActiveConnectionCount” in CloudWatch.","correct":false},{"id":"1056f30813bb025d216b87a2fdd790d9","text":"Enable CloudTrail in the region that your ALB is in. Using CloudTrail metrics look for the “ActiveConnectionCount” metric.","correct":false},{"id":"98c71b3c230ff081ea967bf92fad4707","text":"In CloudWatch metrics look for the “ActiveConnectionCount”","correct":true}]},{"id":"89d134f1-d269-43a5-b281-7103503d6fda","domain":"ResilientDesign","question":"You have been creating a number of EBS volumes for your EC2 instances. Your company has asked that you to ensure these EBS volumes are available in the event of a disaster. What can be done to help accomplish this?","explanation":"You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots. Snapshots are constrained to the Region in which they were created. To share a snapshot with another Region, copy the snapshot to that Region.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"Amazon EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modifying-snapshot-permissions.html","title":"Sharing an Amazon EBS Snapshot"}],"answers":[{"id":"2a6b8582b314574632c267c828b5b80b","text":"Ensure Snapshots are made available in another region.","correct":false},{"id":"c7b84d21fb27659b1379dae03375ac7c","text":"Ensure Snapshots are made available in another Availability Zone.","correct":false},{"id":"d74765a9c34b22db50cadcb7e20ce91c","text":"Create Snapshots of the EBS volumes.","correct":true},{"id":"d14f5bb7ac86c400a8c1a96b61346194","text":"Configure Amazon Storage Gateway with the source being the EBS volumes, then store the backups on premise.","correct":false}]},{"id":"9ddc17c5-4849-4869-b79f-a7e2b6630be1","domain":"Performant","question":"Which AWS service should you use to host MySQL, MariaDB, Oracle, SQL Server, or PostgreSQL database where you do not need to manage the underlying operating system?","explanation":"Amazon RDS is available on several database instance types - optimized for memory, performance or I/O - and provides you with six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle, and Microsoft SQL Server.","links":[{"url":"https://aws.amazon.com/rds/","title":"AWS RDS: Available Engines"}],"answers":[{"id":"1574cf43006500eb74cc583eef4a8b87","text":"EC2 with EBS","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true},{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false}]},{"id":"aaff9d18-ee89-4f46-8b06-36cacf10c72d","domain":"SecureSolutions","question":"A regional telecommunications company requires that applications be isolated from each other on their AWS cloud network in order to minimize the impact of a security issue in any one of the applications. The applications must be able to exchange data with each other, and they need to be able to communicate with two company-owned data centers. Which architecture will accomplish these requirements in the most secure and operationally efficient way?","explanation":"Direct Connect offers greater security than a VPN because it doesn’t involve an Internet connection. Creating separate VPCs provides greater isolation and greater operational efficiency because Network ACL firewall rules don’t need to be maintained every time the characteristics of application-to-application communication change.","links":[{"url":"https://aws.amazon.com/answers/networking/aws-single-region-multi-vpc-connectivity/","title":"Single Region Multi-VPC Connectivity"}],"answers":[{"id":"a89251b806fbe05bdcf7d40074d812cc","text":"Place each application in separate subnets in a single VPC and lock down Network ACL rules on each subnet. Use Direct Connect from this same VPC to the company-owned data centers","correct":false},{"id":"03f6fa016703ef26250435d21e5558d8","text":"Create individual VPCs for each application with peering connections between them. Create a shared VPC with IPSec VPNs to the company-owned data centers","correct":false},{"id":"d8d115b0f357da698c35adf6751c3468","text":"Place each application in separate subnets in a single VPC and lock down Network ACL rules on each subnet. Use IPSec VPNs from this same VPC to the company-owned data centers","correct":false},{"id":"ddad117753774711835e99bfacdb8c83","text":"Create individual VPCs for each application with peering connections between them. Create a shared VPC with Direct Connect to the company-owned data centers","correct":true}]},{"id":"d759f777-8830-47ae-ac99-038049debd8c","domain":"SecureSolutions","question":"As a solutions architect, you notice that one of the IAM roles in your company's AWS account has not been used for a year. What's the recommended course of action?","explanation":"If a role has not been in use for a very long time, it's best to delete it and its associated permissions as a security measure. However, you must make sure that there are no EC2 instances running with the role you are about to delete. Removing a role from a running EC2 instance linked to it will break any applications running on the instance.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_manage_delete.html","title":"Deleting Roles or Instance Profiles"}],"answers":[{"id":"191a23ce196611912881e94971f9a19e","text":"Check for any Amazon EC2 instances running with the role. If there are none, delete the role and its associated permissions.","correct":true},{"id":"49113178e5bef494be62b3a0ca9d622b","text":"Delete the role and its associated permissions.","correct":false},{"id":"47865d465f7ee9291a6a7955bb192b38","text":"Continue to monitor activity associated with the role.","correct":false},{"id":"e478f7c2a4052004cfe4e32a8d71c106","text":"Leave the role alone; you never know when you might need it.","correct":false}]},{"id":"5c841746-5aea-4a32-8a87-65b78fb0184b","domain":"ResilientDesign","question":"You want to use an AWS service that can monitor your EC2 instances and automatically recover it if it becomes impaired. Which of the following automation tools will enable you to do so?","explanation":"Using a CloudWatch alarm, you can monitor your EC2 instance and automatically recover it if it becomes impaired. Elastic Beanstalk is for deploying and managing web applications, Auto Scaling is for automatically scaling your resources up or down, and Lambda can be set up to automatically execute a function on a regular schedule. None of these tools, however, are used for auto EC2 recovery.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html","title":"Recover Your Instance"}],"answers":[{"id":"dee7ff8f7b10b9d388c7c561e9413b0d","text":"AWS Lambda","correct":false},{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":true},{"id":"afd14eb3f151c84e6ef7ab63812b4fbc","text":"Auto Scaling","correct":false},{"id":"bcf6eb183b7da148701bcc059a34675f","text":"AWS Elastic Beanstalk","correct":false}]},{"id":"43fc02ed-4b66-416e-affa-8cfa3643bfd6","domain":"SecureSolutions","question":"To simplify your environment configuration how should you manage access from EC2 instances to AWS services?","explanation":"Access keys should *never* be stored on an AMI or in plain text anywhere.  Roles are specifically designed to abstract the Keys away from front line services reducing the risk of exposure, and allowing secure and non-impacting Key management.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html","title":"IAM Best Practices"},{"url":"https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html","title":"BBest Practices for Managing AWS Access Keys"}],"answers":[{"id":"fca203d4e929e309ed060a778ff1f1aa","text":"Create service accounts and embed the Keys for these accounts in the AMIs.","correct":false},{"id":"19543199cf399870f8acf4b311ac0435","text":"Build one or two Roles with high levels of access each, and assign to the EC2 instances according to the team managing them.","correct":false},{"id":"11f52231435fc56bb21e9a4b5a11bd39","text":"Create service accounts and store the Keys in an encrypted S3 and access them programmatically.","correct":false},{"id":"364e7e3be5971c70b948d12c536dafe1","text":"Build multiple Roles with minimal viable access each, and assign them to the EC2 launch configurations according to their function.","correct":true}]},{"id":"6e46373a-f81d-4469-8ad0-7251ab8aedc8","domain":"Performant","question":"You have an active NoSQL database which is hosted in DynamoDB. The DynamoDB table is queried by a Lambda function which is responding to requests made by individual users via API-Gateway. Your application peaks at 4pm each day with literally 100,000’s of requests per second. During this time your application becomes sluggish. Which step below may help to improve your applications performance.","explanation":"DAX is an obvious solution if the queries are hitting the same data frequently and the total set of re-read data does not exceed the size of the DAX. Re platforming is possible but will add complication. The Aurora answer refers to the 'cluster endpoint'. This would focus all traffic on the single Write node not the multiple Read replicas.","links":[{"url":"https://aws.amazon.com/dynamodb/dax/","title":"DynamoDB Accelerator (DAX)"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Overview.Endpoints.Types","title":"Types of Aurora Endpoints"}],"answers":[{"id":"8966ac7acedbe0ee7b1f05790a1cf747","text":"Enable DynamoDB Accelerator to deliver an in memory cache to increase performance.","correct":true},{"id":"cfa63e0907a36062a7762af5c7808fb7","text":"Migrate the database from DynamoDB to Amazon Aurora and provision 15 read replicas. Update the application to send all read traffic to the cluster endpoint.","correct":false},{"id":"5b96dd7f94ff3a1e6a339b7d4bfc8322","text":"Re-architect the application to use a Network Load Balancer and a 3 EC2 instances in 3 different Availability Zones.","correct":false},{"id":"8b119eee795f3c32a2d1f9ebff37bae9","text":"Host the web front end on S3 using static website hosting. Use a combination of CloudFront and Elasticache to help distribute the load.","correct":false}]},{"id":"2bf99c9d-4fc2-409d-b791-c6c4a0768549","domain":"Performant","question":"Which of the following are true about Amazon S3 - OneZone-IA?","explanation":"S3 - OneZone-IA enables customers to reduce their costs by storing non-critical, reproducible data at lower levels of availability than Amazon S3’s standard storage.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/?nc=sn&loc=3","title":"S3 - Storage Classes Overview"}],"answers":[{"id":"dc2b74cf19d83fee510b2c972d70db9a","text":"S3 - OneZone-IA is designed for 99.999999999% durability.","correct":true},{"id":"ddd83209deb4bf5fdc24d22fb5e12c3c","text":"S3 - OneZone-IA is most often used with objects that are easy to re-create.","correct":true},{"id":"d18f42bdcdbac2b13beeadb7f15654a6","text":"S3 - OneZone-IA is designed for 99.50% availability.","correct":true},{"id":"d1a5624e6fbe325e3889a95a62c96184","text":"S3 - OneZone-IA is designed for 99.90% availability.","correct":false},{"id":"80e69120164bdeae440ac4a4af1b973d","text":"S3 - OneZone-IA is designed for 99.99% durability","correct":false}]},{"id":"cc769fff-7738-4265-93c0-a92d5c113bcd","domain":"ResilientDesign","question":"You are a solutions architect working for a company that conducts surveys on specific industries. Each industry that you survey has its own EC2 fleet, separate from those of other industries. Company policy dictates that you should keep costs to a minimum, using only 1 load balancer, if possible. What type of load balancer should you use to suit this requirement?","explanation":"You need an application-aware load balancer, so your best option would be to use an Application Load Balancer.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html","title":"Application Load Balancer - Overview"}],"answers":[{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false},{"id":"6bee0fa60aa90f436c7e97e3621b8e15","text":"Elastic Load Balancer with IDS","correct":false},{"id":"d7d91b002fbcf2615a58bba06d7028eb","text":"Elastic Load Balancer with IPS","correct":false},{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":true}]},{"id":"b3e0d6fc-310d-4245-b634-5783129ea33a","domain":"Performant","question":"Your large scientific organization needs to use a fleet of EC2 instances to perform high-performance, CPU-intensive calculations. Your boss asks you to choose an instance type that would best suit the needs of your organization. Which of the following instance types should you recommend?","explanation":"C-class instances are recommended for high-performance front-end fleets, web servers, batch processing, distributed analytics, high performance science and engineering applications, ad serving, MMO gaming, and video-encoding. The best answer would be to use a C4 instance.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types - Compute Optimized"}],"answers":[{"id":"b713e6323a68d3ddabf4855826c50148","text":"C4","correct":true},{"id":"c4d62b6dcca08e5caf06c01889282859","text":"D2","correct":false},{"id":"5c108ce0fe89d0632cfce75f650b36c2","text":"R3","correct":false},{"id":"f1c6eb6f4e48eb34ab40b2987d4976a8","text":"M3","correct":false}]},{"id":"70abc519-13c2-4878-a92d-1f900d5d34bf","domain":"SecureSolutions","question":"You have a multi-tier application with each tier in a separate subnet. The application server is in Subnet1 which needs to connect with a MySQL RDS DB instance in Subnet2. Each subnet has its own NACL: NACL1 (Subnet1), NACL2 (Subnet2). How should these NACLs be configured to allow communication between your app servers and the back-end database in the most secure fashion?","explanation":"Since NACLs are stateless, you need to define the connectivity rules for both Inbound and Outbound traffic. Since the EC2 Application server initiates the connection to the DB server an Outbound rule is required on MySQL Port to Subnet2, and an Inbound rule is required on the ephemeral ports (1024 - 65535) to accommodate the response traffic. The reverse settings are then required for the NACL assigned to the DB subnet. Entries that do not have inbound and outbound rules defined in each NACL are incorrect and the other answer would fail as it assumes the connection is established by the DB instance.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"83ad7d3c5441dc555087558f4c399889","text":"NACL1 - Outbound: Allow MySQL Port 3306 To Subnet2 CIDR \\n NACL2 - Inbound: Allow MySQL Port 3306 From Subnet1 CIDR","correct":false},{"id":"4bd6d783cff055f4697a7428bf873467","text":"NACL1 - Inbound: Allow MySQL Port 3306 From Subnet2 CIDR \\n NACL1 - Outbound: Allow Ephemeral Ports 1024 - 65535 To Subnet2 CIDR \\n NACL2 - Inbound: Allow Ephemeral Ports 1024 - 65535 From Subnet1 CIDR \\n NACL2 - Outbound: Allow MySQL Port 3306 To Subnet1 CIDR","correct":false},{"id":"fd62ee6f8cf88749a1466c60e1763061","text":"NACL1 - Inbound: Allow MySQL Port 3306 From Subnet2 CIDR \\n NACL2 - Outbound: Allow MySQL Port 3306 To Subnet1 CIDR","correct":false},{"id":"1cd158c1b99fd66989e3b5708242c5ef","text":"NACL1 - Inbound: Allow Ephemeral Ports 1024 - 65535 From Subnet2 CIDR \\n NACL1 - Outbound: Allow MySQL Port 3306 To Subnet2 CIDR \\n NACL2 - Inbound: Allow MySQL Port 3306 From Subnet1 CIDR \\n NACL2 - Outbound: Allow Ephemeral Ports 1024 - 65535 To Subnet1 CIDR","correct":true}]},{"id":"5b52d388-382c-4f3c-9d9d-0e15d2c4dccd","domain":"CostOptimized","question":"You have a static HTML website that requires inexpensive, highly available hosting solution that scales automatically to meet traffic demands. Which AWS service would best suit this requirement?","explanation":"S3 Static Website Hosting offers the best solution here: it is highly-available, scales automatically, and is cost-effective.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Static Website Hosting"}],"answers":[{"id":"b0bca3ada773197571a3697e029cdfc4","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 1 instance","correct":false},{"id":"a98f92c3d9a3073bdf1d35f748a53342","text":"S3 - Static Website Hosting","correct":true},{"id":"7e247cebfa4700e9281d3e30ac07ac70","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 2 instances","correct":false},{"id":"b812d3912dbd32666e0d2865e0ee9d19","text":"EC2 with CloudFront","correct":false}]},{"id":"e9205ab6-d7ce-4708-b92d-e6814f79c6d4","domain":"ResilientDesign","question":"The dashboard application for multiple company contact centers requires fast update response times for a large number of concurrent users. Call center metric data is stored in an Oracle version 11 database. Which architecture will provide high-availability and the low response times needed for this mission-critical data?","explanation":"Since the dashboard updates are needed across multiple contact centers, leveraging read-only replicated databases will provide fast response times. Amazon RDS doesn’t support read replicas for Oracle version 11, so hosting the database on EC2 and replicating the data with Oracle Data Guard is the only viable solution. AWS Database Replication Service is not an offered service, and using EBS snapshots won't provide real-time replication.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/oracle-database/overview.html","title":"Oracle Database on AWS"}],"answers":[{"id":"0129ed97e5c2ec017bdc05d836f10049","text":"Oracle hosted on Amazon EC2 in multiple Availability Zones with Oracle Data Guard replication","correct":true},{"id":"c1e824f46134bc6696eba635f30df032","text":"An Amazon RDS Oracle instance with Multi-AZ and Read Replicas","correct":false},{"id":"5ee29b50026caa8c20c9e469f93b5a2a","text":"Oracle hosted on Amazon EC2 in Multiple Availability Zones with EBS snapshots","correct":false},{"id":"de5ad68debdabd478d7d4f66542b9ca8","text":"An Amazon RDS Oracle Instance with AWS Database Replication Service","correct":false}]},{"id":"4529a700-0c98-4d1e-a64a-fe1543c8bcdd","domain":"SecureSolutions","question":"You have a 3-tier application that you want to deploy into AWS - this application is accessed by users around the world over the Internet.  The design calls for an Application Load Balancer, EC2 Instances for the application software and another set of EC2 Instances to run the custom relational database system for the application. Also, periodically you want the instances to be able to download updates from the internet, via an already-deployed NAT gateway & Internet Gateway in the public subnet. Which of the below deployments would you recommend, keeping in mind that you want to keep costs and complexity to a minimum? ","explanation":"Placing the ALB in a private subnet would generally make it inaccessible to users outside your organization, so these two options can be discounted. Of the remaining two options, although both could work in theory, one has you deploying the application servers into the same public subnet as the ALB - this would mean having to attach a public IP to them in order to allow them to download updates, or using some custom routing at the OS which increases complexity. The recommended architecture is to deploy the ALB into the public subnet, and the application & database tiers into different private subnets.","links":[],"answers":[{"id":"f8d132549046a020830a21bd5dad78ee","text":"Place the ALB in a public subnet inside the VPC. Deploy the application EC2 instances into a private subnet, and the EC2 instances required for the database into a different private subnet","correct":true},{"id":"918887f1baa6a0485499321635ed99c9","text":"Place the ALB in a public subnet inside the VPC. Deploy the application EC2 instances into the same public subnet, and the EC2 instances required for the database into a private subnet","correct":false},{"id":"187ce2fdaf78304235d6899a3a1049e7","text":"Place the ALB in a private subnet inside the VPC. Deploy the application EC2 instances into a different private subnet, and the EC2 instances required for the database into a the same subnet as the application instances","correct":false},{"id":"afa56b5db37a4928a03e39cab6650e6e","text":"Place the ALB in a private subnet inside the VPC. Deploy the application EC2 instances into the same private subnet, and the EC2 instances required for the database into a different private subnet","correct":false}]},{"id":"922ca882-d73b-4685-acf4-7c0827021c2b","domain":"ResilientDesign","question":"The customer service organization at your company just told you that a client purchase from your website was processed twice. Your order process involves EC2 instances processing messages from an SQS queue. What changes might you make to ensure this does not happen again?","explanation":"An SWF workflow ensures that actions are executed only once.","links":[{"url":"https://aws.amazon.com/documentation/swf/","title":"SWF Documentation"}],"answers":[{"id":"bacf185330f80f745f66f02bab85053a","text":"Manually delete the order after processing.","correct":false},{"id":"da3af33124cb0627efe41ca5c7617ddf","text":"Increase the visibility timeout on the SQS queue.","correct":false},{"id":"24e1d12f9d1b3de53719bbd5341fbdf1","text":"Rewrite the order-processing workflow to use SWF, rather than SQS.","correct":true},{"id":"ae73003f30fc75b349d6c7e1407060ca","text":"Switch to long-polling.","correct":false}]},{"id":"2466b024-1f81-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"You work as a website administrator at a real estate developer. The company’s website uses S3 to store pictures of the single-family homes it builds. The company recently released a brand-new elevation for one of its most popular models, which is called 'Greenberry C.' So far, there’s only one picture of the 'Greenberry C', so you want to ensure that it is not accidentally deleted by enabling the object lock feature. Which of the following actions will accomplish that?","explanation":"Amazon S3 object lock prevents an object from being deleted or overwritten. Object lock is enabled at the bucket level; when creating the bucket, you can select the feature to lock objects in it. However, once the bucket has been created, you cannot enable object lock, you will have to contact customer support to do so. Right-click is not a valid option - you must select the object then go to Properties, Object lock.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/object-lock.html","title":"How Do I Lock an Amazon S3 Bucket?"}],"answers":[{"id":"84bd7d36c453cdfc1f04955deb54c376","text":"Enable object lock at the bucket level.","correct":true},{"id":"a92ccdd56e18b47fbb5d18c2c342ca6f","text":"Right-click the picture and choose the object lock option.","correct":false},{"id":"2c6b543047434bd3ad31060693bc8e5b","text":"Enable object lock at the object level.","correct":false},{"id":"49cd0706698c83f66fe5b9deb203a420","text":"Contact customer support.","correct":true}]},{"id":"680c52c8-07f9-4f32-9cdb-ede2e267faa6","domain":"ResilientDesign","question":"Your organisation is planning on storing mission-critical data in Redshift. This data has high value and is frequently used for business decisions, so management has decided that a 99.999% availability SLA is needed. How would you achieve this with RedShift?.","explanation":"RedShift does not currently support Multi-AZ or Multi-Region deployments, so neither of these are valid options, and with an SLA of 99.9% neither is not doing anything extra. AWS recommends running multiple clusters when true high availability is required, and making sure they are kept in sync. Note that there no automated synchronisation options for RedShift clusters, and this must be handled outside of RedSift (e.g. with Kinesis)","links":[{"url":"https://aws.amazon.com/redshift/sla/","title":"RedShift SLA"},{"url":"https://aws.amazon.com/redshift/faqs/","title":"RedShift FAQ"},{"url":"https://aws.amazon.com/blogs/big-data/building-multi-az-or-multi-region-amazon-redshift-clusters/","title":"Building Multi-AZ or Multi-Region Amazon Redshift Clusters"}],"answers":[{"id":"aebe0fe52f1dc1589726d832f1ec5d97","text":"Use a Multi-AZ Redshift Cluster","correct":false},{"id":"d675283647d42878fe1f19b1b2789e1f","text":"Use a Multi-Region Redshift Cluster","correct":false},{"id":"77d03cf39a714f11e72a87578d5f20e0","text":"This level of SLA is built into RedShift so there is no need to do anything extra.","correct":false},{"id":"0e3881a1bf5e96676203a9fc439bd048","text":"Deploy a second RedShift Cluster in another AZ and ensure all writes happen to both clusters","correct":true}]},{"id":"e768ecaa-8e40-4cd8-b6ae-9a344d560c70","domain":"CostOptimized","question":"An organization which runs critical services in AWS has a requirement to store backups in another account.  One application uses S3 as its back-end data store.  The backups should be as automated as possible but resilient and cost-effective.  How would you satisfy backup requirements for this application's S3 objects?","explanation":"The organization requires that backups are held in a separate accounts which means replication cannot be within the same account.  The backups must also be highly-resilient and cost-effective which means One Zone-IA is less desirable (the backups would only be stored in one Availability Zone for that region). Infrequently Accessed is the best storage type to fit these needs.  Lastly since the solution needs to be as automated as possible, it makes sense to use the build-in replication features of S3 rather than coding a custom Lambda function.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-walkthrough-2.html","title":"Configuring Replication When the Source and Destination Buckets Are Owned by Different Accounts"},{"url":"https://aws.amazon.com/s3/storage-classes/","title":"Amazon S3 Storage Classes"}],"answers":[{"id":"e2bbecb893a3a44ba253e47129c3119d","text":"Configure S3 events in the source bucket to trigger same-account copies using Lambda into the backup account to S3 Infrequently Accessed","correct":false},{"id":"1ae32621b4651accf109c1736e5feac1","text":"Configure S3 events in the source bucket to trigger cross-account copies using Lambda into the backup account to S3 Standard Storage","correct":false},{"id":"1cd85e1edc45929e969cd3f8a2469253","text":"Configure cross-account replication and configure the storage class for the replicated objects as S3 Infrequently Accessed","correct":true},{"id":"3c441e2bfc7b0c5824eb8df8bbf8373b","text":"Configure cross-account replication and configure the storage class for the replicated objects as S3 Standard Storage","correct":false},{"id":"686edabc75287b4e419ece13f6eb6c64","text":"Configure cross-account replication and configure the storage class for the replicated objects as S3 One Zone-IA","correct":false}]},{"id":"00be4bb5-a556-48d8-a95c-cac6852e76ba","domain":"CostOptimized","question":"You are operating a popular TV Show news website using a static site generator (SSG) with the resulting HTML pages being served from S3. The vast majority of pages are less than 85 KB in size. After 60 days, new episode page access drops off significantly. Which of the following statements are true?","explanation":"Similar to the STANDARD storage class, STANDARD_IA objects are available for millisecond access.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html","title":"Storage Classes"}],"answers":[{"id":"b84620799ba94f53d53c1aa19f69bb8a","text":"While objects in the STANDARD storage class are available for millisecond access, accessing STANDARD_IA objects is slightly slower.","correct":false},{"id":"ff55b529dbaaea1355acdc097ad29298","text":"The ONEZONE_IA storage class is as durable as STANDARD_IA, but it is less available and less resilient.","correct":true},{"id":"0c8d66b9d1503b991d171f09f8943ee1","text":"Using the STANDARD_IA storage class, these older pages are stored redundantly across 3 or more geographically separated facilities.","correct":true},{"id":"a32b993ff0fa61fd0da4533f7fc8f1be","text":"Using the STANDARD_IA storage class, Amazon S3 charges you for 128 KB per object if it is less than 128 KB in size.","correct":true}]},{"id":"912352c0-d2a0-4e7c-89cd-d4ee66445744","domain":"CostOptimized","question":"You have been asked to design a scalable solution for a simple customer service survey that is shown online after each of the ~10 million chat bot interactions per month: Emoticons for 3 rating options ('positive', 'neutral' and 'negative') are to be presented with the expectation that about 10% of users submit their feedback. The bot is public facing and operates 24x7. Select a feasible and most cost effective solution.","explanation":"RDS alone is more expensive than any of the serverless solutions and therefore not an option here. Because of this use case's simplicity (i.e. no request validation, rate limiting, authentication/authorization, etc. required), there is essentially no need for a Lambda fronting API Gateway. Given the described requirements (load and availability), an ALB is more expensive as it's billed hourly.","links":[{"url":"https://serverless-training.com/articles/save-money-by-replacing-api-gateway-with-application-load-balancer/","title":"Saving Money By Replacing API Gateway With Application Load Balancers Lambda Integration"},{"url":"https://aws.amazon.com/blogs/networking-and-content-delivery/lambda-functions-as-targets-for-application-load-balancers","title":"Lambda functions as targets for Application Load Balancers"},{"url":"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/browser-invoke-lambda-function-example.html","title":"Invoking a Lambda Function in a Browser Script"}],"answers":[{"id":"39329c7ee88152a625a8d565e6b38f36","text":"You front your Lambda that writes the ratings to a DynamoDB table with an ALB.","correct":false},{"id":"b63327b72ecc6921a7e43eb0f786a3fe","text":"You invoke a Lambda function on demand in a browser script using the AWS SDK for JavaScript. For that to work you will need to create an Amazon Cognito identity pool with access enabled for unauthenticated identities and include the identity pool ID in your code to obtain credentials for the browser script. The function writes the submitted rating value to a DynamoDB table.","correct":true},{"id":"909f43a37c73caa5e0c764e4d8d8201c","text":"Given the expected load, you are better off with an Elastic Beanstalk app and RDS such as PostgreSQL or MySQL","correct":false},{"id":"852949aded12102365acbeb1052394f9","text":"You develop a proper API and use an API Gateway, Lambda and DynamoDB solution","correct":false}]},{"id":"f354dcdd-8250-4f18-a666-c1da3a174154","domain":"ResilientDesign","question":"You are configuring your application load balancer to enable users to access your application, which is in a staging environment and only has a private IP address. Which of the following schemes will enable this type of access?","explanation":"When configuring load balancers, you get two scheme choices, which are internet-facing and internal. If the users were to access the application through the Internet, then internet-facing would be the correct answer. Internal load balancing is right in this instance because the internal scheme choice will create an internal load balancer for routing requests from the users to the application with the private IP address.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-internal-load-balancers.html","title":"Internal Classic Load Balancers"}],"answers":[{"id":"e82fcc3d0c37dcaf93bb7b620da3c563","text":"Internet-facing","correct":false},{"id":"afbf0897a5a83fdd873dfb032ec695d3","text":"Internal","correct":true},{"id":"ef85538ce0d687a7f414634e39f842dc","text":"User-facing","correct":false},{"id":"b206a1b4ea1097761f78e8876f6da779","text":"External","correct":false}]},{"id":"b8be7547-0f55-4f09-addd-11907477196e","domain":"CostOptimized","question":"You have a one-year contract with a client to create and maintain its cloud environment with an AWS account, with the awareness that each AWS service and resource used has a 12-month free usage term. When that 12-month term expires, which of the following happens?","explanation":"After the 12-month free usage term expires for an AWS service, you will start paying the standard, pay-as-you-go service rates. There are no reduced rates, extensions from AWS Support, or automatic renewals of the 12-month term.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc","title":"AWS Free Tier"}],"answers":[{"id":"233245ebe184276bbec368b4fd80f067","text":"You will pay standard, pay-as-you-go service rates.","correct":true},{"id":"cb548d5d972e20059df43a3c680b32b5","text":"AWS Support will extend the free usage term to another 12 months upon request.","correct":false},{"id":"674c02a2df56483f7902847e2dbb8cd8","text":"The free usage term will be automatically renewed for another 12 months.","correct":false},{"id":"a0cdfc4210cbbb0f723b10fafa2c6120","text":"You will pay a fee that is reduced from the full pricing.","correct":false}]},{"id":"5d18ab25-729c-46ea-aa11-66386391c0cd","domain":"SecureSolutions","question":"One of your junior developers needs access to an Elastic Load Balancer in your custom VPC. This is the first and only time he will need access to AWS services. Which of the following choices is the most secure way to grant this access?","explanation":"It's always best practice to grant users access via IAM roles and groups. In this case, there's no sense in adding him to a group that may have more permissions than he requires to do his job. Add an individual user with the minimum permissions required.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html","title":"Creating an IAM User"}],"answers":[{"id":"5b7444663d6c0d306878b7c2959e8297","text":"Create a new IAM user with only the required credentials.","correct":true},{"id":"625d4a006020f25fe043418f2e83fab2","text":"Add that developer to a Group with the requisite access.","correct":false},{"id":"80e0b9e929eb83fd3841f5b6395082f3","text":"Let them log in with Admin credentials and change the Admin password when he is finished.","correct":false},{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false}]},{"id":"86bc5815-e2a2-435d-b36a-de0291f03384","domain":"ResilientDesign","question":"A company disaster recovery policy requires that all RDS backups are retained in a secondary AWS region. What is the optimal solution to meet this requirement?","explanation":"RDS automated backups store backup data in the same region as the RDS instance. It is not possible to configure RDS automated backups to store data in a different region. The correct solution to meet the requirement is to copy RDS snapshots to the secondary region. It is not possible to copy RDS DB snapshots to an S3 bucket. Although it is possible to configure an RDS read-replica with automated backups in the secondary region, this is not an optimal solution as it involves additional costs associated with the running RDS instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html","title":"Working With Backups"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html","title":"Creating a DB Snapshot"}],"answers":[{"id":"0ffef8639c8e9a75fa845bb6e9e6488b","text":"Configure RDS Read-Replica instance in the secondary region. Enable RDS automated backups on the read-replica instance.","correct":false},{"id":"6cb16d4a90eb4167d69dad6d62a4afa0","text":"Create an RDS DB snapshot. Copy the RDS DB snapshot to an S3 bucket. Enable Cross-Region replication on the S3 bucket.","correct":false},{"id":"1575bfe0f50108d320a7b04107a11d21","text":"Configure an RDS automated backups target region to the secondary region.","correct":false},{"id":"bc87f2bd894c0887220a36be79571629","text":"Create an RDS DB snapshot. Copy the RDS DB snapshot to the secondary region.","correct":true}]},{"id":"c4ce254d-d835-4beb-b096-153d84bada07","domain":"SecureSolutions","question":"Which of the following services allows you to access the service's underlying operating system?","explanation":"Access to the underlying operating system is granted for Elastic Map Reduce and Elastic Beanstalk. The others are managed services.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html","title":"About Elastic Beanstalk"},{"url":"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html","title":"About EMR"}],"answers":[{"id":"8d4c0b2cef256d21ab680366c8b1c6bf","text":"EMR","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false}]},{"id":"70c6a808-0d5d-40d3-9b62-aa2fd031a543","domain":"CostOptimized","question":"You have three AWS payer accounts consolidated under an AWS Organization . Which of the below statements is TRUE for purposes of volume discounts?","explanation":"If you have multiple accounts, your charges will decrease because AWS combines usage from all accounts in the organization to qualify you for volume pricing discounts.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html","title":"Consolidated Billing for Organizations"}],"answers":[{"id":"c9c2416d95c8112070b7a5b032629fdf","text":"Usage in each account will be evaluated individually to determine the volume discount it is individually entitled to","correct":false},{"id":"4fb1af36b069dca73268eedbfab53e7b","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled at the Organisation level","correct":false},{"id":"98e718508cd32b9ffb27d8648e9129d0","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to","correct":true},{"id":"a6cd99e8b1bbcfc82e184acc9f28eede","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled in each account","correct":false}]},{"id":"4527c4d5-21af-43d6-bb31-827ec2b91ebf","domain":"Performant","question":"What is the minimum size of an General Purpose SSD EBS Volume?","explanation":"SSD volumes must be between 1 GiB - 16 TiB.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html","title":"EBS Volume Types"}],"answers":[{"id":"2820ea55c8d1ec2fa9dfcf1495076480","text":"1GiB","correct":true},{"id":"785dfc0dff56385171bea51ba18b6a95","text":"1MB","correct":false},{"id":"208b4367cf771ded0e29ff6f9282442e","text":"1GB","correct":false},{"id":"8b3e84771bc65950c3e79446c2e72978","text":"1byte","correct":false}]},{"id":"5b1aa557-c9a9-4366-af14-86557460213b","domain":"SecureSolutions","question":"You are a managed services company who hosts websites on AWS for a number of different customers. The websites are on a fleet of EC2 instances and many websites share the same EC2 instance. You need to enable SSL for these websites but want to minimize costs. You decide to use an application load balancer. How can you enable SSL using your ALB?","explanation":"The ability to terminate multiple different SSL certs on a single ELB is a big improvement over the previous requirement to terminate on the web server, or have multiple ELBs","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2017/10/elastic-load-balancing-application-load-balancers-now-support-multiple-ssl-certificates-and-smart-certificate-selection-using-server-name-indication-sni/","title":"ALB now supports Server Name Indication (SNI)"}],"answers":[{"id":"6d1c7989485d55f0973cfff0c61dcf7f","text":"Create an ALB for each website requiring SSL. Load each SSL certificate on to each ALB.","correct":false},{"id":"f8680fbaa85ed90c0052bd3e53598d4e","text":"Create a single ALB for the EC2 fleet. Use an SSL Wild Card certificate to enable SSL termination on the ALB.","correct":false},{"id":"794a2e0084785b78fc929594b40f3dca","text":"Create a single ALB for the EC2 fleet. Use Server Name Indication (SNI) with the ALB.","correct":true},{"id":"bd6663711a63b5635e7b16e407a0c239","text":"Create an ALB for each website requiring SSL. Use Server Name Indication (SNI) with each website requiring SSL.","correct":false}]},{"id":"c138fec3-1027-4dc1-9215-b9108252ffab","domain":"Performant","question":"You have a production application that is on the largest RDS instance possible, and you are still approaching CPU utilization bottlenecks. You have implemented read replicas, ElastiCache, and even CloudFront and S3 to cache static assets, but you are still bottle-necking. What should your next troubleshooting step be?","explanation":"If your application requires more compute resources than the largest DB instance class or more storage than the maximum allocation, you can implement partitioning, thereby spreading your data across multiple DB instances.","links":[{"url":"https://aws.amazon.com/rds/faqs/","title":"See 'Q: How can I scale my DB instance beyond the largest DB instance class and maximum storage capacity?'"}],"answers":[{"id":"062e544e8a9ad6c5491af7b0e682e372","text":"You should provision a secondary RDS instance and then implement and ELB to spread the load between the two RDS instances.","correct":false},{"id":"637dc8debb4ed3bebabdb2faf2cc89c3","text":"You should implement database partitioning and spread your data across multiple DB Instances.","correct":true},{"id":"f08b245b716a56cb1a5a93fe863992a0","text":"You should consider using RDS Multi-AZ and using the secondary AZ nodes as read only nodes to further offset load.","correct":false},{"id":"d7a5a5cf870141d209e3e9cda6322823","text":"You have reached the limits of public cloud. You should get a dedicated database server and host this locally within your own data center.","correct":false}]},{"id":"b492e9e4-864d-4ff2-9702-262996b05c46","domain":"Performant","question":"How does AWS deliver high durability for DynamoDB?","explanation":"Amazon DynamoDB is highly available, with automatic and synchronous data replication across three facilities within a Region. This helps protect your data against individual machine, or even facility level failures.","links":[{"url":"https://aws.amazon.com/dynamodb/details/#High_Availability","title":"DynamoDB High Availability"}],"answers":[{"id":"d617d277b2fd6ec82cdccb131e3676a4","text":"AWS maintains a schedule of incremental backups and log shipping.","correct":false},{"id":"b0991ddf7a0ec7d6b52ed6e7bfc4c119","text":"DynamoDB data is automatically replicated across multiple AZs.","correct":true},{"id":"9cb98abf406dd2e8a688aeb9c3ffdbcd","text":"DynamoDB supports user Snapshots to S3.","correct":false},{"id":"e8d0300d557f883b2150d8e9c16a64f9","text":"Like S3, DynamoDB is a global service -- data is automatically replicated across multiple AWS Regions.","correct":false}]},{"id":"f3e923a2-2e1a-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You want to track the amount of money you ideally want your company to spend for EC2 data transfers every month. Which of the following actions will accomplish that?","explanation":"AWS Cost Explorer is for providing information that you can use to track and manage costs, but it doesn’t enable the creation of budgets; that’s what AWS Budgets is for. If the question was strictly addressing cost, then creating a Cost budget with AWS Budgets would have been the correct answer. However, your concern is specifically with a usage type, which is EC2 data transfers. In this case, you would need to create a Usage budget with AWS Budgets and receive alerts when your defined threshold is met.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/budgets-managing-costs.html","title":"Managing Your Costs with Budgets"}],"answers":[{"id":"e7f799a3bc73b229cd75d773a9d7f547","text":"Create a Usage budget with AWS Budgets.","correct":true},{"id":"41e006394cc745a90a25e57065b658c2","text":"Create a Cost budget with AWS Budgets.","correct":false},{"id":"8d35bf16b7d263f4ab864e392d023e54","text":"Enable AWS Cost Explorer","correct":false},{"id":"4407cc58412e1c4727ad336bd8b8453f","text":"Create a Reservation budget with AWS Budgets.","correct":false}]}]}}}}
