{"data":{"createNewExamAttempt":{"attempt":{"id":"491534d1-4ed2-4da1-9905-1c63204ff46c"},"exam":{"id":"5f863183-929c-49e6-bb6e-0c2a31ccc9bd","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"ab704d26-226d-4951-b238-549daba176a5","domain":"ResilientDesign","question":"What is the durability of S3 - IA?","explanation":"S3 Standard - IA is designed for the same 99.999999999% durability as S3 Standard and Amazon Glacier.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#Infrequent_Access","title":"S3 Infrequent Access"}],"answers":[{"id":"19fb9916968211db983d13bffe0cc6af","text":"99.99%","correct":false},{"id":"91009c0d8d2ec85d07a48cb81bfcfb0d","text":"99%","correct":false},{"id":"78262a35fc5fdefbb7740ac7102b8cc4","text":"99.999999999%","correct":true},{"id":"ebb51b0b7e8f1fcf89ef483709bd61c6","text":"99.9%","correct":false}]},{"id":"2403cf92-cd58-4ade-8a82-52be2b2a6b5b","domain":"SecureSolutions","question":"Your Security team is concerned about a recent spate of large-scale DDoS attacks on other providers in your industry. You have a number of internet-exposed services in your business, and any potential outage has significant financial impact. The security team wants to be informed of any attack as it happens, and would like some assistance from AWS to help mitigate an attack should one happen. You currently have WAF deployed, and an Enterprise support agreement in place, but which of the below extra steps would you recommend","explanation":"AWS Shield Standard does not include notification of any attacks detected, therefore can be eliminated straight away. Although WAF can be used during a DDoS attack to help mitigate the attack with custom block rules, there are no in-built DDoS protections with WAF as these are provided by Shield. AWS has a dedicated DDoS Response Team (DRT) to assist during any DDoS attacks - however in order to access them, you need to be on an Enterprise or Business support agreement, and relevant to this scenario, have purchased Shield Advanced. This combined with the alerting of attacks that is available with Shield Advanced make purchasing Shield Advanced the most appropriate choice. ","links":[{"url":"https://aws.amazon.com/shield/getting-started/","title":"Getting Started with AWS Shield"},{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-overview.html#ddos-drt","title":"How AWS Shield Works"}],"answers":[{"id":"b41f4d516374b164d0a2c054a39dfe3f","text":"Enable rate limiting on your load balancers, and during an attack lodge a support request using your Enterprise support agreement for assistance","correct":false},{"id":"6afd0c59a36c013760fbb187d8bbb415","text":"Purchase AWS Shield Advanced, and during an attack lodge a support request asking for assistance from AWS","correct":true},{"id":"191789dacb98c2ed977f4a62437a00af","text":"Enable the inbuilt AWS WAF DDoS protections, use SNS to notify when an attack is detected. During an attack lodge a support request using your Enterprise support agreement for assistance","correct":false},{"id":"b8ede9969b12d6122fcef9029ff00b52","text":"By default all AWS services are automatically protected against DDoS attacks by AWS Shield - nothing extra needs to be done. During an attack lodge a support request using your Enterprise support agreement for assistance","correct":false}]},{"id":"ac8f79d2-72d6-4dcb-84c7-2ec0b61e48ca","domain":"Performant","question":"Power plant technicians at an electrical utility need to monitor equipment heat readings in real-time on their mobile devices. They would like to be able to see changing temperature values without refreshing the device's screen. Temperature sensors have already been installed on the equipment, and they've connected the sensors to AWS IoT Core. A mobile app has been developed in React Native to receive the temperature updates. An additional twenty percent more equipment will be installed at the plant over the next year. Which architecture will provide the most scalable solution for the utility?","explanation":"An AWS AppSync GraphQL update mutation will update a sensor's record in DynamoDB and broadcast updated data to mobile device clients. A Lambda function can initiate a connection to an AppSync GraphQL API endpoint. Each component of this architecture is a managed service that will scale with the power plant's growth plans. AWS Mobile Hub is used for building mobile applications, not for broadcasting messages to mobile devices. DynamoDB and Mobile Hub are not valid consumers of a Kinesis Data Streams stream. Amazon Pinpoint is used to send personalized communications, not forward data updates to mobile devices.","links":[{"url":"https://aws.amazon.com/appsync/","title":"AWS AppSync"},{"url":"https://aws.amazon.com/blogs/mobile/iot-with-aws-appsync/","title":"Monitoring IoT devices in real time with AWS AppSync"}],"answers":[{"id":"fe256ea9199399aa63a19f558746acda","text":"Implement an AWS IoT rule to forward messages to a Lambda function. Have the Lambda function execute an AWS AppSync GraphQL mutation to write updates to Amazon DynamoDB and broadcast changed data to mobile device users.","correct":true},{"id":"0fea673c8089e1f7d3a591bdaa3af824","text":"Configure an AWS IoT rule to forward messages to a Lambda function. Have the Lambda function write the messages to DynamoDB, and to AWS Mobile Hub, which broadcasts the changed data to mobile device users.","correct":false},{"id":"436ea268a30690aa25516a2df81f12f6","text":"Create an AWS IoT rule to forward messages to an Amazon Simple Queue Service queue. Have an EC2 instance read the queue and write the messages to DynamoDB, and forward the data to Amazon Pinpoint to broadcast the changed data to mobile device users.","correct":false},{"id":"f3d62c495d620412d9f919ff6f58fafc","text":"Have an AWS IoT rule forward messages to an Amazon Kinesis Data Streams stream. Create one consumer of the stream to be Amazon DynamoDB. Create a second consumer of the stream to be AWS Mobile Hub, which broadcasts the changed data to mobile device users.","correct":false}]},{"id":"c691150c-ad1f-44aa-9703-3270663efa8c","domain":"SecureSolutions","question":"A client is concerned that someone other than approved administrators is trying to gain access to the Linux web app instances in their VPC. She asks what sort of network access logging can be added. Which of the following might you recommend?","explanation":"Security and Auditing in AWS needs to be considered during the Design phase.","links":[{"url":"http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/flow-logs.html","title":"About VPC Flow Logs"},{"url":"http://www.howtogeek.com/177621/the-beginners-guide-to-iptables-the-linux-firewall/","title":"The Beginner’s Guide to iptables"}],"answers":[{"id":"cb2c46e6bc9bae0d23657eb1c5e27690","text":"Use Event Log filters to trigger alerts that are forwarded to CloudWatch.","correct":false},{"id":"3d6ade3e2e2886799ea63589b84aa78b","text":"Make use of an OS level logging tools such as iptables and log events to CloudWatch or S3.","correct":true},{"id":"501f5479b4e062548b22ef097036d0cc","text":"Set up a traffic logging rule on the VPC firewall appliance and direct the log to CloudWatch or S3.","correct":false},{"id":"bf4114d934f75133b491d8501b3e8063","text":"Set up a Flow Log for the group of instances and forward them to CloudWatch.","correct":true}]},{"id":"390ab5d8-2fc2-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"As a Cloud Solutions Architect, you have been tasked to set up an enterprise-class database with six-way replication across three Availability Zones. This measure is proposed to strengthen the database’s fault tolerance to disk failures. Which of the following engines will enable you to do that?","explanation":"Aurora is the database engine that provides six-way replication of each database volume across three Availability Zones. The other responses are just like Aurora in that they are relational database engines that offer Multi-AZ deployments. However, Oracle, MariaDB, and MySQL do not have this specific ability.","links":[{"url":"https://aws.amazon.com/rds/aurora/faqs/","title":"Amazon Aurora FAQs"}],"answers":[{"id":"69670a9d53817d1ec89e685997343ce2","text":"Amazon Aurora","correct":true},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"30162ed78b6c10f731411f2fc440c24f","text":"Oracle","correct":false},{"id":"7f9733e208088b1ce6df3d4be1765396","text":"MariaDB","correct":false}]},{"id":"3252d84d-08d9-4bde-a8e7-d716502d1855","domain":"Performant","question":"You have a very heavily-trafficked WordPress blog that has approximately 95% read traffic and 5% write traffic. You notice that the blog is getting slower and slower. You discover that the bottleneck is in your RDS instance. Which of the following answers can improve your WordPress blog's performance?","explanation":"You should use a combination of Read Replicas and ElastiCache to help offload the traffic.","links":[{"url":"https://aws.amazon.com/elasticache/","title":"About ElastiCache"}],"answers":[{"id":"1af32ee0c62b109e45b92828dbc33f2d","text":"Create a secondary Multi-AZ database and run the queries off the secondary Multi-AZ database.","correct":false},{"id":"e94a05a7348f87c7b9c4f7036d632a9c","text":"Use ElastiCache to cache the most commonly read posts of your WordPress blog.","correct":true},{"id":"fdc556bb3ab9b5da3b290c181aaefb3c","text":"Create a number of read replicas and update the connection string on your EC2 instances so that traffic is evenly shared amongst these new RDS instances.","correct":true},{"id":"1c551a09129057627b3b75fb70e6f527","text":"Export the database to DynamoDB which has push button scalability.","correct":false}]},{"id":"318a95d0-0a57-4cee-9a35-2dc933a36f41","domain":"SecureSolutions","question":"Your Lambda function needs to write to the ev_charge_stations, ev_networks and ev_plugs DynamoDB tables. From a security perspective, select the best answer that describes the most suitable policy for that.","explanation":"Serverless applications should always follow the principle of 'least privilege'. In this case, this can be achieved by spelling out the exact actions on the specific resources.","links":[{"url":"https://aws.amazon.com/blogs/security/how-to-create-an-aws-iam-policy-to-grant-aws-lambda-access-to-an-amazon-dynamodb-table/","title":"How to Create an AWS IAM Policy to Grant AWS Lambda Access to an Amazon DynamoDB Table"},{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_dynamodb_specific-table.html","title":"Amazon DynamoDB: Allows Access to a Specific Table"},{"url":"https://github.com/puresec/sas-top-10","title":"The Ten Most Critical Risks for Serverless Applications v1.0"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/api-permissions-reference.html","title":"DynamoDB API Permissions: Actions, Resources, and Conditions Reference"}],"answers":[{"id":"9020212f745cc56a8b6726a924138d1a","text":"For the resource value, specify all 3 tables individually, e.g. 'arn:aws:dynamodb:region:account-ID:table/ev_charge_stations' and use 'dynamodb:PutItem' as the policy's action value.","correct":true},{"id":"05782ed32acf1ce539e07394ac6d3d87","text":"Use '*' as the resource value and specify 'dynamodb:PutItem' as the policy's action value.","correct":false},{"id":"16294f715650d1a7ddd0b5a7aabe9464","text":"Specify 'dynamodb:PutItem' as the policy's action value and use 'arn:aws:dynamodb:region:account-id:table/ev_*' as the value for the resource.","correct":false},{"id":"08f833d7f3cafc72d04c7106212c36a1","text":"Configure the resource and action values as 'arn:aws:dynamodb:region:account-id:table/*' and 'dynamodb:*'","correct":false}]},{"id":"52b4ee51-c7d0-4c64-b94d-b1f86a123943","domain":"SecureSolutions","question":"After setting up a VPC peering connection between your VPC and that of your client, the client requests to be able to send traffic between instances in the peered VPCs using private IP addresses. What must you do to make this possible?","explanation":"If a route is added to your Route Table, your client will have access to your instance via private IP address.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/vpc-peering-routing.html","title":"Updating Your Route Tables for a VPC Peering Connection"}],"answers":[{"id":"632092f5f77636400a32ddb6d00d405a","text":"Establish a private peering connection.","correct":false},{"id":"70fe8660a356152780014ffc78eefba9","text":"Use an IPSec tunnel","correct":false},{"id":"cd1b0b1bbb6896df3ad3df97bda1b143","text":"Add your instance and the client's instance to a Placement Group.","correct":false},{"id":"1b8e530a822ea4c63050aef5b724db10","text":"Add a route to a Route Table that's associated with your VPC.","correct":true}]},{"id":"291ca555-1236-404c-a465-fa9fa118364b","domain":"ResilientDesign","question":"You're running an application that needs to be highly available in eu-west-1. In order for this application to function correctly,  10 related EC2 instances must running at all times. Which of the following deployments provides the ability to meet the requirements should an AZ go down?","explanation":"Should an AZ go down, only the answers of 5,5,5 or 10,0,10 EC2 instances are correct because if you take out one of those AZs, you would still have 10 EC2 instances running. Of course 10,10,10 will be more expensive, butit is still a valid answer.","links":[{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Reliability-Pillar.pdf","title":"Reliability Pillar - AWS Well-Architected Framework"}],"answers":[{"id":"c77fd5803949296fc9e47e645230c402","text":"4 EC2 instances in eu-west-1a, 4 EC2 instances in eu-west-1b, and 2 EC2 instances in eu-west-1c.","correct":false},{"id":"23ed0726519369cf6068f29abb57e8e7","text":"3 EC2 instances in eu-west-1a, 3 EC2 instances in eu-west-1b, and 3 EC2 instances in eu-west-1c.","correct":false},{"id":"6d68ff6a6b53ca045964ee07faeeab96","text":"5 EC2 instances in eu-west-1a, 5 EC2 instances in eu-west-1b, and 5 EC2 instances in eu-west-1c.","correct":true},{"id":"611169e594d21e09c256b0c24733c751","text":"10 EC2 instances in eu-west-1a, 0 EC2 instances in eu-west-1b, and 10 EC2 instances in eu-west-1c.","correct":true}]},{"id":"1cf391c5-1e10-4035-bbcb-931668050afa","domain":"SecureSolutions","question":"To maintain compliance with HIPAA, all healthcare-related data being stored on Amazon S3 needs to be encrypted at rest. Assuming S3 is being used for storing the data, which of the following are the preferred methods of encryption?","explanation":"You could encrypt locally or let S3-SSE handle encryption for you. Local encryption will generally cost more due to overhead, testing and management not required if you use the certified S3 offering.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html","title":"Protecting Data Using Encryption"},{"url":"https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act","title":"Health Insurance Portability and Accountability Act - Wikipedia"}],"answers":[{"id":"996c2bc03412d5b5de24b5af01a48b23","text":"Encrypt the data locally using your own encryption keys and then transfer the encrypted data to S3.","correct":true},{"id":"1f1caf8ba4ec7f94f06dfd02d7a51ec6","text":"Enable Server Side Encryption on your S3 bucket. S3 automatically applies AES-256 encryption.","correct":true},{"id":"85edfed008f011d2344559959b2aaff4","text":"Store the data in S3 as EBS snapshots.","correct":false},{"id":"02bb16b919dcd1a7380c8e461f0eab12","text":"Store the data on encrypted EBS volumes.","correct":false}]},{"id":"bdfff765-ad59-45a9-9e3c-605a3d2ad9d7","domain":"ResilientDesign","question":"You have been asked to set up an EFS storage solution for a project team.  Which of the following tasks do you need to complete ?","explanation":"It is necessary to set up the bi-directional network permissions, normally with Security Groups. You will connect the EFS Target to your EC2 instance with a 'mount' statement. You do not need to stipulate the size or format the volume. AWS provide a nominally unlimited file system ready for you to use.  As normal under the shared security model AWS will ensure that the EFS system is secure, but you are responsible for the access control security inside the EFS file space provided to you.","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html","title":"EFS - How It Works"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/limits.html","title":"EFS limits"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/security-considerations.html","title":"EFS Security"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/accessing-fs-create-security-groups.html","title":"EFS Security Groups"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/wt1-getting-started.html","title":"Mounting and EFS target"}],"answers":[{"id":"30f2e62c04d187f6e6f58e730e462680","text":"Configure a Security Group to allow admin traffic on port 22 to connect to the EFS system.","correct":false},{"id":"9bc552892ca2c2c5be9e7c352fc0cdc8","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EC2 server.","correct":true},{"id":"8388b16ddec8dec25d6caba4dbe7f8cb","text":"specify and provision disk capacity on the EFS system using 'fdisk' and 'mkfs -t xfs'.","correct":false},{"id":"7f41c759c946659e0ef49f87f6684503","text":"Set Linux file system permissions on the presented EFS volume using 'chmod' and 'chown'.","correct":true},{"id":"417164507c199eb8b0fb1daa3bae285c","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EFS target","correct":true},{"id":"9a0eabcd19e62a99932848808a473c0f","text":"mount EFS vol to your EC2 instance using 'mount -t nfs -o xxxx '.","correct":true}]},{"id":"d5733ca8-59ad-4f5d-b36f-b9ab95f39669","domain":"SecureSolutions","question":"A company has begun building applications in AWS. They have come to you for some guidance around security.  Occasionally they need to SSH into their application and web servers, which are hosted in a public subnet.  What recommendations would you make to the company in order to improve the security of their workload?","explanation":"Deploying workloads into public subnets is generally an unnecessary risk, so moving them from public to private subnets is a good idea. AWS load balancers can sit in your public subnets in front of your EC2 instances which are protected in private subnets.  In order to SSH to those instances from the Internet you can also deploy Bastion Hosts in the public subnets.  AWS Security Manager is not a service providing monitoring of malicious activity (the service would be provided by AWS Guard Duty.)  Similarly, the CloudWatch agent does not analyse the behaviour of applications, that is an offering of the AWS Inspector service and agent.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/public-load-balancer-private-ec2/","title":"How do I connect a public-facing load balancer to EC2 instances that have private IP addresses?"},{"url":"https://aws.amazon.com/blogs/security/securely-connect-to-linux-instances-running-in-a-private-amazon-vpc/","title":"Securely Connect to Linux Instances Running in a Private Amazon VPC"},{"url":"https://aws.amazon.com/blogs/security/controlling-network-access-to-ec2-instances-using-a-bastion-server/","title":"Controlling Network Access to (Windows) EC2 Instances Using a Bastion Server"}],"answers":[{"id":"0cac7b74e61a7847a4f70d6683c3b45c","text":"Move the application and web servers to private subnets to restrict access","correct":true},{"id":"4766a3554e4aca8517eb72b2422912e8","text":"Enable AWS Security Manager to continuously monitors for malicious activity and unauthorized behavior","correct":false},{"id":"6ec4bcc6e53670dd38e466f86448b64a","text":"Install the CloudWatch agent on the servers to analyze the behavior of the applications and identify potential security issues","correct":false},{"id":"7f7d3f30def404b95583fc1925c5ac58","text":"Use Bastion Hosts to SSH from the Internet and then connect to application and web servers","correct":true},{"id":"48a2dae1ec2dd4ef4ac0ce35564240ac","text":"Use Network and Elastic Load Balancers in front of any application or web servers to serve traffic","correct":true}]},{"id":"f1eea1a4-0b1e-4702-bb51-0937708005a3","domain":"ResilientDesign","question":"In the future, you will need to preserve, restore, and retrieve every version of every file that you have stored in AWS. Which service should you use?","explanation":"Versioning allows you to preserve, retrieve, and restore every version of every object stored in an Amazon S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"Using Versioning with S3"}],"answers":[{"id":"e9a5105fa288ef2b71c037e42d665d91","text":"S3 - OneZone-IA","correct":false},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"8eeeb63c58948c56dc93f4dd229fc796","text":"S3 with Versioning enabled.","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false}]},{"id":"c7389a3c-56be-4682-8ee3-af150046cc22","domain":"ResilientDesign","question":"A business-critical application requires multi-region deployment in order to meet availability SLA's. What solution is suitable for achieving these requirements?","explanation":"ELB and API Gateway are both regional services and are not able to route traffic to different AWS regions. CNAME DNS records cannot be used to route traffic to multiple endpoints. In order to implement traffic routing across multiple regions, Route53 must be used. For each application endpoint, create an A (or Alias) record. A weighted routing policy can be used where each record has equal weight. In order to support automatic failover, application health-check should be implemented.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html#dns-failover-types-active-active","title":"Active-Active and Active-Passive Failover"}],"answers":[{"id":"d2c21c6f551d5cf92df475bb36f7984e","text":"Route53 with Weighted Routing Policy and application health-check configured.","correct":true},{"id":"03f1b0386c6511e6b329683a17ee66cf","text":"API Gateway with application endpoints configured as targets.","correct":false},{"id":"3f6dd4980f466bfc756fc9424b447273","text":"ELB with application health-check configured.","correct":false},{"id":"c615b1eb411e5e6b2475753e1742787c","text":"Configure CNAME record for each application endpoint in Route53.","correct":false}]},{"id":"05ab8679-89d2-4db7-83f2-6cd0a315ae13","domain":"CostOptimized","question":"Amazon Web Services offers 4 different levels of support. Which of the following are valid support levels?","explanation":"The correct answers are Enterprise, Business, Developer. The 4th level is Basic.  Remember that Free Tier is a billing rebate not an account type or support level.","links":[{"url":"https://aws.amazon.com/premiumsupport/compare-plans/","title":"AWS Support Plans"}],"answers":[{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":true},{"id":"7effe80425095de4d5b996a01e4f00a3","text":"Corporate","correct":false},{"id":"5ef2f1c1df8b6b0fed2186a0abe18f50","text":"Free Tier","correct":false},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":true}]},{"id":"d5e8caaa-e2d5-4d00-b9bc-53efee2b366f","domain":"Performant","question":"You have a production work load on AWS consisting of a Web Tier, Application Tier and Database Tier. Your web application starts to slow down under heavy use and can even become unresponsive. You investigate the issue and discover the issues are with the PostgreSQL RDS. What two steps could you do to improve performance?","explanation":"This is a classic scale-up or scale-out question. upgrading the disk is a scale-up solution, and adding read-replicas is a scale-out solution. Multi-AZ is possible, but will not help with performance, only resiliency.  RDS autoscaling is available only with Aurora","links":[{"url":"https://aws.amazon.com/blogs/database/scaling-your-amazon-rds-instance-vertically-and-horizontally/","title":"Scaling Your Amazon RDS Instance Vertically and Horizontally"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html","title":"Aurora Auto Scaling"}],"answers":[{"id":"eda178658eacb51c3dcfd2f1f9e2c4c5","text":"Add multi-AZ to the RDS cluster and direct all read traffic to the secondary instance.","correct":false},{"id":"ad6b88231cab9ea7642a5c16ce20722e","text":"Upgrade the storage type from General Purpose SSD to Provisioned IOPS SSD.","correct":true},{"id":"4b8062204769a36aff6ebc2fb3ffb313","text":" Turn on RDS Autoscaling and scale when CPU Utilization reaches 90% for 5 minutes.","correct":false},{"id":"bd7d139b54a720f913080f4bec971220","text":"Provision 3 Read Replicas and direct all read traffic to these new instances.","correct":true}]},{"id":"5c03ba91-e120-426c-846a-13b35d3a94c3","domain":"Performant","question":"You've been tasked with backing-up the files that exist on an in-house SAN to S3. You need to minimize cost, and company policy states that objects must be instantly accessible. What S3 storage class should you use?","explanation":"The best solutions for instant access, but lowest cost, would be S3 - Infrequently Accessed storage.  OneZone-IA has a lower Availability, so an increased chance that it will not be accessible when needed.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#Infrequent_Access","title":"S3 - Infrequent Access"}],"answers":[{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"31e831ec49678aed7f467f791d1f8704","text":"S3 - RRS","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":false},{"id":"4340570ba672bfa48cd45e3f026c01d1","text":"S3 - IA","correct":true},{"id":"243d5b67be4ede5834d736f1eac578ef","text":"S3 - 1Zone-IA","correct":false}]},{"id":"cbcc2938-15ec-4a2f-bb94-1fefe41f3efe","domain":"Performant","question":"You have an RDS database that has high performance OLTP workloads. Which storage medium would be best to accommodate these requirements?","explanation":"Amazon RDS Provisioned IOPS (SSD) Storage would be the most suitable.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS","title":"RDS Provisioned IOPS for OLTP Workloads"}],"answers":[{"id":"e774a96af9adfaa2402148c9828271e7","text":"Amazon RDS Magnetic Storage","correct":false},{"id":"0db6de47eed9671e44098c2117fe8916","text":"Amazon RDS Cold Storage","correct":false},{"id":"a257df0abf37db5da9b921f8222eab2a","text":"Amazon RDS General Purpose (SSD) Storage","correct":false},{"id":"4d548ff7278077c929b63c67f768cc97","text":"Amazon RDS Provisioned IOPS (SSD) Storage","correct":true}]},{"id":"54f49b19-525b-42bc-956a-c02a709ea575","domain":"Performant","question":"A political consulting group wants to monitor Twitter tweets from all candidates in an election to assess campaign statements and positions on current issues. They'll implement calls to the Twitter API from a Python script on an EC2 instance to get the tweets, and they'll use Amazon QuickSight to visualize the data. They anticipate that as the election approaches, tweet volume will increase dramatically. Which architecture will provide the scalability they need in the most cost effective way?","explanation":"Using Kinesis Streams to batch the tweets for the Lambda consumer function helps orchestrate the process of invoking Comprehend on a specific set of tweets. If the data is written directly to S3 via Kinesis Firehose PutRecord calls without some batching of the tweets, Comprehend will scan the same data multiple times. Comprehend currently does not support DynamoDB as a data source. Comprehend is a natural language processing service and doesn't require the data to be pre-formatted.","links":[{"url":"https://aws.amazon.com/kinesis/","title":"Amazon Kinesis"},{"url":"https://aws.amazon.com/comprehend/","title":"Amazon Comprehend"},{"url":"https://github.com/aws-samples/lambda-refarch-streamprocessing","title":"Serverless Reference Architecture: Real-time Stream Processing"}],"answers":[{"id":"60a15003c784ca46eb2291738f62038a","text":"Have the Python script write the tweets to an Amazon Kinesis Streams stream. Configure a Lambda function as the consumer of the stream. Have the Lambda function write the data to Amazon DynamoDB. Invoke Amazon Comprehend from the Lambda function to assess sentiment in the tweets and write the results back to DynamoDB","correct":false},{"id":"2447562bf64c3157516a40a083254449","text":"Have the Python script write the tweets to an Amazon Kinesis Firehose stream with PutRecord API calls. Configure the stream to write the data to Amazon S3. Trigger a Lambda function to invoke Amazon Comprehend to assess sentiment in the tweets and write the results back to S3","correct":false},{"id":"4e077d33575cabb8babd3a56c3f77d32","text":"Have the Python script write the tweets to an Amazon Kinesis Firehose stream with PutRecordBatch API calls. Configure the stream to write the data to Amazon S3. Trigger a Lambda function to put the data into a standard format, and then invoke Amazon Comprehend to assess sentiment in the tweets. Write the results back to S3","correct":false},{"id":"29db045869ea4a45b00a8df4819dc756","text":"Have the Python script write the tweets to an Amazon Kinesis Streams stream. Configure a Lambda function as the consumer of the stream which receives tweets in batches. Have the Lambda function write the data to Amazon S3. Have the Lambda function also invoke Amazon Comprehend to assess sentiment in the batch and write the results back to S3","correct":true}]},{"id":"1ad4b101-8078-4f3c-86bf-2f865ee09a54","domain":"CostOptimized","question":"A government agency has a regulatory mandate that all archived data must be preserved exclusively in a non-rewriteable and non-erasable format. What solution satisfies this requirement in the most cost-effective way?","explanation":"Amazon S3 versioning does not protect object versions from being deleted and is therefore an incorrect solution. Amazon S3 bucket policies do not satisfy the requirement and is not the correct solution. Amazon S3 bucket policies can be changed, thus removing protection on the objects. Implementing Amazon S3 Object Locks is incorrect because it is not the most cost-effective solution. The question specifically asks about archived data. Storing archived data in Amazon S3 Glacier is more cost-effective than Amazon S3. Amazon S3 Glacier is the most cost-effective storage solution for archive data. Amazon S3 Glacier Vault Lock can be used to implement a 'Write-Once-Read-Many' archive storage solution.","links":[{"url":"https://docs.aws.amazon.com/amazonglacier/latest/dev/vault-lock.html","title":"Amazon S3 Glacier Vault Lock"},{"url":"https://aws.amazon.com/blogs/aws/glacier-vault-lock/","title":"Create Write-Once-Read-Many Archive Storage with Amazon Glacier"}],"answers":[{"id":"554acd3f3712f630497b0180dbb5124c","text":"Implement Amazon S3 Glacier Vault Lock.","correct":true},{"id":"1430bbbd409858a9a820458c0f311d39","text":"Enable Amazon S3 Object Lock.","correct":false},{"id":"6a730079c6c38844cd80386edd5634f3","text":"Enable Amazon S3 Versioning.","correct":false},{"id":"c367faed034f6f722c499e129d8ca5dd","text":"Implement Amazon S3 Bucket Policy with deny statements for object delete operations.","correct":false}]},{"id":"37bacf63-a62f-4f99-a0b0-6bf9bf5a5210","domain":"CostOptimized","question":"You have a series of websites hosted in AWS. You need to ensure that users from Europe are directed to www.my-gdpr-site.com for regulatory purposes. What could help accomplish this?","explanation":"Geolocation routing lets you choose the resources that serve your traffic based on the geographic location of your users, meaning the location that DNS queries originate from. For example, you might want all queries from Europe to be routed to an ELB load balancer in the Frankfurt region.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"4b3ecb216d2654061f67ae382d891333","text":"Using the Autoscaling service.","correct":false},{"id":"3efbfae41092bb136dee3c26de7750f1","text":"Using the Route 53 service.","correct":true},{"id":"adba6b9b5a5387ec8af8d012d272715b","text":"Using the AWS Config service.","correct":false},{"id":"2b840caf003f35a0ca6a82ea4d66b8a8","text":"Using the Elastic Load Balancer service.","correct":false}]},{"id":"74da1953-0d65-427a-bbba-a17f2cf81ddd","domain":"SecureSolutions","question":"You need to implement a new web application that allows users to store family photos online in such a way that only invited guests will be able to view the images. Which type of S3 encryption should you choose to maintain full end-to-end control of the encryption/decryption of objects and assure that only encrypted objects are transmitted over the Internet to Amazon S3.","explanation":"","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html","title":"Using a Client-Side Master Key"}],"answers":[{"id":"5e146922b28cce8eae49ecb39eef972d","text":"Provide a client-side master key to the Amazon S3 Encryption Client","correct":true},{"id":"1562bb9d2d9567740605dcb1ccab5c80","text":"SSE-S3","correct":false},{"id":"472035b16201f5505380c16ec3eb8518","text":"SSE-C","correct":false},{"id":"e17194408dc439e1658a544965724d44","text":"SSE-KMS","correct":false}]},{"id":"89f330aa-397e-49a6-99c1-59a911318d03","domain":"SecureSolutions","question":"To protect S3 data from accidental overwrites and deletes, which of the following should you do first?","explanation":"The first thing you should do is enable versioning.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html","title":"S3 Object Versioning"}],"answers":[{"id":"9fb0a6abf0e1bda745fab85832252ee0","text":"Use a bucket policy to disable deletes from S3","correct":false},{"id":"d5ea3592264e2a8848ca043466fd5c46","text":"Allow only MFA access","correct":false},{"id":"253efe32850426ce32c509612536c798","text":"Enable versioning on the bucket.","correct":true},{"id":"f85fb671c749e7fcc0f440124d0879d7","text":"Access S3 only from signed URLs.","correct":false}]},{"id":"e7685041-5997-4788-9e77-4ec3abb76e30","domain":"Performant","question":"As a Solutions Architect, you advise on team planning activities. A team is building an application that must store persistent JSON data and be able to have an index. Data access must remain consistent if there is high traffic volume. What service should you recommend to the team?","explanation":"Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. The data stored in DynamoDB is JSON format, making it the perfect data store for this requirement.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html","title":"What is Amazon DynamoDB?"}],"answers":[{"id":"f7415e33f972c03abd4f3fed36748f7a","text":"Amazon Redshift","correct":false},{"id":"8679a1944db93938a65e47107be5d2b8","text":"AWS CloudFormation","correct":false},{"id":"ecafbaed9f41dac736e496a7cd234ce4","text":"Amazon DynamoDB","correct":true},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false}]},{"id":"b66725f5-c28a-40e3-a66f-ab440f24f05d","domain":"SecureSolutions","question":"You work for a construction company that has their production environment in AWS. The production environment consists of 3 identical web servers that are launched from a standard Amazon Linux AMI using Auto Scaling. The web servers are launched in to the same public subnet and belong to the same security group. They also sit behind the same ELB. You decide to do some testing: you launch a 4th EC2 instance into the same subnet and same security group. Annoyingly, your 4th instance does not appear to have internet connectivity. What could be the cause of this?","explanation":"Of these choices, the absence of the Elastic IP is the only one that could prevent internet access.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Internet_Gateway.html","title":"Enabling Internet Access"}],"answers":[{"id":"3645b812b5554461edf969a5a7b19083","text":"You need to update your route table so as to provide a route out for this instance.","correct":false},{"id":"dbfb29d2865a1da80068dc82bdf11f7f","text":"You have not configured a NAT in the public subnet.","correct":false},{"id":"3de8a51a1f321c3839a3ac9442da1f72","text":"You have not assigned an elastic IP address to this instance.","correct":true},{"id":"1b5e2f314ee9201857bbf929863476b9","text":"You have not configured a routable IP address in the host OS of the fourth instance.","correct":false}]},{"id":"912352c0-d2a0-4e7c-89cd-d4ee66445744","domain":"CostOptimized","question":"You have been asked to design a scalable solution for a simple customer service survey that is shown online after each of the ~10 million chat bot interactions per month: Emoticons for 3 rating options ('positive', 'neutral' and 'negative') are to be presented with the expectation that about 10% of users submit their feedback. The bot is public facing and operates 24x7. Select a feasible and most cost effective solution.","explanation":"RDS alone is more expensive than any of the serverless solutions and therefore not an option here. Because of this use case's simplicity (i.e. no request validation, rate limiting, authentication/authorization, etc. required), there is essentially no need for a Lambda fronting API Gateway. Given the described requirements (load and availability), an ALB is more expensive as it's billed hourly.","links":[{"url":"https://serverless-training.com/articles/save-money-by-replacing-api-gateway-with-application-load-balancer/","title":"Saving Money By Replacing API Gateway With Application Load Balancers Lambda Integration"},{"url":"https://aws.amazon.com/blogs/networking-and-content-delivery/lambda-functions-as-targets-for-application-load-balancers","title":"Lambda functions as targets for Application Load Balancers"},{"url":"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/browser-invoke-lambda-function-example.html","title":"Invoking a Lambda Function in a Browser Script"}],"answers":[{"id":"909f43a37c73caa5e0c764e4d8d8201c","text":"Given the expected load, you are better off with an Elastic Beanstalk app and RDS such as PostgreSQL or MySQL","correct":false},{"id":"852949aded12102365acbeb1052394f9","text":"You develop a proper API and use an API Gateway, Lambda and DynamoDB solution","correct":false},{"id":"b63327b72ecc6921a7e43eb0f786a3fe","text":"You invoke a Lambda function on demand in a browser script using the AWS SDK for JavaScript. For that to work you will need to create an Amazon Cognito identity pool with access enabled for unauthenticated identities and include the identity pool ID in your code to obtain credentials for the browser script. The function writes the submitted rating value to a DynamoDB table.","correct":true},{"id":"39329c7ee88152a625a8d565e6b38f36","text":"You front your Lambda that writes the ratings to a DynamoDB table with an ALB.","correct":false}]},{"id":"327b05c9-9075-44f6-aa13-2256b224ddd0","domain":"SecureSolutions","question":"You work for a famous bakery who are deploying a hybrid cloud approach. Their legacy IBM AS400 servers will remain on premise within their own data center. However, they will need to be able to communicate to the AWS environment over a site-to-site VPN connection. What do you need to do to establish the VPN connection?","explanation":"A virtual private gateway is the VPN concentrator on the Amazon side of the VPN connection. You create a virtual private gateway and attach it to the VPC from which you want to create the VPN connection.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html#VPNGateway","title":"Virtual Private Gateways"}],"answers":[{"id":"0d9b1a79d184042e38ad85fb92194245","text":"Assign a public IP address to your Amazon Virtual Private Gateway.","correct":true},{"id":"4ee8aaa281d6b39d679d377e073cb093","text":"Update your route table to add a route for the NAT to 0.0.0.0/0.","correct":false},{"id":"4854a199e41f20aaa56b2eb9ec81163a","text":"Connect to the environment using AWS Direct Connect.","correct":false},{"id":"7183da525dce8df94a54eeefb5c8e963","text":"Create a dedicated NAT and deploy this to the public subnet.","correct":false}]},{"id":"3f41cb1e-265b-11ea-978f-2e728ce88125","domain":"Performant","question":"You are setting up the properties of an S3 bucket created for storing monthly pie charts. You want to use a template that will serve as the pie chart for the month of January, and for making alterations corresponding with subsequent months. All charts will be stored in the same bucket. Which of the following options should you select to allow that to happen?","explanation":"Enabling the Versioning feature will enable you to keep multiple versions of the pie chart in the S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/enable-versioning.html","title":"Enable Versioning"}],"answers":[{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false},{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":false},{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":false},{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":true}]},{"id":"5fac4bb4-d450-440d-bc31-62fd409b5bee","domain":"ResilientDesign","question":"A company has an LNMP (Linux, Nginx, MySQL, PHP) stack application deployed to AWS. The availability requirements for their backend database specify automatic failover in case of disaster recovery. What is the optimal solution that meets this requirement?","explanation":"Since the scenario calls for MySQL, we must choose a relational database for the backend database. This means that DynamoDB is not a correct option. With RDS Multi-AZ deployment, a primary DB instance is automatically and synchronously replicated to a secondary RDS instance in a different availability zone (AZ). In case of a disaster causing primary instance failure, RDS performs automatic failover to the secondary standby RDS instance. During the failover, the database endpoint remains the same. RDS Read-Replica provide secondary RDS instances that are asynchronous replicated from the primary. RDS read-replicas have different endpoints and do not provide automatic failover. Additionally, they only provide read (not write) operations. It is possible to use Route53 with Health-check and DNS failover configurations to route traffic to multiple RDS instances. However, this solution does not provide automatic data synchronization between instances.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"High Availability (Multi-AZ) for Amazon RDS"}],"answers":[{"id":"8a8d90b530fbd9c90820ca63425401b5","text":"Deploy multiple RDS instances. Use Route53 with Health-Check and DNS failover configured.","correct":false},{"id":"f38116f4410ef57b5ffc6e17d11b1721","text":"RDS with Multi-AZ deployment.","correct":true},{"id":"23f694af0e449b15b6fb26401d12eb0e","text":"DynamoDB with Global Tables deployment.","correct":false},{"id":"9e445d25eaf3cc7b2f2412dbf19e6e4b","text":"RDS with Read-Replica deployment.","correct":false}]},{"id":"f26af436-9d46-43c4-bc90-7102c73af3c5","domain":"SecureSolutions","question":"You are creating a new website where users will be able to login using their facebook, google and amazon.com credentials. You need to deploy this website as quickly as possible and you are looking for an AWS service that will enable you to deploy the authentication quickly. Which AWS service should you use?","explanation":"Cognito is a service that can authenticate users via federated Identity Providers, and assign them manage access to AWS resources based on your policies.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/external-identity-providers.html","title":"Identity Pools (Federated Identities)"}],"answers":[{"id":"8a1c4d12f4eb4126267c40d270d264c4","text":"IAM with Microsoft Active Directory Authentication","correct":false},{"id":"e402520d8999ab859a1625c0012ecb4a","text":"Identity Access Management with Open Connect","correct":false},{"id":"a095c741ced0e0849b29ce2600af29b0","text":"Cognito with Identity Pools (Federated Identities) External Identity Providers","correct":true},{"id":"5de42305de3cd44564a54719deb43a37","text":"Amazon Authentication Zero","correct":false}]},{"id":"596626b1-f08c-4afb-a723-39c8abf31af5","domain":"ResilientDesign","question":"An EC2 instance retrieves a message from an SQS queue, begins processing the message, then crashes. What happens to the message?","explanation":"When the message visibility timeout expires, the message becomes available for processing by other EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html","title":"SQS Visibility Timeout"}],"answers":[{"id":"82e027481e331aba93999ce96b1af424","text":"To prevent corruption, the message is deleted.","correct":false},{"id":"d69db62ea1f468c166c785ced48037ba","text":"It remains in the queue in a locked state until the EC2 instance comes back online.","correct":false},{"id":"b7b87efcf5ef61b425d9a60bc33efe62","text":"When the message visibility timeout expires, the message becomes available for processing by other EC2 instances.","correct":true},{"id":"77d789cecbe676c6c677cc6cd389b99a","text":"When the message timeout expires, the message is duplicated, the original message is archived, and the duplicate becomes available for processing.","correct":false}]},{"id":"126e898c-dd73-4447-b5a7-59701a16a92d","domain":"ResilientDesign","question":"You are reviewing Change Control requests and you note that there is a proposed change designed to reduce errors due to S3 Eventual Consistency by updating the 'DelaySeconds' attribute. What does this mean?","explanation":"Poor timing of SQS processes can significantly impact the cost effectiveness of the solution.","links":[{"url":"http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"464400e5333b3beab1128b1b1f7cedf7","text":"While processing a message, a consumer instance can amend the message visibility counter by a fixed amount.","correct":false},{"id":"f170b98804f18cb00b57e135f0a3f116","text":"When the consumer instance polls for new work, the consumer instance will wait a certain time until it has a full workload before closing the connection.","correct":false},{"id":"4b46d6ad9dd090f0143cc40fecbad7b5","text":"When a new message is added to the SQS queue, it will be hidden from consumer instances for a fixed period.","correct":true},{"id":"6e5b2857717c8cf5b2722dc270183515","text":"While processing a message, a consumer instance can reset the message visibility by restarting the preset timeout counter.","correct":false}]},{"id":"61549fca-bf43-4de6-a057-4539abb557f5","domain":"Performant","question":"Your business is evaluating several database technologies from AWS. It is expected that you will need to scale out the performance for read operations using read replicas. The business has decided to reduce management overheads as much as possible by using RDS for the database. Which of the following RDS Database engines would NOT be suitable in this scenario?","explanation":"MS SQL Server does not support Read Replicas when using RDS. MySQL, PostgreSQL, MariaDB and Aurora support Read Replicas to improve performance for Read Heavy applications.","links":[{"url":"https://aws.amazon.com/rds/details/read-replicas","title":"Amazon RDS Read Replicas"}],"answers":[{"id":"d2727816fa1087ddac7dff69e35c5536","text":"MS SQL","correct":true},{"id":"7f9733e208088b1ce6df3d4be1765396","text":"MariaDB","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false}]},{"id":"0e567584-0bb5-4dd8-afa7-6afa3281ade6","domain":"ResilientDesign","question":"You and your Developer team are building a web application for a real estate company that will include a field for conducting full-text keyword searches. Which of the following AWS services must you choose to provide this type of search experience?","explanation":"Elasticsearch Service is based on a full-text search engine. As a result, developers can use the service to help potential buyers find their desired homes, price ranges, and neighborhood locations with the real estate web application. EBS and EFS are storage tools, and ElastiCache is an in-memory cache service.","links":[{"url":"https://aws.amazon.com/elasticsearch-service/","title":"Amazon Elasticsearch Service"}],"answers":[{"id":"9bd4d2488a57ffddd2506feb893c6ca5","text":"Amazon Elasticsearch Service","correct":true},{"id":"d2a6652ddeb631da029d1f2806e11fdc","text":"Amazon Elastic File System (EFS)","correct":false},{"id":"9155453f43b8a6472df0b8ffa5b5a028","text":"Amazon Elastic Block Storage (EBS)","correct":false},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false}]},{"id":"08233176-e11b-410e-98eb-25ca6e2eebcb","domain":"ResilientDesign","question":"A large enterprise has a distributed application in its own data center and relies on message brokers to connect and co-ordinate different systems. Message Brokers serve as the backbone for their IT environment and ultimately their business services. The enterprise has started to move some of its applications to the cloud and is looking for a cloud message broker solution so that the on-premise applications can interact with cloud-based application components. Which of the following services best suit the customer requirements?","explanation":"Amazon MQ is recommended for messaging between on-premises and cloud application components. It also supports industry-standard APIs and protocols such as JMS, AMQP and MQTT. Amazon SQS is best utilized as a messaging solution between components entirely on AWS. Amazon Step Functions is a fully managed service which makes it easy to co-ordinate components of distributed applications using visual workflows. Amazon SNS is a managed publish/subscribe service which reliably delivers messages to all valid AWS endpoints.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-activemq-in-a-hybrid-cloud-environment-with-amazon-mq/","title":"AWS Application Integration Services"}],"answers":[{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true},{"id":"860f0e709d06a1c1529c01a39cdfd798","text":"Amazon Step Functions","correct":false},{"id":"55daa020bacdf7e4ae1a33c9f14c45b3","text":"Amazon SNS","correct":false},{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":false}]},{"id":"cbd65c24-5330-4cbe-aadc-f65637bed971","domain":"CostOptimized","question":"Your SQL server requires a specific type of collation and some unique third party tools installed on it. You will need access to the underlying operating system for management and monitoring of these third party tools. However, you'd like to keep the overall amount of management to a minimum. Which AWS service would best suit your needs?","explanation":"With all services you are trading control of underlying processes for cost saving and ease of management.  In the case of RDS, AWS has exclusive control of the DB engine and underlying processes.  If you need to have access to these, building a bespoke DB server on an EC2 instance is the correct technical choice.","links":[{"url":"https://aws.amazon.com/sql/","title":"SQL Server on AWS"}],"answers":[{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"8f23d472ee9e39b19dec8c94f59f497b","text":"ElasticCache","correct":false},{"id":"8d8f3d54a16acc76a831ced6958141b9","text":"SQL server installed on EC2 with EBS","correct":true},{"id":"0ccd2cb2fe485108788ab60e8dbdfb4e","text":"RDS with SQL Server","correct":false}]},{"id":"2aad5b9a-23aa-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"As a Solutions Architect helping to develop and add an unabated stream of web applications, you worry that the company’s cloud architecture is increasingly getting more complicated, making it difficult to track the applications’ performance. Which AWS service checks how applications are performing and helps to identify and resolve issues?","explanation":"AWS Trusted Advisor is for optimizing the cloud environment and does not specifically address applications. Although AWS CloudWatch monitors applications and can direct you to issues with them, it does not fix errors. And Amazon Inspector is a security assessor, not an application performance tracker. Only AWS X-Ray helps to optimize the performance of applications by identifying and fixing their issues.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html","title":"What is AWS X-Ray?"}],"answers":[{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":false},{"id":"3dc993924bceb799c7009d281aa91408","text":"AWS X-Ray","correct":true},{"id":"543096643aa6d28d9fac278e9257783d","text":"Amazon Inspector","correct":false},{"id":"5714e9332e476d05d9a1763a1b10be50","text":"AWS CloudWatch","correct":false}]},{"id":"f30c65af-6476-4a69-87ac-1e8e1bf69df8","domain":"ResilientDesign","question":"A company's SOC is implementing a system to perform real-time analysis of CloudTrail logs to enhance their security. What option would enable them to receive logs from CloudTrail in real-time in the most optimal way?","explanation":"CloudTrail can be configured to send notifications to an SNS topic. SQS Queue can be configured to subscribe to the SNS topic so that messages can be processed programmatically. S3 notifications do not have ability to send messages to Kinesis Streams, so this is not a valid option. Likewise, CloudTrail does not have ability to send notification to Kinesis Streams. Using CloudWatch Events rules as a trigger is not an operationally optimal solution since CloudTrail has native notification capability.","links":[{"url":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/configure-sns-notifications-for-cloudtrail.html","title":"Configuring Amazon SNS Notifications for CloudTrail"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-subscribe-queue-sns-topic.html","title":"Tutorial: Subscribing an Amazon SQS Queue to an Amazon SNS Topic"}],"answers":[{"id":"ac8b34a41e5e43b017a506c82a4ad0b5","text":"Create an SNS Topic. Configure the CloudTrail trail to send notifications to the SNS Topic. Configure SQS Queue to subscribe to the SNS Topic.","correct":true},{"id":"cd0e5b49f050ae2342a147f66f2a9f10","text":"Configure CloudWatch Events rule that is triggered when new logs are written to CloudTrail. Implement a Lambda function to analyse the event. Configure the Lambda function as the CloudWatch Event target.","correct":false},{"id":"f9aeb59c8eacbc153e39c069dbe71d3a","text":"Create a Kinesis Stream. Configure the CloudTrail trail to send notifications to the Kinesis Stream. Use Kinesis Data Analytics to perform analysis on the data.","correct":false},{"id":"074f8c98d1aa39441f8f17d8ea7f72d5","text":"Create a Kinesis Stream. Configure the CloudTrail S3 bucket notifications with the Kinesis stream as the message destination. Implement a Lambda function to process messages from the Kinesis Stream.","correct":false}]},{"id":"b21cf2a7-0cf1-47d4-a0c2-60403bb9cf37","domain":"CostOptimized","question":"To stay within the AWS Free Tier using Amazon EC2 for the first 12 months of having an AWS account, which of the following instance types should you use?","explanation":"One of the EC2 requirements for staying within the AWS Free Tier is using EC2 micro instances only. That makes t2.micro and t3.micro the correct responses.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc","title":"AWS Free Tier"}],"answers":[{"id":"7d3869f3c790e32d408d21d331095b0b","text":"t3.micro","correct":true},{"id":"affa6cb0576af5aa6e603780fe7b203c","text":"t3a.small","correct":false},{"id":"1d4f2c610dbeb44e7ba09fed19564c76","text":"t2.micro","correct":true},{"id":"ab61127647912c159c3fc08e9a102efc","text":"t2.small","correct":false}]},{"id":"c138fec3-1027-4dc1-9215-b9108252ffab","domain":"Performant","question":"You have a production application that is on the largest RDS instance possible, and you are still approaching CPU utilization bottlenecks. You have implemented read replicas, ElastiCache, and even CloudFront and S3 to cache static assets, but you are still bottle-necking. What should your next troubleshooting step be?","explanation":"If your application requires more compute resources than the largest DB instance class or more storage than the maximum allocation, you can implement partitioning, thereby spreading your data across multiple DB instances.","links":[{"url":"https://aws.amazon.com/rds/faqs/","title":"See 'Q: How can I scale my DB instance beyond the largest DB instance class and maximum storage capacity?'"}],"answers":[{"id":"d7a5a5cf870141d209e3e9cda6322823","text":"You have reached the limits of public cloud. You should get a dedicated database server and host this locally within your own data center.","correct":false},{"id":"062e544e8a9ad6c5491af7b0e682e372","text":"You should provision a secondary RDS instance and then implement and ELB to spread the load between the two RDS instances.","correct":false},{"id":"f08b245b716a56cb1a5a93fe863992a0","text":"You should consider using RDS Multi-AZ and using the secondary AZ nodes as read only nodes to further offset load.","correct":false},{"id":"637dc8debb4ed3bebabdb2faf2cc89c3","text":"You should implement database partitioning and spread your data across multiple DB Instances.","correct":true}]},{"id":"2d66a68a-db0b-46af-93f2-8fbb712d7f8d","domain":"ResilientDesign","question":"Which of the following are the application integration services enable communication between decoupled components in order to build a scalable and more resilient solution?","explanation":"Amazon SQS, Amazon MQ and Amazon App Sync are AWS application integration services. Application integration services enable communication between decoupled components within micro-services, distributed systems, and serverless applications so you can easily build scalable and more resilient solutions. Amazon DataSync is AWS Migration and Transfer service and is not an integration service. AWS SES is a cloud-based email sending service designed for customer engagement.","links":[{"url":"https://aws.amazon.com/products/application-integration/?nc2=h_m1","title":"AWS Application Integration Services"}],"answers":[{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true},{"id":"335523617c1b39d5772d3e75b7da2014","text":"AWS Simple Email Service (SES)","correct":false},{"id":"71f398f7b21d60364b4a577a13a1271f","text":"Amazon Data Sync","correct":false},{"id":"b65c2d4cd3e247c1554f92a08e6ea48b","text":"Amazon App Sync","correct":true},{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":true}]},{"id":"b492e9e4-864d-4ff2-9702-262996b05c46","domain":"Performant","question":"How does AWS deliver high durability for DynamoDB?","explanation":"Amazon DynamoDB is highly available, with automatic and synchronous data replication across three facilities within a Region. This helps protect your data against individual machine, or even facility level failures.","links":[{"url":"https://aws.amazon.com/dynamodb/details/#High_Availability","title":"DynamoDB High Availability"}],"answers":[{"id":"b0991ddf7a0ec7d6b52ed6e7bfc4c119","text":"DynamoDB data is automatically replicated across multiple AZs.","correct":true},{"id":"e8d0300d557f883b2150d8e9c16a64f9","text":"Like S3, DynamoDB is a global service -- data is automatically replicated across multiple AWS Regions.","correct":false},{"id":"9cb98abf406dd2e8a688aeb9c3ffdbcd","text":"DynamoDB supports user Snapshots to S3.","correct":false},{"id":"d617d277b2fd6ec82cdccb131e3676a4","text":"AWS maintains a schedule of incremental backups and log shipping.","correct":false}]},{"id":"6f866b44-3c21-444d-bba6-8e4bd7518c71","domain":"SecureSolutions","question":"You need to configure a new subnet in your VPC for a database cluster you are building. The subnet will never need more than six IP addresses. Which of the following is the best choice for this subnet?","explanation":"Databases generally do not require public access from the Internet, so a private subnet is the better choice from a security perspective. /28 is the smallest possible subnet in an AWS VPC.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.WorkingWithRDSInstanceinaVPC.html","title":"Working with Database Instances in a VPC"}],"answers":[{"id":"36d970f20594c42f714fbe7feb90f0ce","text":"A /28 private subnet","correct":true},{"id":"631501125c3f67c533a6eeb749167f34","text":"A /16 private subnet","correct":false},{"id":"f9f9754c2b663d65bb88ab8ceb7fc40a","text":"A /16 public subnet","correct":false},{"id":"59576e63cff32d93d8d2abef68a6b99e","text":"A /28 public subnet","correct":false}]},{"id":"6af2d489-ba4c-49a6-a1b5-b7b41d27ec82","domain":"ResilientDesign","question":"Your team is designing a new competitive intelligence application for the sales team. Account executives will be able to pull the latest information on another company's product pricing while at customer locations. The application will allow for retrieval of information by product type, version, size, and a number of other characteristics. The database administration team will not support MySQL databases due to professional preferences. Which storage architecture will provide the best resiliency with the least amount of downtime?","explanation":"Amazon Aurora delivers high performance and availability with read replicas, point-in-time recovery, continuous backup, and replication across three Availability Zones. It's active-passive nature requires a brief pause in database activity if a failover from the primary instance to the secondary instance is required. Aurora currently only offers active-active Multi-Master functionality for MySQL databases. Due to the requirement for data join activity, Elastic File System is not a good option. Oracle RAC doesn't run natively on EC2.","links":[{"url":"https://aws.amazon.com/rds/aurora/","title":"Amazon Aurora"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-multi-master.html","title":"Working with Aurora Multi-Master Clusters"}],"answers":[{"id":"07e09461587d7848b81bfb4e0daeabb5","text":"Deploy an Amazon Aurora PostgreSQL Multi-Master cluster accessed by AWS Lambda functions","correct":false},{"id":"6da917908387b9af39547c6e9ab8534d","text":"Implement an Amazon Elastic File System accessed by AWS Lambda Functions","correct":false},{"id":"ebdeb996034c5e0f763c6591b82cc77f","text":"Use an Amazon Aurora PostgreSQL database accessed by Amazon Elastic Container Service containers","correct":true},{"id":"768cf4db1c73a7ca24f37004c5206aab","text":"Deploy an Oracle RAC cluster on Amazon EC2 accessed by EC2 instances in an Auto Scaling Group","correct":false}]},{"id":"09223b1a-2169-4791-94b1-9ecf1716c8eb","domain":"Performant","question":"Which of the following AWS services store data as key-value pairs?","explanation":"Both DynamoDB and S3 use key-value pairs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html","title":"Working With S3 Objects"},{"url":"https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs","title":"DynamoDB Data Models"}],"answers":[{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false}]},{"id":"0b32b547-cba2-4db6-bd51-fa085a318c33","domain":"SecureSolutions","question":"You are working for a real estate company and you need to be able to record configuration changes to Amazon RDS DB Instances, DB Subnet Groups, DB Snapshots, DB Security Groups, and Event Subscriptions. Which AWS service should you use to achieve this?","explanation":"You can use AWS Config to continuously record configurations changes to Amazon RDS DB Instances, DB Subnet Groups, DB Snapshots, DB Security Groups, and Event Subscriptions and receive notification of changes through Amazon Simple Notification Service (SNS).","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/WhatIsConfig.html","title":"About AWS Config"}],"answers":[{"id":"74c9a0ed16e6de2d66b6b9663ac3e5cb","text":"CloudAudit","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false}]},{"id":"b974c044-33bf-4fe8-9edd-1cdac5b32fa5","domain":"Performant","question":"Your new cost tracking application runs on AWS Lambda and Amazon RDS PostgreSQL. All testing has shown that the software is ready for production. Shortly after launch, users begin complaining about performance issues. After some investigation, you suspect a database query problem. What approach will you take to diagnose and resolve the problem in the most operationally efficient way?","explanation":"RDS Performance insights provides an easy-to-understand dashboard for detecting performance problems on both RDS and Aurora database instances. You can monitor SQL queries that caused load and I/O waits, and you can identify the users and hosts through which the queries ran. A slow running query using a DISTINCT clause for a one-to-many join will benefit from removing the DISTINCT clause and adding an EXISTS qualifier to the WHERE clause. Using a native PostgreSQL tool like pgBadger will work, but it requires extra work to set logging parameters in the RDS parameter group. Adding a GROUP BY clause will not improve performance in this case.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.html","title":"Using Amazon RDS Performance Insights"},{"url":"https://aws.amazon.com/blogs/database/optimizing-and-tuning-queries-in-amazon-rds-postgresql-based-on-native-and-external-tools/","title":"Optimizing and tuning queries in Amazon RDS PostgreSQL based on native and external tools"}],"answers":[{"id":"436d7294f9c14ac6bd54f376404a16f3","text":"Install a PostgreSQL native tool like pgBadger on an EC2 instance to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to remove the DISTINCT clause and add an EXISTS qualifier to the WHERE clause.","correct":false},{"id":"cb046ece5a7170684077db42c1f41742","text":"Use RDS Performance Insights to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to remove the DISTINCT clause and add an EXISTS qualifier to the WHERE clause.","correct":true},{"id":"04ad0f28212ab7830934651ac9ec003b","text":"Install a PostgreSQL native tool like pgBadger on an EC2 instance to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to add a GROUP BY clause.","correct":false},{"id":"2b25e3600ffb4b52d5931af53bb18834","text":"Use RDS Performance Insights to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to add a GROUP BY clause.","correct":false}]},{"id":"d87fd5d8-0ab7-4f87-a1c1-0635871020ca","domain":"SecureSolutions","question":"You work for a security company that stores highly sensitive documents on S3. One of your customers has had a security breach and, as a precaution, they have asked you to remove a sensitive PDF from their S3 bucket. You log in to the AWS console using your account and attempt to delete the object. You notice that versioning is turned on, and when you dig a little deeper you discover that you cannot delete the object. What may be the cause of this?","explanation":"Only the owner of an Amazon S3 bucket can permanently delete a version.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/delete-or-empty-bucket.html","title":"Deleting and Emptying S3 Buckets"}],"answers":[{"id":"be0a836d5e8a55696d3634aff7f51473","text":"You can never permanently delete an object on S3 after versioning is enabled.","correct":false},{"id":"6cca1efe9e60d13f3b73e61daaa6ba12","text":"S3 server-side encryption is preventing you from doing this.","correct":false},{"id":"96952afde438b94cf1de90e31b71d6bd","text":"You must be logged in as a Super User to delete objects.","correct":false},{"id":"34815cde786bfe064a8e2da0c0dfdcb6","text":"You cannot delete the object because you are not the bucket owner.","correct":true}]},{"id":"f85240a5-118e-4367-b2ed-0c442a60bec4","domain":"ResilientDesign","question":"You currently have a web application that uses two EC2 instances and you want 75% of the web traffic to go to one server and the other 25% to go to the other. Which of the following routing policies should you choose?","explanation":"You need a weighted routing policy because you want to be able to set the proportions traffic routed to your servers. A simple routing policy would have been ideal if you had a single server. Although failover and geolocation routing policies are for routing traffic to more than one resource, the former is ideal for configuring active-passive failover, and the latter is for specifying location rather than traffic proportions.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"323d4eb70b252acb4a04eaf9e0882597","text":"Geolocation","correct":false},{"id":"7388404ef116c3ff812bfd290b094d9e","text":"Failover","correct":false},{"id":"582368ac8232617ead14ac74ccc40ea9","text":"Weighted","correct":true},{"id":"1fbb1e3943c2c6c560247ac8f9289780","text":"Simple","correct":false}]},{"id":"4884c069-b179-4be0-ba18-d5fbfdd15e99","domain":"CostOptimized","question":"Your fleet of EC2 instances is running 100% of the time, and there is no reason to believe that the demand will decrease. What pricing model might you use to reduce costs?","explanation":"Reserved Instances provide you with a significant discount (up to 75%) compared to On-Demand instance pricing. You have the flexibility to change families, OS types, and tenancies while benefiting from Reserved Instance pricing when you use Convertible Reserved Instances.  To maintain a fleet of Spot instances you would need to be bidding fairly high, so it is likely the RIs will give you a better price point. But you would need to check.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","title":"About Reserved Instances"}],"answers":[{"id":"02982929de0aab45a9fe119838ad82e6","text":"On-Demand Instances","correct":false},{"id":"d1328967694907a29a579faae6055cae","text":"Special Instances","correct":false},{"id":"29068f6044e3fedf44165e646a2d2bb1","text":"Reserved Instances","correct":true},{"id":"026db7f2265667575c05772f32778b8a","text":"Spot Instances","correct":false}]},{"id":"58af5529-d965-4ab9-ae2f-a906c0b8c41e","domain":"Performant","question":"You've enabled website hosting on a bucket called 'aspiring-guru' in the us-west-2 Region. Which of the following is the URL that will be assigned to your website?","explanation":"Your bucket name *always* comes first. 's3-website', followed by the Region, *always* comes next.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Website Hosting"}],"answers":[{"id":"09cbf53f89e143efb0fb279e5d14b9e8","text":"s3-website-us-west-2.aspiring-guru.amazonaws.com","correct":false},{"id":"b7ac852a2cf809dc4fb801df9b658c8a","text":"aspiring-guru.s3-website-us-west-2.amazonaws.com","correct":true},{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"eff2fbc9e562b82d9381082df00c92d6","text":"s3-website.aspiring-guru-us-west-2.amazonaws.com","correct":false}]},{"id":"d5d30bcd-fdb1-44d2-88ab-5f84a76d7054","domain":"CostOptimized","question":"Comma-delimited files with information about how customers navigate your company website arrive from a third party on a nightly basis. The data is pre-sorted by the third party for concurrent access by multiple compute instances running in the AWS cloud. Which storage service will provide the highest cost optimization for the solution?","explanation":"Since the data is pre-sorted by the third-party, a relational database is unnecessary. Amazon Elastic File System provides a more cost-effective solution. Amazon Elastic Block Store storage cannot be shared across multiple instances, and Amazon ElastiCache will be a higher cost solution.","links":[{"url":"https://aws.amazon.com/efs/","title":"Amazon Elastic File System"}],"answers":[{"id":"6b039cd7fadc9d6a3d6a936b729c3900","text":"Amazon RDS for SQL Server","correct":false},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false},{"id":"02f85544eeded6ef1b6c40d62bcadddd","text":"Amazon Elastic File System","correct":true},{"id":"4b6ccd94421822eaaf7bd027992018af","text":"Amazon Elastic Block Store","correct":false}]},{"id":"b09415bc-dd01-42c0-a7f8-f3603cd59468","domain":"CostOptimized","question":"You need to automatically migrate objects from one S3 storage class to another based on the age of the data. Which S3 service can you use to achieve this?","explanation":"S3 Lifecycle management provides the ability to define the lifecycle of your object with a predefined policy and reduce your cost of storage. You can set lifecycle transition policy to automatically migrate Amazon S3 objects to Standard - Infrequent Access (Standard - IA) and/or Amazon Glacier based on the age of the data.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html","title":"S3 Object Lifecycle Management"}],"answers":[{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"fa532045e834ec2fac1200964a189516","text":"Lifecycle Management","correct":true},{"id":"b1926a8ac417114ef193a282594538c7","text":"Infrequent Access","correct":false},{"id":"5b6019950a69fdc69d23187a8254c7b4","text":"Reduced Redundancy","correct":false}]},{"id":"201115d1-c8eb-40b2-99f7-a7bdc873415e","domain":"ResilientDesign","question":"If you deploy an ELB-Classic as part of your VPC web app which is true","explanation":"An ELB-Classic Load Balancer in an EC2-Classic (Legacy, nonVPC) environment it can have an associated IPv4, IPv6, and dual-stack (both IPv4 and IPv6) DNS name, and supports IPv6 on the External/public interface.  However inside a VPC IPv6 is not supported on the external or internal interface(s).","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/#Details_for_Elastic_Load_Balancing_Products","title":"Public DNS Names for Your Load Balancer"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-internet-facing-load-balancers.html","title":"Internet-Facing Classic Load Balancers"},{"url":"https://aws.amazon.com/about-aws/whats-new/2017/01/announcing-internet-protocol-version-6-ipv6-support-for-elastic-load-balancing-in-amazon-virtual-private-cloud-vpc/","title":"IPv6 & ALBs"}],"answers":[{"id":"cefc0897ae3b7657719ffbe65a40690d","text":"The inward facing interface supports IPv4 addressing","correct":true},{"id":"f1b0e8335cc3141d8a839113b08e7d64","text":"The outward facing interface supports IPv6 addressing","correct":false},{"id":"0cc7e342248d1e776b6a5b2be595a293","text":"The Listener can be set up to distribute 'Apache Derby Network Server'(1527) connections","correct":true},{"id":"6225c3cb563136a130f426ead0fee025","text":"AWS publishes a Dual-stack (both IPv4 and IPv6) DNS name on R53","correct":false},{"id":"dbb768359241c4036c277451c201e3ea","text":"The outward facing interface supports IPv4 addressing","correct":true},{"id":"b93f3b7545f37cf29d0c55ac7fab99c6","text":"The inward facing interface supports IPv6 addressing","correct":false}]},{"id":"331294bf-39e7-425e-9bac-d8b0d7f3c5b9","domain":"Performant","question":"You have a data warehouse on AWS utilizing Amazon Redshift of 50 Tb. Your data warehouse is located in us-east-1 however you are opening a new office in London where you will be employing some data scientists. You will need a copy of this Redshift cluster in eu-west-2 for performance and latency considerations. What is the easiest way to manage this migration?","explanation":"Where AWS provides a service, it is wise to use it rather than trying to create a bespoke service.  The AWS service will have been designed and tested to ensure robust and secure transfer taking into account key management and validation.","links":[{"url":"https://docs.aws.amazon.com/redshift/latest/mgmt/managing-snapshots-console.html#xregioncopy-kms-encrypted-snapshot","title":"Cross-Region Snapshot Copy"}],"answers":[{"id":"b3e2fd4ff81f2e4fff2f071064c717b0","text":"Order an AWS Snowball. Export the Redshift data to the Snowball and then ship the snowball from us-east-1 to eu-west-2. Load the data into Redshift in London.","correct":false},{"id":"fcdde9340024a4e534cb48d9980a5511","text":"Export the data to S3 using Data Pipeline and configure Cross Region Replication to an S3 bucket based in London. Use AWS lambda to import the data back to Redshift.","correct":false},{"id":"391581e947946e86d8de1e84eaadaf1e","text":"Create a new redshift cluster in eu-west-2. Once provisioned use AWS data pipeline to export the data from us-east-1 to eu-west-2.","correct":false},{"id":"ebe9254e3a4f7de6dbfc80c13f29082d","text":"In the AWS console go in to Redshift and choose Backup, and then choose Configure Cross-Region Snapshots. Select Copy Snapshot and then choose the eu-west-2 region. Once successfully copied use the snapshot in the new region to create a new Redshift cluster from the snapshot.","correct":true}]},{"id":"7589448c-e00c-4c64-9d5f-04e10ac556e4","domain":"CostOptimized","question":"An enterprise is planning to move its on-premise application to AWS cloud. The enterprise planned to build the non-production applications first as a proof of concept, and the governance team has provided approval for downtime for a brief period if cost can be compensated. You recommend spot instances as this satisfies the scenario explained above. Do vCPU limits apply when requesting a spot instance?","explanation":"Amazon EC2 is transitioning on-demand instance limits from the current instance count-based limits to vCPU-based limits to simplify the limit management experience for AWS customers. Beginning September 24, 2019, customers can opt in to vCPU-based instance limits. Count-based instance limits will not be available or supported after November 8, 2019. The vCPU-based limits only apply to running on-demand instances and does not apply when purchasing reserved or spot instances.","links":[{"url":"https://aws.amazon.com/ec2/faqs/","title":"Amazon EC2 compute service features"}],"answers":[{"id":"9bfb4cfa201ec7e2242c7df2c0d39906","text":"vCPU limits apply to spot instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false},{"id":"1fe04947ca4403eb3588fb87310de29e","text":"vCPU limits apply to reserved instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false},{"id":"a4fb94942aaa43d251b18a4126ce6d18","text":"In AWS, only instance count based limits exist and there is no concept of vCPU limits.","correct":false},{"id":"34394b797e4a477511982b1ac4a38d19","text":"vCPU limits apply only to on-demand instances and do not apply for spot instances.","correct":true}]},{"id":"1526073d-2742-4b82-87d5-3949f4737c27","domain":"ResilientDesign","question":"Your manager has approached you about storing image and video files for the company website (which is very popular) in AWS. These files need to be immediately available when requested. The company cannot afford for these files to go missing and they must survive an outage of an Availability Zone. Which of the following S3 Storage Tiers is best suited for this request?","explanation":"S3 Standard offers high durability, availability, and performance object storage for frequently accessed data.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#General_purpose","title":"Amazon S3 Storage Classes - General purpose"}],"answers":[{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"57eb154f0b5fcce31260dba603e6a6a4","text":"S3 One Zone - Infrequently Accessed","correct":false},{"id":"a4172aee8a692bd73f2781afe65fda72","text":"S3 Infrequently Accessed","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":true}]},{"id":"a0f81c00-4d69-4eda-ab8e-4a3c3ff8162b","domain":"ResilientDesign","question":"You have been tasked with creating a secondary copy of your production environment - this environment is located in US-EAST-1 and the copy will need to exist in US-EAST-2. Which of the below resources will need to be copied or created in US-EAST-2?","explanation":"IAM Roles and Route 53 records are global, and do not need to be created in the new region. VPCs and security groups are regional entities and therefore will need to be re-created.","links":[],"answers":[{"id":"d85c80578ad0849a611c1056b63e385c","text":"VPC","correct":true},{"id":"5af83476a58c870df52d1d246574922c","text":"IAM Roles","correct":false},{"id":"452cd4369ec5aa9b91c10fb0b19f352b","text":"Route 53 records","correct":false},{"id":"fe11e14b29ee1462bdb7764b3ba2f4bd","text":"Security Groups","correct":true}]},{"id":"a33133b0-1731-4f6e-b38b-4aaf31d64a45","domain":"Performant","question":"You currently have a web app that is using a Microsoft SQL Server database hosted in RDS, using a db.m5.xlarge instance. This application is read-heavy, and as the number of users of the app has increased, you have noticed a gradual degradation of performance. With a recent marketing push, you are at the stage where performance is no longer acceptable and something needs to be done to improve it. At this stage cost is not an issue, and you are looking for the option which will give the best performance increase. Which option would you choose?","explanation":"Although read replicas are usually the correct choice when discussing read performance, RDS Read Replicas are not available for Microsoft SQL, ruling this option out. Moving from a memory optimized (M-class) to a compute optimized (C-class) would only help in this case if the size of the Compute instance was larger - since the primary concern here is reads, extra memory will provide a better outcome. As there is a similar sized M-class option available as one of the answers, a C-class instance is not the answer. Not to mention that moving from RDS to an EC2 instance would introduce a lot of management overhead. Throughput Optimized disk is backed by standard hard drives (non-SSD), and will therefore give worse performance that General Purpose as these are SSD backed. This leaves the resizing to an db.m5.2xlarge instance as the best of the options provided.","links":[{"url":"https://aws.amazon.com/rds/details/read-replicas/","title":"Amazon RDS Read Replicas"},{"url":"https://aws.amazon.com/ebs/features/?nc=sn&loc=1","title":"EBS Volume Types"},{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types"}],"answers":[{"id":"dd2623a54a7d521619db9426332d60a0","text":"Change the underlying instance type to a db.m5.2xlarge instance","correct":true},{"id":"55d73c9a33e38a32b3a2dabd8d1d9cb0","text":"Deploy an RDS Read Replica for the database","correct":false},{"id":"d25db331f475d77fa6cbbbdd0fd04670","text":"Change the underlying EBS volume from General Purpose to Throughput Optimised type","correct":false},{"id":"187905872afd5e73e4d0760c852fa482","text":"Migrate the database to a c5.2xlarge EC2 instance","correct":false}]},{"id":"7d17894a-afd7-44cf-8ef0-0b4698e75902","domain":"Performant","question":"You need to upgrade your RDS database to a larger instance class and you must minimize the amount of disruption to your business as much as possible. What should you do.","explanation":"When upgrading an RDS instance class your database will be temporarily unavailable while the DB Instance Class is modified. This period of unavailability typically lasts only a few minutes, and will occur during the maintenance window for your DB Instance, unless you specify that the modification should be applied immediately.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ModifyInstance.MySQL.html","title":"Modifying an RDS Instance"}],"answers":[{"id":"088f69f13b003fa224256412f3a2e237","text":"Do the upgrade using the AWS CLI using the option --NOREBOOT","correct":false},{"id":"9645ca2d23347fd27cb00e4048158900","text":"Do the upgrade using the AWS console and ensure the 'do not reboot' option is checked when upgrading.","correct":false},{"id":"9e621f1fb2263ab1552a7d3086c500a7","text":"Schedule the upgrade for a maintenance window during a time when you have the fewest possible customers. The production database should only be unavailable for a couple of minutes.","correct":true},{"id":"64c0cf5fc5de497475145808fffcff77","text":"You do not need to worry: when upgrading an instance class, your database will not go off line.","correct":false}]},{"id":"4eb40e8a-8251-44ca-a55f-7a2d2e39a78c","domain":"CostOptimized","question":"A large company is running multiple Amazon EC2 and Amazon RDS services across several AWS Regions. You are an AWS consultant and the company approaches you to provide recommendations on how to reduce operational cost without any major changes. The company confirms that certain instances are required to be run only during business hours from 8AM to 6PM on weekdays and can be shutdown on weekends and non-business hours. Which of the following automated solutions best matches the requirements?","explanation":"AWS offers infrastructure on demand so that customers can control their resource capacity and pay only for what they consume. One simple method to reduce costs is to stop resources that are not in use, and then start those resources again when their capacity is needed. The AWS Instance Scheduler is a simple AWS-provided solution that enables customers to easily configure custom start and stop schedules for their Amazon EC2 and Amazon RDS instances. The solution is easy to deploy and can help reduce operational costs for both development and production environments. Customers who use this solution to run instances during regular business hours can save up to 70% compared to running those instances 24 hours a day. AWS Auto Scaling is not a correct solution as auto-scaling groups can contain Amazon EC2 instances from multiple Availability Zones within the same Region and cannot contain instances from multiple regions. As the company confirms that the instances are required to be run during Business hours, Spot Instance is not a good choice as spot instances may be terminated if the spot price is higher than the bid price. Also, moving AWS Instances to lesser configurations is neither an automated solution nor guarantees saving operational cost if run 24 hours.","links":[{"url":"https://docs.aws.amazon.com/solutions/latest/instance-scheduler/overview.html","title":"AWS Instance Scheduler"}],"answers":[{"id":"f657bd5509ffc79a6cb033747ff52f50","text":"Move AWS instances to lesser configuration Instance Type","correct":false},{"id":"2f766b7c3ac605171e839f447d7e239c","text":"AWS Auto Scaling","correct":false},{"id":"c9eccc5399c22049703ce9be447d23d7","text":"AWS Instance Scheduler","correct":true},{"id":"f4bf61a51bd424cab4d9129fd4f2ef6a","text":"Move Instances to Spot Instances","correct":false}]},{"id":"536131e1-bbd8-4ef5-b765-4bd089487b28","domain":"Performant","question":"Your on-premise servers are running low on disk storage space, but your company is not yet ready for a complete move to the public cloud. You've been tasked with finding an interim storage solution that also offers backup and archiving capabilities. Which AWS service would you recommend to meet this immediate need?","explanation":"Storage Gateway is a storage solution that provides on-premise capacity while taking advantage of some of the benefits of Cloud Storage.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/StorageGatewayConcepts.html#storage-gateway-cached-concepts","title":"Gateway-Cached Volumes Architecture"}],"answers":[{"id":"759533f205f8af35f7da47dc76331eee","text":"Storage Gateway with Gateway-Stored Volumes.","correct":false},{"id":"c0429b6a658dd488f7262d983c7e02bb","text":"Snowball","correct":false},{"id":"cdd0d04de2b79c78e792aec6263d2d3d","text":"DirectConnect","correct":false},{"id":"04567b32a7bb8490dda99a0fe4c3323a","text":"Storage Gateway with Gateway-Cached Volumes","correct":true}]},{"id":"30e234fe-027c-4ba0-b92a-717833173b25","domain":"CostOptimized","question":"The pharmaceutical company you work for has an aggressive schedule to bring a number of new products to market. You’d like to provide a library of metabolism assessment functions to application developers across the various teams so that each one doesn’t have to write their own. Which AWS compute solution will be the most cost-effective to host this library?","explanation":"A microservices architecture provides the most cost-effective environment for a library of code, and the serverless nature of AWS Lambda allows you to do that with zero administration. You could host your microservices on Elastic Container Service, but the serverless nature of Lambda makes it more cost-effective. EC2 Spot and Reserved Instances provide lower cost options to EC2 On-Demand, but not lower than Lambda executions.","links":[{"url":"https://aws.amazon.com/lambda/","title":"AWS Lambda"}],"answers":[{"id":"dee7ff8f7b10b9d388c7c561e9413b0d","text":"AWS Lambda","correct":true},{"id":"8a869b4068c02de382b5cb07d67b4479","text":"Amazon EC2 Spot Instances","correct":false},{"id":"2f9fc8b2a7a4c8ac66ec03afff926e96","text":"Amazon EC2 Reserved Instances","correct":false},{"id":"0383d27e1438422d247bbe8ffedfe1d4","text":"Amazon Elastic Container Service","correct":false}]},{"id":"6a9be830-9658-4f9f-a5ea-518038423adb","domain":"ResilientDesign","question":"You're running an application that needs to be highly available in eu-west-1. In order for this application to function correctly,  9 related EC2 instances must running at all times. Which of the following deployments provides the ability to meet the requirements should an AZ go down and is the most cost optimized solution?","explanation":"Should an AZ go down, only the answers of 5,5,5 or 6,6,6 or 9,9,0 would meet the requirement of having 9 EC2 instances up, with the most cost optimized being the answer with 15 total EC2 instances.","links":[{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Cost-Optimization-Pillar.pdf","title":"Cost Optimization Pillar - AWS Well-Architected Framework"},{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Reliability-Pillar.pdf","title":"Reliability Pillar - AWS Well-Architected Framework"}],"answers":[{"id":"23ed0726519369cf6068f29abb57e8e7","text":"3 EC2 instances in eu-west-1a, 3 EC2 instances in eu-west-1b, and 3 EC2 instances in eu-west-1c.","correct":false},{"id":"6d68ff6a6b53ca045964ee07faeeab96","text":"5 EC2 instances in eu-west-1a, 5 EC2 instances in eu-west-1b, and 5 EC2 instances in eu-west-1c.","correct":true},{"id":"640aac80e904b262d7fadd12c44a5802","text":"9 EC2 instances in eu-west-1a, 9 EC2 instances in eu-west-1b, and no EC2 instances in eu-west-1c.","correct":false},{"id":"3c730af5a3243511e706f8068c1afc8c","text":"6 EC2 instances in eu-west-1a, 6 EC2 instances in eu-west-1b, and 6 EC2 instances in eu-west-1c.","correct":false}]},{"id":"22315d49-9040-4de7-ae4f-ead04e5b4966","domain":"CostOptimized","question":"An application that performs statistical analysis on weather data receives files once a week. It assimilates the data in these files with previously collected data via its algorithms, and publishes a report at the end of each month. At unspecified times during the week, interim results need to be made available to meteorologists within minutes. Which architecture will meet the data availability requirements for the solution at the least cost, and with the simplest application code?","explanation":"Hibernating an EC2 instance provides a warm-start capability. When an EC2 instance is hibernated, RAM contents are saved to the EBS root volume. RAM contents are reloaded when the instance is restarted. AWS doesn't charge for the time that an instance is in the hibernated state. Storing data in Amazon DynamoDB costs more than EBS. EMR clusters cost more than EC2 instances. Stopping an EC2 instance clears RAM and requires the application to reload the data from a storage source when the instance is restarted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html","title":"Hibernate Your Instance"}],"answers":[{"id":"1270950fb1ac5049d96bd1c8633745fe","text":"Process the data on EC2 and stop the instance until new data files arrive or an interim results request is made","correct":false},{"id":"79010e5d6c3a7a1b4739890ce79939bd","text":"Process the data on EC2 and store temporary results in Amazon DynamoDB","correct":false},{"id":"e45f5352867fe69bdbc5efaad38e34b2","text":"Process the data on a transient EMR cluster and store temporary results in S3","correct":false},{"id":"591c99dbc7dc2331d09abbc9ee1fb721","text":"Process the data on EC2 and hibernate the instance until new data files arrive or an interim results request is made","correct":true}]}]}}}}
