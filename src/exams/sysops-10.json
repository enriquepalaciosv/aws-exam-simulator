{"data":{"createNewExamAttempt":{"attempt":{"id":"3575c6ea-fe10-4d39-b027-ae3f871f11e7"},"exam":{"id":"3ff35c2a-ba29-4155-a065-e7c987d6588e","title":"AWS Certified SysOps Administrator - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"bc639267-4b1b-4a5e-820e-27495782af83","domain":"data-man","question":"You have a mobile gaming application that uses an RDS MySQL database. The allocated storage of the database instance is 100GiB. As users are adopting rapidly, the available database storage is also rapidly decreasing, and will soon lead to performance issues if additional storage capacity is not added soon. Which of the following statements is correct in terms of addressing this database storage issue?","explanation":"You can manually scale up the storage. There is no outage during scaling and the performance of the server is not degraded. When the storage is modified, the change can be applied immediately. You can also enable auto scaling to automatically adjust the storage.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PIOPS.StorageTypes.html","title":"Working with storage for Amazon RDS DB instances"}],"answers":[{"id":"528fd2301cd5c616abc137beeb7755e9","text":"The database status is \"degrading\" when you scale up the storage.","correct":false},{"id":"65998a26d3cbe450d273182cc29db11d","text":"You have to wait until the next scheduled maintenance window to apply the change.","correct":false},{"id":"bea16cc246ddc8340245b09063aeb7e8","text":"The database has an outage for a short period when the storage is being modified.","correct":false},{"id":"7a4336887970da0724cffecb782ab21f","text":"You can enable the RDS Storage Autoscaling feature to avoid manually scaling up the database storage.","correct":true}]},{"id":"386d9e39-b0a3-498b-9157-f845a768869a","domain":"mon-rep","question":"Which of the following are valid EC2 Auto-Scaling instance health statuses?","explanation":"Auto-scaling EC2 instances are either healthy or unhealthy.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/healthcheck.html","title":"Health Checks for Auto Scaling Instances"}],"answers":[{"id":"46c4c4d980dfe025ae5b35aa0011dde4","text":"Alarm","correct":false},{"id":"a9409139570c30da21e2629ed2d65361","text":"Compromised","correct":false},{"id":"396d45b57c2fbe3318e7b93272a2686b","text":"Healthy","correct":true},{"id":"2b329fc84084b45754e42488aca3114b","text":"Unhealthy","correct":true}]},{"id":"daea596c-77ce-4763-bc26-c7eabbeb3fed","domain":"automation","question":"The CTO of an e-commerce company has mandated the use of Infrastructure as Code (IaC) services and tools to manage the application resources and processes. The engineering team has divided the resources into two groups: application resources and network (VPC) resources. The engineering team lead has been instructed to transform the configuration of these resources into templates that can easily be configured to prepare different environments. How can the engineering team lead accomplish this?","explanation":"CloudFormation can be used for the IaC requirements in provisioning and managing AWS resources including VPC resources and other managed services. Out of all the options, only OpsWorks can be used as a Configuration Management service for the management application level processes and workloads inside EC2 instances. OpsWorks is not used for provisioning network resources. Amazon EKS is for managing and orchestrating containers using Kubernetes.","links":[{"url":"https://docs.aws.amazon.com/opsworks/latest/userguide/welcome.html","title":"OpsWorks"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc.html","title":"EC2 VPC"}],"answers":[{"id":"9328d9954617430931d24f7812f5d613","text":"Use Amazon EKS for the network resources. Use OpsWorks for the application resources.","correct":false},{"id":"1148de578466f53ad53ec6613254366b","text":"Use CloudFormation for the network resources. Use OpsWorks for the application resources.","correct":true},{"id":"450822349ee2cf9d667ee39de6b39f39","text":"Use CloudFormation for the network resources. Use AppSync for the application resources.","correct":false},{"id":"17ad6545a81ec8297ada8e103fe040f9","text":"Use OpsWorks for the network resources. Use CloudFormation for the application resources.","correct":false}]},{"id":"29e51c05-d93d-4868-9c14-8c7940bf9d4c","domain":"security-comp","question":"The CFO has raised concerns about rising AWS costs and has asked you to look into this potential issue. When you look at CloudTrail logs you notice that certain IAM Users in multiple AWS accounts within your organization are using AWS services without discretion, and these services are not relevant to their business functions. How would you implement security policies to limit which AWS services these users can access in the most effective way?","explanation":"Creating IAM policies for each IAM User is not best practice and can become an administrative burden. AWS GuardDuty does not provide IAM-related services, and thus is irrelevant. It is not possible to view CloudTrail logs at the OU level. The best solution is to use Service Control Policies (SCPs) to govern use of the AWS environment at the OU level.","links":[{"url":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html","title":"AWS Organizations: Service Control Policies (SCPs)"}],"answers":[{"id":"5b2ff64d8adf96a19f7dc89c3b3d76ef","text":"Attach a Service Control Policy at the Organization Unit to blacklist AWS Services that all Accounts under the OU shouldn't use.","correct":true},{"id":"93faedb0826b3c6a97423da318c0b775","text":"Use AWS GuardDuty to detect and monitor each IAM Users' activity to document unauthorized behavior.","correct":false},{"id":"c6d620763c9f148cf7eaab8ef0467d62","text":"Send CloudTrail logs at the Organizational Units' level to CloudWatch Events. Use Lambda to change IAM permission to DENY any AWS service if users attempt to use non-business critical services.","correct":false},{"id":"633fa64e9f9d9f6b601b4400d9ca6b30","text":"Identify the IAM Users within each Organizational Unit. Attach IAM policies to each user to restrict access based on each users' job function.","correct":false}]},{"id":"4f95f73a-fabd-44b4-a043-0bdee8159a99","domain":"security-comp","question":"You are a SysOps Administrator running security checks throughout your AWS environment. Your AWS account recently launched a new application and you need to ensure access to the application's web servers is restricted to certain ports. How would you implement a policy so that SSH traffic from port 3389 is restricted?","explanation":"The restricted-common-ports checks whether the incoming SSH traffic for the security groups is accessible to the specified ports. The rule is COMPLIANT when the IP addresses of the incoming SSH traffic in the security group are restricted to the specified ports. This rule applies only to IPv4. Amazon Inspector helps to identify security vulnerabilities as well as deviations from security best practices in applications, but not for security groups.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/restricted-common-ports.html","title":"AWS Config rules"}],"answers":[{"id":"3783cbf28ccda5bf3b6aa20d913bb34e","text":"Set up and activate the restricted-common-ports AWS Config rule.","correct":true},{"id":"c2e5ba2c7f9b96b874027fd22e836d7d","text":"Restrict the application to run only on Linux/Unix instances.","correct":false},{"id":"6e274e1e00f14fe4302875974cf5b4c1","text":"Architect your application using the IPv6 communications Internet Protocol.","correct":false},{"id":"3bd73de961085bba965e8589f52a6c08","text":"Install the Amazon Inspector agent on your application to run automated security assessments to identify and restrict any SSH traffic originating from port 3389.","correct":false}]},{"id":"113a7914-1249-4e12-a748-03392c0570e8","domain":"high-avail","question":"You are a Security Administrator for your company. Your CIO wants to ensure that company data is highly available in multiple AWS Regions. What would you suggest to your CIO as the most effective approach?","explanation":"Deploying a multi-AZ RDS instance would only make it fault tolerant between Availability Zones, and not AWS Regions. Creating a Lambda function and creating/deploying EBS snapshots into different AWS Regions would both be an administrative and operational burden. The easiest, most effective, way is to utilize S3 Cross Region Replication","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 Cross Region Replication"}],"answers":[{"id":"a4ca2ada50730e36dd0f3302f60ab0dc","text":"Create multiple snapshots of your company data on EBS volumes. Deploy those EBS volumes on EC2 instance in different AWS Regions.","correct":false},{"id":"f876473fb6289d5a1e3e6d449713b0e7","text":"Copy the company data to an RDS instance. Deploy a multi-AZ configuration for your RDS instance to make it highly available.","correct":false},{"id":"6e22da724261694b4ecf8fa105ef5174","text":"Enable Cross-Region Replication on your bucket to copy objects to a destination bucket in another AWS Region.","correct":true},{"id":"fbde7989c5f0da5bb91bb5593f9c8e4e","text":"Create a Lambda function that downloads data from your S3 Bucket and executes a PUT operation to upload copied objects into a new bucket in a new Region.","correct":false}]},{"id":"89d55a3e-4442-4e1a-9700-ca84f89c2bd2","domain":"security-comp","question":"As a consultant, many of your AWS clients come to you for answers regarding security on AWS. One client is concerned about data confidentiality and security running on their EC2 instances. The client has learned that the same instance host is shared between multiple AWS customers. She has asked you if sharing the resource would make it easy to hack into her resource to obtain confidential data. Which of the below responses would ease your client's concerns?","explanation":"256-bit AES is used for encrypting the data. Ensuring the isolation of the VMs running on a hypervisor is not the purpose of AES-256. CMKs are also used for encrypting data but have no part in securing underlying hardware. IAM permissions have nothing to do with the isolation of the VMs running on a hypervisor. The shared responsibility model for infrastructure services, such as Amazon Elastic Compute Cloud (Amazon EC2) for example, specifies that AWS manages the security of the following assets: Facilities, Physical security of hardware, Network infrastructure, Virtualization infrastructure.","links":[{"url":"https://d0.awsstatic.com/whitepapers/aws-security-best-practices.pdf","title":"AWS Security Best Practices"}],"answers":[{"id":"3341fae60e0212eff137abdf4602fa85","text":"EC2 instances running on the same physical host are isolated from each other via the hypervisor.","correct":true},{"id":"74a2e39c263c57894c9cd11a70b72db8","text":"EC2 instances running on the same physical host are isolated from each other via IAM permissions per AWS account.","correct":false},{"id":"5a474b0ed68df81d57c5bddfb611f66c","text":"EC2 instances running on the same physical host are isolated from each other via Customer Master Keys (CMKs) under KMS policies that you own and manage.","correct":false},{"id":"748cb8264234b20c598b5ca25cfed5a2","text":"EC2 instances running on the same physical host are isolated from each other via 256-bit Advanced Encryption Standard (AES-256).","correct":false}]},{"id":"fa06cd79-3e11-4410-b67d-078ff338c946","domain":"automation","question":"A FinTech company has been aggressively managing their AWS resources using CloudFormation templates. The company has started using a new AWS service that is not yet available in CloudFormation. The engineering team has been given the strict compliance requirement of making sure that all resources need to be deployed and orchestrated automatically. The engineering manager has also been instructed to ensure that the team does not over-engineer or over-complicate the solution. How can the team accomplish this?","explanation":"Given that CloudFormation may not necessarily support new AWS resources and products right away, CloudFormation custom resources will allow CloudFormation to use another resource such as AWS Lambda to create resources on its behalf and continue the processing of the template after the Lambda function has completed its execution. AppSync is not used to generate new AWS service resources and is used primarily for hosting GraphQL powered APIs. Generating an Elastic Beanstalk environment would over-complicate the solution. Using nested stacks would not solve the unsupported service issue of CloudFormation.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html","title":"AWS CloudFormation - Template Custom Resources"}],"answers":[{"id":"1c3eb64e993a1f308aa47da24cfd0143","text":"Use nested stacks in CloudFormation to generate the new AWS service resource","correct":false},{"id":"4eb557d837b6a756dabf8724f0237688","text":"Use custom resources in CloudFormation to generate the new AWS service resource","correct":true},{"id":"19a39cb24cfb7593d023becd2b712ec3","text":"Generate an Elastic Beanstalk environment in CloudFormation that generates the new AWS service resource","correct":false},{"id":"97ebd9f4402ff1438c34af60ee4997f2","text":"Generate an AppSync resource in CloudFormation that generates the new AWS service resource","correct":false}]},{"id":"9c6bdf99-3728-43be-9772-59500b1f2276","domain":"dep-prov","question":"A team of developers plans to migrate their GraphQL-powered web application to AWS and the development lead has been instructed to use managed services whenever possible. How can the team accomplish this?","explanation":"API Gateway is used for RESTful applications. AWS AppSync is used for GraphQL powered applications. RDS and DynamoDB are managed database services but Amazon EC2 is not a managed service.","links":[{"url":"https://docs.aws.amazon.com/appsync/latest/devguide/designing-a-graphql-api.html","title":"Designing a GraphQL API"}],"answers":[{"id":"4481f8f19e1b5f28da2b0f396643167b","text":"Use Lambda for the GraphQL API. Use RDS for the managed database service.","correct":false},{"id":"13017b9feb28c5d8fdda19e3c79df90d","text":"Use AppSync for the GraphQL API. Use DynamoDB for the managed database service.","correct":true},{"id":"6f76fbab4996d8c8cb993a9c4569275b","text":"Use API Gateway for the GraphQL API. Use DynamoDB for the managed database service.","correct":false},{"id":"58fa18d14ef959d0d59e88ef26f8c391","text":"Use Amazon EC2 for the GraphQL API. Use RDS for the managed database service.","correct":false}]},{"id":"1a37a76e-3c69-4ae6-8ae3-5b0db850807c","domain":"mon-rep","question":"You need to monitor memory utilization of an EC2 instance. How could you achieve this?","explanation":"Monitoring memory utilization requires the installation of the CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html","title":"Collecting Metrics and Logs from Amazon EC2 Instances and On-Premises Servers with the CloudWatch Agent"}],"answers":[{"id":"8b901f2e0a6136525aaf5ffcb881b223","text":"EC2 instance memory utilization is monitored by default.","correct":false},{"id":"c5d4aec73235f6dc0fda6738ef7c93f9","text":"Install CloudWatch Agent on the instance and have it collect memory utilization metrics.","correct":true},{"id":"30041d2fc11ea9b43497c2fe847b6461","text":"From the EC2 console, enable memory ulitization metric for the instance.","correct":false},{"id":"e1771db5f560892163019427b6f3742c","text":"From the CloudWatch console, enable memory ulitization metric for the instance.","correct":false}]},{"id":"cde5021e-5b37-406b-b25a-1bdb489d3b24","domain":"security-comp","question":"Following a recent security event, a SysOps administrator has been asked to provide details of source IP addresses of requests to a website which is hosted on EC2 instances behind an Application Load Balancer. Where can the administrator find these details?","explanation":"Application Load Balancer (ALB) Access Logs record details of client connections which include the client's IP address and port.  CloudTrail logs AWS API calls so will not provide client IP addresses, neither will CloudWatch Custom Metrics which are for logging performance metrics.  EC2 instances will log the ALB's internal IP address as the source unless specifically configured to record the true source IP by using the x-forwarded-for header, which is not enabled by default.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html#access-log-entry-format","title":"ALB Access Log Entries"}],"answers":[{"id":"43bc48b76d9918101fb772b4cfc58235","text":"/var/log/httpd/","correct":false},{"id":"8480ea5c787566c9a8bd2a608c725a06","text":"ALB Access Logs","correct":true},{"id":"6a219c87573826721cb51b987140a267","text":"CloudTrail Event Trail","correct":false},{"id":"9a19403fef543b4899ec570ad1a29ca6","text":"CloudWatch Custom Metrics","correct":false}]},{"id":"fc9ff1cd-6d2b-4416-a26e-4f5d2630373c","domain":"security-comp","question":"Your organization is going through a security audit with an external party. As the security administrator for your AWS account, you are tasked with providing three auditors permissions to view and access resources in your AWS account. You have set up a trust policy between your account and the external AWS account, and have created an IAM role that the auditors can assume. How would you specify the Principal element on the IAM policy to grant auditors access?","explanation":"When you use an AWS account identifier as the principal in a policy, you delegate authority to the account. Within that account, the permissions in the policy statement can be granted to all identities. This includes IAM users and roles in that account. You can specify an individual IAM user (or array of users) as the principal. You cannot specify IAM groups and instance profiles as principals. When you specify users in a Principal element, you cannot use a wildcard (*) to mean 'all users'. Principals must always name a specific user or users. Principals cannot be specified in IAM User policies.","links":[{"url":"https://docs.aws.amazon.com/en_pv/IAM/latest/UserGuide/reference_policies_elements_principal.html","title":"AWS JSON Policy Elements: Principal"}],"answers":[{"id":"a9d62bc8ec727bff1ac84f134ad665af","text":"Specify the individual IAM users as an array of users as the principal.","correct":true},{"id":"0eec382d3971e7cbd93e0d29f5f7899c","text":"Specify the users in the Principal using the wildcard (*) element to capture all users in the external account.","correct":false},{"id":"8b4aa9586ddd5e271aed20fa3d20e078","text":"Create IAM Users within your account instead. Provide credentials for the auditors to access your account but grant read-only access for security purposes.","correct":false},{"id":"122f9e575f0b4f7a2e7224a31d53f328","text":"Create am IAM Group. Group the auditors' ARNs in the group. Specify the IAM Group as the Principal in the policy.","correct":false}]},{"id":"3xre6hrv-j02a-kj8k-nkyn-5951wwipzpzd","domain":"automation","question":"Which service can you use to enable configuration management using Chef or Puppet?","explanation":"OpsWorks is a configuration management service that provides managed instances of Chef and Puppet. Config allows you to record and evaluate configuration but doesn't use Chef or Puppet, Systems Manager is an operational insights tool and Athena is used to run SQL queries on data held in S3.","links":[{"url":"https://aws.amazon.com/opsworks/","title":"OpsWorks"}],"answers":[{"id":"c42aaccedc51aac929c8ae313066f320","text":"OpsWorks","correct":true},{"id":"fa535ffb25e1fd20341652f9be21e06e","text":"Config","correct":false},{"id":"8e75b153e61c22a8ea4e14aadc7cb4ee","text":"Systems Manager","correct":false},{"id":"582ca45acfd3e21caca8b786c1413850","text":"Athena","correct":false}]},{"id":"0c3624fc-3f1d-4663-9593-d1b228afb36b","domain":"mon-rep","question":"An organisation has been notified of an issue with their website loading slowly.  On investigation your autoscaling group has been scaled down to two servers, when it usually operates with two. Your CTO wants you to get to the bottom of this as quickly as possible. Which service in the Console will help you understand where the reconfiguration came from?","explanation":"AWS Config logs all changes to your configuration on a timeline, and it also allows you to retrace the steps via CloudTrail to see associated events with the configuration changes. In this case you could check the autoscaling group in AWS Config and would be able to see exactly when the number of servers was changed, and who performed the change.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/TrackingChanges.html","title":"Tracking Configuration Changes with AWS Config"}],"answers":[{"id":"7c90c8f2a24f3a1a28525f19fb2c75ab","text":"AWS Inspector","correct":false},{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false},{"id":"fefa18704e871eb671528fd4b7bc6ca2","text":"AWS Macie","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true}]},{"id":"0260f2a1-85f9-489c-b235-461207089452","domain":"networking","question":"You are a network administrator for your organization and have been tasked to address a recent security threat to your application that sits in a subnet. VPC flow logs show that malicious activity has been coming from a specific IP address source. You need to add an extra layer of security to control traffic coming into your VPC from that IP address. How would go about making your application secure from the malicious IP source?","explanation":"You can associate a network ACL with multiple subnets; however, a subnet can be associated with only one network ACL at a time. When you associate a network ACL with a subnet, the previous association is removed. Amazon WAF is not applied at the subnet level. AWS Config will only set your AWS resources as compliant to rules you set, but it won't prevent any external traffic from accesses your resources. As best practice, start by creating rules for your NACL in increments (for example, increments of 10 or 100) so that you can insert new rules where you need to later on.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"cd96a1230ce2e15c29f01e30180e1d67","text":"Associate another NACL to the subnet holding the application. Add rule as the lowest number to the second NACL that explicitly denies traffic from the malicious IP source.","correct":false},{"id":"e81b37b199479422fa7a10cb981356d9","text":"Activate the WAF with your VPC flow log. Add the malicious IP source address to the WAF's blacklist.","correct":false},{"id":"03bb7768562d89b49c918ae64b4183f9","text":"Configure an AWS Config rule to detect traffic originating from the malicious source. Configure a Lambda function to block the IP address whenever the Config rule is triggered.","correct":false},{"id":"b78c14382f6b1586c4a8016924d49783","text":"Add a rule to the NACL to explicitly deny traffic coming from the malicious IP source. Insert the rule as a lower number from the desired traffic from the same port.","correct":true}]},{"id":"d1f23ad4-6255-449e-ba3e-93f4ea692185","domain":"dep-prov","question":"You encounter problems while detaching an EBS volume through the Amazon EC2 console. What can help you diagnose the issue?","explanation":"The 'describe-volumes' CLI command can be used to gather further information to help with diagnosing volume issues and is therefore the most appropriate. The 'detach-volume --force' CLI command forces detachment if the previous detachment attempt did not occur cleanly (for example, logging into an instance, unmounting the volume, and detaching normally). This option can lead to data loss or a corrupted file system. Use this option only as a last resort to detach a volume from a failed instance. The 'Dismount-EC2Volume' PowerShell command will perform the same action as the EC2 console and will therefore not help with additional diagnosis. The 'fix-volumes' command is not a valid CLI command.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-detaching-volume.html","title":"Detaching an Amazon EBS Volume from an Instance"}],"answers":[{"id":"8f6461e3ace3c5f5cab7f6c269e12420","text":"Run the 'fix-volumes' CLI command.","correct":false},{"id":"8f52ce0a3a674b594aaed05357a3d828","text":"Run the 'detach-volume --force' CLI command.","correct":false},{"id":"75f13dd600a356952c8f887bd5bcb626","text":"Run the 'Dismount-EC2Volume' PowerShell command.","correct":false},{"id":"6dab4100f13c64be47fc0b254385f5ab","text":"Run the 'describe-volumes' CLI command.","correct":true}]},{"id":"5dc94849-7cfe-45fd-ae52-8e634c5e7d04","domain":"mon-rep","question":"Which of the following services does CloudWatch use to send you an email following an alarm event?","explanation":"Amazon EC2, S3 and CloudWatch, can all publish messages to your SNS topics to trigger event-driven computing and workflows. Amazon CloudWatch uses SNS to send email.","links":[{"url":"https://docs.aws.amazon.com/sns/latest/dg/welcome.html","title":"About SNS"}],"answers":[{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":true},{"id":"ef4ba2f338cdf4b615ed280ff0b2777d","text":"SQS","correct":false},{"id":"8513f757701b24dbadad3df74e817df5","text":"SES","correct":false},{"id":"f62772d94b939126ee608465cf5e0881","text":"SWF","correct":false}]},{"id":"2bd13304-db2d-4120-9487-7e13d7008a63","domain":"dep-prov","question":"EC2 instances are launched from Amazon Machine Images (AMIs). A given public AMI:","explanation":"An AMI cannot be launched into another region. To launch an AMI into a region other that the one in which it was created, the AMI must be copied to that other region first.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"3b690d9883c0bbec853ffdc3be150208","text":"Can only be used to launch EC2 instances in the same AWS country as the AMI is stored.","correct":false},{"id":"5a70861f841598d574b8ebd61e20cfc1","text":"Can only be used to launch EC2 instances in the same AWS Availability Zone (AZ) as the AMI is stored.","correct":false},{"id":"7096f3da806d7b3014ab808eb74d213a","text":"Can only be used to launch EC2 instances in the same AWS region as the AMI is stored.","correct":true},{"id":"9ba6ee29e152b251b8fc17d5d2aca126","text":"Can be used to launch EC2 instances in any AWS region.","correct":false}]},{"id":"c4f661ee-5ea1-4e69-9440-52bea0321a6a","domain":"mon-rep","question":"You have set CloudWatch billing alarms for your instances running in eu-west-2. However, when you try to access the billing information and alarms, no information is visible. Why might this be?","explanation":"Billing and Alarm data can be accessed only from the us-east-1 region.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/free-tier-alarms.html","title":"Creating a Billing Alarm"}],"answers":[{"id":"cd2c9fa4324b5861276dbbf7f4f593a8","text":"You need to login as the root user to see such information.","correct":false},{"id":"fb7a7d16c3f39960e7afde6babd422e1","text":"Billing and Alarm data can be accessed only from the us-east-1 region.","correct":true},{"id":"b5ff6f2dfd759f7e70f27d7529e4462b","text":"You need to login as the account owner to see such information.","correct":false},{"id":"7f3a3688c3f0cddb24c07255b9d13767","text":"Billing and Alarm data can be accessed only from the us-west-1 region.","correct":false}]},{"id":"32db26ef-70e3-4541-b3e5-7cde3ad73c9e","domain":"dep-prov","question":"In order to enable encryption at rest using EC2 and Elastic Block Store,  you must ________.","explanation":"To enable encryption, you must specify encryption when creating the EBS volume.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html","title":"About EBS Encryption"}],"answers":[{"id":"d8e355c7726e173ad29951d3461865d6","text":"Configure encryption when creating the EBS volume","correct":true},{"id":"aaed5dee4871b8256093659e8bbeba4a","text":"Configure encryption using the appropriate Operating Systems file system","correct":false},{"id":"64237cc9809266ebc9fb12b6cede9aa8","text":"Configure encryption using X.509 certificates","correct":false},{"id":"4bd8d581e477097d1396901aab8b3cf4","text":"Mount the EBS volume in to S3 and then encrypt the bucket using a bucket policy","correct":false}]},{"id":"27109f2b-2906-43cb-90b4-3e2bcfad7ab8","domain":"high-avail","question":"You are a consultant working for a global company. They are hosting their companies CRM web application on-premise across servers in three different countries. Amazon Route 53 is being used as their DNS Provider. When the servers in one of the countries goes down, traffic starts to drop instead of being redirected to the two working sites. Corporate policies prohibit client data being stored or transferred through a Public Cloud Provider. What would the simplest solution be to their issue?","explanation":"Multivalue Answer Routing will perform simple health checks on IP addresses before sending traffic to them. This has advantages over a simple routing, where an outage of one of the IP Addresses would result in failures to connect. Corporate policies prohibit in this scenario the storage or transfer of client data from the CRM through a Public Cloud Provider. This effectively rules out the migration to EC2, or the use of CloudFront as a CDN. Transferring DNS to an on-premise service may allow for more flexibility and abilities to write special health checks, but it would certainly not be the most simple option","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Amazon Route 53 Routing Policies"}],"answers":[{"id":"bad6a2c2cd6a244c640ffb67243421bd","text":"Migrate the servers to EC2 in three different regions to prevent outages in local datacentres","correct":false},{"id":"1ed8875652253a24ebf466592454a1be","text":"Use a Multivalue Answer Routing Policy on their Route 53, including the Health Checks to detect outages","correct":true},{"id":"dcfd51b6eec1175ce379fb23d19ec48f","text":"Transfer their DNS Zone to on-premise DNS servers to allow administrators more power to respond to outages","correct":false},{"id":"abb8f1f2096c4f271cf6c11ab4be0ab4","text":"Implement CloudFront as a CDN for their website, ensuring global fault tolerance","correct":false}]},{"id":"a8d6d4f3-6877-4e89-9e7c-c6f83b83e1de","domain":"automation","question":"A small business has a monolithic application utilizing several EC2 instances. The technology consultant has suggested to the engineering team of the business that the application is containerized to improve the deployment and scaling processes of the team. The engineering team processes both critical and non-critical workloads within the application. Given the size of the application and the number of transactions being processed by the system, the CFO has instructed the engineering team to ensure that the setup must be as cost-effective as possible without introducing the risk of data loss for critical workloads. How can the engineering team accomplish this?","explanation":"On-demand EC2 instances should be used for critical workloads and spot instances can be used for non-critical workloads. ECR (Elastic Container Registry) is not used to run container processes. Instead, it is used to store container images. For containerization requirements, ECS (Elastic Container Service) is used to manage container workloads. Step Functions is used for orchestrating different processes and can not be used by itself to manage the workloads.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-high-scale-web-on-spot-instances/","title":"Running High-Scale Web Applications on Spot Instances"}],"answers":[{"id":"1d3682fdb0beec13b13a37502cfb3108","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use Step Functions and on-demand EC2 instances for non-critical workloads.","correct":false},{"id":"ddf2c2e29f2118061f6a160054593338","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECR and spot EC2 instances for non-critical workloads.","correct":false},{"id":"b8864524b96a467a8f1023b5a2c9f003","text":"Use Step Functions and on-demand EC2 instances for the critical workloads. Use Step Functions and spot EC2 instances for non-critical workloads.","correct":false},{"id":"47e42a6e665f0a913236e5580553e3ad","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECS and spot EC2 instances for non-critical workloads.","correct":true}]},{"id":"2a16f1cd-530d-4e30-ad08-d89afae34484","domain":"mon-rep","question":"You create a new DynamoDB table with the provisioned read and write capacity units set to 5. The auto scaling feature is enabled for both read and write. And the target utilization is set as 70%. After monitoring the table for some time, you notice that there are two CloudWatch alarms related to the table. The description of one alarm is \"ConsumedWriteCapacityUnits < 150 for 15 datapoints within 15 minutes\". Which action do you need to take to address the alarm?","explanation":"DynamoDB manages the throughput capacities automatically with the auto scaling feature. The alarms are used for the feature and no action is required. There is no need to disable the feature or modify the provisioned capacities.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html","title":"Manage throughput capacity automatically with DynamoDB Auto Scaling"}],"answers":[{"id":"859412aa0d0666ab4c2b8d20707c8f41","text":"They are fake alarms. You can manually delete them from the console.","correct":false},{"id":"2131aeffdfb01948cc4943432a680327","text":"You need to adjust the provisioned read and write capacities to a higher value such as 10.","correct":false},{"id":"3a5208c005673a46313dce67b9e2dd57","text":"You should disable the auto scaling feature for the table.","correct":false},{"id":"252cd5486e4ae9685450c3e9ad208b05","text":"No action is required as the alarms are used for auto scaling for the DynamoDB table.","correct":true}]},{"id":"3eaf9c7f-ec35-42cb-af59-f26b9b358432","domain":"automation","question":"Which of the following sections is required for a CloudFormation template to be valid?","explanation":"The Resources section is the only required section. It specifies the stack resources and their properties, such as an Amazon Elastic Compute Cloud instance or an Amazon Simple Storage Service bucket.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/resources-section-structure.html","title":"CloudFormation - Resources"}],"answers":[{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"229eb04083e06f419f9ac494329f957d","text":"Conditions","correct":false}]},{"id":"0a54c671-954d-4e52-8a46-83eadcf029cd","domain":"mon-rep","question":"Which of the following are valid alarm statuses in CloudWatch?","explanation":"The three alarm statuses are OK, INSUFFICIENT_DATA and ALARM.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html","title":"About CloudWatch Alarms"}],"answers":[{"id":"e0aa021e21dddbd6d8cecec71e9cf564","text":"OK","correct":true},{"id":"9de6d0a670ae5a0dee31a6318aa00e8d","text":"ALARM","correct":true},{"id":"320f86f60f25459ba5550e000b2c3929","text":"ALERT","correct":false},{"id":"f5d0aa0db6ffc40d938f1412b89d946c","text":"INSUFFICIENT_DATA","correct":true}]},{"id":"463d990a-0af1-4e11-ad8a-c379444c02fd","domain":"automation","question":"A government agency currently runs all of their AWS workloads in a single region. Services utilized include S3, EC2, ECS, RDS, CloudFront, and Route 53 in multiple accounts. Their new business continuity plan calls for readiness in a separate AWS region in case disaster recovery is needed. Which approach will provide them with the most efficient way to manage their primary and business continuity environments?","explanation":"By default, CloudFormation templates are tied to a single account and a single region. However, CloudFormation allows for the creation of a custom resource that can launch a nested stack in another account or region with the appropriate IAM roles setup. The CloudFormation parameter and mappings sections don't provide cross-region functionality. Creating templates in each account would also work, but will require significant maintenance to keep resource definitions in-sync across all the templates.","links":[{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/multiple-account-multiple-region-aws-cloudformation/","title":"Multiple-account, multiple-Region AWS CloudFormation"}],"answers":[{"id":"b3128e59899200446191df0bbc118793","text":"Create AWS CloudFormation templates in each account that provision stacks with resources into the primary and business continuity regions using the CloudFormation 'Region' parameter","correct":false},{"id":"12eb00153c980c0e9e1fec8d03035f78","text":"Create AWS CloudFormation templates in each account and each region that provision stacks with the resources for their specific accounts/regions","correct":false},{"id":"fabf8fa8f7205c00448ae603a1d1af90","text":"Create AWS CloudFormation templates in a single account and configure the CloudFormation mappings section for the appropriate primary and business continuity regions","correct":false},{"id":"21d658a249d3a95d1de0860519bd585b","text":"Create an AWS CloudFormation template in a single account that defines custom resources to launch nested stacks into the other accounts and regions","correct":true}]},{"id":"08cb4706-7aac-48de-a4c8-c7e742aeb4d9","domain":"data-man","question":"A Multi-AZ RDS deployment will automatically fail-over as a result of which two of the following?","explanation":"Amazon RDS detects and automatically recovers from the most common failure scenarios for Multi-AZ deployments so that you can resume database operations as quickly as possible without administrative intervention. Amazon RDS automatically performs a failover in the event of any of the following: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, Storage failure on primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"Failover Process for Amazon RDS"}],"answers":[{"id":"8851c500044adfe0ba4a247acdb86eda","text":"Loss of network connectivity to the Primary","correct":true},{"id":"7ecc550bc4f7f4c4d01c334d359bb0d9","text":"Loss of availability in standby Availability Zone","correct":false},{"id":"215b7e6d7f48e4225c06a3c50bf400d2","text":"Loss of availability in primary Availability Zone","correct":true},{"id":"7b75b57dbe879950151e7a40cf0aed41","text":"A region-wide loss of service","correct":false}]},{"id":"f0c663f6-c133-4064-93f1-5a68ec604f86","domain":"networking","question":"A company is developing a software product on AWS. The product requires some dependencies on an external software application developed by another company. In order for the product to run properly, it must connect with the external software that has a configured AWS PrivateLink to run some tasks. Both companies want the connection between the product and the external application to be secured privately and not over the open Internet. How would you configure this connection?","explanation":"An interface VPC endpoint is required to use AWS PrivateLink. In this case, since the external software application has configured a PrivateLink, connecting the interface VPC endpoint to the PrivateLink will provide private connectivity. A VPN connection and Direct Connect are best suited for connectivity between AWS and an on-premise data center. A VPC endpoint is more appropriate in this case. Cross account access would not apply in this case.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html#what-is-privatelink","title":"What Is Amazon VPC?"}],"answers":[{"id":"a295a681bdc68fccdefa0245a0f3cb22","text":"Create a IAM role for the product. Enable cross account access for the product to communicate with the external software application to run its dependencies.","correct":false},{"id":"396ed1524965dd42f15a5584a5df2111","text":"Set up a VPN connection between a gateway endpoint on your VPC and a customer gateway in the external company's VPC. Encrypt the IPSec tunnel to ensure private connectivity.","correct":false},{"id":"82d6bd6a8ad9b046abc832a10aab46ec","text":"Configure a Direct Connect connection between your software product and the external software application's VPC. Data traversed over this connection will be private.","correct":false},{"id":"125e90bd89dd9a655f80754756185ade","text":"Put the product within a VPC and configure a VPC endpoint for the external application. Use the elastic network interface in the subnet with a private IP address.","correct":true}]},{"id":"5b0a461a-8b87-4e0b-b090-bb310aa5888f","domain":"dep-prov","question":"You are a SysOps Engineer for a fancy umbrella manufacturer \"Raincloud Gurus\".  You have been asked to deploy a new EC2 instance in your VPC to act as a bastion host for access to their systems. When you try to launch the instance you receive the error InsufficientInstanceCapacity.  What is the cause of your error?","explanation":"You get the InsufficientInstanceCapacity error when you try to launch a new instance or restart a stopped instance.  If you receive this error it means that AWS does not currently have enough available On-Demand capacity to service your request.  Either wait some time for the capacity to be provisioned in your region/Availability zone or try a different instance type.  ","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html","title":"Troubleshooting EC2 Launch"}],"answers":[{"id":"f130e4749fd898444fc50993d748bfb8","text":"AWS does not currently have enough available On-Demand capacity to service your request","correct":true},{"id":"98b15ca0626988b3169c48a7a2053331","text":"The instance type you selected is not available in your region","correct":false},{"id":"68d9f0033f27b30099c86ea525509a2a","text":"You selected an EBS volume size that is too small for the AMI you are trying to deploy","correct":false},{"id":"c6bcc41fea94bf39436d5eca43b66c34","text":"You forgot to raise EC2 instance service limits on your instance type","correct":false}]},{"id":"0e17eb91-9745-4365-8b54-5ebb2c6ffeb5","domain":"data-man","question":"A company wants to create a disaster recovery account involving creating snapshots of RDS, EC2 instances and EFS.  There are additional business and regulatory backup compliance requirements such as backups must be kept for three years but then must be destroyed.  Your manager wants to know how you could go about taking scheduled snapshots and deleting them once the retention period is expired with the lowest cost and operational overhead.","explanation":"AWS Backup is a centralised place to create backups of your EBS, RDS, and EFS resources.  There is no additional cost for setting up backup plans and retention policies, and this is a managed service so it's a perfect option to present to your manager.","links":[{"url":"https://aws.amazon.com/backup/","title":"AWS Backup"}],"answers":[{"id":"fc24b51d19eedb53ab68e9e1569c9458","text":"Use AWS Backup to create a vault and a Backup Plan to take backups on a schedule and automatically delete them once expired.","correct":true},{"id":"52b5e3e90161fce097eca53313efd955","text":"Use AWS Data Recovery Manager to create a storage vault and automated backup and retention rules.","correct":false},{"id":"d75279ac650753a76148e6ac6c1b380e","text":"Your team should write some Lambda functions which are triggered by CloudWatch Events on a cron expression.  Create another lambda to delete snapshots once they are expired.","correct":false},{"id":"8be1adb291f4f253ef46691652254d1f","text":"Browse the AWS Marketplace and purchase a backup tool which can run in your AWS account and perform the backup for you.","correct":false}]},{"id":"88de3a5c-b9ce-46eb-928f-f0f909bfe5dd","domain":"networking","question":"You own the registered domain name cloudcanines.com and are trying configure Route53 to map the DNS name to the DNS name of your Elastic Load Balancer. Which Route53 record can you use to achieve this?","explanation":"cloudcanines.com is a Zone Apex and you can't create a CNAME record at the zone apex. Instead you need to use an alias record to map the Zone Apex to the Elastic Load Balancer","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html","title":"Route53 Record sets"}],"answers":[{"id":"adc4bfdb0829dae99e3699393e3fbaa4","text":"CNAME","correct":false},{"id":"0b98720dcb2cc6fd60358a45dfbc5b87","text":"MX","correct":false},{"id":"de46eab399f3ea0bbf1912c1d14a1544","text":"Zone Apex","correct":false},{"id":"effdb9ce6c5d44df31b89d7069c8e0fb","text":"Alias","correct":true}]},{"id":"67a5ebe3-a3e7-426e-b6f1-ae8e7e58ba45","domain":"dep-prov","question":"You're using AWS CloudFormation template to provision an environment that consists of Amazon EC2 instances behind a load balancer. You want to output the DNS name of the load balancer in the Outputs section. Which intrinsic function should you use?","explanation":"The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. To return a string containing the DNS name of the load balancer with the logical name myELB, you could use \"Fn::GetAtt: [ myELB, DNSName ]\" in a YAML template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getatt.html","title":"Fn::GetAtt"}],"answers":[{"id":"fdf1a9a682e23e506b7afbdd8a427126","text":"Fn::GetAtt","correct":true},{"id":"45e374d45acef37653e6212bf389674d","text":"Fn::FindInMap","correct":false},{"id":"f39ff73d166b2d89703ba99b860cc1d2","text":"Fn::Join","correct":false},{"id":"9755e3403594515213433801d07f5476","text":"Fn::Select","correct":false}]},{"id":"64ee23de-9703-4090-983d-d36552dac361","domain":"networking","question":"You are a SysOps Administrator running security checks throughout your AWS environment. One of your tasks is to clean up the environment and remove any idle resources that are no longer in use. You identify a VPC that was configured and used by a team that no longer works at the company and you are looking to delete the VPC. The VPC has a few running instances, a route table, a NAT Gateway, and an Internet Gateway. When you try to delete the VPC you get an error. How would you troubleshoot this situation?","explanation":"In AWS, you will get the following error if you attempt to delete the VPC with a network interface in-use: 'The VPC contains one or more in-use network interfaces, and cannot be deleted until those network interfaces have been deleted. View in-use network interfaces in the VPC.' Moreover, you cannot delete a subnet that has instances in it. The best answer would be to terminate the instances before deleting the VPC. There is no need to take snapshots before deleting a VPC (unless for backup purpose), and detaching the Internet Gateway is unnecessary as well. Assuming the role of the VPC creator is unnecessary if you already have the proper IAM permissions to do so.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html","title":"VPCs and Subnets"}],"answers":[{"id":"64ab90b44ef9b90a49072f93bb50a615","text":"Assume the role of the creator of the VPC. The credentials for the VPCs creator is required to delete the VPC.","correct":false},{"id":"4fd6f1d4acf6323fa52621653e2a6150","text":"Take a snapshot of the EBS volumes before deleting the VPC. Upload the snapshots into S3 and proceed deleting the VPC.","correct":false},{"id":"dc869ce95aa68ff14f2265e56e10d33d","text":"Stop and terminate the running instances. Delete all the resources in the VPC before deleting the VPC itself.","correct":true},{"id":"bdba6bd2f5a22439d78f3ae5512c9213","text":"Detach the Internet Gateway from the VPC. Delete the Internet Gateway to restrict public traffic into the VPC. Delete the VPC.","correct":false}]},{"id":"2ed81e01-78af-4ca1-8cc9-2ecfeeff8984","domain":"data-man","question":"Which of the following is not a use case for read replicas?","explanation":"Providing greater redundancy via automatic failovers is not a use case for read replicas. They're not useful in this case.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.Overview","title":"Overview: Read Replicas"}],"answers":[{"id":"5224fa97bf0d7d77ee80e90a695f1e40","text":"Serving read traffic while the source DB instance is unavailable. If your source DB Instance cannot take I/O requests (e.g. due to I/O suspension for backups or scheduled maintenance), you can direct read traffic to your read replicas.","correct":false},{"id":"865c6a9aca74af0e2c37ab4e50ca6013","text":"Providing greater redundancy via automatic failovers.","correct":true},{"id":"61cb6fc4fb9c00d23b126d6e5c0d8905","text":"Scaling beyond the compute or I/O capacity of a single DB Instance for read-heavy database workloads. This excess read traffic can be directed to one or more read replicas.","correct":false},{"id":"82d85c0b4a19e372bf779bb4908cd64a","text":"Business reporting or data warehousing scenarios; you may want business reporting queries to run against a read replica, rather than your primary DB Instance.","correct":false}]},{"id":"095bed19-081d-4865-acff-d6f9bc29eb7c","domain":"automation","question":"Which of the following is the only required component of a CloudFormation template?","explanation":"As the primary purpose of CloudFormation is to create a collection of related AWS resources, the Resources section is the only required section of a CloudFormation template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"}],"answers":[{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"7df96b18c230f90ada0a9e2307226338","text":"Templates","correct":false},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false}]},{"id":"3acceef5-9df8-49d6-a227-cd414a046293","domain":"networking","question":"As a SysOps Administrator you are tasked with improving the performance of a website that is serving customers in two separate Regions. There are customers in us-west-2, and customers in ap-southeast-1. There is growing demand for the website from customers in ap-southeast-1, and customers have been complaining about poor latency. How would you ensure that users are directed to the Region with the best performance?","explanation":"If your application is hosted in multiple AWS Regions, you can improve performance for your users by serving their requests from the AWS Region that provides the lowest latency. To use latency-based routing, you create latency records for your resources in multiple AWS Regions. When Route 53 receives a DNS query for your domain or subdomain (example.com or acme.example.com), it determines which AWS Regions you've created latency records for, determines which region gives the user the lowest latency, and then selects a latency record for that region. Geolocation may sound like the right answer but it may trick you thinking that the closest Region assumes the lowest latency, but this is not the case. There is no need to separate the website into two Regions as this is an administrative burden. An ALB with HTTP path routing has nothing to do with improving latency.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-latency","title":"Choosing a Routing Policy"}],"answers":[{"id":"4a2ab96fd93984723a369708f83fec95","text":"Configure an Application Load Balancer in front of your website. Use the HTTP path routing to direct the customer to the best performing website.","correct":false},{"id":"eb8c189707a52253445f78cd5791eb37","text":"Use Amazon Route 53 geolocation routing to direct customers.","correct":false},{"id":"57eb7a3ea4c9eabfca928f3ce81be0b7","text":"Use Amazon Route 53 latency-based routing to direct customers.","correct":true},{"id":"20977b79538e17806537e17b503fb602","text":"Separate your website into two websites -- one in us-west-2, and one in ap-southeast-1. Routinely log into both Regions to maintain both websites.","correct":false}]},{"id":"4fa7de17-2f03-4b83-a519-e00b011ca644","domain":"security-comp","question":"You are a SysOps Administrator for your organzation. The organization has one AWS account that all users share. You are asked by the CISO to make access to AWS secure and manageable. What would be the best solution?","explanation":"AWS Single Sign-On makes it easy to centrally manage access to all of your AWS accounts. It supports Security Assertion Markup Language (SAML) 2.0 so you don't have to create IAM users for every individual in your organization. The other solutions would be an administrative and unnecessary burden, while encrypted login credentials using KMS is not used for AWS access.","links":[{"url":"https://docs.aws.amazon.com/en_pv/singlesignon/latest/userguide/iam-auth-access.html &https://docs.aws.amazon.com/cli/latest/reference/sts/assume-role-with-saml.html","title":"AWS Single Sign-On"}],"answers":[{"id":"0949ef9615ffc62f343f10d27d0bea2e","text":"Encrypt Active Directory logins using AWS KMS. Store encrypted logins in an RDS table. When users access AWS, set up permissions to decrypt the credentials to securely access AWS resources.","correct":false},{"id":"678d5bab1e8e14c5f9a7055f83d2aa56","text":"Set up an AWS Organization to manage accounts and apply permissions boundaries. Set up IAM users and group them in the appropriate OU.","correct":false},{"id":"48371df9efaa3423dc8c9153f0af03c3","text":"Group Active Directory users and mirror their permissions with IAM policies. Create IAM users in AWS and group them into IAM groups that correspond to the Active Directory Group.","correct":false},{"id":"b18f21a1b9a12f45b180d3ba09d175a0","text":"Configure a SAML federation between AWS and your organization's Active Directory. Set up Active Directory groups with AWS IAM groups to manage user permissions.","correct":true}]},{"id":"y895ku45-wsg2-9rye-087a-zdmu2wd7qtr8","domain":"mon-rep","question":"Which AWS service can be used to log API calls from the AWS console, the EC2 CLI, the AWS CLI, or the AWS SDKs.","explanation":"CloudTrail captures API calls and delivers the log files to an Amazon S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/APIReference/using-cloudtrail.html","title":"Logging API Calls Using AWS CloudTrail"}],"answers":[{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false}]},{"id":"557a8cbf-ffb7-492a-b24a-7662b95c6269","domain":"automation","question":"A startup is planning to migrate their existing on-premise application to AWS. The company is already using Chef as the configuration management tool to manage their on-premise application and is looking to continue using Chef to manage their AWS resources. In addition to this, the team is looking to use a managed service to reduce the overhead of managing its PostgreSQL databases. How can the team accomplish this?","explanation":"OpsWorks is a managed service for Chef and Puppet and can easily be used to deploy and manage resources utilizing the Chef recipes already prepared. CloudFormation uses AWS's own engine to process and convert JSON or YAML templates to AWS resources. For requirements involving Chef and Puppet, OpsWorks is the primary (and only) managed service. For managed database service requirements, Aurora, RDS, and DynamoDB can be used as the managed database.","links":[{"url":"https://aws.amazon.com/opsworks/","title":"OpsWorks"}],"answers":[{"id":"378e25243c4a87f77553aed4ddbb2808","text":"Use ECS for the configuration management requirements. Use Athena for the database management requirements.","correct":false},{"id":"33b2bf9a830d2dddb0570706a774902f","text":"Use OpsWorks for the configuration management requirements. Use RDS for the database management requirements.","correct":true},{"id":"ce66fcb736d2db75172e1c56777a36e1","text":"Use CloudFormation for the configuration management requirements. Use Aurora for the database management requirements.","correct":false},{"id":"5b18a2364c2c69356af48e23e5347e81","text":"Use Elastic Beanstalk for the configuration management requirements. Use DynamoDB for the database management requirements.","correct":false}]},{"id":"6c456d08-f571-4a63-833d-ef8c49757ef4","domain":"automation","question":"You have an application running on several Amazon EC2 instances in an Auto Scaling group attached to an Elastic Load Balancer. You check the ELB logs in the S3 bucket and realize that instances that fail the ELB health checks are not being replaced. How would you troubleshoot this issue?","explanation":"The default health checks for an Auto Scaling group are EC2 status checks only. If an instance fails these status checks, the Auto Scaling group considers the instance unhealthy and replaces it. If you've attached one or more load balancers or target groups to your Auto Scaling group, the group does not, by default, consider an instance unhealthy and replace it if it fails the load balancer health checks. To do this, configure the Auto Scaling group to use Elastic Load Balancing health checks. The listener rules determines how your load balancer routes request traffic, and the trace ID traces request through your ELB.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-elb-healthcheck.html","title":"Amazon EC2 Auto Scaling"}],"answers":[{"id":"e5f3d2525407af983596253361c1af26","text":"Configure the Auto Scaling group to use ELB health checks to have the Auto Scaling group replace the instance.","correct":true},{"id":"9bc372b00a1c40e68b34b0d3e9f6edc3","text":"Update the listener rules on the load balancer to allow for health checks on the ELB.","correct":false},{"id":"ba4ba5112eec0a2ca6312a45f8834c76","text":"Check the access logs permissions. Adjust the log permissions to allow ELB to write logs to the S3 logs bucket.","correct":false},{"id":"9283050a2c9b87649381de2f1f54a3e7","text":"Configure request tracing on the load balancer to update the X-Amzn-Trace-Id header before sending the request to the Auto Scaling group.","correct":false}]},{"id":"d69480f4-f12c-471d-bf7f-f6b0994a441f","domain":"mon-rep","question":"You are supporting an online gaming platform which runs on a number of application servers behind an Application Load Balancer, your Security Architect asks you to start monitoring HTTP requests from users to your application? Which of the following can you use to achieve this?","explanation":"Request Tracing can be used to track HTTP requests from clients to targets. CloudWatch monitors performance metrics, Trusted Advisor makes recommendations based on best practices for security, performance and cost optimization. Cloud Trail monitors API calls within your account. ","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-request-tracing.html","title":"Request Tracing on Application Load Balancer"}],"answers":[{"id":"50ed91980adb1dac23689554eb719277","text":"CloudWatch metrics","correct":false},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"f0d36f4f7323e9b431c82349dcc3ab89","text":"CloudTrail Logs","correct":false},{"id":"e86c7149423f18f89a2a67af3295477a","text":"Request Tracing","correct":true}]},{"id":"2729f0e9-af70-412f-b6bb-388bd9f0af12","domain":"dep-prov","question":"You application needs to send data to DynamoDB, but you dont want the application to have to wait for acknowledgment from the database to continue sending data. In decoupling this application, which AWS service might you use.","explanation":"SQS is a fully-managed queuing service that allows you to decouple components of a cloud application.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/Welcome.html","title":"About SQS"}],"answers":[{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":false},{"id":"f62772d94b939126ee608465cf5e0881","text":"SWF","correct":false},{"id":"ef4ba2f338cdf4b615ed280ff0b2777d","text":"SQS","correct":true},{"id":"8513f757701b24dbadad3df74e817df5","text":"SES","correct":false}]},{"id":"8938dba3-4740-4cfa-9226-f27006233c27","domain":"security-comp","question":"You work for a large multi-national corporation who has literally 100s of AWS accounts. Some of these accounts belong to subsidiary companies, some to departments and some to individual teams. You need to implement a strategy so that when a new account is created you can lock down which AWS services are available to that account on an account by account basis. What is the easiest way to do (and manage) this?","explanation":"SCPs enable you to restrict, at the account level of granularity, what services and actions the users, groups, and roles in those accounts can do.","links":[{"url":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html","title":"Service Control Policies"}],"answers":[{"id":"27f329a839e5b524103723898c84aaf4","text":" Using AWS Cognito","correct":false},{"id":"55006bb8960ca3bd15aedc34fc19c9fe","text":"Using AWS Organizations Service Control Policies (SCP)","correct":true},{"id":"74765eedd0b4460b44e6233fb940b347","text":"Using IAM Policies within each individual AWS account","correct":false},{"id":"55b133327fbc344978b0c06c0821cf5f","text":"Using AWS Inspector with Lambda Integration in to Athena","correct":false}]},{"id":"b44c9f0b-805c-4de9-8ae7-71a6c2885b76","domain":"mon-rep","question":"Which of the following can you use to monitor API usage in AWS?","explanation":"CloudTrail logs all API calls within your account, CloudWatch monitors performance metrics, RunCommand is a Systems Manager feature which lets you run a command simultaneously on multiple instances, Trusted Advisor makes security, performance and cost optimization recommendations.","links":[{"url":"https://aws.amazon.com/cloudtrail/faqs/","title":"CloudTrail FAQs"}],"answers":[{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"64d231d79e9f7640a4572f7ae75aa226","text":"RunCommand","correct":false}]},{"id":"83ef4c6f-4ebd-4ab1-b964-42345661b16e","domain":"security-comp","question":"As a Sysops Administrator for your company, you are the point of contact for a third-party auditor who is examining your AWS environment. The auditor requires a view of all the resources in your AWS account and the relationship between each resource to see the overall impact of any resource configuration change. How would you provide this information?","explanation":"When you use multiple AWS resources that depend on one another, a change in the configuration of one resource might have unintended consequences on related resources. With AWS Config, you can view how the resource you intend to modify is related to other resources and assess the impact of your change. Amazon Neptune is a graph database but is not the appropriate use case. Amazon Inspector runs security assessements on EC2 instance, not your AWS environment. CloudTrail log history only shows API calls and not the relationships between resources.","links":[{"url":"https://docs.aws.amazon.com/en_pv/config/latest/developerguide/WhatIsConfig.html","title":"What is AWS Config?"}],"answers":[{"id":"2b4d2e523329145cc3674082eaec8d38","text":"Retrieve configurations of one or more resources that exist in your account using AWS Config and view the relationships between resources.","correct":true},{"id":"e249cf2d1b853d8faf906785117f8a16","text":"Deploy an Amazon Neptune database that is optimized for storing and querying relationships such as network security. Create an IAM role for the auditor for read-only access to your Neptune database.","correct":false},{"id":"2609fd7b786b580dd1a731400e416bc4","text":"Run an Amazon Inspector assessment that will produce a detailed list of security findings around configuration changes within your environment.","correct":false},{"id":"f6417679ee015e02f36ea3663d5a6300","text":"Export log data from CloudTrail event history. Parse the data to only include relevant AWS resources.","correct":false}]},{"id":"b2d3b949-889b-4bbd-8ec9-c65b764c47c3","domain":"mon-rep","question":"You are a SysOps Administrator monitoring a web app that lets users upload high-quality images and use them online. Each image requires resizing and encoding. The images are placed in an Amazon SQS queue for processing by an EC2 instance. It processes the images and then publishes the processed images where they can be viewed by users. When you monitor the EC2 instance you see that the CPU utilization is consistently at 90% and that image processing time is being delayed. The team is looking for a cost-effective solution. What would you recommend?","explanation":"You can use an Auto Scaling group to manage EC2 instances for the purpose of processing messages from an SQS queue. Set a custom metric to send to Amazon CloudWatch that measures the number of messages in the queue per EC2 instance in the Auto Scaling group, and then set a target tracking policy that configures your Auto Scaling group to scale based on the custom metric and a set target value. CloudWatch alarms invoke the scaling policy. Increasing the size of the instance may work but is not a cost-effective solution since Auto Scaling gives you the option to scale down during low demand. Kinesis Data Streams are best suited for real-time data processing, and they have a size limit of 1MB which would be too low for high-quality images. Migrating the data to DynamoDB would not be a viable, let alone cost-effective, solution.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html","title":"Scaling Based on Amazon SQS"}],"answers":[{"id":"c1c44e18b3c0f81b8ec026e9e1ab5b38","text":"Place the instance in an Auto Scaling group. Use CloudWatch metrics to scale out the Auto Scaling group depending on the size of the SQS queue.","correct":true},{"id":"40fe2365fa7bae167e628c9ef29bd6ca","text":"Move the images into Kinesis Data Streams where you'll be able to process the data in real time.","correct":false},{"id":"3a781b7e075f07b31a51c98b18d84a2e","text":"Increase the size of the instance and ensure that it is compute-optimized to boost it's capacity to process the images.","correct":false},{"id":"52bcbdff61b39eafa67d9496dc77ee09","text":"Migrate the image data into DynamoDB. Attach a role to the instance to be able to access the data from DynamoDB and process the images.","correct":false}]},{"id":"a6c51ca7-52b5-43a3-aa33-000fe7c6eb28","domain":"networking","question":"You want to configure an IPv4 subnet for 30 devices. Which subnet mask will give you the most appropriate IP address range?","explanation":"Out of the available options, /25 is the most appropriate as it gives you 123 useable IPs, /24 gives you 251 useable IPs, /28 only gives you 11 useable IPs and /16 is the largest subnet with around 65k IP addresses","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html#vpc-sizing-ipv4","title":"VPC Subnets"}],"answers":[{"id":"f338fdcb41c5dfa52b9ed8882816edc8","text":"/25","correct":true},{"id":"ff95ba81ae512ac21c01f6e4a389d550","text":"/24","correct":false},{"id":"8cc8342afd8761102293089057e08fdb","text":"/16","correct":false},{"id":"56b06b5537fc068776178062155a9ea1","text":"/28","correct":false}]},{"id":"f253314b-765f-471a-a5de-bc5f6095164a","domain":"dep-prov","question":"An application server running in an autoscaling group is terminating and relaunching every few minutes. What is the most likely cause?","explanation":"When an instance is seen to be terminating and relaunching regularly (commonly known as 'flapping' or 'thrashing'), the most likely cause is that the Autoscaling group is marking the instance as unhealthy to trigger a replacement.  This can be caused if the Load Balancer health check has been improperly configured- for instance if a missing security group rules means the ALB cannot perform health checks. or the health check too aggressively marks instances as unhealthy before launch has completed (i.e. before userdata has finished.  Termination of an autoscaling instance when using Spot fleet is common, but to see the regular launch and termination would suggest this is health-check related rather than due to spot price changes.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html#health-check-grace-period","title":"EC2 AutoScaling - Replacing Unhealthy Instances"}],"answers":[{"id":"22b774b395936efd71fe7ddaf41a3f8a","text":"The autoscaling health check is marking the instance as unhealthy before it has time to initalise fully.","correct":false},{"id":"ef10fce024d97295098b2e7c8b9de34e","text":"The Launch Configuration is using an unsupported AMI for your Availability Zone.","correct":true},{"id":"ceb2643dc2123b2807f446e103bad7ff","text":"The price for the EC2 spot instance has increased to above the maximum price for your autoscaling group Launch Configuration.","correct":false},{"id":"18d69cdccb048f832573792064f79345","text":"There is a temporary outage in the AWS Autoscaling service in that region.","correct":false}]},{"id":"83fd057a-07f2-4372-a889-abf74e907806","domain":"data-man","question":"You own and manage an S3 bucket with which you have PUT request access to select users in various regions and countries. Users have recently complained about long upload lengths and poor latency. How would you improve the upload performance for your users?","explanation":"Amazon S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and an S3 bucket. Transfer Acceleration takes advantage of Amazon CloudFronts globally distributed edge locations. As the data arrives at an edge location, data are routed to Amazon S3 over an optimized network path. Multipart upload can be used in conjunction with Transfer Acceleration but will not itself solve the issue. Buckets are universal and cannot be replicated in other regions. Geo-location routing policy applies to Route 53.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html#transfer-acceleration-requirements","title":"Amazon S3 Transfer Acceleration"}],"answers":[{"id":"42bc9efd5b2b629ef42ae7e808d66fa2","text":"Configure a geo-location routing policy to route the object upload based on the location of the user to reduce latency.","correct":false},{"id":"edda60f4b576cd518abc4e1430e86a30","text":"Replicate the bucket in multiple Regions so that users can upload the objects to the Region closest to them.","correct":false},{"id":"61ae8ec9b582ff4ea402f7ca1b7e5cba","text":"Edit the bucket policy to require Multipart upload for any PUT requests for objects greater than 100 megabytes in size.","correct":false},{"id":"3d973493e7cdf70d033fb8c92c83b75f","text":"Use S3 Transfer Acceleration to minimize the effect of distance on throughput.","correct":true}]},{"id":"316dd185-ef97-4e16-81d7-b5c062f1ec47","domain":"high-avail","question":"You are providing a storage solution for a customer. The customer requires a scalable, secure, and highly available network file system accessed by EC2 instances to support highly parallelized workloads and performance needs of big data and analytics. What AWS storage solution would you build for your customer?","explanation":"To understand Amazon EFS, it is best to examine the different components that allow EC2 instances access to EFS file systems. You can create one or more EFS file systems within an AWS Region. Each file system is accessed by EC2 instances via mount targets, which are created per Availability Zone. You create one mount target per Availability Zone in the VPC you create using Amazon Virtual Private Cloud. Traffic flow between Amazon EFS and EC2 instances is controlled using security groups associated with the EC2 instance and the EFS mount targets. Access to EFS file system objects (files and directories) is controlled using standard Unix-style read/write/execute permissions based on user and group IDs.","links":[{"url":"https://d0.awsstatic.com/whitepapers/AWS%20Storage%20Services%20Whitepaper-v9.pdf & https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html","title":"Amazon EFS: How It Works"}],"answers":[{"id":"bb6c11aa159a74b89de0fe51a29de08f","text":"Create an EFS file accessible by EC2 via mount targets in each Region. Control traffic flow between Amazon EFS and EC2 instances using NACLs.","correct":false},{"id":"1ec0f5d67390f1b741ec4ec61ce713f1","text":"Create an EFS file accessible by EC2 via mount targets in each Availability Zone. Control traffic flow between Amazon EFS and EC2 instances using security groups.","correct":true},{"id":"ed0d300169a44f10c753efc49ccb714c","text":"Create an EFS file accessible by EC2 via mount targets in each Availability Zone. Control traffic flow between Amazon EFS and EC2 instances using NACLs.","correct":false},{"id":"1bb9e848b8d17a7885bee17d76e56c27","text":"Create an EFS file accessible by EC2 via mount targets in each Region. Control traffic flow between Amazon EFS and EC2 instances using security groups.","correct":false}]},{"id":"f1f36583-612f-4946-ac77-a6e78aede912","domain":"networking","question":"You have an Amazon VPC with one private subnet, one public subnet and one network address translation (NAT) server. You are creating a group of EC2 instances that configure themselves to deploy an application via GIT. Which of the following setups provides the highest level of security?","explanation":"You should use EC2 instances in private subnet; no EIPs; and route outgoing traffic via the NAT.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_NAT_Instance.html#basics","title":"NAT Instance Basics"}],"answers":[{"id":"6a084c8ddbef4573cc627373b1a04456","text":"Amazon EC2 instances in public subnet; assign EIPs; route outgoing traffic via the NAT.","correct":false},{"id":"1f9416e0df4342a7c5298d9f43d4d392","text":"Amazon EC2 instances in a private subnet; assign EIPs; route outgoing traffic via the internet gateway (IGW).","correct":false},{"id":"9767e7ce6f652652e1ec42f2d2a48af1","text":"Amazon EC2 instances in public subnet; no EIPs; route outgoing traffic via the internet gateway (IGW).","correct":false},{"id":"03808744fcc2ec07927563e827ba457a","text":"Amazon EC2 instances in private subnet; no EIPs; route outgoing traffic via the NAT.","correct":true}]},{"id":"48613ba4-57e3-45db-8f05-7f933ca75c8d","domain":"security-comp","question":"Security Token Service (STS) allows for the creation of temporary token credentials. STS can work with users from what sources?","explanation":"The AWS Security Token Service (STS) is a web service that enables you to request temporary, limited-privilege credentials for AWS Identity and Access Management (IAM) users or for users that you authenticate (federated users). ","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"eefdebb91d87138fe3b156d1b5ad571d","text":"Only federated identity users can gain a generated security token","correct":false},{"id":"ec3222de3069bf4526f19703213ed211","text":"Only IAM users that have administrator privileges can access a generated security token","correct":false},{"id":"78526e12a19b987737f48b26e84171b1","text":"Any user that has an IAM user account for my account can gain a generated security token","correct":false},{"id":"6f0a2b742bca843f3f7166f9ec5b1eeb","text":"Any configured IAM users or supported federated identity users can gain a generated security token","correct":true}]},{"id":"e6e97329-0325-41bb-99cd-95f73d8cbf7b","domain":"security-comp","question":"You are running a public facing website which is hosted on 6 EC2 instances across 2 AZs. Your security team have identified some suspicious traffic originating from a public IP address outside your organisation, and you have been asked to block this IP from your public website. What is the quickest and simplest way to achieve this?","explanation":"Of all the options, using subnet NACLs is the quickest and easiest. Security Groups do not allow block rules so can be discounted. AWS Firewall Manager is used to manage multiple instances of AWS WAF and Shield Advanced, and neither of those are mentioned in this scenario. Although using iptables would work for linux EC2 instances, it adds unneeded complexity to the issue.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"AWS Network Access List"}],"answers":[{"id":"fd8b9b77d42ae65ac062f3da9516a18c","text":"Add a block rule to AWS Firewall Manager","correct":false},{"id":"a1286c8d10d0d6ae23294cfd877c9f5b","text":"Add a block rule to the NACLs on the public subnets","correct":true},{"id":"e4603e8c6c15ef19dd3adf7da6725d16","text":"Use the System Manager to run the \"iptables -A INPUT -s <IP-ADDRESS> -j DROP\" on all the servers,","correct":false},{"id":"672072a1bc5bd9c47eb8de77e500d285","text":"Add a block rule to the security group of your web EC2 instances","correct":false}]},{"id":"3f14908a-fb13-4a6a-a777-7eeb6722447d","domain":"dep-prov","question":"You are running a legacy application on an EC2 instance and have created and attached an EBS volume with default settings. The volume occasionally encounters data consistency errors making the EBS volume inaccessible to the instance. How can this be prevented?","explanation":"When Amazon EBS determines that a volume's data is potentially inconsistent, it disables I/O to the volume from any attached EC2 instances by default. This causes the volume status check to fail, and creates a volume status event that indicates the cause of the failure. Switching on Enable Volume IO will allow the instance to access the volume. Switching on Auto-Enabled IO will also achieve this outcome automatically when enabled. All other options are incorrect.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html#work_volumes_impaired","title":"Working with an Impaired Volume"}],"answers":[{"id":"65e65e38f33598416e8a272b6ad29b2a","text":"This cannot be prevented","correct":false},{"id":"58bcefbd4466f36f955a0383bd253082","text":"Switch on Auto-Enabled IO","correct":true},{"id":"bf737cfd17a3b913cb405f896e5e9b7d","text":"Switch on Enable Volume IO","correct":true},{"id":"1775e91227da79ae13b5522ccf280ca0","text":"Switch on Auto-Consistency IO","correct":false},{"id":"628b701156eef0c168e27dc6d58a9d15","text":"Switch off Auto-Enabled IO","correct":false}]},{"id":"8473f19c-c3f7-4f2b-93a5-55ed10d99f83","domain":"mon-rep","question":"You run a hybrid environment with some servers in AWS and other Servers on Premise. Your boss has been impressed with your CloudWatch dashboard which shows the performance of all your EC2 instances around the world, however it does not show any metrics for your on premise servers. What could you do to rectify this?","explanation":"AWS Systems Manager Agent (SSM Agent) is Amazon software that runs on your Amazon EC2 instances and your hybrid instances that are configured for Systems Manager (hybrid instances). You can manually install SSM Agent on servers or virtual machines in your on-premises environment","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html","title":"SSM Agent"}],"answers":[{"id":"02a9311d5b1ac89de02acaf3c528c90a","text":"Install a third party monitoring agent and export performance data to the third party platform. Use AWS datapipeline to create a pipeline of this data from the third parties platform, in to CloudWatch","correct":false},{"id":"5aa17ac5ff5e522d0cbd19818e8b854d","text":"It is not yet possible to monitor on premise servers using AWS CloudWatch","correct":false},{"id":"38763eaec7d5f8126a56abeb236b9d27","text":"Install and run the SSM agent on your on premise servers. Once finished, install and run the CloudWatch agent on the on premise servers. Create the required role in IAM and verify that the agent is publishing data to CloudWatch. Add the widget for the on premise tools","correct":true},{"id":"2b914a41bdba2bd7ceb93d6306696cd4","text":"Use AWS Storage Gateway and configure Gateway Monitoring Mode. Publish the monitoring statistics to S3 and use AWS Datapipeline to import this data in to CloudWatch","correct":false}]},{"id":"eab3e224-a279-4865-a746-4595551b4cfb","domain":"security-comp","question":"As a systems administrator, it's your job to grant IAM access to your entire development team as your company transitions to AWS. What's the best strategy in doing this?","explanation":"Instead of defining permissions for individual IAM users, it's usually more convenient to create groups that relate to job functions (administrators, developers, accounting, etc.). Next, define the relevant permissions for each group. Finally, assign IAM users to those groups. All the users in an IAM group inherit the permissions assigned to the group.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#use-groups-for-permissions","title":"Using Groups to Assign IAM Permissions"}],"answers":[{"id":"5ed32311b773a2bfca008d3086a7bd62","text":"Use Active Directory and copy its permissions.","correct":false},{"id":"f070e391c12dea8466645d67cc18ef12","text":"Use the default access provided by your identity provider.","correct":false},{"id":"d07d419ef9a8d5dfbaa087cd534554de","text":"Create IAM access specific to each user's needs.","correct":false},{"id":"58d601b0c64e419e78ca3f11a589b34a","text":"Create groups based on the relevant permissions for that job function and assign each user to the appropriate group.","correct":true}]},{"id":"8c1dec5f-627d-4f25-af24-119b092ca2ef","domain":"high-avail","question":"A client asks you how they can make their current database running on AWS highly available. The client is running a MySQL RDS database in us-west-1. The client does not currently have a Multi-AZ deployment. The client wants to know what the benefits are with a Multi-AZ deployment as it would incur additional costs to their AWS bill. How would you explain the benefits to the customer?","explanation":"Amazon RDS Multi-AZ deployments provide enhanced availability and durability for databases. When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone. In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby. It does not lower latencies nor does it increase read performance. It cannot tolerate the failure of a single AWS Region as failure of a Region would implicate failure of all the Availability Zones within that Region.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"Amazon RDS Multi-AZ Deployments"}],"answers":[{"id":"834345e14f96992b8d4b2e785595f697","text":"Multi-AZ tolerates the failure of a single Region. It also allows higher availability during maintenance tasks.","correct":false},{"id":"aa4c2ced080ae70c33f36fe825b972ce","text":"Multi-AZ lowers latencies for application servers when they are accessing the database in multiple Availability Zones.","correct":false},{"id":"6772f4dc3173a8dd298656b65d2b6efa","text":"Multi-AZ makes it faster for application servers to access the database by reading data at a quicker rate.","correct":false},{"id":"4983004598ef3be1bb46819c748a09ab","text":"Multi-AZ tolerates the failure of a single Availability Zone. It also allows higher availability during maintenance tasks.","correct":true}]},{"id":"a633d884-fccf-4ab0-bdff-72974f6fe06c","domain":"networking","question":"You have launched an EC2 instance into the public subnet of your custom VPC. The VPC's internet gateway is properly specified in the default route table and the instance's security group allows SSH traffic over port 22. However, you are still unable to SSH into your instance. Which of the following could explain this?","explanation":"To communicate with your instance, it must have either a public IP or an Elastic IP.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html","title":"AWS Elastic IP"}],"answers":[{"id":"62c19bb64f03bcc2aa277034eca8fa21","text":"You have the Internet Gatweway specified as the destination in the Route Table.","correct":false},{"id":"780a0b2b6809da8bfafa8cc49a2d62e3","text":"Your instance doesn't have an Elastic IP.","correct":true},{"id":"0111365d729d1d299458b0a3069b9a25","text":"Your EC2 instance doesn't have a public IP address.","correct":true},{"id":"3376ac0efb861775fb39e3946d485331","text":"The security group isn't properly connected to the Internet Gateway.","correct":false}]},{"id":"5d0c33cd-3b30-46ae-937a-7ffe3350e8d0","domain":"automation","question":"Which of the following services is used to develop and deliver infrastructure as code?","explanation":"CloudFormation is used for Infrastructure-as-Code.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"About CloudFormation"}],"answers":[{"id":"a907a7338c1fb3821fbe8ed113c64b33","text":"CloudHSM","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false}]},{"id":"44b4605e-3e4b-4762-8db1-29f4d8bdadb1","domain":"data-man","question":"Your team has come to you for advice on finding the best storage solution on AWS. Your team's application runs on a load balanced pool of web servers and needs to store frequently changing data like buffers, caches, and other interim data. What AWS storage solution would you recommend to maximize performance and minimize costs?","explanation":"An instance store provides temporary block-level storage for your instance. This storage is located on disks that are physically attached to the host computer. Instance store is ideal for temporary storage of information that changes frequently, such as buffers, caches, scratch data, and other temporary content, or for data that is replicated across a fleet of instances, such as a load-balanced pool of web servers. Amazon Instance Store is best used for temporary storage. The other options would incur additional storage costs.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","title":"Amazon EC2 Instance Store"}],"answers":[{"id":"270fcb785810d0206945029bb05f4e97","text":"Amazon S3","correct":false},{"id":"e58f9c51d5656ba7cd0d4796730248a7","text":"Amazon EBS. Read contents on the EBS volume to improve performance.","correct":false},{"id":"e2b73d2522b2b07ac67d36de7ac51b75","text":"Amazon EC2 Instance Store","correct":true},{"id":"f7b96044a16becafecad63df1725e9c8","text":"Amazon EFS","correct":false}]},{"id":"0b73a5a1-e9ff-4bf8-8f53-0fb5aa540566","domain":"high-avail","question":"You run a bespoke security application on AWS and have a very limited (but highly valuable) number of customers over the globe. Your application is extremely sensitive and you limit who can access this application. The application sits on a fleet of EC2 webservers in an autoscaling group across multiple availability zones behind an elastic load balancer. Your end customers are investments banks and this application helps to keep one of their extremely sensitive database servers secure. The financial regulations state that these databases should not be internet facing and if they need access to specific internet resources, these resources must be whitelisted on the banks firewalls by a single fixed IP address only. In order to have a single fixed IP address to give to your customers in order to connect to your application, what choice of Elastic Load Balancer should you make to meet this strict security requirement?","explanation":"Only the Network Load Balancer supports the use of a single fixed IP address. The other load balancer offerings do not provide this","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html","title":"Network Load Balancer"}],"answers":[{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":true},{"id":"37e242ab2d525505933bbdb47d50d2b9","text":"Route53","correct":false},{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false},{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":false}]},{"id":"a7e0b35e-a0a9-43fb-86a8-4677970f57ae","domain":"mon-rep","question":"Your Auto-Scaling group is configured to launch a new EC2 instance whenever it detects an unhealthy instance in your Auto-Scaling group. However, you wish to be notified when this happens. Which of the following AWS services would you join with Auto-Scaling to achieve this?","explanation":"When you use Auto Scaling to scale your applications automatically, it is useful to know when Auto Scaling is launching or terminating the EC2 instances in your Auto Scaling group. Amazon SNS coordinates and manages the delivery or sending of notifications to subscribing clients or endpoints. You can configure Auto Scaling to send an SNS notification whenever your Auto Scaling group scales.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/ASGettingNotifications.html","title":"SNS Notifications With Auto Scaling"}],"answers":[{"id":"ef4ba2f338cdf4b615ed280ff0b2777d","text":"SQS","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"f62772d94b939126ee608465cf5e0881","text":"SWF","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":true}]},{"id":"7b724c4c-726d-4da7-9021-59e459427ecd","domain":"networking","question":"Placement Groups can either be of the type 'Cluster', 'Spread', or 'Partition'.  Choose options from below which are only specific to Spread Placement Groups.","explanation":"There is only one answer that is specific to Spread Placement Groups.  Whilst some of these answers are correct for either Cluster Placement Groups only, or for both Cluster and Spread Placement Groups, the question stated that only options specific to Spread Placement Groups should be chosen, which would rule out two options as they are true for both Spread & Cluster type placement groups.  The Logical grouping of instances within a single Availability Zone is only true of Cluster Placement Groups and is also incorrect.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"Placement Groups"}],"answers":[{"id":"bb229a2ce0bd114f2e002f94923618d2","text":"A spread placement group is a group of instances that are each placed on distinct underlying hardware","correct":true},{"id":"5e91fe627c2bd0613378a96fab7f8bc3","text":"Spread placement groups require a name that is unique within your AWS account for the region","correct":false},{"id":"0156cb85707daf221315fb25ac1bb505","text":"An instance can be launched in one placement group at a time and cannot span multiple placement groups.","correct":false},{"id":"2ce403ef492eb181bff27c45219186ad","text":"A spread placement group is a logical grouping of instances within a single Availability Zone","correct":false}]},{"id":"bc7cd5cf-6c7b-4f45-bb7c-5700451bd9aa","domain":"data-man","question":"You are managing an S3 bucket that contains business critical objects for your operations department. You are tasked with optimizing the storage costs of the bucket. You've identified 130 objects in the bucket that need to be available but can be recreated by your department. What would you do to optimize your costs?","explanation":"Amazon recommends using One Zone-IA if you can recreate the data if the Availability Zone fails, and for object replicas when setting cross-region replication (CRR). Use Standard-IA for your primary or only copy of data that can't be recreated. S3 Standard would not be a cost-effective solution, and S3 Glacier does not provide millisecond retrieval times and would not fulfill the availability requirement.","links":[{"url":"https://docs.aws.amazon.com/en_pv/AmazonS3/latest/dev/storage-class-intro.html","title":"Amazon S3 Storage Class"}],"answers":[{"id":"901f665e98aabd9853d4e0f9d3031ac2","text":"Set the storage class to S3 Glacier","correct":false},{"id":"daeec30860ad314818a31cb7ea5ba05e","text":"Set the storage class to S3 Standard","correct":false},{"id":"9b7e1e30e477deece7a8b6d9eecd9331","text":"Set the storage class to S3 Standard-IA","correct":false},{"id":"98c96ddb15112194ea3d2c44c1addd3b","text":"Set the storage class to S3 One Zone-IA","correct":true}]},{"id":"17b1cb9e-6c30-4cb5-8122-ac0799b51470","domain":"mon-rep","question":"Your team uses a CloudFormation template to configure a CloudWatch dashboard. The dashboard includes metrics of a classic load balancer such as HTTPCode_Backend_5XX and HTTPCode_ELB_5XX. The development team changes the type of the load balancer to network load balancer. However, after you recreate the CloudFormation stack, the metrics in the CloudWatch dashboard do not report any data. What is the cause of it?","explanation":"CloudFormation uses the resource type AWS::CloudWatch::Dashboard to create a CloudWatch dashboard. And the resource configures the metrics names in the DashboardBody. Metrics: HTTPCode_Backend_5XX and HTTPCode_ELB_5XX are valid only for the Classic Load Balancer, and are not supported in the Network Load Balancer (NLB), since NLBs operate in layer 4. The DashboardBody in the template needs to be modified to include the appropriate NLB metrics.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-cloudwatch-metrics.html","title":"CloudWatch Metrics for network load balancer"}],"answers":[{"id":"0c719bf2f29ec9b673c0092df8426d3c","text":"The target groups of the network load balancer are unhealthy so that they do not report any data.","correct":false},{"id":"fb1a3d94cf187bb86bd85a8a4d584c4d","text":"It takes longer time for the network load balancer to send metrics data to the CloudWatch dashboard. Wait at least half an hour.","correct":false},{"id":"959ff1c7a797aea82688e7a5b2468b64","text":"The selected metrics: HTTPCode_Backend_5XX and HTTPCode_ELB_5XX are not supported in a network load balancer.","correct":true},{"id":"fee717ce407145a9caf9135e8b046e55","text":"Network load balancers do not support reporting metrics to CloudWatch dashboard. Only Classic load balancers do.","correct":false}]}]}}}}
