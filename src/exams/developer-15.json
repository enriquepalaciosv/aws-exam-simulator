{"data":{"createNewExamAttempt":{"attempt":{"id":"c1def867-5a6e-4f96-a987-4c8f44937c56"},"exam":{"id":"9f5fc260-2d32-4105-a173-71f568e622a4","title":"AWS Certified Developer - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"b476baa3-99dc-4d87-a37a-2d0b23a7375c","domain":"deployment","question":"What is the largest size file you can transfer to S3 using a PUT operation?","explanation":"The largest file you can transfer to S3 using a PUT operation is 5GB. ","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html","title":"Uploading Objects to S3"}],"answers":[{"id":"208b4367cf771ded0e29ff6f9282442e","text":"1GB","correct":false},{"id":"84fb7b98e6e50302bf6cc709c92a6192","text":"5TB","correct":false},{"id":"6df47862fbfbd67605dc294d3f41925a","text":"100MB","correct":false},{"id":"0be25e5b91d25f9db3b4d3dcaf2cfd1f","text":"5GB","correct":true}]},{"id":"d1b0d0fe-4931-441c-83d5-716d63424a58","domain":"mon-trb","question":"You are working on an application which shares video content to subscribed users. This morning you have received a number of complaints that users are unable to access your content and they are seeing an HTTP 504 Status Code. Which of the following could be a possible explanation?","explanation":"An HTTP 504 status code is a Gateway Timeout which indicates that when CloudFront forwarded a request to the origin, because the requested object was not in the edge cache, one of the following happened: The origin returned an HTTP 504 status code to CloudFront; or, the origin didnâ€™t respond before the request expired. This is a server side issue, i.e. a problem or misconfiguration in your AWS infrastructure. Remember that any 5XX error indicates a server-side error, and a 4XX error indicates a client-side error.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/http-504-gateway-timeout.html","title":"HTTP 504 Gateway Timeout"}],"answers":[{"id":"b9434940d2516177efc8f8eef8b3de37","text":"There is a server side error within your AWS infrastructure","correct":true},{"id":"84f05e093a7f246d10fef9ea043d217a","text":"The users have a network connectivity problem","correct":false},{"id":"76b78bdea733c0e70e13c80add3c975d","text":"There is a client side error in the user's infrastructure","correct":false},{"id":"c8cffd0bf5d95cfc0541c7ad2d54d740","text":"The users could be attempting to access your site using an unsupported browser","correct":false}]},{"id":"d36289fe-be3b-4a73-8cc2-c216cfd47b05","domain":"security","question":"You're part of a developer team which is building an application that requires access to S3. Everyone on your team requires the same IAM permissions. As your team grows, how would you manage IAM policies and access to the right AWS resources in the most efficient manner?","explanation":"IAM groups are collections of IAM users in one AWS account. You can create IAM groups on a functional, organizational, or geographic basis, or by project, or on any other basis where IAM users need to access similar AWS resources to do their jobs. You can provide each IAM group with permissions to access AWS resources by assigning one or more IAM policies. All policies assigned to an IAM group are inherited by the IAM users who are members of the group. Creating IAM Users for each team member is not the most efficient manner; IAM Groups is more efficient. You cannot log into the AWS Management Console using an IAM role, nor can you do the same with Amazon Cognito. Amazon Cognito is best suited for mobile applications.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"7c9871a327396074304930d0dbe0fcee","text":"Create IAM Users for each team member. Attach an IAM policy to each user. Edit the IAM policy for each user adhering to the Principle of Least Privilege. Create new IAM policies for new team members as appropriate.","correct":false},{"id":"a834e2bd501ea84ca860e5213b4290ea","text":"Create one IAM role with the necessary permissions. Have all team members log into the AWS Management Console using that role. Rotate the password regularly.","correct":false},{"id":"d81d323b3e2be35dfba6061c653ce5d1","text":"Create an Amazon Cognito user pool for each user and a corresponding S3 bucket. Grant S3 bucket GET requests for each bucket to each Cognito user. Require users to log into the Console using their Cognito credentials.","correct":false},{"id":"9ef5172ef2f91f7f79640375254443b1","text":"Create an IAM Group called 'Developers'. Attach an IAM policy to the group with the appropriate permissions. Associate your IAM user and your team members' users to the Group. Add new team members to the group as appropriate.","correct":true}]},{"id":"bd3b8069-4ee1-480b-8738-d0683a3de962","domain":"security","question":"A company security team wants to implement a solution for securely storing RDS database credentials.  The solution should provide automatic rotation of database credentials.  What AWS service can the team use to meet these requirements?","explanation":"AWS Secrets Manager is an AWS service that can be used to securely store, retrieve, and automatically rotate database credentials. AWS Secrets Manager has built-in integration for RDS databases. Applications use Secrets Manager API's to retrieve database credentials, enabling secure storage of sensitive information outside of the application code. Systems Manager Parameter Store provides secure storage of sensitive information. However, it does not provide automatic credentials rotation capability specified as a requirement in the question scenario. Key Management Service (KMS) is used for management of cryptographic encryption keys, not for storage of sensitive information. Resource Access Manager is not applicable here as it is used for managing access to AWS resources between multiple accounts.","links":[{"url":"https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html","title":"What Is AWS Secrets Manager?"}],"answers":[{"id":"fcba7bd474eb1fdf49705827bbb6f28c","text":"AWS Key Management Service","correct":false},{"id":"b77e6ac1dd339ec1c0d94107e6c9d3d2","text":"AWS Systems Manager Parameter Store","correct":false},{"id":"7898cb92c418aeed6974ede9cb146462","text":"AWS Secrets Manager","correct":true},{"id":"7c09430feea9bf5bdf657bd178ce574c","text":"AWS Resource Access Manager","correct":false}]},{"id":"a3b17c55-ba03-4019-a9bd-d5c7a7eaab29","domain":"mon-trb","question":"You are running an online fitness tracker application on a number of EC2 instances behind an Elastic Load Balancer. You have noticed some anomalies with the way the application is performing lately and would like to collect the application logs from all of your application servers into one central location. Which of the following will you need to do for each instance?","explanation":"You will need the agent installed and running as well as configuring permission for the EC2 instance role to send logs to CloudWatch - i.e. permission to CreateLogGroup, CreateLogStream, PutLogEvents and DescribeLogStreams","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html","title":"CloudWatch Logs & EC2"}],"answers":[{"id":"66f294ea95cd02688d654dd101e3f370","text":"Ensure the instance role associated with your EC2 instance has permission to write logs to S3","correct":false},{"id":"0370efa52057a20e18cf2cd865cc462e","text":"Ensure the CloudWatch agent is installed and running on your EC2 instance","correct":true},{"id":"47bbd1c8d4e0c0c15af8e41856e95e45","text":"Ensure the CloudWatch agent has permission to write log files on your EC2 instance","correct":false},{"id":"e089da1319f2968b0773412e2fd71897","text":"Ensure the instance role associated with your EC2 instance has permission to write logs to CloudWatch","correct":true},{"id":"e24633db195c7650668666e7e12e5d24","text":"Ensure the instance role associated with your EC2 instance has read permission for CloudWatch","correct":false}]},{"id":"51d0eac3-d55e-4a50-aa5b-c133add86037","domain":"refactoring","question":"A content publishing organization runs its own platform, which uses DynamoDB as its data store. A bug report has come in from the content team. They say that when two editors are working on the same content they frequently overwrite each other's changes.\n\nWhat DynamoDB feature would prevent the most number of overwrite bug reports?","explanation":"Using a condition-expression we can perform a conditional update to an item. The condition must evaluate to true; otherwise, the update operation fails. We can use this feature to make sure the content of an article has not changed since it was last read, before we update it.\n\nacid-expression is incorrect because there is no such expression.\n\nDynamoDB TTL is incorrect because it is for deleting items from DynamoDB after a given duration, not creating a lock.\n\nCalling GetItem immediately before calling UpdateItem would help mitigate the issue, but still leaves a small race condition where condition-expression does not. It is, therefore, not the best solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ConditionExpressions.html","title":"Condition Expressions in DynamoDB"}],"answers":[{"id":"b1d92ca8c7500f89cffdf0057251aec1","text":"Include a condition-expression in the UpdateItem command.","correct":true},{"id":"058706dd0f32f05aa73a515774a5dc2d","text":"Call GetItem immediately before calling UpdateItem to ensure the item has not changed.","correct":false},{"id":"ddb55880d9b1b331207bcb38cebd6dbf","text":"Include an acid-expression in the UpdateItem command.","correct":false},{"id":"9d2d53ddaae2b905e48ea3705529a19c","text":"Apply a time-limited lock to the item while an author is editing it using a DynamoDB TTL.","correct":false}]},{"id":"6d9f501f-bc25-4802-8cb9-adb7b7cc9724","domain":"deployment","question":"In addition to choosing the correct EBS volume type for your specific task, what else can be done to increase the performance of your volume?","explanation":"There are a number of ways you can optimise performance above that of choosing the correct EBS type.  One of the easiest options is to provide more I/O throughput than you can provision for a single EBS volume.  This can be done by striping using RAID 0.  You can join multiple gp2, io1, st1, or sc1 volumes together in a RAID 0 configuration to provide parallel read/write performance. The second option is to choose an EC2 instance type that supports EBS optimization.  This ensures that network traffic will not contend with traffic between your instance and your EBS volumes.  The final correct choice is only related to HDD based EBS volumes.  When you create a snapshot of a Throughput Optimized HDD (st1) or Cold HDD (sc1) volume, performance may drop as far as the volume's baseline value while the snapshot is in progress. This behaviour is specific to these volume types.  Therefore you should ensure that scheduled snapshots are carried at times of low usage.  The one option on the list which is entirely incorrect is the one that states \"Never use HDD volumes, always ensure that SSDs are used\" as the question first states \"In addition to choosing the correct EBS volume type for your specific task\".  HDDs may well be suitable to certain tasks and therefore they should not be discounted because they may not have have the highest specification on paper.","links":[{"url":"https://aws.amazon.com/ebs/features/","title":"Amazon EBS features"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html","title":"Amazon EBS Volume Performance on Linux Instances"}],"answers":[{"id":"2b3853ec27d2a5f7a8fb114b5fcfc321","text":"Never use HDD volumes, always ensure that SSDs are used","correct":false},{"id":"5f33f064dbad9a3f30cd0395c1ae2106","text":"Ensure that your EC2 instances are types that can be optimized for use with EBS","correct":true},{"id":"060ad726277222bf1fdf1470ea833f1a","text":"Stripe volumes together in a RAID 0 configuration.","correct":true},{"id":"154b9cbae5d3f37e232f1a00c5364547","text":"Schedule snapshots of HDD based volumes for periods of low use","correct":true}]},{"id":"4b2ceeba-7d15-4ada-b47c-2761154d3cb9","domain":"deployment","question":"If your table item's size is 3KB and you want to have 90 eventually consistent reads per second, how many read capacity units will you need to provision on the table?","explanation":"3 rounds up to 4. 4/4=1. 90*1/2=45","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html","title":"Throughput Capacity for Reads and Writes"}],"answers":[{"id":"6c8349cc7260ae62e3b1396831a8398f","text":"45","correct":true},{"id":"642e92efb79421734881b53e1e1b18b6","text":"48","correct":false},{"id":"1ff1de774005f8da13f42943881c655f","text":"24","correct":false},{"id":"8613985ec49eb8f757ae6439e879bb2a","text":"90","correct":false}]},{"id":"6641f65a-c837-49a2-bbeb-11af158d44e0","domain":"mon-trb","question":"What is the maximum execution duration for a Lambda request?","explanation":"As of Oct 2018 the maximum execution duration has been increased from 300 seconds to 900 seconds (15 minutes)","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/limits.html","title":"Lambda Limits"},{"url":"https://aws.amazon.com/about-aws/whats-new/2018/10/aws-lambda-supports-functions-that-can-run-up-to-15-minutes/","title":"Update notice- Oct 2018"}],"answers":[{"id":"533f546e5ddb63fb2c810f7cca06678f","text":"300 seconds","correct":false},{"id":"4234838a99b7912e550babb083c205c4","text":"60 seconds","correct":false},{"id":"7ed53d277129b356be62369ec930e3b8","text":"500 seconds","correct":false},{"id":"a51534ea662db3ce23238035e25859e2","text":"900 seconds","correct":true},{"id":"8d15ed7d27d83ed6229a66b1f44b7696","text":"3 minutes","correct":false}]},{"id":"70e8f135-19fb-4ad6-82bc-8ec0ed899d83","domain":"security","question":"You are developing a video streaming application which users can access using multiple devices, for example, laptop, tablet and cell phone. You would like to be able to track usage across the different devices and limit the number of devices from which a user can stream content. Which of the following AWS technologies could you use to achieve this?","explanation":"Cognito enables developers to remember the devices on which end-users sign in to their application. You can see the remembered devices and associated metadata through the console. In addition, you can build custom functionality using the notion of remembered devices. For example, with a content distribution application (e.g., video streaming), you can limit the number of devices from which an end-user can stream their content.","links":[{"url":"https://aws.amazon.com/blogs/mobile/tracking-and-remembering-devices-using-amazon-cognito-your-user-pools/","title":"Tracking and Remembering Devices Using Amazon Cognito"}],"answers":[{"id":"3a73d44e5a5b2804c4cc5dd0b6c0bfe5","text":"Use S3 to store metadata about the device and link it to session state held in DynamoDB","correct":false},{"id":"6cbb574c9488bb59fdd64fa8f509fce8","text":"Use Cognito","correct":true},{"id":"5348de0d4df2bd40fa189bd4e5ff1b6c","text":"Store device metadata linked to session state in ElastiCache","correct":false},{"id":"425684337e67b0a12f438c06f1c5818d","text":"Use MFA on the device","correct":false},{"id":"3cff09984a222738fa34702f699ab961","text":"Use a Lambda function to store session state and device type in DynamoDB","correct":false}]},{"id":"d33e682c-89d2-4932-9b6d-a8095809bd88","domain":"deployment","question":"You are using CloudFormation to automate the build of several application servers in your test environment. Which of the following are valid sections that can be used in your CloudFormation template?","explanation":"Parameters, Resources and Outputs are all valid. It is worth learning the CloudFormation template anatomy and understanding how each section relates.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"}],"answers":[{"id":"ee611c8b9dfbbc792a9318c9837b2bcd","text":"Inputs","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"e4ba47693cf74a797e63f4557d4b88f4","text":"Transformations","correct":false},{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":true},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":true}]},{"id":"e475aa36-e8a9-4d0d-81db-abf30a055ef5","domain":"mon-trb","question":"How can you configure CodeBuild to notify the DevOps team of a failure in the build process?","explanation":"CodeBuild natively supports CloudWatch Events, SNS is a subscription based notification service which integrates with CloudWatch.","links":[{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/sample-build-notifications.html","title":"Build Notifications"}],"answers":[{"id":"d6c5ab1abdce3cd74b1ebe325b88d27e","text":"Use the CodePipeline dashboard to view the CodeBuild events log","correct":false},{"id":"1448724d0c2de970718ae2bfe3159256","text":"Use CloudWatch Events and SES notifications to send an email to the DevOps team","correct":false},{"id":"4a31b4240a14801eefb085b05f7985a6","text":"Use CloudWatch Events and an SNS topic to notify subscribers of build events","correct":true},{"id":"571ab39fe2270d1c1193587ccfd234f1","text":"Add the name of the email group to the notifications section of the CodeBuild console","correct":false}]},{"id":"802be8c8-07cc-48a7-94c8-21d785d18f5a","domain":"deployment","question":"Your organization is developing a CI/CD environment to improve software delivery of your applications. It has already adopted a plan to execute the various phases of the CI/CD pipeline from continuous integration to continuous deployment. There are now discussions around restructuring the team make-up to implement a CI/CD environment. How would you recommend creating developer teams as a best practice to support this change in the long run?","explanation":"AWS recommends organizing three developer teams for implementing a CI/CD environment: an application team, an infrastructure team, and a tools team. This organization represents a set of best practices that have been developed and applied in fast-moving startups, large enterprise organizations, and in Amazon itself. The teams should be no larger than groups that two pizzas can feed, or about 10-12 people. This follows the communication rule that meaningful conversations hit limits as group sizes increase and lines of communication multiply. Hiring an external consulting firm will not be beneficial in the long run. Setting up a single team is not best practice. AWS CodePipeline is a continuous integration and continuous delivery service for fast and reliable application and infrastructure updates and not used for team structuring.","links":[{"url":"https://d0.awsstatic.com/whitepapers/DevOps/practicing-continuous-integration-continuous-delivery-on-AWS.pdf","title":"Practicing Continuous Integration and Continuous Delivery on AWS"}],"answers":[{"id":"f3054a7a017a533ace8f081538d0b664","text":"Set up an application team to develop applications. Set up an infrastructure team to create and configure the infrastructure to run the applications. Set up a tools team to build and manage the CI/CD pipeline.","correct":true},{"id":"d163f1cc494b3cde77122207a42d9de1","text":"Set up one team to own an operate all components of the CI/CD pipeline to consolidate tasks and improve efficiency.","correct":false},{"id":"3e514092970cfe2b9a3ea7331a0828cf","text":"Use CodePipeline to manage your CI/CD environment and assign team members to own different phases within your CodePipeline.","correct":false},{"id":"b943ddf4265197477c4036cdd230b033","text":"Hire an external consulting firm to build and manage the pipeline. Provide them with the proper IAM roles to access your AWS environment.","correct":false}]},{"id":"43e8c8e5-d0e3-4502-b7e7-8c236a6625e3","domain":"mon-trb","question":"A company wants to monitor all traffic to a network interface on their bastion host. They wish to be alerted if there are more than 10 attempts to connect to the host via SSH within a one-hour time interval. What solution can the company employ to meet this requirement?","explanation":"VPC flow logs can be sent to CloudWatch Logs. A CloudWatch metric filter and alarm can be configured to send notifications when the specified criteria are satisfied. CloudTrail is not a supported destination for VPC flow logs. Amazon Inspector cannot be used to inspect network traffic in the way specified by the requirements. It performs vulnerability assessments on the host VM. Lambda functions cannot mount EBS volumes.","links":[{"url":"https://docs.aws.amazon.com/amazonglacier/latest/dev/vault-lock.html","title":"Amazon S3 Glacier Vault Lock"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-cwl.html#flow-logs-cwl-create-flow-log","title":"Creating a Flow Log That Publishes to CloudWatch Logs"}],"answers":[{"id":"cdab2e49cfa676ebe99e79d8f77f49b3","text":"Create a Lambda function that mounts the bastion host EBS volume and sends logs to CloudWatch logs. Create a CloudWatch metric filter for destination port 22. Create a CloudWatch Alarm trigger.","correct":false},{"id":"343b93587a12ff88f4e59413fbbd5d96","text":"Install the Amazon Inspector agent on the bastion host. Configure CloudWatch alerts based on Amazon Inspector findings.","correct":false},{"id":"6e51df099a849474d4791bce4aa25bb5","text":"Configure a VPC flow log with CloudWatch Logs as the destination. Create a CloudWatch metric filter for destination port 22. Create a CloudWatch Alarm trigger.","correct":true},{"id":"ecb0bcaac946feb8b9a9c2abcaace499","text":"Create a VPC flow log for the network interface with CloudTrail as the destination. Create a Lambda function that queries the CloudTrail logs for SSH login attempts. Trigger the Lambda function every 5 minutes with a scheduled CloudWatch event.","correct":false}]},{"id":"56a3a6cc-4c72-4b6c-a06c-4c310d107296","domain":"development","question":"An application successfully updates an existing object in S3. When checking the file contents, the developer does not see the updated file contents. What is the cause of this issue?","explanation":"Amazon S3 offers eventual consistency for overwrite PUTS and DELETES in all Regions. Amazon S3 provides high availability and high durability by replicating bucket objects across multiple availability zones and servers. This means that any updates to objects must replicate across all servers storing the data. This can take some time. Therefore, any updates to existing objects (using POST or DELETE), will take some time to be propagated across all of S3, and hence are eventually consistent.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Introduction to Amazon S3"}],"answers":[{"id":"4756256f32016be9d23caa16a75bb9c5","text":"HTTP 200 response code was not received.","correct":false},{"id":"47ad6c66cb5b231f66170a797fbb7782","text":"Overwrite PUTS in S3 have eventual consistency.","correct":true},{"id":"a693ecd0f4b5da724ee692d2059fc4c3","text":"S3 bucket policy permissions were not correct.","correct":false},{"id":"57d934f14c5f166d5f0604507d795cc0","text":"S3 Bucket Versioning was not enabled.","correct":false}]},{"id":"33d838eb-6e2a-499f-b1a0-0d385c20732a","domain":"deployment","question":"You have deployed an application using Elastic Beanstalk and your code is running in a Docker container. What is the process for upgrading this application?","explanation":"When you use the Elastic Beanstalk console to deploy a new application or an application version, you'll need to upload a source bundle. Your source bundle must consist of a single ZIP file or WAR file which does not exceed 512 MB. By using Docker with Elastic Beanstalk, you have an infrastructure that automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html","title":"Create an Application Source Bundle"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html","title":"Deploying Elastic Beanstalk Applications from Docker Containers"}],"answers":[{"id":"50ca13bdc867153ec83d6d066d4950b3","text":"Use CodeBuild to deploy the new code to the docker container","correct":false},{"id":"c9bd7c34b6482e6240a3a8a6404e5d09","text":"Upload your code to Elastic Container Registry and select the \"Deploy Now\" option in Elastic Container Service console","correct":false},{"id":"9142b51f935ad294eb31a909cbe9336e","text":"Upload a zip file containing the new version of your code using the \"Upload and Deploy\" button in the ElasticBeanstalk console","correct":true},{"id":"f65c3a605a6af1f8f362fab1debc50b2","text":"Upload your code to CodeCommit and select the \"Deploy Now\" option in Elastic Container Service console","correct":false}]},{"id":"b41da940-4b4e-11ea-b77f-2e728ce88125","domain":"mon-trb","question":"You created a CloudFormation template that launched a web application in us-west-1. However, you are experiencing a problem creating a development stack in us-east-1 to serve clients in another geographical location. What should you do to solve the problem?","explanation":"An Amazon Machine Image, or AMI, is used to launch an EC2 instance in a specified region. So, to use it in another region, you will have to copy it to the region of your choice. Recreating the resources is unnecessary since you only need to copy the AMI. And the IAM role is irrelevant to the question, since IAM roles are valid across the entire AWS account.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"b5a9be3c7b03258224fb637458459b99","text":"Recreate the AWS resources used for the application in us-west-1.","correct":false},{"id":"e72b5dc8983df71bdc1fa0c5b4985e4f","text":"Copy the AMI in the template from us-east-1 to us-west-1.","correct":false},{"id":"e3bebd36eb37842d75a71b0a69c37abe","text":"Copy the AMI in the template from us-west-1 to us-east-1.","correct":true},{"id":"6971fa728cde2ee82b21faac08aeb60a","text":"Copy your IAM role to us-east-1 region so that you have permissions to deploy CloudFormation stacks in that region.","correct":false}]},{"id":"c6126f50-a373-47bf-8245-6037dcea0b5a","domain":"security","question":"Your e-commerce application needs to use database connection strings to access a database containing product and customer data. Which of the following is a secure and scalable way to manage this?","explanation":"Using secure string parameters in Parameter Store is an appropriate way to avoid hard coding a password in your template code. This ensures that sensitive runtime parameters are kept as secure as you keep other secrets, while also keeping them separate from your deployment code.","links":[{"url":"https://aws.amazon.com/systems-manager/features/","title":"Systems Manager - Parameter Store"},{"url":"https://aws.amazon.com/blogs/mt/using-aws-systems-manager-parameter-store-secure-string-parameters-in-aws-cloudformation-templates/","title":"Using AWS Systems Manager Parameter Store Secure String parameters"}],"answers":[{"id":"62fc1a48d6c466824dfef123b5407ab3","text":"Store the encrypted credentials in an S3 bucket","correct":false},{"id":"65b9be4196a653fc5de9a6427a2f168a","text":"Store the credentials in Parameter Store","correct":true},{"id":"7cb38c21a4fc2e2ad04aca2dfe89bb59","text":"Add encrypted IAM credentials to the application server and use an IAM role to access the database","correct":false},{"id":"1c2a034c75f70a59fff1e639175239dd","text":"Allow the EC2 instance to access the database using an instance role","correct":false},{"id":"0d2bb1f681b1226217a023c4cb989aaa","text":"Hard code the connection strings in the application code","correct":false}]},{"id":"2d2bf934-5970-454e-846b-eaec6bf8d227","domain":"security","question":"A financial services organization is using Amazon S3 service to store highly sensitive data. What is the correct IAM Policy that must be applied to ensure that all objects uploaded to the S3 bucket are encrypted?","explanation":"In IAM Policy, the optional condition block enables specification of conditions for when a policy is in effect. In the Condition block, condition operators (such as equal, less than, etc.), the condition keys, and values can be combined into an expression to be evaluated. The IAM policy is applied when the condition expression is true. Condition key s3:x-amz-server-side-encryption must be used to validate that the object being uploaded is encrypted. Resource S3 ARN must include /* at the end of the S3 bucket name to be a valid ARN.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/amazon-s3-policy-keys.html","title":"Specifying Conditions in a Policy"}],"answers":[{"id":"38189a723781ee6f9148edfaeaf7f44b","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket/*\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:x-amz-server-side-encryption\":\"AES256\"\n                   }\n                }\n             }\n       ","correct":true},{"id":"6d70f3311566d7a45c1ee462595ab321","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:x-amz-server-side-encryption\":\"AES256\"\n                   }\n                }\n             }\n          ]\n       }\n       ","correct":false},{"id":"ca109710bb536d634e22f18fabf99d28","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:sse-encryption-cipher\":\"AES256\"\n                   }\n                }\n             }\n          ]\n       }\n       ","correct":false},{"id":"1cf9545900a32abf21ee1166aa1f7d3d","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket/*\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:sse-encryption-cipher\":\"AES256\"\n                   }\n                }\n             }\n          ]\n       }\n       ","correct":false}]},{"id":"c1fc5f56-f74e-405f-a974-d9bb2e2c57e6","domain":"deployment","question":"You have deployed a new version of your Lambda function, however during testing, you notice that  your application is not behaving as expected. How can you roll back to the previous version of your code?","explanation":"Remapping the PROD alias to the previous version will allow you to quickly roll back","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda versioning and Aliases"}],"answers":[{"id":"aa97bfdc9437ce44352de51699501c4d","text":"Make a new version of your function using the original Lambda code","correct":false},{"id":"28ab809ddc3a2aee352db2592bca020a","text":"Remap the PROD alias to point to the previous version of your function","correct":true},{"id":"1ba636d1ad4c4e2a9239fc75d17ffc41","text":"Update the $LATEST alias to point to the previous version of your function","correct":false},{"id":"60682da7d7f6df421c71e7e42cf4b227","text":"Redeploy your original code to $LATEST","correct":false}]},{"id":"33a233e7-f5ba-44d5-8c29-c72d59329262","domain":"development","question":"You are planning to write some Python code which will query a DynamoDB table and display the output on your website, which of the following tools can you use to start writing your code?","explanation":"AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser.","links":[{"url":"https://aws.amazon.com/cloud9/faqs/","title":"Cloud9 FAQs"}],"answers":[{"id":"706f0c9ac9a93c06a6db5f8838d71b0c","text":"CodeStar","correct":false},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":false},{"id":"fc8e90107dabb9a35c490b0d86adea06","text":"Cloud9","correct":true}]},{"id":"9822dfa6-67ab-47c1-9ee6-16f567e8f9ae","domain":"development","question":"You have created a DynamoDB table for your application with one partition key and no local secondary index. The table will include the following attributes: \nAccountID (partition key)\nAccountName\nReportingPeriod\nTotalRevenue\n You have an application running on EC2 that displays revenue data as a dashboard for your sales organization. The dashboard requires a view of total revenue over multiple reporting periods by customer name as a readable format. What secondary index will you need to add to your table?","explanation":"The requirement is for a particular CustomerName as it would be difficult for a reader to identity customers by their ID. We need a Global Secondary Index for a different partition key because a local secondary index must be created at the time you create a table. To retrieve only the time of interest, the ReportingPeriod must be the sort key. Finally, projecting TotalRevenue into the index will provide the necessary data to fulfill the requirement.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SecondaryIndexes.html","title":"Improving Data Access with Secondary Indexes"}],"answers":[{"id":"c923b638655c852ecf536b4a089fc8b3","text":"Local secondary index with a partition key of CustomerName and sort key of ReportingPeriod; project the TotalRevenue attribute","correct":false},{"id":"5a18172e710f5f6e062e96ddfedb6f9b","text":"Global secondary index with a partition key of CustomerName and sort key of ReportingPeriod; project the TotalRevenue attribute","correct":true},{"id":"54b2fc130eec92721970eedc9f515ad9","text":"Global secondary index with a partition key of ReportingPeriod and sort key of CustomerName; project the TotalRevenue attribute","correct":false},{"id":"ce82afc52e016682dd4eb59cdcc0d6dd","text":"Local secondary index with a partition key of ReportingPeriod and sort key of CustomerName; project the TotalRevenue attribute","correct":false}]},{"id":"aef3c172-a47c-4705-8241-936c06d9bb7c","domain":"development","question":"You have configured your CI/CD process using CodePipeline, however you want to introduce a manual sign-off and approval process which needs to be completed before a new version of your application is deployed to Production. How can you achieve this?","explanation":"With CodePipeline, you can add an approval action to a stage in a pipeline at the point where you want the pipeline execution to stop so that someone with the required AWS Identity and Access Management permissions can approve or reject the action.","links":[{"url":"https://docs.aws.amazon.com/codepipeline/latest/userguide/approvals.html","title":"Manual Approvals in CodePipeline"}],"answers":[{"id":"dc965161695cb07b80f56150a5a689f1","text":"Use CodePipeline to handle build, compile, test and packaging activities, then manually start a CodeDeploy job to run an automated deployment of successfully tested code","correct":false},{"id":"e53c0ca92d915920a376534f6d7a4e99","text":"Configure MFA for CodeDeploy deployments","correct":false},{"id":"fbfc1e99b3679cb29f80f55cf63c4a8d","text":"Use the CodePipeline Manual Approvals feature","correct":true},{"id":"5c0749c1409b05011fac6531c17f2cf8","text":"Configure two pipelines, one to handle code build and test, and one to handle automated deployment. Use SNS and Lambda to trigger the Deployment Pipeline following notification of successful completion of the Build and Test Pipeline","correct":false}]},{"id":"8b887631-86bd-436d-adee-4e2ba3b02111","domain":"security","question":"You have an application running on multiple EC2 instances, however every time an instance fails, your users complain that they lose their session. What can you do to prevent this from happening?","explanation":"There are various ways to manage user sessions including storing those sessions locally to the node responding to the HTTP request or designating a layer in your architecture which can store those sessions in a scalable and robust manner. Common approaches used include utilizing Sticky sessions or using a Distributed Cache for your session management. In order to address scalability and to provide a shared data storage for sessions that can be accessed from any individual web server, you can abstract the HTTP sessions from the web servers themselves. A common solution for this is to leverage an In-Memory Key/Value store such as ElastiCache.","links":[{"url":"https://aws.amazon.com/caching/session-management/","title":"Session management in AWS"}],"answers":[{"id":"89230492f141a4f85234c624287bb96a","text":"Store session state in ElastiCache","correct":true},{"id":"76fc6bddee6b0f8d088ea5cbe4e57160","text":"Store session state in S3","correct":false},{"id":"ef4fd36fa55c3c499f3fffa82a0c95e8","text":"Store session state in on the Elastic Load Balancer","correct":false},{"id":"b225818943ba4680b8e7dc9d9c376359","text":"Store session state in RDS","correct":false},{"id":"b193b1caff1bda86125cc326ca1058ac","text":"Store session state on a dedicated EC2 instance","correct":false}]},{"id":"f7fd0d7a-5d45-4f72-aa8e-d9a65270360f","domain":"refactoring","question":"You are developing an online hotel booking application which makes an number of requests to different back end applications to get quotes for travel related add-on services. You are using API gateway handle all the API calls and you notice that the majority of requests are for the same 5 or 6 services. How can you optimize the configuration to ensure the best performance for your application?","explanation":"You can enable API caching to cache your endpoint's responses, this reduces the number of calls made to your endpoint and improves the latency of requests to your API.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html","title":"API Caching"}],"answers":[{"id":"b255bca6117b1096664ab7b1415fae80","text":"Add an ElastiCache cluster in front of your database to cache the most frequently accessed data","correct":false},{"id":"9a86454fefc71c7430655ce2e18ac716","text":"Configure a CloudFront CDN in front of the API Gateway to cache the most frequent HTTP requests","correct":false},{"id":"59a69a5bb20a3dbe9214ef93c38041f7","text":"Configure auto-scaling for the API Gateway","correct":false},{"id":"336a729744a0b4682222e3a4a1cdc750","text":"Implement API Caching to cache the endpoint's response for the most popular requests","correct":true}]},{"id":"87896ba2-d675-4fce-97b9-f144f05d42f1","domain":"security","question":"You are building an S3 hosted website and your website is accessing javascript and image files located in another S3 bucket. How can you enable this? ","explanation":"Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html","title":"Cross-Origin Resource Sharing (CORS)"}],"answers":[{"id":"39e38061c46bfab6a44c6c8b5482763f","text":"Cross Origin Resource Sharing (CORS)","correct":true},{"id":"bef5f130edd0f036b2ca659d3295d5c7","text":"IAM roles","correct":false},{"id":"be48e3ddc7b57744c693982774a47dad","text":"S3 ACLs","correct":false},{"id":"0e0c1a7e0b6fe582226b82afc8eec89b","text":"S3 bucket policies","correct":false}]},{"id":"eebfef11-98bd-48f5-9775-b70b3600480a","domain":"development","question":"You are working on updates to your .NET application which has been deployed using Elastic Beanstalk. Your environment consists of 4 EC2 instances, as well as a number of different Lambda functions and DynamoDB tables. The application requires at least 2 instances to cope with the average workload and a minimum of 3 instances to cope with peak-time traffic. The Project Manager has asked you to roll out the updates as quickly as possible. Which of the following deployment strategies do you recommend?","explanation":"An all-at-once deployment deploys to all instances simultaneously which will put all of your web servers out of action at once. Rolling with additional batch launches an extra batch of instances before starting the deployment, to maintain full capacity. However, full capacity is not required in this scenario. Immutable deployments perform an immutable update to launch a full set of new instances running the new version of the application in a separate Auto Scaling group, alongside the instances running the old version; this is not required in this scenario. You can use a rolling update with a batch size of 25%, to ensure that 75% of your servers remain available at any time.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","title":"Elastic Beanstalk Deployment Options"}],"answers":[{"id":"11efd9ae6f76e706e3f1b34d97584ebc","text":"Immutable","correct":false},{"id":"f4920797afb92022a9c6608efcd86317","text":"Rolling","correct":true},{"id":"d5b066eef81dedf1d0352f27d2128586","text":"All at once","correct":false},{"id":"ff2713a6181db42fded101c670bbd0dd","text":"Rolling with additional batch","correct":false}]},{"id":"d4258c06-e769-46cc-b5ab-1571ea57879b","domain":"development","question":"You are pair programming with another senior developer in your team and you have been tasked with writing a number of different Lambda functions. Your colleague recommends that you separate the Lambda handler from the core business logic of your code. What is the rationale for this?","explanation":"At the time you create a Lambda function, you specify a handler, which is a function in your code, that AWS Lambda can invoke when the service executes your code. Separating the handler from the core business logic is best practice as it enables code re-use as well as making unit testing easier. See the URL below for best practices for developing Lambda functions.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html","title":"Best Practices for Working with AWS Lambda Functions"}],"answers":[{"id":"0f56edddb67c69aafb238d531d6abdfb","text":"To reduce the size of your deployment package","correct":false},{"id":"1763988c31a85fbf689902e6d3e1a185","text":"To reduce complexity caused by dependencies","correct":false},{"id":"79c80a290b9838caa5e24e1f96a2a8f7","text":"To make the code easier to re-use","correct":true},{"id":"6a5519ec7f0685c57d611a5c6731c5a4","text":"To improve function performance","correct":false}]},{"id":"72b0a4e6-82a6-4355-aa09-cf28563f00ed","domain":"development","question":"You are developing an online gaming application which needs to synchronize user profile data, preferences and game state across multiple mobile devices. Which of the following Cognito features enables you to do this?","explanation":"Amazon Cognito Sync is an AWS service and client library that enable cross-device syncing of application-related user data. You can use it to synchronize user profile data across mobile devices and web applications. The client libraries cache data locally so your app can read and write data regardless of device connectivity status. When the device is online, you can synchronize data, and if you set up push sync, notify other devices immediately that an update is available.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-sync.html","title":"Amazon Cognito Sync"},{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-cognito-sync.html","title":"Getting Started with Amazon Cognito Sync"}],"answers":[{"id":"67cb5d76e7fadc7e245c0cce89ad6dbf","text":"Cognito Sync","correct":true},{"id":"9a09b38e27134b81a45f7f2ed3939edc","text":"Cognito User Pools","correct":false},{"id":"0b422b4e655adc456bd9363c2dba938a","text":"Cognito Events","correct":true},{"id":"31aa670fdceaaf4289c74a1425e69d5b","text":"Cognito Streams","correct":false}]},{"id":"eeabb3b1-06bd-4a2f-89e9-425c07670c09","domain":"security","question":"Your application uses the STS API call AssumeRoleWithWebIdentity to enable access for users who have authenticated using a Web ID provider. Which of the following best describe what is returned by a successful call to AssumeRoleWithWebIdentity?","explanation":"AssumeRoleWithWebIdentity returns a set of temporary credentials, giving the user temporary access to AWS. It also returns an Amazon Resource Name (ARN) and the assumed role ID, which are identifiers that you can use to refer to the temporary security credentials.","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithWebIdentity.html","title":"STS: AssumeRoleWithWebIdentity"}],"answers":[{"id":"c4dee05a317f3836954c0577fb8df356","text":"AssumeRoleWithWebIdentity returns an assumed role ID which the user is allowed to assume temporarily","correct":false},{"id":"33401d97362173f45bb04e5a8c41b8a3","text":"AssumeRoleWithWebIdentity returns a set of temporary credentials (access key ID, secret access key and security token) which give temporary access to AWS services","correct":true},{"id":"5cf1fe7b63a8a99d7d3457d8b021e2c4","text":"AssumeRoleWithWebIdentity returns an ARN of the IAM user that the user is allowed to assume temporarily","correct":false},{"id":"b80ac03d28d57f31929047a4ce86a48c","text":"AssumeRoleWithWebIdentity returns an ARN of the IAM role that the user is allowed to assume temporarily","correct":false}]},{"id":"6593608d-3801-4b5d-8947-89efa395825a","domain":"refactoring","question":"You need to monitor application-specific events every 10 seconds. How can you configure this?","explanation":"You need to configure a custom metric to handle application specific events and if you want to monitor at 10 second intervals, you need to use high-resolution metrics. Detailed monitoring reports metrics at 1 minute intervals.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html","title":"CloudWatch Custom Metrics"}],"answers":[{"id":"8625460160031630c52a466b7a91f16b","text":"configure a high-resolution custom metric in CloudWatch","correct":true},{"id":"886f04b8880657a2d07a12c6355639a7","text":"Configure the application to send notifications using SNS every 10 seconds","correct":false},{"id":"f3e15ffbefd8415dda26321a2912dca1","text":"Select detailed monitoring in CloudWatch","correct":false},{"id":"da902bf148db5983868bf3383162183a","text":"Select high-resolution metrics in CloudWatch","correct":false}]},{"id":"943289f7-db1b-4439-b4c2-915168f617f9","domain":"development","question":"You work for a company which facilitates and organizes technical conferences. You ran a large number of events this year with many high profile speakers and would like to enable your customers to access videos of the most popular presentations. You have stored all your content in S3, but you would like to restrict access so that people can only access the videos after logging into your website. How should you configure this?","explanation":"All objects by default are private. Only the object owner has permission to access these objects. However, the object owner can optionally share objects with others by creating a pre-signed URL, using their own security credentials, to grant time-limited permission to download the objects. Anyone who receives the pre-signed URL can then access the object. For example, if you have a video in your bucket and both the bucket and the object are private, you can share the video with others by generating a pre-signed URL.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html","title":"Serving Private Content"},{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-urls.html","title":"CloudFront and Signed URLs"}],"answers":[{"id":"1925533bcb7e305a66391f083dd879d9","text":"Use CloudFront with HTTPS to enable secure access to the videos","correct":false},{"id":"ccfccd796a677ec7b7686f3d8c21a602","text":"Remove public read access from the S3 bucket where the videos are stored","correct":true},{"id":"07b930b04afb83395edadd40528e8336","text":"Use web identity federation with temporary credentials allowing access to the videos","correct":false},{"id":"9d3d0a72e06711a3345d6dd192885795","text":"Use SSE-S3 to generate a signed URL","correct":false},{"id":"90d89af9eb0c2a7b8b70ca4a300d9920","text":"Share the videos by creating a pre-signed URL","correct":true}]},{"id":"55fbda31-57ba-4009-a6da-09f690b40351","domain":"security","question":"You are developing an application which will use Cognito to allow authenticated Facebook users to sign-in and use your application. You would like to use Cognito to handle temporary access allowing authenticated users to access product and transaction data that your application stores in S3 and DynamoDB. Which is the best approach?","explanation":"Cognito is the recommended approach for user sign-up and sign-in for mobile applications which allow access to users with Facebook, Google or Amazon.com credentials. Identity pools enable you to grant your users temporary access to AWS services. User pools are user directories that provide sign-up and sign-in options for your app users.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/what-is-amazon-cognito.html","title":"What Is Cognito?"}],"answers":[{"id":"67a47bfe3685e0b65597b1bb14c5426f","text":"Configure an IAM User Group to provide temporary AWS credentials to your users to allow temporary access to AWS resources","correct":false},{"id":"edac71e5f6a783c051f80c7369a90c0d","text":"Configure a User Pool to provide temporary AWS credentials to your users to allow temporary access to AWS resources","correct":false},{"id":"e83779413869ed1569c2eb035ca21ef9","text":"Configure an Identity Pool to provide temporary AWS credentials to your users to allow temporary access to AWS resources","correct":true},{"id":"6e4d8be48c9bbd213381e12f94eaa9a7","text":"Configure a SAML 2 Federation to provide temporary AWS credentials to your users to allow temporary access to AWS resources","correct":false}]},{"id":"ece363fd-ee54-4d01-9e79-4ea34bf9b04a","domain":"mon-trb","question":"Your application is using SQS to send and receive messages. On average, it takes your application between 20 and 40 seconds to process a message and you have noticed that quite frequently, multiple application servers are attempting to process the same message which is causing issues within the application. What can you do to help prevent this from happening?","explanation":"Default message visibility timeout is 30 seconds. Your application is not always able to process a message within that time which means that after 30 seconds, the message is becomes visible on the queue again and is available for other consumers. Increasing the Visibility Timeout will give your application servers more time to processing and delete the message from the queue.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html#changing-message-visibility-timeout","title":"SQS Visibility Timeout"}],"answers":[{"id":"b2228b2fb368662ba42277270a2d0545","text":"Lower the message visibility timeout","correct":false},{"id":"9ef993bf7e61fa02b5f6ac0fc8da6b18","text":"Enable Short Polling","correct":false},{"id":"33e24a8e438593d0ed4994ce9ea68ccd","text":"Enable Long Polling","correct":false},{"id":"ece10cb74c921cec6162012cfe67d416","text":"Increase the message visibility timeout","correct":true}]},{"id":"0471ebc4-d106-4e3d-a3d4-0f594589ad5f","domain":"deployment","question":"How long can a message be retained in an SQS Queue?","explanation":"Messages will be retained in queues for up to 14 days.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-how-it-works.html#sqs-basic-requirements","title":"SQS - Basic Prerequisites"}],"answers":[{"id":"e3b481d5297f475abc283227bedbd9b9","text":"1 day","correct":false},{"id":"cb8f14fd3a41cfe1236a3c6b90077ca0","text":"7 days","correct":false},{"id":"0e92d2ae86e7d3e8eece27b399af6ea3","text":"14 days","correct":true},{"id":"947d8520f04473da621f2718138f3bc6","text":"30 days","correct":false}]},{"id":"13a47732-f4cd-40ed-a1e4-341826169510","domain":"refactoring","question":"You need to retrieve some data from your DynamoDB table, which of the following methods would consume the greatest number of provisioned Capacity Units?","explanation":"A Query is generally far more efficient than a Scan operation. Strongly consistent reads use up double the amount of Read Capacity Units compared to eventually consistent reads","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Query Vs Scan"},{"url":"https://aws.amazon.com/dynamodb/pricing/provisioned/","title":"Provisioned Capacity"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","title":"DynamoDB Read Consistency "}],"answers":[{"id":"d87fc0cde8df11c904ff6fe25cac6bfc","text":"Query with eventual consistency","correct":false},{"id":"5d682b15ed6ff4d0b5100242fa11d4ea","text":"Scan with eventual consistency","correct":false},{"id":"8747d18821697e99310487487007af03","text":"Scan with strong consistency","correct":true},{"id":"ac9570514b07db98ad6cc89ea1cc8741","text":"Query with strong consistency","correct":false}]},{"id":"847e9972-b2da-4c6c-b5b5-74fde22cf193","domain":"refactoring","question":"Your application is storing a lot of data in an S3 bucket called mybucket and is routinely exceeding 100 requests per second using a mix of GET, PUT and DELETE operations. Which of the following naming strategies will ensure low latency performance with S3?","explanation":"Prior to July 2018, AWS recommendation was to use random keyname prefixes to ensure objects were stored on separate partitions in order to give the best performance for mixed workloads. Since July 2017 this is no longer necessary, however we expect the use of random key names to still be tested in the exam so it is still important to be aware of this approach.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","title":"Updated guidance on S3 performance - for reference"}],"answers":[{"id":"015205126ff1a0346b8753dbe82a2306","text":"mybucket/2018-02-07-12-00-00/cust26347456/file1.txt","correct":false},{"id":"e327db1b1bbc74ad0be34391c8c54367","text":"mybucket/8761-2018-02-07-12-00-00/cust26347456/file1.txt","correct":true},{"id":"214a113d4fbf2063b6cbae4047f7e027","text":"mybucket/2018-02-07-12-00-00/cust26347456/8761file1.txt","correct":false},{"id":"a4df002d6a19b2b0edf9097af5315fce","text":"mybucket/customers/cust26347456/file1.txt","correct":false}]},{"id":"93862748-7e4b-4c90-a475-b52a4d1f6f4c","domain":"development","question":"You are planning to deploy a new version of your application using CodeDeploy. You only have a window of 2 hours to complete the deployment and test it. Your team leader is concerned about the time it could take to roll back the upgrade if it should fail. Which deployment approach would you recommend?","explanation":"Blue / Green is the one to use as this allows you to roll back with minimal disruption. An In-Place upgrade is very disruptive to roll back as it will involve re-deploying the original version of the code and during this time your application will be unavailable. Canary and Rolling updates are not an option for CodeDeploy","links":[{"url":"https://aws.amazon.com/blogs/devops/performing-bluegreen-deployments-with-aws-codedeploy-and-auto-scaling-groups/","title":"Blue/Green Deployments with AWS CodeDeploy"}],"answers":[{"id":"ff2713a6181db42fded101c670bbd0dd","text":"Rolling with additional batch","correct":false},{"id":"3a27747f75c4e73e94223a9e4065cd9c","text":"Blue / Green","correct":true},{"id":"53b8ba497ea2cdea89f60da12d94b46d","text":"In-Place","correct":false},{"id":"ecf715d6d79a2698b7fec0357f9d721f","text":"Canary","correct":false}]},{"id":"dfa117ef-d974-4b50-86d3-ee991142ac42","domain":"security","question":"You are developing a Lambda function written in Python which uploads a number of sensitive files to S3. The application architect has told you to use client-side encryption to protect the files. How can you do this?","explanation":"Client-side encryption means you need to encrypt the files where they are currently stored before uploading them to S3. You can do this in Lambda by using the AWS Encryption SDK.","links":[{"url":"https://aws.amazon.com/blogs/security/how-to-encrypt-and-decrypt-your-data-with-the-aws-encryption-cli/","title":"How to Encrypt and Decrypt Your Data with the AWS Encryption CLI"},{"url":"https://docs.aws.amazon.com/encryption-sdk/latest/developer-guide/crypto-cli.html","title":"AWS Encryption SDK Command Line Interface"},{"url":"https://docs.aws.amazon.com/encryption-sdk/latest/developer-guide/introduction.html","title":"What Is the AWS Encryption SDK?"},{"url":"https://docs.aws.amazon.com/encryption-sdk/latest/developer-guide/python-example-code.html","title":"AWS Encryption SDK for Python Example Code"}],"answers":[{"id":"46cf5e7bd245efaa706dc8411b60bf17","text":"Encrypt your local root disk before uploading the files","correct":false},{"id":"4de5ebab316fcf09fab5f4f030c8d0cb","text":"Encrypt the files using the AWS Encryption SDK","correct":true},{"id":"0bac92f5f923eb79514a753141a293ec","text":"Select S3 default encryption","correct":false},{"id":"442f843aa3641259b4c36e5565ff02c7","text":"Select the Encryption checkbox in the Lambda console ","correct":false},{"id":"349aac318f19b866d43ee7ad35140312","text":"Use SSL to upload the files","correct":false}]},{"id":"15a0fdc7-3a7a-42b2-a937-ccfda81d4261","domain":"mon-trb","question":"You have developed a CloudFormation stack in the AWS Management Console. You have a few small number of CloudFormation stacks saved in the Region in which you are operating in. When you launch your stack that contains many EC2 resources, you receive the error Status=start_failed. How would you troubleshoot this issue?","explanation":"Verify that you didn't reach a resource limit. For example, the default number Amazon EC2 instances that you can launch is 20. If you try to create more Amazon EC2 instances than your account limit, the instance creation fails and you receive the error Status=start_failed. Also, during an update, if a resource is replaced, AWS CloudFormation creates new resource before it deletes the old one. This replacement might put your account over the resource limit, which would cause your update to fail. You can delete excess resources or request a limit increase. Saving the template in the CLI or waiting a few minutes will have no impact. The default limit for CloudFormation stacks is 200 and the question explicitly states that there are only a very small number of existing stacks.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/troubleshooting.html","title":"Troubleshooting AWS CloudFormation"}],"answers":[{"id":"3e994bcee300070c97a3c141bc9967bd","text":"Use the Support Center in the AWS Management Console to request an increase in the number of EC2 instances.","correct":true},{"id":"2e0c1157e1b5a9bc0a985d53a1a60aa6","text":"Wait a few minutes before saving the template and retry the process.","correct":false},{"id":"57b1bceff40ae164e764946db0128ea0","text":"Save the template via the AWS CLI.","correct":false},{"id":"dae0c844938d270767115f5f50079227","text":"Use the Support Center in the AWS Management Console to request an increase in the number of CloudFormation stacks.","correct":false}]},{"id":"235fa5cd-42b5-4017-af9a-e62d0503651a","domain":"security","question":"You are working on a Lambda function which needs to access data in RDS, which of the below are valid approaches for securely storing the encrypted database connection strings and other secrets which your function needs to use?","explanation":"Parameter Store provides secure storage for configuration data, connection strings, passwords and secrets management. None of the other options are secure.","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html","title":"AWS Systems Manager Parameter Store"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/tutorial-env_console.html","title":"Create a Lambda Function Using Environment Variables To Store Sensitive Information"}],"answers":[{"id":"ca7c47bd30833fb42e5bc78f6c7583be","text":"Use Lambda Environment Variables","correct":true},{"id":"f2523ec5429fa4e1be124d650a69a0f5","text":"Store the encrypted connection string and other secrets in S3","correct":false},{"id":"913d4a9f910c7f6b836d623b39131480","text":"Use Systems Manager Parameter Store","correct":true},{"id":"53708b71a9f9d0c3994b3bd1d470b254","text":"Use DynamoDB to store the encrypted connection string and secrets","correct":false}]},{"id":"730a845f-ecf8-44f3-aedd-063e6c82f952","domain":"development","question":"A company is developing its first lambda function. The function needs access to their existing EC2 instances, which are all hosted in private subnets within their VPC.\n\nWhat must the company do to ensure their lambda can access the EC2 instances?","explanation":"To configure a lambda to connect to a VPC, one or more subnets into which it can connect must be defined.\n\nThe lambda function creates an Elastic Network Interface in one of the given subnets. It, therefore, needs an execution policy that allows it permissions to do so. The specific permissions required are in the attached AWS documentation link.\n\nThe Elastic Network Interface through which the lambda connects should then be associated with one or more security groups that allow network communication to the desired destinations, over the desired ports.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html","title":"Configuring a Lambda Function to Access Resources in a VPC"}],"answers":[{"id":"b83e0ff6499487c14dfb5578bbd8f3d2","text":"Configure the lambda's execution role to match the role applied to your EC2 instances.","correct":false},{"id":"48e1378bc6d56c11575da9eaf6e585a1","text":"Configure lambda's execution role to have permissions for managing an ENI within the VPC.","correct":true},{"id":"58f3dd590a2af5106b444d3ba4135b92","text":"Configure the lambda's function policy to allow EC2 to involve the function.","correct":false},{"id":"3c5b22594c1609c3eb107b6bb74dd18a","text":"Configure the lambda function to connect the private subnets used by the EC2 instances.","correct":true},{"id":"dff8a08528259b15e8eaa21fd941b858","text":"Configure lambda's security group, so it has access to the EC2 instances.","correct":true}]},{"id":"2204af3d-2ed7-41c4-9182-2df403ce77df","domain":"security","question":"An organization receives documents from its users, which must be put into a SQS queue, ready for processing. The documents range in size from 3 MB to 20 MB, and must always be encrypted at rest.\n\nWhat is the best was to queue these documents?","explanation":"SQS has a maximum message size of 256 KB, and DynamoDB has a maximum Item size of 400 KB; therefore, neither of these would be suitable for storing such large documents.\n\nGlacier would not be suitable as its use-case is for long term document archiving, not short term document processing.\n\nAll options listed provide encryption at rest.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-limits.html","title":"SQS Limits"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"e0d9c5dbccbb6899d85b6efde57b2929","text":"Base64 encode the document, then attached it to the SQS message as a Message Attribute.Â ","correct":false},{"id":"23a28d35794f1802b4590c8433d5f0be","text":"Store the document in S3. Include a reference to the object in a SQS message.","correct":true},{"id":"f9c2efbd72c96aab06a14e4f3be9b830","text":"Store the document in DynamoDB. Include a reference to the item in a SQS message.","correct":false},{"id":"19455cef763d19eace0135946b6c4a0b","text":"Store the document in Glacier. Include a reference to the object in a SQS message.","correct":false}]},{"id":"6a5ea0b3-2527-4c20-9410-d8807d16fcd3","domain":"security","question":"An organization is hosting their static website on S3, using a custom domain name. Users have started reporting that their web browsers' are alerting them to the fact that the organization's website is \"Not Secure\" because it is not served via a secure HTTPS connection.\n\nWhat is the easiest way to start serving the website via HTTPS?","explanation":"S3 buckets do not directly support HTTPS with a custom domain name. The simplest solution is to create a CloudFront distribution and set its origin to the S3 bucket. CloudFront allows you to specify a custom domain name, and supports managed certificates via Amazon Certificate Manager.\n\nEnabling AES-256 Default Encryption on the S3 bucket only affects the object at rest.\n\nApplication Load Balancers do support SSL termination but do not support S3 as a target.\n\nAWS Shield relates to Distributed Denial of Service protection, not encryption over the wire.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-requests-s3/","title":"Use CloudFront to serve HTTPS requests for Amazon S3"}],"answers":[{"id":"27631f4c194c5ea5116e308788e945f2","text":"Enable AES-256 Default Encryption on the S3 bucket, which ensures all content is delivered via HTTPS.","correct":false},{"id":"674d0590e06799926f232e63b73894a8","text":"Add a CloudFront distribution in front of the S3 static website, which supports HTTPS with a custom domain name.","correct":true},{"id":"6d63f6dae98a20c7db6446021c83e7f5","text":"Enable AWS Shield on the S3 bucket. Browsers automatically detect that Shield is enabled and report that the website is secure.","correct":false},{"id":"d76d398f54d04a531867ae84eda26050","text":"Add an Application Load Balancer in front of the S3 bucket and enable SSL termination.","correct":false}]},{"id":"764c68cc-0596-485a-b5a0-4bb272444d02","domain":"deployment","question":"Which of the following services enables you to automatically build, test and release new software whenever a developer makes an update to their code?","explanation":"CodeBuild only builds your code, it won't deploy it to your environment. CloudFormation is used to deliver Infrastructure As Code. CodeCommit manages your source code. CodeDeploy can be used to deploy code, but in isolation, it cannot create an automated release process. CodePipeline automates the build, test, and can be used to deploy phases of your release process every time there is a code change, based on the release model you define.","links":[{"url":"https://aws.amazon.com/codepipeline/","title":"AWS CodePipeline"}],"answers":[{"id":"56c20df941e069e1a35a1871f662298a","text":"CodeCommit","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":false},{"id":"5f6f48261d96567b3014b43c23382021","text":"CodePipeline","correct":true},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":false},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false}]},{"id":"95a7c517-4b4e-4996-b4d4-8ae11f359065","domain":"development","question":"An organization is considering performing canary deployments with their application. Which of the following statements best describes a canary deployment?","explanation":"A canary deploy allows us to gain confidence in an application update by initially just releasing it to a subsection of users. Once we are satisfied that the update is working as expected, the update is then rolled out to the remaining users.\n\nThe concept of a canary deployment is covered in the AWS Well-Architected Framework, and is a feature of API Gateway.\n\nIt can also be performed manually using Route53 Weighted Records, or via an Application Load Balancer with a Forward Action and Weighted Target Groups.","links":[{"url":"https://wa.aws.amazon.com/wat.concept.canary-deployment.en.html","title":"Canary deployment - Well-Architected Framework"}],"answers":[{"id":"03ff12365c5a8fc5fe5dfdbd2f1f00b6","text":"Each instance of the original application is taken out of service one at a time and replaced with the new version of the application. During the deployment, traffic is sent to a mix of the original and new versions.","correct":false},{"id":"0beefb480486ea595083b6d39062c27b","text":"All instances of the original application are stopped, after which new instances of the application are started up in their place. During the transition, there is a short period of downtime.","correct":false},{"id":"d593ae8cd7b7dc0ff31e7a286abc4a60","text":"A new version of the application is deployed alongside the existing version. Once the new version is ready to handle traffic, all traffic is redirected to it.","correct":false},{"id":"18c6683d5f9bd9718e5549310c8647e2","text":"A new version of the application is deployed alongside the existing version. A proportion of applicationâ€™s traffic is directed to the new application. If, after a given number of minutes, metrics demonstrate that the new version is performing correctly, the remainder of the traffic is moved to the new version.","correct":true}]},{"id":"f4f9e915-de73-4bcb-b2ad-dc9f35db47b8","domain":"development","question":"A document management application stores a catalogue of documents, each uniquely identified by its Document Number. Each document is also described by additional attributes: Document Title, Publication Date, Publisher Name, Country of Origin, and Length.  Functional requirements specify that the application should be able to produce a listing of all documents for each country of origin.  What would be the optimal DynamoDB data model for this application?","explanation":"Document Number is unique for each item thus making it a good choice for the table partition key.  Using a random prefix for the GSI partition key and County of Origin as the sort key enables us to have high cardinality for the partition key (thus avoiding any hot partitions) while still allowing for fast querying based on the Country of Origin. Publication Date is a poor choice for the partition key as it is a low cardinality attribute. It results in a hot partition for all items published on that date. Country of Origin is a low cardinality attribute and makes a poor choice for the partition key of the GSI.  This would result in a hot partition for the GSI.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-uniform-load.html","title":"Designing Partition Keys to Distribute Your Workload Evenly"},{"url":"https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/","title":"Choosing the Right DynamoDB Partition Key"}],"answers":[{"id":"5758693e8b3c98551e39e76dc9a454f3","text":"Table Partition Key=Document Number; Table Sort Key=Document Type; GSI Partition Key=Publication Date; GSI Sort Key=Country of Origin;","correct":false},{"id":"a164aeb879c69b453a5da649dcf8644e","text":"Table Partition Key=Publication Date; Table Sort Key=Document Number; GSI Partition Key=Publisher Name; GSI Sort Key=Country of Origin;","correct":false},{"id":"6885e1c4312042be0a8e712ed8803a35","text":"Table Partition Key=Document Number; Table Sort Key=Document Type; GSI Partition Key=Country of Origin; GSI Sort Key=Publisher Name;","correct":false},{"id":"c564e5a2356a715aed2326166cf46f04","text":"Table Partition Key=Document Number; Table Sort Key=Document Title; GSI Partition Key=Random Prefix; GSI Sort Key=Country of Origin;","correct":true}]},{"id":"e362623f-0040-49f7-8b76-f0d7484d7ade","domain":"mon-trb","question":"You have a distributed application which is made up of a number of different Lambda functions as well as API gateway endpoints and DynamoDB tables. You have noticed that the application is running unusually slowly today. Which of the following tools would be the best choice to help identify what is going on?","explanation":"AWS X-Ray helps developers analyze and debug production, distributed applications, such as those built using a micro-service architecture. With X-Ray, you can understand how your application and its underlying services are performing to identify and troubleshoot the root cause of performance issues and errors.","links":[{"url":"https://aws.amazon.com/xray/","title":"What Is X-Ray?"}],"answers":[{"id":"0863526e514d88cd2d00b39f8dda0920","text":"X-Ray","correct":true},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"8db8c2b0bbd0ff71d1d15bb32f69e3b8","text":"VPC Flow Logs","correct":false}]},{"id":"5cd0d201-9b93-42f0-9ae7-585263307009","domain":"development","question":"You've been asked to create a Web application with an endpoint that can handle thousands of REST calls a minute.  What AWS service can be used in front of an application to assist in achieving this?","explanation":"Questions containing 'REST' are usually related to APIs, so API Gateway looks the best answer.  Elastic Beanstalk is a service which allows you to run applications without understanding the infrastructure and can be discounted, as can Global Accelerator which is a networking service that improves the availability and performance of applications.  CloudFront can be used in conjunction with API Gateway to assist in geographically disparate calls, but won't process calls by itself.","links":[{"url":"https://aws.amazon.com/api-gateway/faqs/","title":"Amazon API Gateway FAQs"}],"answers":[{"id":"2ef9dd82927a3196ca2df3fc0cdf2e0b","text":"API Gateway","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"9ce65e2b30ed635c84bef82218a94fdf","text":"Global Accelerator","correct":false},{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false}]},{"id":"4ebf4856-d4c7-4ea6-85c6-602dba6571a3","domain":"development","question":"You are developing a latency-sensitive application which stores a lot of data in DynamoDB. Each item is 3.5KB in size. Which of the following DynamoDB settings would give you the greatest read throughput?","explanation":"A read capacity unit represents one strongly consistent read per second, or two eventually consistent reads per second, for an item up to 4 KB in size. Eventually consistent reads provide greater throughput than strongly consistent.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ProvisionedThroughput.html#ProvisionedThroughput.CapacityUnits.Read","title":"DynamoDB Provisioned throughput"}],"answers":[{"id":"53f0f96b15844d8d110ee8bc7174411d","text":"Configure the table with 10 read capacity units and use eventually consistent reads","correct":true},{"id":"58dedf407e5eb2c525e6732d526eeca0","text":"Configure the table with 10 read capacity units and use strongly consistent reads","correct":false},{"id":"fa75717ea7d6fc295eb8d4b34d6ac4f6","text":"Configure the table with 15 read capacity units and use strongly consistent reads","correct":false},{"id":"85f208ed09607ef8653aef5841e25848","text":"Configure the table with 15 read capacity units and configure the application to use a scan operation","correct":false},{"id":"882e4855b7af9b2ffa948de81b75cf47","text":"Configure the table with 10 read capacity units and use high-performance reads","correct":false}]},{"id":"108f8299-0018-4835-91f6-329fc5f9c1de","domain":"deployment","question":"Which of the following are considered to be Serverless?","explanation":"The following AWS technologies are Serverless: DynamoDB, API Gateway, SNS, Lambda, Kinesis and S3. RDS and Elastic Beanstalk both deploy EC2 instances to run their services","links":[{"url":"https://aws.amazon.com/serverless/","title":"Serverless Computing"}],"answers":[{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"2ef9dd82927a3196ca2df3fc0cdf2e0b","text":"API Gateway","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":true}]},{"id":"88a77a58-b901-4605-a657-98cdc90dff65","domain":"deployment","question":"A developer needs to compile Java code to produce a deployment artifact. Which Amazon service can the developer use for this task?","explanation":"Amazon CodeBuild is a service that compiles source code, runs tests, and produces software packages that are ready to deploy. Amazon CodeCommit is a source control service that hosts Git-based repositories. Amazon CodeDeploy is a deployment service that automates software deployments. Amazon CodePipeline is a continuous delivery service that helps you automate your release pipelines.","links":[{"url":"https://aws.amazon.com/codebuild/","title":"AWS CodeBuild"}],"answers":[{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":false},{"id":"5f6f48261d96567b3014b43c23382021","text":"CodePipeline","correct":false},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":true},{"id":"56c20df941e069e1a35a1871f662298a","text":"CodeCommit","correct":false}]},{"id":"b9987e32-c46c-4c78-b9db-e9a5283d7b16","domain":"development","question":"You are planning to use CodeDeploy to deploy an application for the first time to a brand new fleet of EC2 instances. Which deployment approach would you recommend?","explanation":"In-Place is the one to use as you are installing to a new fleet of instances, therefore Blue/Green is not possible. Canary and Rolling updates are not an option for CodeDeploy","links":[{"url":"https://docs.aws.amazon.com/codedeploy/latest/userguide/deployments.html","title":"Working with Deployments in AWS CodeDeploy"}],"answers":[{"id":"53b8ba497ea2cdea89f60da12d94b46d","text":"In-Place","correct":true},{"id":"ecf715d6d79a2698b7fec0357f9d721f","text":"Canary","correct":false},{"id":"3a27747f75c4e73e94223a9e4065cd9c","text":"Blue / Green","correct":false},{"id":"ff2713a6181db42fded101c670bbd0dd","text":"Rolling with additional batch","correct":false}]},{"id":"d91b5d09-a238-441f-b247-d81789372ec1","domain":"development","question":"GetItem operation is used to read data from a DynamoDB table. What strategy can be used to reduce the size of the read operations and increase read efficiency?","explanation":"Projection Expressions are a DynamoDB feature used to limit the attributes returned by the GetItem operation. Thus, this can be used to reduce the size of the payload returned by a read operation. Parallel Scans allows multi-threaded applications to perform DynamoDB Scan operations quicker. It cannot be used with GetItem operations to make them more efficient. Pagination allows developer to perform a Scan operation on a table and divide the result set into multiple pages. It cannot be used to make GetItem operations more efficient. Filter expression can be used with Scan operations to filter the results returned by the scan operation. It is not a GetItem operation feature.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ProjectionExpressions.html","title":"Projection Expressions"}],"answers":[{"id":"e37aefa5950be4eef211c98b18690f64","text":"Use Projection Expression.","correct":true},{"id":"ba803153fcb13208c9f26c6ae0dedef6","text":"Use Filter Expression.","correct":false},{"id":"30eb0435ad1702227f2d730850a75e93","text":"Use Pagination.","correct":false},{"id":"5081ca486a2f5aed471c714c6d81489f","text":"Use Parallel Scan.","correct":false}]},{"id":"8856df48-5866-4ee3-a5a7-2033444e21eb","domain":"security","question":"You have provisioned an RDS database and then deployed your application servers using Elastic Beanstalk. You now need to connect your application servers to the database. What should you do?","explanation":"As you are connecting to a database that was not created within your Elastic Beanstalk environment, you will need to create the Security Group yourself and also provide connection string and credentials to allow your application servers to connect to the database","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.RDS.html#rds-external-defaultvpc","title":"Elastic Beanstalk And RDS"}],"answers":[{"id":"26b897f7474a08158506b32e7c566323","text":"Provide the ip address of the RDS instance to Elastic Beanstalk","correct":false},{"id":"24e204c62e09f215959e144cbb8611d4","text":"Configure a security group allowing access to the database and add it to your environments auto-scaling group","correct":true},{"id":"50021ae41e50f1b10069ebcccab3c0ef","text":"Provide the database connection information to your application","correct":true},{"id":"1aa1798c4c20c22832e9a949af74ada3","text":"Configure Elastic Beanstalk to install a database client on your application servers","correct":false}]},{"id":"76086e8c-3f24-4bae-ba57-f5ac18dc1ff5","domain":"development","question":"What is the name of the SAM template property that defines the point in a Lambda function's code where execution begins?","explanation":"The Handler property specifies the Lambda function's entry point. For example, if the Lambda function was written in Python, and Handler was set to lambda_function.lambda_handler, execution would begin with the lambda_handler function, contained within the lambda_function.py file.\n\nRuntime refers to the language in which the Lambda function is written. For example, python3.6 or nodejs6.10, etc.\n\nSource and Index are not valid SAM template properties.","links":[{"url":"https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md","title":"AWS Serverless Application Model Specification"}],"answers":[{"id":"88fa71f0a6e0dfedbb46d91cc0b37a50","text":"Index","correct":false},{"id":"bc366f2d0ba3d681e7a3899917c5d3de","text":"Runtime","correct":false},{"id":"0bb4c52ba15ca41d65967d91840c66fb","text":"Handler","correct":true},{"id":"f31bbdd1b3e85bccd652680e16935819","text":"Source","correct":false}]},{"id":"47e074a7-e675-4918-92bf-d9a34b82803c","domain":"security","question":"Your application needs to access content located in an S3 bucket which is residing in a different AWS account, which of the following API calls should be used to gain access?","explanation":"The STS AssumeRole API call returns a set of temporary security credentials which can be used to access AWS resources, including those in a different account","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html","title":"Providing temporary access to AWS resources"}],"answers":[{"id":"c2599de6f471b00ab3948981939f8315","text":"STS:GetFederationToken","correct":false},{"id":"100979100796827d7bcafe4666e4984f","text":"STS:AssumeRole","correct":true},{"id":"5854d57d52033e05be8f9fda06330abd","text":"STS:AttachRole","correct":false},{"id":"818a55892aa657e5ef8dae6d12ee9273","text":"IAM:AddRoleToInstanceProfile","correct":false}]},{"id":"03ea5729-a486-470f-8cf7-a006c62c2045","domain":"deployment","question":"You have been asked to run your in-house application code using Lambda. Which of the following services could you use to deploy your code?","explanation":"You cannot deploy code using CodeCommit or CodeBuild. All of the other services can be used to deploy code in a Serverless environment","links":[{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/deploying-aws-lambda-functions-using-aws-cloudformation-the-portable-way/","title":"Deploying Lambda Functions Using CloudFormation"},{"url":"https://aws.amazon.com/blogs/compute/implementing-safe-aws-lambda-deployments-with-aws-codedeploy/","title":"Deploying Lambda Functions Using CodeDeploy"},{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"AWS SAM"}],"answers":[{"id":"56c20df941e069e1a35a1871f662298a","text":"CodeCommit","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":true},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"2565605f16beacf2f11c0ac6e7510e80","text":"AWS Serverless Application Model","correct":true}]},{"id":"08e64f1f-bcb0-40f6-843c-3457d9588552","domain":"refactoring","question":"A mobile social network application uses AWS SQS to distribute user's friends' profile updates. As the application grows in popularity, the required updates are reaching the 256KB message limit of SQS. What is a suitable solution to this problem?","explanation":"Using compression to reduce the size of the message payload is a possible approach to solving this issue. However, this would only be a temporary solution. As the number of members increased, the payload size would increase and would start to exceed the SQS message limit again. A more flexible approach is to store the update data in S3. This ensures that the data is stored reliably without any concerns regarding the data size. The SQS message payload would then contain a reference to the S3 blob. If the application is written in Java, the AWS SDK for Java supports this functionality out of the box. SNS has the same message payload limit as SQS, so this is not a suitable option. AWS AppSync is a service for enabling development of GraphQL based applications.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"520228b4da343e55c373c25f4d422e6e","text":"Use AWS AppSync to synchronize data to mobile app.","correct":false},{"id":"a2b93e7b257a6da054c32b0dd043384e","text":"Use compression to store the update data in a smaller SQS message.","correct":false},{"id":"8face15b61dcc69017b29352cd7dc288","text":"Create an SNS Topic. Use SNS to send updates instead of SQS.","correct":false},{"id":"0f7d51f145a99e3a18dbed75b79df613","text":"Store update data in S3 bucket. Send the reference to the S3 blob in the SQS message.","correct":true}]},{"id":"5f0e91e8-9de9-4bfe-b30d-6c00cb4e25ee","domain":"deployment","question":"Your application stores files in an S3 bucket located in us-east-1, however many of your users are located in ap-south-1. The files are less than 50MB in size, however users are frequently experiencing delays when attempting to upload files. Which of the following options will maximize the upload speed?","explanation":"S3 Transfer Acceleration is recommended to increase upload speeds and especially useful in cases where your bucket resides in a Region other than the one in which the file transfer was originated. Multipart upload is a good option for large files, e.g. >100MB in size.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html","title":"S3 Transfer Acceleration"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html","title":"Multipart Upload"}],"answers":[{"id":"137ef2be67b8313e80b25b2c3ea64ec0","text":"Implement a third party CDN solution.","correct":false},{"id":"34188758a0d842537d7d14f43c94c315","text":"Design the application to use multipart upload, so that the file is split in to multiple parts which are then uploaded simultaneously.","correct":false},{"id":"27cbe99b103845434c5d99034be17b10","text":"Utilize S3 Transfer Acceleration.","correct":true},{"id":"c1b6778485fc5a390b6a08f16f22afec","text":"Require the users to use Direct Connect in order to use to application so as to maximize the upload bandwidth.","correct":false}]},{"id":"3f74aa43-386f-49e4-bc1d-3e32a1282397","domain":"development","question":"An application uses DynamoDB table as its backend data store. Each item has size of 10KB.  The application needs to perform 100 eventually consistent read operations per second, and 50 write operations per second.  What is the provisioned WCU value required to meet these requirements?","explanation":"One write capacity unit is equivalent to one write per second for an item up to 1 KB in size.  Thus, the required WCU in this scenario is 10KB item size x 50 write operations per second = 500 WCU.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.ProvisionedThroughput.Manual","title":"Provisioned Mode"}],"answers":[{"id":"7ef605fc8dba5425d6965fbd4c8fbe1f","text":"150","correct":false},{"id":"cee631121c2ec9232f3a2f028ad5c89b","text":"500","correct":true},{"id":"a9b7ba70783b617e9998dc4dd82eb3c5","text":"1000","correct":false},{"id":"6c9882bbac1c7093bd25041881277658","text":"250","correct":false}]},{"id":"43f82a5f-84eb-4bda-9424-b03f27fa79ab","domain":"security","question":"What is the recommended approach to configuring a mobile application to allow users to sign-in and sign-up to your application via Facebook?","explanation":"Cognito is the preferred Web ID Federation mechanism in AWS","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc_cognito.html","title":"Cognito For Mobile Apps"}],"answers":[{"id":"a9d9e07070663e9217c3fcc296f07259","text":"Use Cognito as an Identity Broker between your application and the Web Identity Provider","correct":true},{"id":"09bea5739247e8d082cd79bd90905562","text":"Use encrypted AWS credentials within your application code and store them locally on the device","correct":false},{"id":"51e84803699eae0c33a7fd3c998881df","text":"Use a custom Lambda function to act as an Identity Broker between your application and the Web Identity Provider","correct":false},{"id":"0aed15971d7cc88de6e66d66abc629f5","text":"Use IAM as an Identity Broker between your application and the Web Identity Provider","correct":false}]},{"id":"4102ce86-6e8c-47b2-86d4-86e3b8b08558","domain":"mon-trb","question":"Your application runs in an Auto Scaling group to scale based on user demand. The Auto Scaling group runs behind an Elastic Load Balancer (ELB). When you check the ELB logs, you notice that a number of instances are failing the health check during periods of high demand. New instances are launching but they periodically fail health checks and subsequent instances are being launched which is increasing costs. What would you do to troubleshoot this issue?","explanation":"Amazon EC2 Auto Scaling waits until the health check grace period ends before checking the health status of the instance. Amazon EC2 status checks and Elastic Load Balancing health checks can complete before the health check grace period expires. However, Amazon EC2 Auto Scaling does not act on them until the health check grace period expires. To provide ample warm-up time for your instances, ensure that the health check grace period covers the expected startup time for your application. In this scenario, the health checks are most likely occurring before the EC2 instance and its applications have fully loaded, so increasing the health check grace period would likely resolve the issue. The cooldown period helps to ensure that your Auto Scaling group doesn't launch or terminate additional instances before the previous scaling activity takes effect, and are not used for health checks. Creating a new ELB or Auto Scaling group would have no impact but the problem would persist. AWS Config is a governance and management tool and is incapable of itself executing automated actions.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html","title":"Health Checks for Auto Scaling Instances"}],"answers":[{"id":"1fec64ae8a7c39cb26d12b3f50438dde","text":"Increase the cooldown period of the Auto Scaling group.","correct":false},{"id":"828102b2cd5f2f5f2873afea3714c7eb","text":"Increase the health check grace period.","correct":true},{"id":"fe8f15e29da594ce0b07d192b5e8f4f3","text":"Use AWS Config to monitor instances with failed health checks to terminate them.","correct":false},{"id":"47d484cdd97dff7b054f3cc746f8bbc6","text":"Create a new Auto Scaling group behind a new ELB. The current ELB is malfunctioning.","correct":false}]},{"id":"3a11539f-9ee0-4b96-a649-ec7635e18dc8","domain":"deployment","question":"What is the size of one unit of read capacity?","explanation":"A read capacity unit is 4KB in size.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html","title":"Throughput Capacity for Reads and Writes"}],"answers":[{"id":"35ef8d3515745f7c6916d7644fb5d6e5","text":"4 KB","correct":true},{"id":"e7363d80bd01165d7bb0c75f5add39c0","text":"5 KB","correct":false},{"id":"bf361755334066f22d019854dd2be686","text":"1 KB","correct":false},{"id":"d54d09275c9dfc95026a3a52d2f66173","text":"3 KB","correct":false}]},{"id":"b668531f-edd2-43f5-bf40-b7e68dad0d08","domain":"development","question":"A developer is working on a new green field project within an organization. The developer has been asked to recommend what technology could be used if the project is to be deployed with Elastic Beanstalk.\n\nWhich of the following platforms could the developer recommend for the project to meet its requirements?","explanation":"Elastic Beanstalk currently supports Docker, Ruby, and Go (amongst others). It does not support Perl or Swift.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html","title":"Elastic Beanstalk Supported Platforms"}],"answers":[{"id":"c5fd214cdd0d2b3b4272e73b022ba5c2","text":"Docker","correct":true},{"id":"0114ad06d728f1834e36fe1a39574ef4","text":"Perl","correct":false},{"id":"9916d1fc59fe22cc046a2fe1615bc764","text":"Ruby","correct":true},{"id":"5f075ae3e1f9d0382bb8c4632991f96f","text":"Go","correct":true},{"id":"ae832e9b5bda2699db45f3fa6aa8c556","text":"Swift","correct":false}]}]}}}}
