{"data":{"createNewExamAttempt":{"attempt":{"id":"7d251dff-7cba-4504-acc7-661384406e93"},"exam":{"id":"07c639b3-3127-4385-91c3-e5ea31add47c","title":"AWS Certified Solutions Architect â€“ Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"22315d49-9040-4de7-ae4f-ead04e5b4966","domain":"CostOptimized","question":"An application that performs statistical analysis on weather data receives files once a week. It assimilates the data in these files with previously collected data via its algorithms, and publishes a report at the end of each month. At unspecified times during the week, interim results need to be made available to meteorologists within minutes. Which architecture will meet the data availability requirements for the solution at the least cost, and with the simplest application code?","explanation":"Hibernating an EC2 instance provides a warm-start capability. When an EC2 instance is hibernated, RAM contents are saved to the EBS root volume. RAM contents are reloaded when the instance is restarted. AWS doesn't charge for the time that an instance is in the hibernated state. Storing data in Amazon DynamoDB costs more than EBS. EMR clusters cost more than EC2 instances. Stopping an EC2 instance clears RAM and requires the application to reload the data from a storage source when the instance is restarted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html","title":"Hibernate Your Instance"}],"answers":[{"id":"e45f5352867fe69bdbc5efaad38e34b2","text":"Process the data on a transient EMR cluster and store temporary results in S3","correct":false},{"id":"591c99dbc7dc2331d09abbc9ee1fb721","text":"Process the data on EC2 and hibernate the instance until new data files arrive or an interim results request is made","correct":true},{"id":"79010e5d6c3a7a1b4739890ce79939bd","text":"Process the data on EC2 and store temporary results in Amazon DynamoDB","correct":false},{"id":"1270950fb1ac5049d96bd1c8633745fe","text":"Process the data on EC2 and stop the instance until new data files arrive or an interim results request is made","correct":false}]},{"id":"b7f28443-c2d5-4605-be5a-960171a70ab0","domain":"Performant","question":"You are auditing your RDS estate and you discover an RDS production database that is not encrypted at rest. This violates company policy and you need to rectify this immediately. What should you do to encrypt the database as quickly and as easy as possible.","explanation":"At the present time, encrypting an existing DB Instance is not supported. To use Amazon RDS encryption for an existing database, create a new DB Instance with encryption enabled and migrate your data into it.  Alternately you can encrypt a copy of a Snapshot and restore the encrypted copy.  However you cannot encrypt as you are restoring from a snapshot.  A key point is that an outage will be required either way.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html","title":"Encrypting RDS Resources"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.Limitations","title":"Encrypting RDS Resources - Limitations"}],"answers":[{"id":"4d7c7e6fcbf43a4e3cb390d6b8f4e775","text":"Use AWS Database Migration Service","correct":false},{"id":"ee1313fab08c86cd71ec82d1ef4ccf05","text":"Create a new DB Instance with encryption enabled and then manually migrate your data into it.","correct":true},{"id":"23f20d1a056e924aa8bcce37914200c4","text":"Use the RDS Import/Export Wizard to migrate the unencrypted RDS instance across to a new encrypted database.","correct":false},{"id":"e3b45db054ee4c24e48b8fa4288bc219","text":"Take a snapshot of your unencrypted DB Instance and then restore it making sure you select to encrypt the new instance.","correct":false}]},{"id":"61549fca-bf43-4de6-a057-4539abb557f5","domain":"Performant","question":"Your business is evaluating several database technologies from AWS. It is expected that you will need to scale out the performance for read operations using read replicas. The business has decided to reduce management overheads as much as possible by using RDS for the database. Which of the following RDS Database engines would NOT be suitable in this scenario?","explanation":"MS SQL Server does not support Read Replicas when using RDS. MySQL, PostgreSQL, MariaDB and Aurora support Read Replicas to improve performance for Read Heavy applications.","links":[{"url":"https://aws.amazon.com/rds/details/read-replicas","title":"Amazon RDS Read Replicas"}],"answers":[{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false},{"id":"d2727816fa1087ddac7dff69e35c5536","text":"MS SQL","correct":true},{"id":"7f9733e208088b1ce6df3d4be1765396","text":"MariaDB","correct":false}]},{"id":"08233176-e11b-410e-98eb-25ca6e2eebcb","domain":"ResilientDesign","question":"A large enterprise has a distributed application in its own data center and relies on message brokers to connect and co-ordinate different systems. Message Brokers serve as the backbone for their IT environment and ultimately their business services. The enterprise has started to move some of its applications to the cloud and is looking for a cloud message broker solution so that the on-premise applications can interact with cloud-based application components. Which of the following services best suit the customer requirements?","explanation":"Amazon MQ is recommended for messaging between on-premises and cloud application components. It also supports industry-standard APIs and protocols such as JMS, AMQP and MQTT. Amazon SQS is best utilized as a messaging solution between components entirely on AWS. Amazon Step Functions is a fully managed service which makes it easy to co-ordinate components of distributed applications using visual workflows. Amazon SNS is a managed publish/subscribe service which reliably delivers messages to all valid AWS endpoints.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-activemq-in-a-hybrid-cloud-environment-with-amazon-mq/","title":"AWS Application Integration Services"}],"answers":[{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true},{"id":"55daa020bacdf7e4ae1a33c9f14c45b3","text":"Amazon SNS","correct":false},{"id":"860f0e709d06a1c1529c01a39cdfd798","text":"Amazon Step Functions","correct":false}]},{"id":"cbd65c24-5330-4cbe-aadc-f65637bed971","domain":"CostOptimized","question":"Your SQL server requires a specific type of collation and some unique third party tools installed on it. You will need access to the underlying operating system for management and monitoring of these third party tools. However, you'd like to keep the overall amount of management to a minimum. Which AWS service would best suit your needs?","explanation":"With all services you are trading control of underlying processes for cost saving and ease of management.  In the case of RDS, AWS has exclusive control of the DB engine and underlying processes.  If you need to have access to these, building a bespoke DB server on an EC2 instance is the correct technical choice.","links":[{"url":"https://aws.amazon.com/sql/","title":"SQL Server on AWS"}],"answers":[{"id":"8d8f3d54a16acc76a831ced6958141b9","text":"SQL server installed on EC2 with EBS","correct":true},{"id":"0ccd2cb2fe485108788ab60e8dbdfb4e","text":"RDS with SQL Server","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"8f23d472ee9e39b19dec8c94f59f497b","text":"ElasticCache","correct":false}]},{"id":"62d8dc77-c233-45c2-a957-5d33339eab6e","domain":"Performant","question":"When reviewing Auto Scaling events, it is noticed that an application is scaling up and down multiple times per hour. What design change could you make to optimize cost while preserving elasticity?","explanation":"Modifying your scaling threshold is preferable to altering your number of instances manually.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/as-instance-termination.html","title":"Auto-scaling Thresholds"}],"answers":[{"id":"efe86514d63b2cddf4fff0701f7625e8","text":"Increase the number of instances in the Auto Scaling group.","correct":false},{"id":"375c182a3d055fd5c0423b9ae48f006a","text":"Add a Provisioned IOPS volume to the instance.","correct":false},{"id":"e8210fd4c78d4a3776a601bbefdec9e3","text":"Change the Launch Configuration to use a larger instance type.","correct":false},{"id":"7ef405f3ad8fb6e5ab62fdb296690514","text":"Change the scale-down CloudWatch metric to a higher threshold.","correct":true}]},{"id":"6f99dc29-9e5a-4d5c-9152-c4e9d5e2325c","domain":"SecureSolutions","question":"When making use of EC2 instances on Dedicated Hosting, which of the following modes are you able to transition between by stopping the instance and starting it again?","explanation":"The tenancy of an instance can only be change between variants of 'dedicated' tenancy hosting. It cannot be changed from or to default tenancy hosting.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-instance.html","title":"About Dedicated Instances and Tenancy"}],"answers":[{"id":"d15424a6445328926f6ca57c29e143ca","text":"Host & Dedicated","correct":true},{"id":"aa095ba3b4f590c56ebe3dd7632cf1d4","text":"Host & Default","correct":false},{"id":"d31d964b101ff444e700016740c91a5e","text":"Default & Dedicated","correct":false},{"id":"04459d2ad5ea321a35a184d5db44d7ec","text":"Dedicated & Host","correct":true}]},{"id":"c138fec3-1027-4dc1-9215-b9108252ffab","domain":"Performant","question":"You have a production application that is on the largest RDS instance possible, and you are still approaching CPU utilization bottlenecks. You have implemented read replicas, ElastiCache, and even CloudFront and S3 to cache static assets, but you are still bottle-necking. What should your next troubleshooting step be?","explanation":"If your application requires more compute resources than the largest DB instance class or more storage than the maximum allocation, you can implement partitioning, thereby spreading your data across multiple DB instances.","links":[{"url":"https://aws.amazon.com/rds/faqs/","title":"See 'Q: How can I scale my DB instance beyond the largest DB instance class and maximum storage capacity?'"}],"answers":[{"id":"f08b245b716a56cb1a5a93fe863992a0","text":"You should consider using RDS Multi-AZ and using the secondary AZ nodes as read only nodes to further offset load.","correct":false},{"id":"d7a5a5cf870141d209e3e9cda6322823","text":"You have reached the limits of public cloud. You should get a dedicated database server and host this locally within your own data center.","correct":false},{"id":"062e544e8a9ad6c5491af7b0e682e372","text":"You should provision a secondary RDS instance and then implement and ELB to spread the load between the two RDS instances.","correct":false},{"id":"637dc8debb4ed3bebabdb2faf2cc89c3","text":"You should implement database partitioning and spread your data across multiple DB Instances.","correct":true}]},{"id":"95089332-27f7-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"A company is open from 6 a.m. to 6 p.m. EST, with core business hours specified between 9 a.m. to 3 p.m. EST. It needs an AWS Support plan that provides email access to Cloud Support Associates during core business hours. Which of the following support plans would be most suitable?","explanation":"Although Business and Enterprise Support plans include email access to the AWS Support team, the company specifically expressed interest in business-hours email support from Cloud Support Associates. The Developer Support plan fulfils this need, and it is ultimately more cost-effective than either the Business or Enterprise option.","links":[{"url":"https://aws.amazon.com/premiumsupport/plans/","title":"AWS Support Plans"}],"answers":[{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":false},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":false},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":true},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false}]},{"id":"e74fe976-5239-428f-a289-a171092a22e5","domain":"CostOptimized","question":"The volume of transactions coming into your online trading application fluctuates each day depending on market events. Log analyses indicate that on the heaviest volume days, compute demand comes in triple that of the average volume days. These heavy volume days occur about 15 days per year. You also have some workloads that need to process before close of business to provide input to daily reporting functions. How would you structure your mix of EC2 General Purpose Linux instances to obtain the highest cost efficiency?","explanation":"The most cost effective pricing for EC2 General Purpose Linux instances will usually involve a mix of pricing models. In this scenario, since the number of heavy volume days is limited, using a combination of reserved instances sized for the average volume days, on-demand instances to handle transaction volume increases on the heavy volume days, and spot instances to handle workloads that just need to complete by a certain time is the best option.  Spot instances for reporting workloads will cost less than using reserved instances and capacity doesn't need to be guaranteed. 3-year reserved instances are more cost-effective than one-year-term reserved instances. Over-provisioning for all but the 15 heavy volume days each year by using RI to cover heaviest load leaves a lot of underutilised capacity.","links":[{"url":"https://aws.amazon.com/ec2/pricing/","title":"Amazon EC2 Pricing"}],"answers":[{"id":"b9561b6540a0f9ae99dee0f11fb11d69","text":"3-Year Term Standard Reserved Instances for 100% of the average volume days, On-Demand instances to handle the spikes from the heavy volume days, and Spot Instances to handle the reporting workloads","correct":true},{"id":"e1376165009a434d36a5271305c1773a","text":"3-Year Term Standard Reserved Instances for 100% of the average and heavy volume days, and the reporting workloads","correct":false},{"id":"e4422c9ca1969401387bc4262b9cc0a7","text":"3-Year Term Standard Reserved Instances for 100% of the average volume days and the reporting workloads, On-Demand instances to handle the spikes from the heavy volume days","correct":false},{"id":"03f9a4a0692a0ea73ab4d51403b45abb","text":"1-Year Term Standard Reserved Instances for 100% of the average and heavy volume days, and Spot Instances to handle the reporting workloads","correct":false}]},{"id":"f85240a5-118e-4367-b2ed-0c442a60bec4","domain":"ResilientDesign","question":"You currently have a web application that uses two EC2 instances and you want 75% of the web traffic to go to one server and the other 25% to go to the other. Which of the following routing policies should you choose?","explanation":"You need a weighted routing policy because you want to be able to set the proportions traffic routed to your servers. A simple routing policy would have been ideal if you had a single server. Although failover and geolocation routing policies are for routing traffic to more than one resource, the former is ideal for configuring active-passive failover, and the latter is for specifying location rather than traffic proportions.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"582368ac8232617ead14ac74ccc40ea9","text":"Weighted","correct":true},{"id":"7388404ef116c3ff812bfd290b094d9e","text":"Failover","correct":false},{"id":"1fbb1e3943c2c6c560247ac8f9289780","text":"Simple","correct":false},{"id":"323d4eb70b252acb4a04eaf9e0882597","text":"Geolocation","correct":false}]},{"id":"85006d63-82b7-45dc-88c6-0baddad33725","domain":"ResilientDesign","question":"Which of the following is true with regards to a private IP address of an EC2 instance?","explanation":"Multiple IP addresses (IPv4 or IPv6) can be specified for an Instance depending upon Instance Types. Multiple IP addresses can be assigned and unassigned to network interfaces attached to running or stopped instances. An instance receives a static private IPv4 address from the address range within a VPC. Private IP address remains associated with the Network Interface when the instance is stopped and restarted, and is released when the instance is terminated. A secondary private IPv4 address can be assigned to any network interface. The network interface need not be attached to the instance. A secondary private IPv4 address that is assigned to a network interface can be reassigned to another one if you explicitly allow it. Although the primary network interface cannot be detached from an instance, the secondary private IPv4 address of the primary network interface can be reassigned to another network interface.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/MultipleIP.html","title":"Instance IP Addressing"}],"answers":[{"id":"9846d1971f5a7fb2fea9fcc99d4cc93d","text":"Private IP address remains associated with the Network Interface when the instance is restarted, and is released when the instance is stopped or terminated","correct":false},{"id":"c8eaf93ec90c897e9475642c70e3e7d2","text":"A secondary private IPv4 address cannot be detached or reassigned from the primary network interface to another network interface","correct":false},{"id":"08ce21259a0fb5332a9f8cf840942c51","text":"Private IP address remains associated with the Network Interface when the instance is stopped and restarted, and is released when the instance is terminated","correct":true},{"id":"8b90202f343b063cae25d7b89efaa9b1","text":"A secondary private IPv4 address can be reassigned from the primary network interface to another network interface","correct":true}]},{"id":"69e2d5c3-0b46-43b6-b5d5-cf1021256e41","domain":"SecureSolutions","question":"Meridian Media Services is migrating their customer facing online applications to AWS. They've experienced revenue impacting DDoS attacks in the past and would like to mitigate that risk going forward. They have both in-house developed and COTS applications that will run on EC2. CloudFront will be used for content delivery. Which security services should they implement to reduce the risk of DDoS interruptions?","explanation":"AWS Shield is a managed DDoS protection service that safeguards applications running on AWS. AWS Shield Standard provides comprehensive availability protection for CloudFront and Route 53, and AWS Shield Advanced gives higher levels of protection for EC2, ELB, and other AWS services.","links":[{"url":"https://aws.amazon.com/shield/","title":"AWS Shield"}],"answers":[{"id":"e34a57da0c06cbb3d1f5743459c20306","text":"Use the standard version of Amazon GuardDuty at no fee to protect CloudFront. Implement Amazon GuardDuty Advanced for a fee to protect the EC2 instances.","correct":false},{"id":"10bfd36d94ade6e61b462d7c05c3065a","text":"Apply the standard version of Amazon GuardDuty to protect both CloudFront and the EC2 instances as they are both included for a small fee.","correct":false},{"id":"62879f82a5496e13612fab26735c4e32","text":"Rely on the standard version of AWS Shield to protect both CloudFront and the EC2 instances as they are both included at no fee.","correct":false},{"id":"4506e0fedb041a54663245c51aa25e81","text":"Leverage the standard version of AWS Shield at no fee to protect CloudFront. Deploy AWS Shield Advanced for a fee to protect the EC2 instances.","correct":true}]},{"id":"08f57874-82ba-4e5e-a750-a59d4ba08d9f","domain":"Performant","question":"Which of the following statements is TRUE.","explanation":"You are able to attach multiple EBS volumes to an EC2 instance.  Plus you can attach an EBS volume (of certain types) to multiple EC2 instances","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html#EBSFeatures","title":"EC2 and Multiple EBS Volumes"},{"url":"https://aws.amazon.com/blogs/aws/new-multi-attach-for-provisioned-iops-io1-amazon-ebs-volumes/","title":"Multi-Attach for Amazon EBS Volumes"}],"answers":[{"id":"f2e3ed76c7a4224a6d0e521f7a926129","text":"You are able to attach multiple EC2 instances to some EBS Volume types.","correct":true},{"id":"1fac5b3ed26be82526f45ca40c282786","text":"It is possible to configure an Autoscaling Group to repair degraded EBS volumes, without the need to terminate the EC2 instances.","correct":false},{"id":"c17b4af7da4243bea4febf9426c65175","text":"You are able to attach multiple EBS volumes to an EC2 instance.","correct":true},{"id":"d3554bd6eace9b51dc90488e17d4f209","text":"It is possible to use Autoscaling with EBS, rather than EC2.","correct":false}]},{"id":"5dcee06e-bd95-4dfd-8540-5c54ae7c5fd3","domain":"SecureSolutions","question":"Your application stores your customers' sensitive passport information in S3. You are required by law to encrypt all data at rest. Company policy states that you must maintain control of your encryption keys. For ease of management, however, you do not want to implement or maintain a client-side encryption library. Which S3 encryption option should you use to secure your data at rest?","explanation":"Use SSE-C (C â‰ˆ customer controlled) if you want to maintain your own encryption keys, but donâ€™t want to implement or leverage a client-side encryption library.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html","title":"S3 - SSE-C"}],"answers":[{"id":"472035b16201f5505380c16ec3eb8518","text":"SSE-C","correct":true},{"id":"e17194408dc439e1658a544965724d44","text":"SSE-KMS","correct":false},{"id":"1562bb9d2d9567740605dcb1ccab5c80","text":"SSE-S3","correct":false},{"id":"bac271f02854883c6bc665637d0a5de6","text":"Amazon S3 Encryption Client","correct":false}]},{"id":"dbb146aa-ae1d-411e-82be-4777bd07c916","domain":"Performant","question":"A financial market dashboard needs to update asset values almost instantaneously for customers across the United States. Updates will be written to the primary application instance which resides in the AWS us-east-1 region. Which database architecture will provide the best performance for consumers of the dashboard's information?","explanation":"With Aurora MySQL you can configure cross-region Aurora Replicas using logical replication to up to five secondary AWS regions. Aurora PostgreSQL currently does not support cross-region replicas. Aurora Replica physical replication can only replicate to one secondary region. Using Aurora over RDS provides multiple read replicas in the deployment region and other benefits automatically without having to configure them.","links":[{"url":"https://aws.amazon.com/rds/aurora/?nc=sn&loc=0","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/?nc=sn&loc=6","title":"Amazon Aurora FAQs - High Availability and Replication"}],"answers":[{"id":"91857d4bed60ff0818ab1d95e0314b9c","text":"Deploy Amazon Aurora MySQL with Aurora Replicas using cross-region logical replication. Create the replicas in the AWS us-east-2 and us-west-2 regions.","correct":true},{"id":"f95722da1c54e4a7b38d775dec9d3952","text":"Implement Amazon Aurora MySQL with Aurora Replicas using cross-region physical replication. Create the replicas in the AWS us-east-2 and us-west-2 regions.","correct":false},{"id":"31441ec91d70f043876be523dca440b3","text":"Use Amazon RDS PostgreSQL with read replicas. Create the replicas in the AWS us-east-1, us-east-2, and us-west-2 regions.","correct":false},{"id":"a3f216bc2a3134a725e71894673ef3cd","text":"Deploy Amazon Aurora PostgreSQL with Aurora Replicas using cross-region logical replication. Create the replicas in the AWS us-east-2 and us-west-1 regions.","correct":false}]},{"id":"2edec957-8dde-4a46-a4af-5c65142d38c3","domain":"ResilientDesign","question":"Which of the following Route 53 policies allow you to a) route data to a second resource if the first is unhealthy, and b) route data to resources that have better performance?","explanation":"Failover Routing and Latency-based Routing are the only two correct options, as they consider routing data based on whether the resource is healthy or whether one set of resources is more performant than another.  Any answer containing location based routing (Geoproximity and Geolocation) cannot be correct in this case, as these types only consider where the client or resources are located before routing the data.  They do not take into account whether a resource is online or slow.  Simple Routing can also be discounted as it does not take into account the state of the resources.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"6036d720543b35a606bc0c2a682b27cf","text":"Geoproximity Routing and Geolocation Routing","correct":false},{"id":"6cc2be97f86de8b660b1fbafb18a890f","text":"Failover Routing and Latency-based Routing","correct":true},{"id":"f44dc584b393fd984b1646d677520fb0","text":"Failover Routing and Simple Routing","correct":false},{"id":"d1333c4521b08ff7084ea38f02e7fd41","text":"Geolocation Routing and Latency-based Routing","correct":false}]},{"id":"e33d4c87-1230-4f2b-88b2-effd138ff06a","domain":"ResilientDesign","question":"Your legal company is moving its production estate to AWS. They currently have a private cloud platform with VMDK files as their virtual machines. You need to move these files to AWS and create EC2 instances using the VMDK files. Which AWS service would help you achieve this goal?","explanation":"","links":[{"url":"https://docs.aws.amazon.com/vm-import/latest/userguide/what-is-vmimport.html","title":"VM Import/Export"}],"answers":[{"id":"87703e16953f8b2edf255258a29aa823","text":"Data Pipeline","correct":false},{"id":"06a107211eb5871f858a954edc47c1eb","text":"VM Migrate","correct":false},{"id":"42966c9ba8482ffc6ec12178fc18895c","text":"VM Import/Export","correct":true},{"id":"7445033ef83270814e799cba3c9fb637","text":"CloudMigration","correct":false}]},{"id":"a42f6119-13ea-4da2-b000-6d83c8d05d43","domain":"Performant","question":"Your company will be importing to AWS 150TB of data to AWS using AWS Snowball. This data will be used at the database layer, and this database should be able to be queried from a business intelligence application. Each item to be stored in the database is roughly 500KB in size. Which of the following is an ideal storage system for this data?","explanation":"Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud. You can start with just a few hundred gigabytes of data and scale to a petabyte or more.  Know the general size limits of the different DB services.","links":[{"url":"https://docs.aws.amazon.com/redshift/latest/mgmt/welcome.html","title":"What is Amazon Redshift?"}],"answers":[{"id":"bb19142594bf36abf39924ce5b3810c2","text":"AWS Aurora","correct":false},{"id":"20ee05108093daf420f5c776f43cf4a2","text":"AWS Redshift","correct":true},{"id":"6e11595bc7ccdbf672fefaababf72939","text":"AWS RDS","correct":false},{"id":"978477d5f5134ae77209d11e2ed888cc","text":"AWS DynamoDB","correct":false}]},{"id":"5228f828-624d-4fc6-998c-c06c2d0d685b","domain":"SecureSolutions","question":"You need to restore an object from S3-Glacier. Which of the following will help you do that?","explanation":"When discussing GLACIER it is important to distinguish between the storage-class 'Glacier' use by S3, and the 'S3-Glacier' service.  The 1st is managed via the 'S3' console & API, and the 2nd the 'S3-Glacier' console & API.  The Amazon 'S3' service maintains the mapping between your user-defined object name and Amazon Glacier system-defined identifier. These objects are not accessible via the 'S3-Glacier' service.  Objects that are stored using the 'S3-Glacier' service are only accessible through the Amazon 'S3' CLI or APIs. ","links":[{"url":"https://docs.aws.amazon.com/amazonglacier/latest/dev/introduction.html","title":"What Is Amazon S3 Glacier?"},{"url":"https://docs.aws.amazon.com/cli/latest/reference/glacier/initiate-job.html","title":"Restoring S3-Glacier objects with CLI (glacier)"},{"url":"https://docs.aws.amazon.com/amazonglacier/latest/dev/api-initiate-job-post.html","title":"Restoring S3-Glacier objects with API (POST)"}],"answers":[{"id":"3ff157bf0479ce95fdeaf68388b55232","text":"Using the AWS s3-Glacier Console","correct":false},{"id":"95668976125050f1b25d5a3b893d912c","text":"Using the Glacier API","correct":true},{"id":"4896195ad6b3c8d2e0061f7df703cc2c","text":"Using the S3 REST API","correct":false},{"id":"b2f31642b1d69fc886a2b9d175e65fcd","text":"Using the S3 sub-command from the AWS CLI","correct":false}]},{"id":"ce9877b8-de12-428e-8ff5-9900b8e817f2","domain":"Performant","question":"You have some EC2 instances in a private subnet that need access to an S3 bucket.  There is a requirement that traffic does not traverse the Internet. Which of the following can be used to achieve this?","explanation":"A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html","title":"VPC Endpoints"},{"url":"https://aws.amazon.com/blogs/aws/aws-privatelink-update-vpc-endpoints-for-your-own-applications-services/","title":"Private link announcement"}],"answers":[{"id":"a0b2b99d905954d58da91017a81d3059","text":"VPC Gateway Endpoint","correct":true},{"id":"8ca0f1328403ec0d05ed995272d74715","text":"NAT Gateway","correct":false},{"id":"3fdc04800c36e2177d81c4431616f533","text":"Internet Gateway","correct":false},{"id":"8f9d3edc1ed25845346d7d64e087edbe","text":"NAT Instance","correct":false}]},{"id":"d5e8caaa-e2d5-4d00-b9bc-53efee2b366f","domain":"Performant","question":"You have a production work load on AWS consisting of a Web Tier, Application Tier and Database Tier. Your web application starts to slow down under heavy use and can even become unresponsive. You investigate the issue and discover the issues are with the PostgreSQL RDS. What two steps could you do to improve performance?","explanation":"This is a classic scale-up or scale-out question. upgrading the disk is a scale-up solution, and adding read-replicas is a scale-out solution. Multi-AZ is possible, but will not help with performance, only resiliency.  RDS autoscaling is available only with Aurora","links":[{"url":"https://aws.amazon.com/blogs/database/scaling-your-amazon-rds-instance-vertically-and-horizontally/","title":"Scaling Your Amazon RDS Instance Vertically and Horizontally"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html","title":"Aurora Auto Scaling"}],"answers":[{"id":"ad6b88231cab9ea7642a5c16ce20722e","text":"Upgrade the storage type from General Purpose SSD to Provisioned IOPS SSD.","correct":true},{"id":"eda178658eacb51c3dcfd2f1f9e2c4c5","text":"Add multi-AZ to the RDS cluster and direct all read traffic to the secondary instance.","correct":false},{"id":"bd7d139b54a720f913080f4bec971220","text":"Provision 3 Read Replicas and direct all read traffic to these new instances.","correct":true},{"id":"4b8062204769a36aff6ebc2fb3ffb313","text":" Turn on RDS Autoscaling and scale when CPU Utilization reaches 90% for 5 minutes.","correct":false}]},{"id":"d87fd5d8-0ab7-4f87-a1c1-0635871020ca","domain":"SecureSolutions","question":"You work for a security company that stores highly sensitive documents on S3. One of your customers has had a security breach and, as a precaution, they have asked you to remove a sensitive PDF from their S3 bucket. You log in to the AWS console using your account and attempt to delete the object. You notice that versioning is turned on, and when you dig a little deeper you discover that you cannot delete the object. What may be the cause of this?","explanation":"Only the owner of an Amazon S3 bucket can permanently delete a version.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/delete-or-empty-bucket.html","title":"Deleting and Emptying S3 Buckets"}],"answers":[{"id":"96952afde438b94cf1de90e31b71d6bd","text":"You must be logged in as a Super User to delete objects.","correct":false},{"id":"be0a836d5e8a55696d3634aff7f51473","text":"You can never permanently delete an object on S3 after versioning is enabled.","correct":false},{"id":"6cca1efe9e60d13f3b73e61daaa6ba12","text":"S3 server-side encryption is preventing you from doing this.","correct":false},{"id":"34815cde786bfe064a8e2da0c0dfdcb6","text":"You cannot delete the object because you are not the bucket owner.","correct":true}]},{"id":"596795cf-105d-48d5-85b6-e405d5fdd9f6","domain":"ResilientDesign","question":"A company is planning on hosting their website in AWS using eight EC2 instances. The host instances should not be accessible from the public internet and all public traffic should be routed via an internet-facing Application Load Balancer. What VPC design would implement these requirements?","explanation":"Application Load Balancer must route traffic to at least two availability zones. Additionally, it can route traffic to exactly one subnet per availability zone. Plus an Application Load Balancer does require public subnets to connect to the public internet. ","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-limits.html","title":"Limits for Your Application Load Balancers"},{"url":"https://docs.aws.amazon.com/cli/latest/reference/elbv2/create-load-balancer.html","title":"CLI - create-load-balancer"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/tutorial-application-load-balancer-cli.html","title":"Create an Application Load Balancer"}],"answers":[{"id":"2e3ac2013c0727da6746e3a47a80b0d2","text":"Create one public subnet, and create two private subnets in two availability zones â€“ one private subnet in each availability zone. Deploy the Application Load Balancer in the public subnet. Deploy four EC2 instances in each private subnet.","correct":false},{"id":"3df1df058425ed65c84d7e840b6e7163","text":"Create two private subnets in two availability zones â€“ one subnet in each availability zone. Deploy four EC2 instances in each private subnet.","correct":false},{"id":"e055fea23504e371bcc6eee8879feb46","text":"Create four private subnets in two availability zones â€“ two subnets in each availability zone. Deploy two EC2 instances in each private subnet.","correct":false},{"id":"4ea9c17efdfefe5a8a4be9839f4e09bc","text":"Create two public subnets, and create two private subnets in two availability zones â€“ one private & one public subnet in each availability zone. Deploy four EC2 instances in each private subnet.","correct":true},{"id":"bbf4221f7315912411a36acb89bd3770","text":"Create one public subnet, and two private subnets in one availability zone. Deploy the Application Load Balancer in the public subnet. Deploy four EC2 instances in each private subnet. ","correct":false}]},{"id":"b21cf2a7-0cf1-47d4-a0c2-60403bb9cf37","domain":"CostOptimized","question":"To stay within the AWS Free Tier using Amazon EC2 for the first 12 months of having an AWS account, which of the following instance types should you use?","explanation":"One of the EC2 requirements for staying within the AWS Free Tier is using EC2 micro instances only. That makes t2.micro and t3.micro the correct responses.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc","title":"AWS Free Tier"}],"answers":[{"id":"1d4f2c610dbeb44e7ba09fed19564c76","text":"t2.micro","correct":true},{"id":"affa6cb0576af5aa6e603780fe7b203c","text":"t3a.small","correct":false},{"id":"ab61127647912c159c3fc08e9a102efc","text":"t2.small","correct":false},{"id":"7d3869f3c790e32d408d21d331095b0b","text":"t3.micro","correct":true}]},{"id":"61614ffb-1208-4742-9ff9-c8b316f13cc4","domain":"Performant","question":"When coding a routine to upload to S3, you have the option of using either single part upload or multipart upload. Identify all the possible reasons below to use Multipart upload.","explanation":"Multipart upload provides options for more robust file upload in addition to handling larger files than single part upload.","links":[{"url":"http://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html","title":"Uploading Objects Using Multipart Upload"}],"answers":[{"id":"fceeb753e12f0056c923fc9115be9472","text":"Multipart upload delivers quick recovery from network issues.","correct":true},{"id":"561cf9617064d07d28982fa0a4c4a5a3","text":"Multipart upload delivers improved security in transit.","correct":false},{"id":"df10e1b59a623a1543c4343ace225b87","text":"Multipart upload delivers the ability to append data into an open data file.","correct":false},{"id":"b2b49e9141fe4ce7eb0932d9c62a38b8","text":"Multipart upload delivers the ability to pause and resume object uploads.","correct":true},{"id":"d935110c327634d57b66601e6957ed42","text":"Multipart upload delivers improved throughput.","correct":true},{"id":"61f9f705b4dc688b86e0b25708cb7d88","text":"Multipart upload delivers the ability to begin an upload before you know the final object size.","correct":true}]},{"id":"57f5e909-774f-43b9-9718-c0b61fc8225c","domain":"SecureSolutions","question":"You are currently running an application in a production environment and you want to ensure that it is free of vulnerabilities. Which of the following AWS services would you use to accomplish this?","explanation":"You will need Amazon Inspector to perform a security assessment. Not only does it identify vulnerabilities in your application, it will also spot deviations from security best practices. AWS Shield and WAF protect the application from attacks that exploit vulnerabilities, rather than identify them. And Trusted Advisor only provides recommendations on how to improve security.","links":[{"url":"https://docs.aws.amazon.com/inspector/latest/userguide/inspector_introduction.html","title":"What is Amazon Inspector?"}],"answers":[{"id":"543096643aa6d28d9fac278e9257783d","text":"Amazon Inspector","correct":true},{"id":"769f2c629067645d4b60e13009500c9f","text":"AWS Web Application Firewall (WAF)","correct":false},{"id":"637d82e8a7206e87344161109cf7112d","text":"AWS Shield","correct":false},{"id":"41a831f771ef9bece59ed5160e335ae7","text":"AWS Trusted Inspector","correct":false}]},{"id":"70c6a808-0d5d-40d3-9b62-aa2fd031a543","domain":"CostOptimized","question":"You have three AWS payer accounts consolidated under an AWS Organization . Which of the below statements is TRUE for purposes of volume discounts?","explanation":"If you have multiple accounts, your charges will decrease because AWS combines usage from all accounts in the organization to qualify you for volume pricing discounts.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html","title":"Consolidated Billing for Organizations"}],"answers":[{"id":"a6cd99e8b1bbcfc82e184acc9f28eede","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled in each account","correct":false},{"id":"c9c2416d95c8112070b7a5b032629fdf","text":"Usage in each account will be evaluated individually to determine the volume discount it is individually entitled to","correct":false},{"id":"98e718508cd32b9ffb27d8648e9129d0","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to","correct":true},{"id":"4fb1af36b069dca73268eedbfab53e7b","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled at the Organisation level","correct":false}]},{"id":"81dc73a3-27d5-4080-99ab-d75edfa081b0","domain":"ResilientDesign","question":"You successfully configure VPC Peering between VPC-A  and VPC-B. You then establish an IGW and a Direct-Connect connection in VPC-B. Can instances in VPC-A connect to your corporate office via the Direct-Connect service as well as connect to the Internet via the IGW?","explanation":"VPC peering only routes traffic between source and destination VPCs. VPC peering does not support edge-to-edge routing.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html","title":"Invalid VPC Peering Connection Configurations"}],"answers":[{"id":"bdb763fa01cc1ea95bbab61b10394fea","text":"Instances in VPC-A will be able to access the corporate office, but not the Internet.","correct":false},{"id":"3542ee08d9923e029f120a6dc9b3d9db","text":"Instances in VPC-A will be able to access the Internet, but not the corporate office.","correct":false},{"id":"6ce9df55ff92945dc320411540661454","text":"Yes: VPC Peering is designed to route traffic between the VPCs.","correct":false},{"id":"d823d585a3fbbbcb9b921454f7d3bd62","text":"VPC peering does not support edge-to-edge routing.","correct":true}]},{"id":"d759f777-8830-47ae-ac99-038049debd8c","domain":"SecureSolutions","question":"As a solutions architect, you notice that one of the IAM roles in your company's AWS account has not been used for a year. What's the recommended course of action?","explanation":"If a role has not been in use for a very long time, it's best to delete it and its associated permissions as a security measure. However, you must make sure that there are no EC2 instances running with the role you are about to delete. Removing a role from a running EC2 instance linked to it will break any applications running on the instance.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_manage_delete.html","title":"Deleting Roles or Instance Profiles"}],"answers":[{"id":"49113178e5bef494be62b3a0ca9d622b","text":"Delete the role and its associated permissions.","correct":false},{"id":"47865d465f7ee9291a6a7955bb192b38","text":"Continue to monitor activity associated with the role.","correct":false},{"id":"191a23ce196611912881e94971f9a19e","text":"Check for any Amazon EC2 instances running with the role. If there are none, delete the role and its associated permissions.","correct":true},{"id":"e478f7c2a4052004cfe4e32a8d71c106","text":"Leave the role alone; you never know when you might need it.","correct":false}]},{"id":"b66725f5-c28a-40e3-a66f-ab440f24f05d","domain":"SecureSolutions","question":"You work for a construction company that has their production environment in AWS. The production environment consists of 3 identical web servers that are launched from a standard Amazon Linux AMI using Auto Scaling. The web servers are launched in to the same public subnet and belong to the same security group. They also sit behind the same ELB. You decide to do some testing: you launch a 4th EC2 instance into the same subnet and same security group. Annoyingly, your 4th instance does not appear to have internet connectivity. What could be the cause of this?","explanation":"Of these choices, the absence of the Elastic IP is the only one that could prevent internet access.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Internet_Gateway.html","title":"Enabling Internet Access"}],"answers":[{"id":"3645b812b5554461edf969a5a7b19083","text":"You need to update your route table so as to provide a route out for this instance.","correct":false},{"id":"3de8a51a1f321c3839a3ac9442da1f72","text":"You have not assigned an elastic IP address to this instance.","correct":true},{"id":"dbfb29d2865a1da80068dc82bdf11f7f","text":"You have not configured a NAT in the public subnet.","correct":false},{"id":"1b5e2f314ee9201857bbf929863476b9","text":"You have not configured a routable IP address in the host OS of the fourth instance.","correct":false}]},{"id":"5c841746-5aea-4a32-8a87-65b78fb0184b","domain":"ResilientDesign","question":"You want to use an AWS service that can monitor your EC2 instances and automatically recover it if it becomes impaired. Which of the following automation tools will enable you to do so?","explanation":"Using a CloudWatch alarm, you can monitor your EC2 instance and automatically recover it if it becomes impaired. Elastic Beanstalk is for deploying and managing web applications, Auto Scaling is for automatically scaling your resources up or down, and Lambda can be set up to automatically execute a function on a regular schedule. None of these tools, however, are used for auto EC2 recovery.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html","title":"Recover Your Instance"}],"answers":[{"id":"dee7ff8f7b10b9d388c7c561e9413b0d","text":"AWS Lambda","correct":false},{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":true},{"id":"afd14eb3f151c84e6ef7ab63812b4fbc","text":"Auto Scaling","correct":false},{"id":"bcf6eb183b7da148701bcc059a34675f","text":"AWS Elastic Beanstalk","correct":false}]},{"id":"2a2db64e-2e02-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You wish to set up a WordPress website consisting of 4 webpages for your client, who recently founded a logo creation business. Based on the clientâ€™s specifications, you will create one webpage that gives a summary of the company and its services, a second one that provides a brief professional biography of the founder, a third one that showcases the business ownerâ€™s portfolio, and a fourth one that serves as the contact information page and simply contains an email and phone number. Three of the four webpages will include images which the client doesnâ€™t expect will change much, if at all. Using the EC2 service to set up the website, which of the following instance types would be the most cost-effective choice?","explanation":"Based on the clientâ€™s specifications, it doesnâ€™t seem like this website requires an elevated level of compute, memory, storage, or networking power. So, a general purpose instance would be the most cost-effective choice.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types"}],"answers":[{"id":"b4820282379b9534539d339e1d898f2b","text":"Storage optimized","correct":false},{"id":"a97bdc2a34beb1500a16c5a5f41d3234","text":"Memory optimized","correct":false},{"id":"4e8e31d149d66214d0c06fd9ee8b877b","text":"Compute optimized","correct":false},{"id":"e65781ecdb4e2c3e7af2864d7b875e57","text":"Accelerated computing","correct":false},{"id":"3da02f3f7a678b5e2c167fb35dcea8f5","text":"General purpose","correct":true}]},{"id":"6d5d2303-29b6-4e31-96a7-b4067a191b9e","domain":"Performant","question":"You have an application that requires that 500 messages per second be sent and processed in order. Which service should be used to accomplish this?","explanation":"SQS FIFO queues are designed to enhance messaging between applications when the order of operations and events is critical, or where duplicates can't be tolerated. SQS Standard queues can process the messages, but cannot guarantee order.  SNS is used to send the messages, but does not process them. SES is an email service.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html","title":"Amazon SQS FIFO Queues"}],"answers":[{"id":"53a5cedcd58452f2752a4cf26d0c79b7","text":"AWS SQS FIFO","correct":true},{"id":"cdc05958362b09ba911028eaf41c71d5","text":"AWS SQS","correct":false},{"id":"74e06b58e00302916a205d2bf24e9837","text":"AWS SNS","correct":false},{"id":"17d68573ef0a017c323182d2cf4e7477","text":"AWS SES","correct":false}]},{"id":"5a47c265-e7a8-455e-9a59-35c26843fc4c","domain":"ResilientDesign","question":"You have a website that uses the HTTP and HTTPS protocols and consists of two web servers and an RDS database server. Which of the following choices would be the most suitable load balancer for distributing incoming web traffic?","explanation":"As of now, AWS offers three types of load balancers, which are Application Load Balancers, Network Load Balancers, and Classic Load Balancers. All three types are elastic load balancers, which means that they automatically distribute incoming traffic and scale resources to meet traffic demands. So 'Elastic Load Balancer' is incorrect.  Going with an application load balancer is the best choice because it makes routing decisions at the application layer, which is HTTP and HTTPS. If the question was addressing routing decisions at the transport layerâ€”which includes protocols like TCP, UDP, and TLSâ€”then Network Load Balancer would have been the correct answer. Classic Load Balancers is no longer the recommended load balancer for the majority of users in AWS; it is now only recommended for use when running in EC2 Classic mode.","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/","title":"Elastic Load Balancing"}],"answers":[{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false},{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":true},{"id":"e95e5a2a3cc8625bca3d71b817367e2d","text":"Elastic Load Balancer","correct":false},{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":false}]},{"id":"d27e19ed-c0a1-430f-b5df-5e792077aaa4","domain":"Performant","question":"Your existing on-premise servers rely on Memcached to provide memory object caching. If you were to move to AWS, how might you preserve this functionality?","explanation":"ElastiCache is a web service that makes it easy to set up, manage, and scale a distributed in-memory cache environment in the cloud. It provides a high-performance, scalable, and cost-effective caching solution, while removing the complexity associated with deploying and managing a distributed cache environment.","links":[{"url":"https://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/WhatIs.html","title":"About ElastiCache"}],"answers":[{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":true},{"id":"769c10500364777e54f2a7c646b7c699","text":"Install Memcached on EC2","correct":false},{"id":"8f3e091d35aa63444fb3aeeecc74eaf3","text":"Elastic MapReduce","correct":false}]},{"id":"24984439-79ad-4ddd-874e-0cf8800affa0","domain":"Performant","question":"You are running a Cassandra database that requires access to tens of thousands of low-latency IOPS. Which of the following EC2 instance families would best suit your needs?","explanation":"High I/O instances use SSD-based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require tens of thousands of IOPS.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/#highio-instances","title":"High I/O Instances"}],"answers":[{"id":"750fc21187d18139777ca329bb74df13","text":"Memory Optimized Instances","correct":false},{"id":"5a09e6d2f372cf15511772f8f380afc0","text":"Dense Storage Instances","correct":false},{"id":"00ce754caeddc3589b864a8e5d665fe7","text":"High I/O instances","correct":true},{"id":"5cd383d698034a613d2efaeb78ade93d","text":"Cluster GPU Instances","correct":false}]},{"id":"60257524-46b9-4fd3-9de7-a7febd7b0199","domain":"SecureSolutions","question":"With SAML-enabled single sign-on, ________.","explanation":"To see the process by which federated users are granted access to the AWS console, please follow the link, below.","links":[{"url":"http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_enable-console-saml.html","title":"Federated User Access to the AWS Console"}],"answers":[{"id":"2687603c9611a7e796998f6cbe63e321","text":"The client browser is immediately directed to the AWS Console.","correct":false},{"id":"78e79272b9f462f911e8226704695628","text":"After the client browser posts the SAML assertion, AWS sends the sign-in URL as a redirect, and the client browser is redirected to the Console.","correct":true},{"id":"3c951c75981deee0dc3b3d1d6f75a03b","text":"The portal first verifies the user's identity in your organization, then generates a SAML authentication response.","correct":true},{"id":"3a567201818696fafbfc66b46325647b","text":"The portal acknowledges a SAML authentication response, then verifies the user's identity in your organization.","correct":false}]},{"id":"b8cb8890-c16a-4609-904f-2cd52cfeba0e","domain":"CostOptimized","question":"What is the minimum billable object size for S3 - IA?","explanation":"The minimum object size is 0 bytes, however you will be billed for 128 KB.  Objects smaller that 128 can still be stored, but will be billed as if they are 128KB. ","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Standard - IA Object Size (table)"},{"url":"https://aws.amazon.com/s3/faqs/?nc=sn&loc=6","title":"S3 Standard - IA minimums"}],"answers":[{"id":"05a402af63179f5ea4189bcb6a7e8bc5","text":"1 Byte","correct":false},{"id":"bf361755334066f22d019854dd2be686","text":"1 KB","correct":false},{"id":"5de6c8bb0062d1883700e0bd14152d0d","text":"128 KB","correct":true},{"id":"fdd68bff35708140c14d3cd3a3b0759d","text":"0 Bytes","correct":false}]},{"id":"7dafc126-8f93-4ac8-97ba-01818de79dc1","domain":"SecureSolutions","question":"As a junior Cloud Engineer, you receive a CloudWatch alarm indicating that there might be a layer 7 attack of your environment. You recall that your company has an AWS Shield Advanced subscription. Which of the following options is the best response?","explanation":"You *can* investigate and mitigate the DDoS attack on your own, so that is a potentially correct answer. Similarly, requesting internal assistance is another possible answer because of your tech leadâ€™s expertise. However, the best course of action is to take advantage of your AWS Shield Advanced subscription, which routes you to true DDoS experts. In this case the *most correct* answer is to work with AWS Support. Doing nothing should never be considered as an answer.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-responding.html","title":"Responding to DDoS Attacks"}],"answers":[{"id":"0b9ac6496fca4f50d60b7665f91d9209","text":"Investigate and mitigate the attack on your own.","correct":false},{"id":"e13ab7a7dcc291aa8a8f5e4e1c3a8646","text":"Do nothing; it is an AWS issue that will resolve itself.","correct":false},{"id":"b62d821db1c6397935c957ddd8214d47","text":"Request assistance from tech lead.","correct":false},{"id":"43d522d2e9a722af4df45616e09e2ff4","text":"Contact AWS Support Center.","correct":true}]},{"id":"7589448c-e00c-4c64-9d5f-04e10ac556e4","domain":"CostOptimized","question":"An enterprise is planning to move its on-premise application to AWS cloud. The enterprise planned to build the non-production applications first as a proof of concept, and the governance team has provided approval for downtime for a brief period if cost can be compensated. You recommend spot instances as this satisfies the scenario explained above. Do vCPU limits apply when requesting a spot instance?","explanation":"Amazon EC2 is transitioning on-demand instance limits from the current instance count-based limits to vCPU-based limits to simplify the limit management experience for AWS customers. Beginning September 24, 2019, customers can opt in to vCPU-based instance limits. Count-based instance limits will not be available or supported after November 8, 2019. The vCPU-based limits only apply to running on-demand instances and does not apply when purchasing reserved or spot instances.","links":[{"url":"https://aws.amazon.com/ec2/faqs/","title":"Amazon EC2 compute service features"}],"answers":[{"id":"9bfb4cfa201ec7e2242c7df2c0d39906","text":"vCPU limits apply to spot instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false},{"id":"1fe04947ca4403eb3588fb87310de29e","text":"vCPU limits apply to reserved instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false},{"id":"a4fb94942aaa43d251b18a4126ce6d18","text":"In AWS, only instance count based limits exist and there is no concept of vCPU limits.","correct":false},{"id":"34394b797e4a477511982b1ac4a38d19","text":"vCPU limits apply only to on-demand instances and do not apply for spot instances.","correct":true}]},{"id":"00be4bb5-a556-48d8-a95c-cac6852e76ba","domain":"CostOptimized","question":"You are operating a popular TV Show news website using a static site generator (SSG) with the resulting HTML pages being served from S3. The vast majority of pages are less than 85 KB in size. After 60 days, new episode page access drops off significantly. Which of the following statements are true?","explanation":"Similar to the STANDARD storage class, STANDARD_IA objects are available for millisecond access.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html","title":"Storage Classes"}],"answers":[{"id":"0c8d66b9d1503b991d171f09f8943ee1","text":"Using the STANDARD_IA storage class, these older pages are stored redundantly across 3 or more geographically separated facilities.","correct":true},{"id":"a32b993ff0fa61fd0da4533f7fc8f1be","text":"Using the STANDARD_IA storage class, Amazon S3 charges you for 128 KB per object if it is less than 128 KB in size.","correct":true},{"id":"b84620799ba94f53d53c1aa19f69bb8a","text":"While objects in the STANDARD storage class are available for millisecond access, accessing STANDARD_IA objects is slightly slower.","correct":false},{"id":"ff55b529dbaaea1355acdc097ad29298","text":"The ONEZONE_IA storage class is as durable as STANDARD_IA, but it is less available and less resilient.","correct":true}]},{"id":"8c7d8c0b-3c91-4d63-9adb-87636a5b8306","domain":"Performant","question":"You are managing a website hosted in an AWS EC2 instance. The logs are stored in Amazon S3. Which of the following is a serverless interactive query service that can be used for analyzing data in S3 to troubleshoot performance issues?","explanation":"Query services like Amazon Athena, data warehouses like Amazon Redshift, and sophisticated data processing frameworks like Amazon EMR, all address different needs and use cases. Amazon Redshift provides the fastest query performance for enterprise reporting and business intelligence workloads, particularly those involving extremely complex SQL with multiple joins and sub-queries. Amazon EMR makes it simple and cost-effective to run highly distributed processing frameworks such as Hadoop, Spark, and Presto when compared to on-premise deployments. Amazon EMR is flexible and can run custom applications and code, and define specific compute, memory, storage, and application parameters to optimize analytics requirements. Amazon Athena provides the easiest way to run ad-hoc queries for data in S3 without the need to setup or manage any servers.","links":[{"url":"https://docs.aws.amazon.com/athena/latest/ug/when-should-i-use-ate.html","title":"Instant Data Analytics Service"}],"answers":[{"id":"cc5cafce27b070d7c2d800486d23fda0","text":"Amazon RedShift","correct":false},{"id":"6d54c710d35b106057d416187bc27ac9","text":"Amazon Glue","correct":false},{"id":"13f4833f14110af4cb2943f6ee04ec0c","text":"Amazon Athena","correct":true},{"id":"469d12a9b614674fd9a6d9168d1494ec","text":"Amazon EMR","correct":false}]},{"id":"8195d824-418f-4a5a-a599-fe3d07a530b3","domain":"SecureSolutions","question":"A shipping company brokers transportation arrangements for a large freight carrier. The shipping company currently uses an online form to make reservations with the freight carrier, but they'd like to automate the ordering process. The freight carrier runs its logistics system on AWS. The shipping company also runs its IT infrastructure on AWS. Which architecture should the shipping company put in place to provide the best security and operational efficiency for their transactions with the freight carrier?","explanation":"AWS PrivateLink provides private connectivity between VPCs and AWS services securely on the AWS network without exposure to the public Internet. AWS PrivateLink is implemented by a service provider creating an Endpoint Service and a service consumer connecting via an Interface VPC Endpoint. Direct Connect is established between a customer and AWS, not between two AWS customers. VPC Peering and VPN connections will work, but will require more operational overhead than PrivateLink.","links":[{"url":"https://aws.amazon.com/privatelink/","title":"AWS PrivateLink"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/endpoint-service.html","title":"VPC Endpoint Services"}],"answers":[{"id":"43204aec60483f400cb38e62488b58cd","text":"Implement VPC Peering to the freight carrier's VPC","correct":false},{"id":"b8f2bb6bbe7e63e7b530dd7f39f28422","text":"Have the freight carrier create an Endpoint Service and use an Interface VPC Endpoint to connect","correct":true},{"id":"9ea31725e0202dfe6aede430c505bded","text":"Establish a Direct Connect circuit to the freight company","correct":false},{"id":"5fbd35f29f2fcaae8769b6cda42eb9ec","text":"Create an IPSec VPN tunnel to the freight carrier's network thorough a Virtual Private Gateway","correct":false}]},{"id":"2ad5b0b6-36ed-43f0-9464-2c438e5d3e76","domain":"ResilientDesign","question":"Over the past month the production environment made up of Classic Load Balances and an autoscaling web farm has failed to scale up resulting in massive disruption during the early morning peak load. Your engineering team do not want to be alerted about every change but agree that they should receive relevant SNS alerts for customer impacting problems. Which of the following are appropriate autoscaling SNS alerts to send?","explanation":"AWS are completely transparent about he fact that systems will fail and you need to design for failures. there are four standard SNS alerts of which the LAUNCH_ERROR is the is the most important for being aware of impending customer impacting problems. The offered ELB Errors are CloudWatch metrics not built in SNS notifications.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html","title":"Auto Scaling Groups"},{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/ASGettingNotifications.html","title":"Autoscaling SNS notifications."},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-cloudwatch-metrics.html","title":"CloudWatch Metrics for Your Classic Load Balancer"}],"answers":[{"id":"abc6e1c7ee610d21427d2f9354cf3a94","text":"autoscaling:EC2_INSTANCE_TERMINATE","correct":false},{"id":"965b81ae140ff5103117c17a9f69e13b","text":"autoscaling:EC2_INSTANCE_LAUNCH_ERROR","correct":true},{"id":"d04f697bc72c89bc10704e46aa085b2a","text":"autoscaling:ELB_SPILL_OVER_COUNT_ERROR","correct":false},{"id":"89a683aa5c68153ea037ac7daf704a13","text":"autoscaling:EC2_INSTANCE_TERMINATE_ERROR","correct":false},{"id":"aac32c743fd98355a24d9989737e40b5","text":"autoscaling:EC2_INSTANCE_LAUNCH","correct":false},{"id":"99c3fbb9dd68cd0e89c066e4489c56d6","text":"autoscaling:ELB_SURGE_QUEUE_LENGTH_ERROR","correct":false}]},{"id":"056f9437-f1cc-46b7-948d-b824e4165927","domain":"CostOptimized","question":"What is a spot block?","explanation":"Spot instances with a specified duration are called spot blocks and are designed not to be interrupted and will run continuously for the desired duration. This is ideal for jobs that take a defined time to complete, such as batch processing, encoding and rendering, modeling and analysis, and continuous integration.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-requests.html","title":"Spot Instance Request"}],"answers":[{"id":"dfc941b3f66764f082aa64b118e967e2","text":"Spot instances that run for the desired duration without interruption.","correct":true},{"id":"7845bf17391493566afba67b5887284a","text":"A limit on the number of spot instances per AWS region within an account.","correct":false},{"id":"668cf201cc25653157e381211eb4f454","text":"A limit on the number of spot instances per AWS availability zone within an account.","correct":false},{"id":"630182c415a3baf017c6f8feb47653ff","text":"A number of spot instances that are launched to meet the target capacity specified.","correct":false}]},{"id":"5fac4bb4-d450-440d-bc31-62fd409b5bee","domain":"ResilientDesign","question":"A company has an LNMP (Linux, Nginx, MySQL, PHP) stack application deployed to AWS. The availability requirements for their backend database specify automatic failover in case of disaster recovery. What is the optimal solution that meets this requirement?","explanation":"Since the scenario calls for MySQL, we must choose a relational database for the backend database. This means that DynamoDB is not a correct option. With RDS Multi-AZ deployment, a primary DB instance is automatically and synchronously replicated to a secondary RDS instance in a different availability zone (AZ). In case of a disaster causing primary instance failure, RDS performs automatic failover to the secondary standby RDS instance. During the failover, the database endpoint remains the same. RDS Read-Replica provide secondary RDS instances that are asynchronous replicated from the primary. RDS read-replicas have different endpoints and do not provide automatic failover. Additionally, they only provide read (not write) operations. It is possible to use Route53 with Health-check and DNS failover configurations to route traffic to multiple RDS instances. However, this solution does not provide automatic data synchronization between instances.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"High Availability (Multi-AZ) for Amazon RDS"}],"answers":[{"id":"23f694af0e449b15b6fb26401d12eb0e","text":"DynamoDB with Global Tables deployment.","correct":false},{"id":"f38116f4410ef57b5ffc6e17d11b1721","text":"RDS with Multi-AZ deployment.","correct":true},{"id":"8a8d90b530fbd9c90820ca63425401b5","text":"Deploy multiple RDS instances. Use Route53 with Health-Check and DNS failover configured.","correct":false},{"id":"9e445d25eaf3cc7b2f2412dbf19e6e4b","text":"RDS with Read-Replica deployment.","correct":false}]},{"id":"1b1cfffe-896f-420c-b64e-8eee23af9a3e","domain":"ResilientDesign","question":"You work at a large financial institution.  You have many files that need to be stored for 7 years or more for regulatory purposes. These files need to be stored at the lowest cost possible. It is acceptable to wait for files to become available. Which of the following S3 Storage Tiers is best suited for this request?","explanation":"S3 Glacier Deep Archive is Amazon S3â€™s lowest-cost storage class and supports long-term retention and digital preservation for data that wonâ€™t be regularly accessed. It is designed for customers â€” particularly those in highly-regulated industries, such as the Financial Services, Healthcare, and Public Sectors â€” that retain data sets for 7-10 years or longer to meet regulatory compliance requirements. S3 Glacier Deep Archive can also be used for backup and disaster recovery use cases, and is a cost-effective and easy-to-manage alternative to magnetic tape systems, whether they are on-premises libraries or off-premises services. S3 Glacier Deep Archive complements Amazon S3 Glacier, which is ideal for more active archives where data is regularly retrieved and needed in minutes. All objects stored in S3 Glacier Deep Archive are replicated and stored across at least three geographically-dispersed Availability Zones, protected by 99.999999999% of durability, and can be restored within 12 hours.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#____","title":"Amazon S3 Storage Classes - Glacier Deep Archive"}],"answers":[{"id":"a5f6e1bef7eaef71d9ea6446f8c21a2e","text":"S3 Glacier Deep Archive","correct":true},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false},{"id":"a4172aee8a692bd73f2781afe65fda72","text":"S3 Infrequently Accessed","correct":false}]},{"id":"9cfdc945-a7e0-479c-9bcc-973f9ebfd7dc","domain":"CostOptimized","question":"You want to set up 2 CloudWatch alarms in addition to the 6 you already have to monitor your cloud environment. It has been 13 months since you created your AWS account, and you want to avoid being charged for creating the alarms. What should you do?","explanation":"Upon signing up for an AWS account, you will get a range of service usage that will never cost you anything. Such offers include 10 alarms with CloudWatch. Thatâ€™s why creating the alarms is the correct answer. Contacting support is wrong because itâ€™s not necessary to request a service increase limit. Avoiding creating new alarms is also wrong because thereâ€™s no term limits on the CloudWatch alarm offer; itâ€™s always free. Creating more alarms in this case is still free of charge because the free offer is limited to 10 CloudWatch alarms.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsm.page-all-free-tier=1","title":"AWS Free Tier"}],"answers":[{"id":"3e9a7ae3a0c82f4aaf031d7400a3774f","text":"Do not create the alarms; you will be charged, since you get a maximum of 10 alarms with CloudWatch for the first 12 months after your account sign-up.","correct":false},{"id":"222fcbee1f68dae67b4406597659a622","text":"Contact AWS Support for a service increase limit.","correct":false},{"id":"d8991b206aa9d731ab999eddedf26d6e","text":"Go ahead and create the alarms; you can have up to 10 CloudWatch alarms without being charged.","correct":true},{"id":"a336fb6001d622e126c7d02da7ab218f","text":"Go ahead and create the alarms; CloudWatch alarms are always free of charge, regardless of number.","correct":false}]},{"id":"cbcc2938-15ec-4a2f-bb94-1fefe41f3efe","domain":"Performant","question":"You have an RDS database that has high performance OLTP workloads. Which storage medium would be best to accommodate these requirements?","explanation":"Amazon RDS Provisioned IOPS (SSD) Storage would be the most suitable.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS","title":"RDS Provisioned IOPS for OLTP Workloads"}],"answers":[{"id":"e774a96af9adfaa2402148c9828271e7","text":"Amazon RDS Magnetic Storage","correct":false},{"id":"a257df0abf37db5da9b921f8222eab2a","text":"Amazon RDS General Purpose (SSD) Storage","correct":false},{"id":"0db6de47eed9671e44098c2117fe8916","text":"Amazon RDS Cold Storage","correct":false},{"id":"4d548ff7278077c929b63c67f768cc97","text":"Amazon RDS Provisioned IOPS (SSD) Storage","correct":true}]},{"id":"00350e3e-1c42-4f88-9a7f-da5a13c3beee","domain":"ResilientDesign","question":"You've been tasked with replicating your production VPC in another region for disaster recovery purposes. Part of your environment relies on EC2 instances with pre-configured software. What steps would you take to configure the instances in another region?","explanation":"The AMIs must be copied to the new Region prior to deployment.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/copy-ami-region/","title":"Cross Region EC2 AMI Copy"}],"answers":[{"id":"9d549a4d4d39135fb60e16e3239b85c3","text":"Write the IAM permissions for the new Region to use the AMIs from the original Region.","correct":false},{"id":"5523070f6b789b40c425d4c3776182fc","text":"Create AMIs of the instances and deploy them in the new Region","correct":false},{"id":"965dceca3b86aea95ef5de037128780c","text":"None of these.","correct":false},{"id":"4bb6756625fe14c21f17ff3bc0e4a53f","text":"Create AMIs of the instances and copy them to the new Region for deployment.","correct":true}]},{"id":"3252d84d-08d9-4bde-a8e7-d716502d1855","domain":"Performant","question":"You have a very heavily-trafficked WordPress blog that has approximately 95% read traffic and 5% write traffic. You notice that the blog is getting slower and slower. You discover that the bottleneck is in your RDS instance. Which of the following answers can improve your WordPress blog's performance?","explanation":"You should use a combination of Read Replicas and ElastiCache to help offload the traffic.","links":[{"url":"https://aws.amazon.com/elasticache/","title":"About ElastiCache"}],"answers":[{"id":"fdc556bb3ab9b5da3b290c181aaefb3c","text":"Create a number of read replicas and update the connection string on your EC2 instances so that traffic is evenly shared amongst these new RDS instances.","correct":true},{"id":"e94a05a7348f87c7b9c4f7036d632a9c","text":"Use ElastiCache to cache the most commonly read posts of your WordPress blog.","correct":true},{"id":"1c551a09129057627b3b75fb70e6f527","text":"Export the database to DynamoDB which has push button scalability.","correct":false},{"id":"1af32ee0c62b109e45b92828dbc33f2d","text":"Create a secondary Multi-AZ database and run the queries off the secondary Multi-AZ database.","correct":false}]},{"id":"bc814aa4-03e8-4a64-aa0e-84f22d812a95","domain":"SecureSolutions","question":"Which of the following DNS record types does Route 53 not support?","explanation":"Route 53 is a scalable and highly available DNS service and it currently supports 13 different DNS record types including; AAAA, CNAME and SPF.  However, Route 53 does not support DNSSEC (other than during domain registration) and therefore any DNSSEC related records, such as DNSKEY, are also not supported.","links":[{"url":"https://aws.amazon.com/route53/faqs/","title":"Amazon Route 53 FAQs"}],"answers":[{"id":"adc4bfdb0829dae99e3699393e3fbaa4","text":"CNAME","correct":false},{"id":"098890dde069e9abad63f19a0d9e1f32","text":"AAAA","correct":false},{"id":"b4efb35349e5d93905531be07dbacd6d","text":"SPF","correct":false},{"id":"548deb43a9afe4abcde34a605eb44700","text":"DNSKEY","correct":true}]},{"id":"487042c6-27f3-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"One of your clients wants an AWS Support plan that provides around-the-clock access to Cloud Support Engineers when needed, as well as access to the seven core Trusted Advisor checks. Which of the following is the most cost-effective choice?","explanation":"Basic Support is included with each AWS account, and it includes access to the seven core Trusted Advisor checks to guide your client in increasing performance and improving security of AWS resources. However, it does not include the around-the-clock access to Cloud Support Engineers for technical assistance. You will need to upgrade your client to the Business Support plan to do so. Indeed, the client will get the full set of Trusted Advisor checks, instead of just the seven core ones. However, it is less expensive than the top-tier Enterprise, which also has those features; thus, the Business plan is the more cost-effective of the two.","links":[{"url":"https://aws.amazon.com/premiumsupport/plans/","title":"AWS Support Plans"}],"answers":[{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":false},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":true}]},{"id":"40bd28c9-dee5-42d8-bc1b-1822db4e5243","domain":"ResilientDesign","question":"An enterprise has a large customer base and sends marketing emails (such as special offers and discounts), transactional orders (such as order confirmations) and correspondence emails (such as newsletters) to all customers. They engaged you to set up an email platform that provides an easy and cost-effective way to send and receive emails using their own email address and domains, and also wanted to set email auto-responders and email unsubscribe systems. Which AWS service below best matches the requirement?","explanation":"Amazon Simple Email Service (Amazon SES) is a highly scalable and cost-effective service for sending and receiving email. Amazon SES eliminates the complexity and expense of building an in-house email solution or licensing, installing, and operating a third-party email solution. Amazon WorkMail is a suite of office tools which help manage daily email workflow. With WorkMail, it is not possible to send transaction email or email newsletters. Amazon WorkMail uses Amazon SES to send and receive mail.","links":[{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/sending-email.html","title":"Setting up Simple Email Service"}],"answers":[{"id":"ca50f9e142e8d3e5e8fa73cf07d1a437","text":"Amazon Integrated Email solution","correct":false},{"id":"09e915452f715da52789fa62d9dd5291","text":"Amazon Simple Email Service","correct":true},{"id":"f25bb6e1bd825ac7b88a0340c5d8f4ec","text":"Amazon WorkMail","correct":false},{"id":"224510290621b43664ba1741744d7c57","text":"Amazon Active Directory Email Service","correct":false}]},{"id":"2d66a68a-db0b-46af-93f2-8fbb712d7f8d","domain":"ResilientDesign","question":"Which of the following are the application integration services enable communication between decoupled components in order to build a scalable and more resilient solution?","explanation":"Amazon SQS, Amazon MQ and Amazon App Sync are AWS application integration services. Application integration services enable communication between decoupled components within micro-services, distributed systems, and serverless applications so you can easily build scalable and more resilient solutions. Amazon DataSync is AWS Migration and Transfer service and is not an integration service. AWS SES is a cloud-based email sending service designed for customer engagement.","links":[{"url":"https://aws.amazon.com/products/application-integration/?nc2=h_m1","title":"AWS Application Integration Services"}],"answers":[{"id":"335523617c1b39d5772d3e75b7da2014","text":"AWS Simple Email Service (SES)","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true},{"id":"b65c2d4cd3e247c1554f92a08e6ea48b","text":"Amazon App Sync","correct":true},{"id":"71f398f7b21d60364b4a577a13a1271f","text":"Amazon Data Sync","correct":false},{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":true}]},{"id":"15c0f4d7-ac13-40b0-98fb-2d8fd8b077ee","domain":"Performant","question":"You have been asked to advise on a scaling concern.  The client has an elegant solution that works well.  As the information base grows they use CloudFormation to spin up another stack made up of an S3 bucket and supporting compute instances.  The trigger for creating a new stack is when the PUT rate approaches 100 PUTs per second.  the problem is that as the business grows that number of buckets is growing into the hundreds and will soon be in the thousands.  You have been asked what can be done to reduce the number of buckets without changing the basic architecture.","explanation":"Until 2018 there was a hard limit on S3 puts of 100 PUTs per second.  To achieve this care needed to be taken with the structure of the name Key to ensure parallel processing.  As of July 2018 the limit was raised to 3500 and the need for the Key design was basically eliminated. Disk IOPS is not the issue with the problem. The account limit is not the issue with the problem.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","title":"S3 Request rates - Whats new"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html","title":"S3 Request rates documentation"},{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage classes"}],"answers":[{"id":"0196ee21bff2d4c35c191d0973220d3c","text":"Upgrade all buckets to S3 provisioned IOPS to achieve better performance.","correct":false},{"id":"906c60dd95d60014479c321de23c5a4c","text":"Refine the key hashing to randomise the name Key to achieve the potential of 300 PUTs per second.","correct":false},{"id":"c1ee6963e6cab066324cc7e832d9ea3d","text":"Change the trigger level to around 3000 as S3 can now accommodate much higher PUT and GET levels.","correct":true},{"id":"b183896b9af1543c0b43e9540b244954","text":"Set up multiple accounts so that the per account hard limit on S3 buckets is avoided.","correct":false}]},{"id":"e9205ab6-d7ce-4708-b92d-e6814f79c6d4","domain":"ResilientDesign","question":"The dashboard application for multiple company contact centers requires fast update response times for a large number of concurrent users. Call center metric data is stored in an Oracle version 11 database. Which architecture will provide high-availability and the low response times needed for this mission-critical data?","explanation":"Since the dashboard updates are needed across multiple contact centers, leveraging read-only replicated databases will provide fast response times. Amazon RDS doesnâ€™t support read replicas for Oracle version 11, so hosting the database on EC2 and replicating the data with Oracle Data Guard is the only viable solution. AWS Database Replication Service is not an offered service, and using EBS snapshots won't provide real-time replication.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/oracle-database/overview.html","title":"Oracle Database on AWS"}],"answers":[{"id":"c1e824f46134bc6696eba635f30df032","text":"An Amazon RDS Oracle instance with Multi-AZ and Read Replicas","correct":false},{"id":"0129ed97e5c2ec017bdc05d836f10049","text":"Oracle hosted on Amazon EC2 in multiple Availability Zones with Oracle Data Guard replication","correct":true},{"id":"5ee29b50026caa8c20c9e469f93b5a2a","text":"Oracle hosted on Amazon EC2 in Multiple Availability Zones with EBS snapshots","correct":false},{"id":"de5ad68debdabd478d7d4f66542b9ca8","text":"An Amazon RDS Oracle Instance with AWS Database Replication Service","correct":false}]},{"id":"2466b024-1f81-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"You work as a website administrator at a real estate developer. The companyâ€™s website uses S3 to store pictures of the single-family homes it builds. The company recently released a brand-new elevation for one of its most popular models, which is called 'Greenberry C.' So far, thereâ€™s only one picture of the 'Greenberry C', so you want to ensure that it is not accidentally deleted by enabling the object lock feature. Which of the following actions will accomplish that?","explanation":"Amazon S3 object lock prevents an object from being deleted or overwritten. Object lock is enabled at the bucket level; when creating the bucket, you can select the feature to lock objects in it. However, once the bucket has been created, you cannot enable object lock, you will have to contact customer support to do so. Right-click is not a valid option - you must select the object then go to Properties, Object lock.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/object-lock.html","title":"How Do I Lock an Amazon S3 Bucket?"}],"answers":[{"id":"2c6b543047434bd3ad31060693bc8e5b","text":"Enable object lock at the object level.","correct":false},{"id":"a92ccdd56e18b47fbb5d18c2c342ca6f","text":"Right-click the picture and choose the object lock option.","correct":false},{"id":"84bd7d36c453cdfc1f04955deb54c376","text":"Enable object lock at the bucket level.","correct":true},{"id":"49cd0706698c83f66fe5b9deb203a420","text":"Contact customer support.","correct":true}]},{"id":"e05cb926-bcab-4cab-8a18-08f38bf70dfa","domain":"SecureSolutions","question":"You have an application that stores data in S3, and you need to design an integrated solution providing encryption at rest. You want Amazon to handle key management and protection using multiple layers of security. Which S3 encryption option should you use?","explanation":"SSE-S3 uses managed keys and one of the strongest block ciphers available, AES-256, to secure your data at rest.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html","title":"SSE - S3 Encryption"}],"answers":[{"id":"bac271f02854883c6bc665637d0a5de6","text":"Amazon S3 Encryption Client","correct":false},{"id":"e17194408dc439e1658a544965724d44","text":"SSE-KMS","correct":false},{"id":"472035b16201f5505380c16ec3eb8518","text":"SSE-C","correct":false},{"id":"1562bb9d2d9567740605dcb1ccab5c80","text":"SSE-S3","correct":true}]},{"id":"7d17894a-afd7-44cf-8ef0-0b4698e75902","domain":"Performant","question":"You need to upgrade your RDS database to a larger instance class and you must minimize the amount of disruption to your business as much as possible. What should you do.","explanation":"When upgrading an RDS instance class your database will be temporarily unavailable while the DB Instance Class is modified. This period of unavailability typically lasts only a few minutes, and will occur during the maintenance window for your DB Instance, unless you specify that the modification should be applied immediately.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ModifyInstance.MySQL.html","title":"Modifying an RDS Instance"}],"answers":[{"id":"088f69f13b003fa224256412f3a2e237","text":"Do the upgrade using the AWS CLI using the option --NOREBOOT","correct":false},{"id":"9645ca2d23347fd27cb00e4048158900","text":"Do the upgrade using the AWS console and ensure the 'do not reboot' option is checked when upgrading.","correct":false},{"id":"64c0cf5fc5de497475145808fffcff77","text":"You do not need to worry: when upgrading an instance class, your database will not go off line.","correct":false},{"id":"9e621f1fb2263ab1552a7d3086c500a7","text":"Schedule the upgrade for a maintenance window during a time when you have the fewest possible customers. The production database should only be unavailable for a couple of minutes.","correct":true}]},{"id":"04a5e1e1-9fc6-4371-a53c-cecc6fad3b2a","domain":"ResilientDesign","question":"Elasticity is a fundamental property of the cloud. Which of the following best describes elasticity?","explanation":"In cloud computing, elasticity is defined as 'the degree to which a system is able to adapt to workload changes by provisioning and de-provisioning resources in an autonomic manner, such that at each point in time the available resources match the current demand as closely as possible'.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html","title":"Scalable Computing Capacity"}],"answers":[{"id":"9b1cc2503b70776f795a2155b7f2e380","text":"The ability to manually deploy instances quickly in response to events.","correct":false},{"id":"71babaf2f5ed118cdbb0f5ff115354ce","text":"The ability to deploy managed services into your environment.","correct":false},{"id":"2d60e660232553b4fb11100329fdb97e","text":"The power to scale resources both up and down with changes in demand.","correct":true},{"id":"80b90762201e3ac35c7921416cc86c81","text":"The power to increase the number of resources at your hands at the click of a mouse.","correct":false}]},{"id":"e5b622bb-0d0e-4fe9-8d86-51e3b7b73de2","domain":"SecureSolutions","question":"You work in the security industry for a large consultancy. One of your customers runs a production environment in AWS, and they require a log of all API calls made to their Elastic Load Balancer. How can you achieve this?","explanation":"Enabling CloudTrail on the ELB will allow you to log all API calls.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/APIReference/using-cloudtrail.html","title":"Logging API Calls Using AWS CloudTrail"}],"answers":[{"id":"cc07c82af39e26f311c53c0cd60e1590","text":"Enable Detailed Monitoring on the ELB when first creating the instance.","correct":false},{"id":"cade67ffa2c30aee6a4d431b6835364a","text":"Enable Cloud Trail on the ELB.","correct":true},{"id":"ef60859d522ea9c9f92d6c118cc16c91","text":"Enable CloudWatch on the ELB.","correct":false},{"id":"b313bfd25a4c18e94874b6e46c8d287e","text":"Enable Cloud Audit on the ELB when first creating the instance.","correct":false}]},{"id":"232e5218-23ae-49a3-b865-c44f4aa3c430","domain":"SecureSolutions","question":"You have just created a new IAM role called US-S3-Access using the GUI at \"https://console.aws.amazon.com/iam/home?region=us-east-1#/roles\". This role grants access to the a bucket called ec2-temp-storage254 which was created in the us-east-1 region. One of your colleagues wants their EC2 instance in us-east-2 region to access this bucket - how can this be accomplished","explanation":"IAM is a global service, and therefore objects created in one region are available in all regions. Although S3 buckets are created and stored in a specific region, they are accessible globally - therefore the correct answer is to attach the existing role to the instance - this will grant the instance access to the bucket. There is no need to create a new role, and there is no such setting as multi-region access on roles.","links":[{"url":"https://aws.amazon.com/iam/faqs/","title":"IAM FAQ"}],"answers":[{"id":"320c9d5e32dfe1dce4ea215892e1d7fe","text":"This cannot be done as the EC2 instance and S3 bucket are in different regions","correct":false},{"id":"dedf1276f190146139ebc76212f15edb","text":"Enable multi-region use for the role, attach it to the instance","correct":false},{"id":"057599d3b676dc5e3f4a5284f641c5ca","text":"Create a new role in the us-east-2 region that grants access to the bucket, and attach it to the instance","correct":false},{"id":"1a108ea83cc5a71b33fe8e2455e7fd37","text":"Attach the existing role to the EC2 instance","correct":true}]},{"id":"07689304-6bbb-46ce-ba91-08edaeee087a","domain":"ResilientDesign","question":"You are creating an RDS database for your production environment and it needs to be highly available and continue to function in the event of an outage to the Primary database. Which of the following options will best meet this requirement?","explanation":"Multi-AZ deployment involves the creation of a standby replica in a different Availability Zone (AZ) from the primary database. A standby replica cannot serve read traffic, it is used to synchronously replicate data from the primary database. AZs are isolated from one another to prevent failure from spreading to them all. So, if the location of the primary database has issues, Amazon RDS automatically fails over to the standby replica. Read replicas are used to scale out to cater for high volumes of read requests - not automated failover. Multi-region deployment is not a valid RDS option and Cross-region deployments enable support for scaling of Read replicas and can be used for cross-region DR, but don't support the automatic failover due to a Primary DB outage.","links":[{"url":" https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Concepts.RegionsAndAvailabilityZones.html","title":"Choosing the Regions and Availability Zones"}],"answers":[{"id":"b75ef1477da122d3b8733ab5da141356","text":"Read replicas","correct":false},{"id":"a9fa9ab64858fe533c9b65e9b8ba2fb9","text":"Multi-region deployment","correct":false},{"id":"794e9156bdd31164380a7005f8599e08","text":"Cross-region deployment","correct":false},{"id":"9256e377c39a64274bd60ff4916a4cb9","text":"Multi-AZ deployment","correct":true}]}]}}}}
