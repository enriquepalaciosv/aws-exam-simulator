{"data":{"createNewExamAttempt":{"attempt":{"id":"b25eb8a2-0426-42e7-a337-f1d4be845c61"},"exam":{"id":"6e613b6a-32f7-48c6-8225-9265611524b8","title":"AWS Certified Developer - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"5cd0d201-9b93-42f0-9ae7-585263307009","domain":"development","question":"You've been asked to create a Web application with an endpoint that can handle thousands of REST calls a minute.  What AWS service can be used in front of an application to assist in achieving this?","explanation":"Questions containing 'REST' are usually related to APIs, so API Gateway looks the best answer.  Elastic Beanstalk is a service which allows you to run applications without understanding the infrastructure and can be discounted, as can Global Accelerator which is a networking service that improves the availability and performance of applications.  CloudFront can be used in conjunction with API Gateway to assist in geographically disparate calls, but won't process calls by itself.","links":[{"url":"https://aws.amazon.com/api-gateway/faqs/","title":"Amazon API Gateway FAQs"}],"answers":[{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"2ef9dd82927a3196ca2df3fc0cdf2e0b","text":"API Gateway","correct":true},{"id":"9ce65e2b30ed635c84bef82218a94fdf","text":"Global Accelerator","correct":false}]},{"id":"5b6fd3fe-de07-4eb3-a61d-f96e4b4b5f1b","domain":"refactoring","question":"Which of the following is NOT a supported event source for Lambda?","explanation":"Supported event sources which can trigger Lambda functions include: CloudWatch, DynamoDB, S3, Kinesis, CodeCommit, IoT buttons, CloudFront, Cognito, SNS, SQS, SES etc. RDS cannot trigger a function directly but you could configure RDS to send notifications to SNS and then use SNS to trigger a Lambda function. ","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/invoking-lambda-function.html","title":"Lambda Event Sources"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"1399767aff0c1931602c17dcfb0d375e","text":"CloudWatch Events","correct":false}]},{"id":"46c2faa3-c022-4c5e-bb6b-fe84f70b3dc4","domain":"deployment","question":"Which of the following AWS services enables you to capture a time-ordered sequence of any modifications which happened to the items in your DynamoDB table over the past 24 hours?","explanation":"DynamoDB Streams captures a time-ordered sequence of item-level modifications in a DynamoDB table and durably stores the information for up to 24 hours.","links":[{"url":"https://aws.amazon.com/blogs/database/dynamodb-streams-use-cases-and-design-patterns/","title":"DynamoDB Streams Use Cases"}],"answers":[{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"1f60690ba7c488a02416a7bf195f900b","text":"DynamoDB Streams","correct":true},{"id":"52d5592ad24a2cda379ce38e9c218d65","text":"DynamoDB TTL","correct":false}]},{"id":"e4f97c28-f9d8-4c78-abf9-70cb5e698678","domain":"deployment","question":"You are creating a DynamoDB table to store customer order data, which of the following attributes would make a good Partition Key?","explanation":"A Partition key is a single attribute and is used as a Primary Key attribute to uniquely identify a record in the DynamoDB table. Customer ID is the best option here because each customer will have a unique ID","links":[{"url":"https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/","title":"Choosing The Right Partition Key"}],"answers":[{"id":"6f6cb72d544962fa333e2e34ce64f719","text":"Size","correct":false},{"id":"b5a34ba8eab605ce7cebca74791768c8","text":"OrderDate","correct":false},{"id":"8deaf45b8d4daa4827510e469b744fdb","text":"CustomerID","correct":true},{"id":"96dd75bd1565f43c5ae81ca5ef326b74","text":"ProductType","correct":false}]},{"id":"742534cf-2038-4f0d-b859-216cca30339e","domain":"deployment","question":"Which of the following statements relating are correct in relation to DynamoDB?","explanation":"A local secondary index maintains an alternate sort key for a given partition key value.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/LSI.html","title":"Local Secondary Indexes"}],"answers":[{"id":"661c4d893c5ff8ef12919a23394749c8","text":"A Local Secondary Index is an index that has the a different partition key and a different sort key to the table.","correct":false},{"id":"b9f028903456b0bc0b4706cf7c6bea8f","text":"You can add a Global Secondary Index to an existing table","correct":true},{"id":"63fb8d2672eb66b5bcaf5267421cacb2","text":"A Local Secondary Index is an index that has the same partition key as the table, but a different sort key to the table.","correct":true},{"id":"1e76bf9bca3dc7acaf4a05fe6bedabc2","text":"You can add a Local Secondary Index to an existing table","correct":false}]},{"id":"313867da-7161-4083-9745-77950b6208dd","domain":"development","question":"You are using CodeBuild to create a Docker image and add the image to your Elastic Container Registry. Which of the following commands should you include in the buildspec.yml?","explanation":"Use the docker push command to add your image to your Elastic Container Registry","links":[{"url":"https://aws.amazon.com/blogs/devops/build-a-continuous-delivery-pipeline-for-your-container-images-with-amazon-ecr-as-source/","title":"Build a Continuous Delivery Pipeline for Your Container Images with Amazon ECR as Source"}],"answers":[{"id":"d2d39a1ed4490154f045931eee5d18e4","text":"aws ecr push $REPOSITORY_URI:latest","correct":false},{"id":"ec1f85b16af01c1d7ec994f6ba6efa32","text":"docker push $REPOSITORY_URI:latest","correct":true},{"id":"c1520af238ed7b988b389f732c0d6287","text":"docker build -t $REPOSITORY_URI:latest .","correct":true},{"id":"585a787c56d351517a27b9d64d3db8ae","text":"docker add $REPOSITORY_URI:latest","correct":false},{"id":"87c7975f8fe350f6f133c1f3d3b6b9f2","text":"aws codebuild docker -t $REPOSITORY_URI:latest .","correct":false}]},{"id":"76086e8c-3f24-4bae-ba57-f5ac18dc1ff5","domain":"development","question":"What is the name of the SAM template property that defines the point in a Lambda function's code where execution begins?","explanation":"The Handler property specifies the Lambda function's entry point. For example, if the Lambda function was written in Python, and Handler was set to lambda_function.lambda_handler, execution would begin with the lambda_handler function, contained within the lambda_function.py file.\n\nRuntime refers to the language in which the Lambda function is written. For example, python3.6 or nodejs6.10, etc.\n\nSource and Index are not valid SAM template properties.","links":[{"url":"https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md","title":"AWS Serverless Application Model Specification"}],"answers":[{"id":"88fa71f0a6e0dfedbb46d91cc0b37a50","text":"Index","correct":false},{"id":"0bb4c52ba15ca41d65967d91840c66fb","text":"Handler","correct":true},{"id":"bc366f2d0ba3d681e7a3899917c5d3de","text":"Runtime","correct":false},{"id":"f31bbdd1b3e85bccd652680e16935819","text":"Source","correct":false}]},{"id":"4216cacb-ee8a-42e5-acff-9b1ea39357e6","domain":"development","question":"A developer is implementing an IoT application using DynamoDB as the data store for device event data. An application requirement is to automatically purge all event data older than 30 days. What is the optimal option to implement this requirement?","explanation":"Time to Live (TTL) for Amazon DynamoDB is functionality that enables automatic deletion of items after a specified expiration time. The expiration time is defined by a timestamp in the TTL attribute. When Time to Live (TTL) is enabled on a table in Amazon DynamoDB, a background job checks the TTL attribute of items. The background job compares the current time in epoch time format to the time stored in the Time to Live attribute of an item to determine whether the item is expired. If the epoch time value stored in the attribute is less than the current time, the item is marked as expired and then deleted.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/howitworks-ttl.html","title":"Time to Live: How It Works"}],"answers":[{"id":"89ff2a65dcb0d5ab07793957e16ed650","text":"Enable TTL on the DynamoDB table and store the expiration timestamp in the TTL attribute in the epoch time format.","correct":true},{"id":"c408a205dcdc64e12ad635afc658fa61","text":"Implement a Lambda function to perform a query on the table and delete items with timestamp greater than 30 days. Use CloudWatch events to trigger Lambda function.","correct":false},{"id":"ac0b210d52da3eacb34d48327798c599","text":"Create a new DynamoDB table every 30 days. Delete the old DynamoDB table.","correct":false},{"id":"0a4018a4dc09457f483a0fb75a49f140","text":"Enable DynamoDB streams on the table. Implement Lambda function to read events from the stream and delete expired items.","correct":false}]},{"id":"0d9472d0-587b-4961-9457-e37e75979b7c","domain":"development","question":"You are working on a Serverless application written in Python and running in Lambda. You have uploaded multiple versions of your code to Lambda, but would like to make sure your test environment always utilizes the latest version. How can you configure this?","explanation":"When you create a Lambda function, there is only one version: $LATEST. You can refer to the function using its Amazon Resource Name (ARN). There are two ARNs associated with this initial version, the qualified ARN which is the function ARN plus a version suffix e.g. $LATEST. Or the unqualified ARN which is the function ARN without the version suffix. The function version for an unqualified function always maps to $LATEST, so you can access the latest version using either the qualified ARN with $LATEST, or the unqualified function ARN. Lambda also supports creating aliases for each of your Lambda function versions. An alias is a pointer to a specific Lambda function version, aliases will not be updated automatically when a new version of the function becomes available.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-intro.html","title":"Introduction To Lambda Function Versioning"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda Function Versioning and Aliases"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/how-to-manage-versioning.html","title":"Lambda Versioning"}],"answers":[{"id":"d483464867986a2d830ac23858944891","text":"Create an alias to point to the correct version of your code","correct":false},{"id":"07c1095b47175c42406ba59e91205281","text":"Reference the function using an unqualified ARN","correct":true},{"id":"0311fc386b14ce5afd0843ecf4a6ff16","text":"Create another function to automatically update your function alias to point to the latest version of the code every time it is updated","correct":false},{"id":"cc67dedc36d230ab3574dc07b41b7443","text":"Configure the alias to automatically update to point to the latest version of the code every time it is updated","correct":false},{"id":"02f663ae252fea90c711171a5572d211","text":"Reference the function using a qualified ARN and the $LATEST suffix","correct":true}]},{"id":"4102ce86-6e8c-47b2-86d4-86e3b8b08558","domain":"mon-trb","question":"Your application runs in an Auto Scaling group to scale based on user demand. The Auto Scaling group runs behind an Elastic Load Balancer (ELB). When you check the ELB logs, you notice that a number of instances are failing the health check during periods of high demand. New instances are launching but they periodically fail health checks and subsequent instances are being launched which is increasing costs. What would you do to troubleshoot this issue?","explanation":"Amazon EC2 Auto Scaling waits until the health check grace period ends before checking the health status of the instance. Amazon EC2 status checks and Elastic Load Balancing health checks can complete before the health check grace period expires. However, Amazon EC2 Auto Scaling does not act on them until the health check grace period expires. To provide ample warm-up time for your instances, ensure that the health check grace period covers the expected startup time for your application. In this scenario, the health checks are most likely occurring before the EC2 instance and its applications have fully loaded, so increasing the health check grace period would likely resolve the issue. The cooldown period helps to ensure that your Auto Scaling group doesn't launch or terminate additional instances before the previous scaling activity takes effect, and are not used for health checks. Creating a new ELB or Auto Scaling group would have no impact but the problem would persist. AWS Config is a governance and management tool and is incapable of itself executing automated actions.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html","title":"Health Checks for Auto Scaling Instances"}],"answers":[{"id":"1fec64ae8a7c39cb26d12b3f50438dde","text":"Increase the cooldown period of the Auto Scaling group.","correct":false},{"id":"fe8f15e29da594ce0b07d192b5e8f4f3","text":"Use AWS Config to monitor instances with failed health checks to terminate them.","correct":false},{"id":"828102b2cd5f2f5f2873afea3714c7eb","text":"Increase the health check grace period.","correct":true},{"id":"47d484cdd97dff7b054f3cc746f8bbc6","text":"Create a new Auto Scaling group behind a new ELB. The current ELB is malfunctioning.","correct":false}]},{"id":"68d79e4d-f827-496d-9fc3-606615dd6fe5","domain":"security","question":"When using Web Identity Federation and Cognito to allow a user to access an AWS service (such as an S3 bucket), which of the following is the correct order of steps?","explanation":"A user authenticates with Facebook first. They are then given an ID token by Facebook. An API call, AssumeRoleWithWebIdentity, is then used in conjunction with the ID token. A user is then granted temporary security credentials.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc_manual.html","title":"Using Web Identity Federation APIs"}],"answers":[{"id":"811872e18604a3d8118cc1c9381bf702","text":"Users cannot use Facebook credentials to access the AWS platform.","correct":false},{"id":"b66b1e5f0bf94eca60bce37aa0702f6e","text":"A user logs in to the AWS platform using their Facebook credentials. AWS authenticates with Facebook to check the credentials. Temporary Security Access is granted to AWS.","correct":false},{"id":"e95a8dc9c210c0c1e6e36f8215ab4978","text":"A user makes the AssumeRoleWithWebIdentity API Call. The user is then redirected to Facebook to authenticate. Once authenticated, the user is given an ID token. The user is then granted temporary access to the AWS platform.","correct":false},{"id":"13bdd19ca71c9978a4642bd95fcb92c5","text":"A user authenticates with Facebook first. They are then given an ID token by Facebook. An API call, AssumeRoleWithWebIdentity, is then used in conjunction with the ID token. A user is then granted temporary security credentials.","correct":true}]},{"id":"99e1be6c-c87a-45fd-b1a4-80ee4e4e1fe9","domain":"deployment","question":"You are creating a DynamoDB table to manage your customer orders, which of the following attributes would make a good Sort Key?","explanation":"A well designed Sort key allows you to retrieve groups of related items and query based on a range of values, e.g. a range of dates. In this case, Order Date is the best choice as it will allow users to search based on a range of dates","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-sort-keys.html","title":"DynamoDB Sort Keys"}],"answers":[{"id":"b5a34ba8eab605ce7cebca74791768c8","text":"OrderDate","correct":true},{"id":"8deaf45b8d4daa4827510e469b744fdb","text":"CustomerID","correct":false},{"id":"f6a56b98d7e5fa6571618bdc13db0c77","text":"OrderNumber","correct":false},{"id":"bb96cafb784d4109a905317afdff8f71","text":"ProductID","correct":false}]},{"id":"32e6ce0f-d2ca-4d5d-a9eb-37cd15470e3e","domain":"refactoring","question":"You've created an online forum to which your users post questions and comments. The 'thread' table has many users and each user has many posts, each marked by a timestamp. Which primary key configuration would be best suited to see all posts by a particular user in chronological order?","explanation":"A composite key with UserID as the partition key and the timestamp as the sort key would be best. The other answers offer non-standard key configurations.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html#HowItWorks.CoreComponents.PrimaryKey","title":"DynamoDB Primary Key Configurations"}],"answers":[{"id":"283e1fc102dc542eede4dee9f921e710","text":"A composite key with UserID as the range key and timestamp as the sort key.","correct":false},{"id":"e69c02c4712b958b2470f1da330f5b56","text":"A composite key with UserID as the sort key and timestamp as the hash key.","correct":false},{"id":"882b516d0dbad0409c65e7c2a820d710","text":"A composite key with UserID as the partition key and the timestamp as the sort key.","correct":true},{"id":"608907c754ce17f1ce80eb47c8fc1341","text":"A composite key with UserID as the sort key and timestamp as the partition key.","correct":false}]},{"id":"779acf8c-3df3-43fe-9714-3ebaf8e40ef2","domain":"refactoring","question":"You are working for an investment bank and have been asked to help the application support team with their annual Disaster Recovery testing. The main production PostgreSQL database is hosted in RDS Multi-AZ deployment, with multiple applications running on a combination of EC2 and Lambda. You have been asked to help the team to demonstrate the impact that a failed Availability Zone will have on the database. Which of the following do you suggest?","explanation":"If the Amazon RDS instance is configured for Multi-AZ, you can perform the reboot with a failover. An Amazon RDS event is created when the reboot is completed. If your DB instance is a Multi-AZ deployment, you can force a failover from one Availability Zone (AZ) to another when you reboot. When you force a failover of your DB instance, Amazon RDS automatically switches to a standby replica in another Availability Zone, and updates the DNS record for the DB instance to point to the standby DB instance. As a result, you need to clean up and re-establish any existing connections to your DB instance. Rebooting with failover is beneficial when you want to simulate a failure of a DB instance for testing, or restore operations to the original AZ after a failover occurs.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RebootInstance.html","title":"RDS - Rebooting a DB Instance"}],"answers":[{"id":"1db313c348c46e6cefc8bf25ce3e0d15","text":"Simulate an AZ failure by moving your RDS instance to a different subnet","correct":false},{"id":"4496cfe7afc55864d488f038430be2b5","text":"Simulate an AZ failure by disconnecting your RDS instance from the network","correct":false},{"id":"428c5da3acc9c6986847b2511e6129f5","text":"Simulate an AZ failure by rebooting the underlying EC2 instance which is running the database","correct":false},{"id":"222811da7a574ef8ec4e058ece75fe23","text":"Simulate an AZ failure by deleting the primary RDS instance","correct":false},{"id":"e8d6fb964d48234750126a73a5fa41f4","text":"Simulate an AZ failure by performing a reboot with forced failover on the RDS instance","correct":true}]},{"id":"3eb49e2e-25b6-4fe6-8bbe-e3ccedcd1efd","domain":"security","question":"A developer is looking to implement a load balancing solution for web-based service oriented application deployed in AWS EC2. The solution must support path based routing and all communication to the users must be encrypted. What is the most performant method to achieve these requirement?","explanation":"The application requirement states support for path based routing. This means that we must use an Application Load Balancer as Network Load Balancer does not have this feature. It is best practice to deploy the SSL certificates on the Load Balancer. This implements SSL termination on the load balancer and off-loads this task from the application, thus reducing the load on EC2 instances. Additionally, it removes the requirement of distributing the certificate to all target EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html","title":"Create an HTTPS Listener for Your Application Load Balancer"}],"answers":[{"id":"206131d0e41aa9e13214ac701d6f08e2","text":"Use Application Load Balancer. Deploy SSL certificate on the Application Load Balancer.","correct":true},{"id":"b97b895cbdc513c48c5bfb7564a38aa7","text":"Use Network Load Balancer. Deploy SSL certificates on the EC2 instances.","correct":false},{"id":"7ebcbebf7f00c8f17f377813b31cc76e","text":"Use Network Load Balancer. Deploy SSL certificates on the Network Load Balancer.","correct":false},{"id":"a5a020608230cb06058ddd6291c7886a","text":"Use Application Load Balancer. Deploy SSL certificates on the EC2 instances.","correct":false}]},{"id":"545a364d-6872-4c56-aa7c-135a89d39133","domain":"mon-trb","question":"What does the error \"ProvisionedThroughputExceededException\" mean in DynamoDB?","explanation":"You exceeded your maximum allowed provisioned throughput for a table or for one or more global secondary indexes.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html","title":"Error Handling in DynamoDB"}],"answers":[{"id":"79851cf660541b5d451c8213382b5e0c","text":"The DynamoDB table is unavailable.","correct":false},{"id":"da824a20e75733561947108177c08dcb","text":"You exceeded your maximum allowed provisioned throughput for a table or for one or more global secondary indexes.","correct":true},{"id":"0e3a814eaadffaf2ce9fbd6c2c8ecaeb","text":"The DynamoDB table has exceeded the allocated space.","correct":false},{"id":"f64333b18f5422f67a98047421afcd5b","text":"There is no such error message. The correct error message would be \"ProvisionedThroughputFailureException\".","correct":false}]},{"id":"eebfef11-98bd-48f5-9775-b70b3600480a","domain":"development","question":"You are working on updates to your .NET application which has been deployed using Elastic Beanstalk. Your environment consists of 4 EC2 instances, as well as a number of different Lambda functions and DynamoDB tables. The application requires at least 2 instances to cope with the average workload and a minimum of 3 instances to cope with peak-time traffic. The Project Manager has asked you to roll out the updates as quickly as possible. Which of the following deployment strategies do you recommend?","explanation":"An all-at-once deployment deploys to all instances simultaneously which will put all of your web servers out of action at once. Rolling with additional batch launches an extra batch of instances before starting the deployment, to maintain full capacity. However, full capacity is not required in this scenario. Immutable deployments perform an immutable update to launch a full set of new instances running the new version of the application in a separate Auto Scaling group, alongside the instances running the old version; this is not required in this scenario. You can use a rolling update with a batch size of 25%, to ensure that 75% of your servers remain available at any time.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","title":"Elastic Beanstalk Deployment Options"}],"answers":[{"id":"d5b066eef81dedf1d0352f27d2128586","text":"All at once","correct":false},{"id":"ff2713a6181db42fded101c670bbd0dd","text":"Rolling with additional batch","correct":false},{"id":"11efd9ae6f76e706e3f1b34d97584ebc","text":"Immutable","correct":false},{"id":"f4920797afb92022a9c6608efcd86317","text":"Rolling","correct":true}]},{"id":"9548796c-789c-42ea-9e90-3da3a9252c1b","domain":"security","question":"Your Security team have recently reviewed the security standards across your entire AWS environment. They have identified that a number of EC2 instances in your development environment have read and write access to an S3 bucket containing highly confidential production data. You have been asked to help investigate and suggest a way to remedy this. Which of the following can you use to find out what is going on so that you can suggest a solution?","explanation":"With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies attached to IAM users, groups, or roles in your AWS account. You can test which actions are allowed or denied by the selected policies for specific resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html","title":"Testing IAM Policies with the IAM Policy Simulator"}],"answers":[{"id":"aac02aded2357ef60d7cc0b8f32df947","text":"Use CloudTrail and Athena to identify which role or policy is granting access","correct":false},{"id":"5bc514eb754ea13140481ed2afc68d45","text":"Use the VPC flow logs to identify which EC2 instances are attempting to access the bucket","correct":false},{"id":"17d9101067c49b2ec4b35087e24ce8eb","text":"Use the IAM Policy Simulator to identify which role or policy is granting access","correct":true},{"id":"58f20da8b31f9e9da2e5a374608338ef","text":"Use the CLI or console to check the public access permissions of the S3 bucket","correct":false}]},{"id":"70e8f135-19fb-4ad6-82bc-8ec0ed899d83","domain":"security","question":"You are developing a video streaming application which users can access using multiple devices, for example, laptop, tablet and cell phone. You would like to be able to track usage across the different devices and limit the number of devices from which a user can stream content. Which of the following AWS technologies could you use to achieve this?","explanation":"Cognito enables developers to remember the devices on which end-users sign in to their application. You can see the remembered devices and associated metadata through the console. In addition, you can build custom functionality using the notion of remembered devices. For example, with a content distribution application (e.g., video streaming), you can limit the number of devices from which an end-user can stream their content.","links":[{"url":"https://aws.amazon.com/blogs/mobile/tracking-and-remembering-devices-using-amazon-cognito-your-user-pools/","title":"Tracking and Remembering Devices Using Amazon Cognito"}],"answers":[{"id":"3a73d44e5a5b2804c4cc5dd0b6c0bfe5","text":"Use S3 to store metadata about the device and link it to session state held in DynamoDB","correct":false},{"id":"425684337e67b0a12f438c06f1c5818d","text":"Use MFA on the device","correct":false},{"id":"6cbb574c9488bb59fdd64fa8f509fce8","text":"Use Cognito","correct":true},{"id":"5348de0d4df2bd40fa189bd4e5ff1b6c","text":"Store device metadata linked to session state in ElastiCache","correct":false},{"id":"3cff09984a222738fa34702f699ab961","text":"Use a Lambda function to store session state and device type in DynamoDB","correct":false}]},{"id":"aadb1fdb-d919-4989-ab28-6bd8ffcd7c7a","domain":"security","question":"You are developing a healthy-eating application which tracks nutrition and water intake on a daily basis. Your users mainly access the application using a mobile device like a cell phone or tablet. You are planning to run a promotion to attract new users by providing a free trial period and you would like to make it easy for guest users to trial your application. Which of the following can you use to configure access for guest users?","explanation":"With a Cognito identity pool, your users can obtain temporary AWS credentials to access AWS services, such as Amazon S3 and DynamoDB. Identity pools support anonymous guest users, as well as federation through third-party IdPs.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-scenarios.html","title":"Common Cognito Scenarios"}],"answers":[{"id":"22d4851cfa5c3b7d3fa506d938aeb081","text":"Cognito Identity Pools","correct":true},{"id":"8102630f0a77efc6d438d44b1badd712","text":"IAM User Pools","correct":false},{"id":"12ffa121095c5fb3ad9fa1f1ed509e46","text":"Identity Federation with SAML","correct":false},{"id":"1c3430e7715f141606c52e6ff2c15c05","text":"Identity Federation with AWS","correct":false}]},{"id":"53899b37-d74d-42b3-9be9-4f9f0d37155d","domain":"security","question":"Your company has a corporate identity store used to authenticate its users. Your company also has resources running on AWS. Your admin has created IAM roles and an identity broker that sits between your corporate users and your AWS resources to manage the authentication and authorization process without needing to re-create all your users as IAM users in AWS. Your CISO asked you to summarize the AWS identity federation process to ensure compliance with your applications' security. Which of the following statements correctly describes the authentication process?","explanation":"Users might already have identities outside of AWS, such as in your corporate directory. However, those users might need to work with AWS resources (or work with applications that access those resources). If so, these users also need AWS security credentials in order to make requests to AWS. The process can be summarized as follows: 1. The enterprise user accesses the identity broker application. 2. The identity broker application authenticates the users against the corporate identity store. 3. The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials. 4. Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console. A sample identity broker application for use with Microsoft Active Directory is provided by AWS. Details on page 22 of the URL link.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"9b6e91665534238e195af79b94bb3233","text":"The enterprise user accesses the identity broker application. The identity broker application authenticates the users against the corporate identity store. Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console. The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials.","correct":false},{"id":"fe4c072b395ee1d0521094c0d1b4a005","text":"The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials. The enterprise user accesses the identity broker application. The identity broker application authenticates the users against the corporate identity store. Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console.","correct":false},{"id":"26461a0c133d31dd86bb803278256573","text":"The enterprise user accesses the identity broker application. The identity broker application authenticates the users against the corporate identity store. The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials. Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console.","correct":true},{"id":"2870fde359fa2a54b4e99faccf44cb32","text":"The enterprise user accesses the identity broker application.  Enterprise users can get a temporary URL that gives them access to the AWS APIs or the Management Console. The identity broker application authenticates the users against the corporate identity store. The identity broker application has permissions to access the AWS Security Token Service (STS) to request temporary security credentials.","correct":false}]},{"id":"c6126f50-a373-47bf-8245-6037dcea0b5a","domain":"security","question":"Your e-commerce application needs to use database connection strings to access a database containing product and customer data. Which of the following is a secure and scalable way to manage this?","explanation":"Using secure string parameters in Parameter Store is an appropriate way to avoid hard coding a password in your template code. This ensures that sensitive runtime parameters are kept as secure as you keep other secrets, while also keeping them separate from your deployment code.","links":[{"url":"https://aws.amazon.com/systems-manager/features/","title":"Systems Manager - Parameter Store"},{"url":"https://aws.amazon.com/blogs/mt/using-aws-systems-manager-parameter-store-secure-string-parameters-in-aws-cloudformation-templates/","title":"Using AWS Systems Manager Parameter Store Secure String parameters"}],"answers":[{"id":"7cb38c21a4fc2e2ad04aca2dfe89bb59","text":"Add encrypted IAM credentials to the application server and use an IAM role to access the database","correct":false},{"id":"62fc1a48d6c466824dfef123b5407ab3","text":"Store the encrypted credentials in an S3 bucket","correct":false},{"id":"65b9be4196a653fc5de9a6427a2f168a","text":"Store the credentials in Parameter Store","correct":true},{"id":"0d2bb1f681b1226217a023c4cb989aaa","text":"Hard code the connection strings in the application code","correct":false},{"id":"1c2a034c75f70a59fff1e639175239dd","text":"Allow the EC2 instance to access the database using an instance role","correct":false}]},{"id":"9554e10d-8fab-4545-b3ea-a756133ffab3","domain":"refactoring","question":"You need to retrieve some data from your DynamoDB table, which of the following methods would consume the least provisioned Capacity Units?","explanation":"A Query is generally more efficient than a Scan operation. Eventual consistency reads use up fewer Read Capacity Units than strongly consistent reads","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Query Vs Scan"},{"url":"https://aws.amazon.com/dynamodb/pricing/provisioned/","title":"Provisioned Capacity"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","title":"DynamoDB Read Consistency "}],"answers":[{"id":"ac9570514b07db98ad6cc89ea1cc8741","text":"Query with strong consistency","correct":false},{"id":"d87fc0cde8df11c904ff6fe25cac6bfc","text":"Query with eventual consistency","correct":true},{"id":"5d682b15ed6ff4d0b5100242fa11d4ea","text":"Scan with eventual consistency","correct":false},{"id":"8747d18821697e99310487487007af03","text":"Scan with strong consistency","correct":false}]},{"id":"ed0618e6-a6db-4b7e-8564-384ae63b0e89","domain":"development","question":"You are working for a small but busy veterinary surgery and you need to design a new DynamoDB table to store information relating to customers, their pets, and any medications that are currently being prescribed. Which of the following attributes would be a good choice for a partition key, in order to achieve maximum provisioned throughput efficiency?","explanation":"When selecting a partition key, you want to distribute the workload evenly across as many partitions as you can, to maximize provisioned throughput of your DynamoDB table. The partition key determines which partition the record will be stored on. To achieve maximum provisioned throughput, choose a partition key with a unique attribute like Customer ID, Product ID, email address, phone number etc. A partition key design that does not distribute I/O requests evenly can create hot partitions which result in throttling and uses your provisioned I/O capacity inefficiently. Values such as Medication, Species and Registration date, are not unique and in some cases may have only a few possible values which could result in hot partitions and inefficient use of provisioned throughput.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-uniform-load.html","title":"Designing Partition Keys to Distribute Your Workload Evenly"}],"answers":[{"id":"22ffd0379431f3b615eb8292f6c31d12","text":"Registration date","correct":false},{"id":"353bd6f65060d17097c3b03141e79cce","text":"Medication","correct":false},{"id":"d37c2bf1bd3143847fca087b354f920e","text":"Customer ID","correct":true},{"id":"e1520b5997a532c7889f6e8883920ab8","text":"Species","correct":false}]},{"id":"93862748-7e4b-4c90-a475-b52a4d1f6f4c","domain":"development","question":"You are planning to deploy a new version of your application using CodeDeploy. You only have a window of 2 hours to complete the deployment and test it. Your team leader is concerned about the time it could take to roll back the upgrade if it should fail. Which deployment approach would you recommend?","explanation":"Blue / Green is the one to use as this allows you to roll back with minimal disruption. An In-Place upgrade is very disruptive to roll back as it will involve re-deploying the original version of the code and during this time your application will be unavailable. Canary and Rolling updates are not an option for CodeDeploy","links":[{"url":"https://aws.amazon.com/blogs/devops/performing-bluegreen-deployments-with-aws-codedeploy-and-auto-scaling-groups/","title":"Blue/Green Deployments with AWS CodeDeploy"}],"answers":[{"id":"ff2713a6181db42fded101c670bbd0dd","text":"Rolling with additional batch","correct":false},{"id":"53b8ba497ea2cdea89f60da12d94b46d","text":"In-Place","correct":false},{"id":"3a27747f75c4e73e94223a9e4065cd9c","text":"Blue / Green","correct":true},{"id":"ecf715d6d79a2698b7fec0357f9d721f","text":"Canary","correct":false}]},{"id":"d1b0d0fe-4931-441c-83d5-716d63424a58","domain":"mon-trb","question":"You are working on an application which shares video content to subscribed users. This morning you have received a number of complaints that users are unable to access your content and they are seeing an HTTP 504 Status Code. Which of the following could be a possible explanation?","explanation":"An HTTP 504 status code is a Gateway Timeout which indicates that when CloudFront forwarded a request to the origin, because the requested object was not in the edge cache, one of the following happened: The origin returned an HTTP 504 status code to CloudFront; or, the origin didnâ€™t respond before the request expired. This is a server side issue, i.e. a problem or misconfiguration in your AWS infrastructure. Remember that any 5XX error indicates a server-side error, and a 4XX error indicates a client-side error.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/http-504-gateway-timeout.html","title":"HTTP 504 Gateway Timeout"}],"answers":[{"id":"84f05e093a7f246d10fef9ea043d217a","text":"The users have a network connectivity problem","correct":false},{"id":"b9434940d2516177efc8f8eef8b3de37","text":"There is a server side error within your AWS infrastructure","correct":true},{"id":"c8cffd0bf5d95cfc0541c7ad2d54d740","text":"The users could be attempting to access your site using an unsupported browser","correct":false},{"id":"76b78bdea733c0e70e13c80add3c975d","text":"There is a client side error in the user's infrastructure","correct":false}]},{"id":"dbc263cc-9e31-4671-b11a-674870a5dcd3","domain":"deployment","question":"You have been asked to use Elastic Beanstalk to build a number of web servers to use in your development environment, which of the following services can you use?","explanation":"Except for Lambda, all of the services listed can be used to create a web server farm. AWS Lambda automatically runs your code without requiring you to provision or manage servers. Lambda is generally used for stateless, short-running tasks and is not suitable for long-running tasks like running a web server.","links":[{"url":"https://aws.amazon.com/lambda/","title":"What Is Lambda?"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html","title":"What Is AWS Elastic Beanstalk?"}],"answers":[{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"e95e5a2a3cc8625bca3d71b817367e2d","text":"Elastic Load Balancer","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"b578e821ab9be9669c17208a583b5899","text":"Auto Scaling Group","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true}]},{"id":"c1fc5f56-f74e-405f-a974-d9bb2e2c57e6","domain":"deployment","question":"You have deployed a new version of your Lambda function, however during testing, you notice that  your application is not behaving as expected. How can you roll back to the previous version of your code?","explanation":"Remapping the PROD alias to the previous version will allow you to quickly roll back","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda versioning and Aliases"}],"answers":[{"id":"28ab809ddc3a2aee352db2592bca020a","text":"Remap the PROD alias to point to the previous version of your function","correct":true},{"id":"aa97bfdc9437ce44352de51699501c4d","text":"Make a new version of your function using the original Lambda code","correct":false},{"id":"1ba636d1ad4c4e2a9239fc75d17ffc41","text":"Update the $LATEST alias to point to the previous version of your function","correct":false},{"id":"60682da7d7f6df421c71e7e42cf4b227","text":"Redeploy your original code to $LATEST","correct":false}]},{"id":"c11f4354-0409-46a1-a058-1e377939c655","domain":"development","question":"You are in a development team working on a popular serverless web application which allows users to book late availability flights and hotels at a significant discount. You occasionally receive complaints that the website is running slowly. After some investigation, you notice that at the time of the complaints, DynamoDB reported a ProvisionedThroughputExceeded error. Which of the following approaches is a recommended way to handle this error?","explanation":"Increasing Lambda capacity will not fix the issue because the problem is with DynamoDB. As the error only appears occasionally, the first thing to do is to ensure that the application is using Exponential Backoff to improve flow control. Increasing the capacity on the DynamoDB table could be considered but only if the problem persists.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff","title":"DynamoDB Error Handling"}],"answers":[{"id":"7f6f787080ee787e0f7554f770e0c693","text":"Ensure your application is using Exponential Backoff","correct":true},{"id":"528fd1044e587b850c48dc8d209cfe11","text":"Increase the read/write capacity of the DynamoDB table","correct":false},{"id":"e7668448048601413de55468a4091b5d","text":"Increase the RAM capacity of the Lambda function","correct":false},{"id":"cbf47ddd16d15ef42c8c335fe895c69f","text":"Increase the CPU capacity of the Lambda function","correct":false}]},{"id":"b668531f-edd2-43f5-bf40-b7e68dad0d08","domain":"development","question":"A developer is working on a new green field project within an organization. The developer has been asked to recommend what technology could be used if the project is to be deployed with Elastic Beanstalk.\n\nWhich of the following platforms could the developer recommend for the project to meet its requirements?","explanation":"Elastic Beanstalk currently supports Docker, Ruby, and Go (amongst others). It does not support Perl or Swift.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html","title":"Elastic Beanstalk Supported Platforms"}],"answers":[{"id":"ae832e9b5bda2699db45f3fa6aa8c556","text":"Swift","correct":false},{"id":"9916d1fc59fe22cc046a2fe1615bc764","text":"Ruby","correct":true},{"id":"0114ad06d728f1834e36fe1a39574ef4","text":"Perl","correct":false},{"id":"c5fd214cdd0d2b3b4272e73b022ba5c2","text":"Docker","correct":true},{"id":"5f075ae3e1f9d0382bb8c4632991f96f","text":"Go","correct":true}]},{"id":"36bd2e7a-adf7-4dae-ad6f-5e04d3ca873e","domain":"security","question":"You work for a large government agency which is conducting research for a top secret defense project. You are using SQS to handle messaging between components of a large, distributed application. You need to ensure that confidential data relating to your research is encrypted by the messaging system, which of the following services can you use to centrally manage your encryption keys?","explanation":"You can use a CMK to encrypt and decrypt up to 4 KB (4096 bytes) of data. Typically, you use CMKs to generate, encrypt, and decrypt the data keys that you use outside of AWS KMS to encrypt your data. This strategy is known as envelope encryption. CMKs are created in AWS KMS and never leave AWS KMS un-encrypted. To use or manage your CMK, you access them through AWS KMS.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys","title":"KMS Concepts"}],"answers":[{"id":"ea52c36203c5f99c3ce2442d531b1a22","text":"SSL","correct":false},{"id":"fa9c36d7e57eae51ce84cfd30a7346a3","text":"Systems Manager Parameter Store","correct":false},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"4a4df63c87b4f42081b846d9b9189984","text":"KMS","correct":true},{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":false}]},{"id":"004b0e0e-f5a4-4354-b130-46786f367c11","domain":"security","question":"A developer is running an application on an Amazon EC2 instance that requires access to an Amazon S3 bucket. An administrator creates a role that includes policies that grant read permissions to the bucket and that allow the developer to launch the role with an Amazon EC2 instance. The instance is launched with the created role attached. What additional step is required for the application running on the instance to access the objects in the bucket?","explanation":"Applications that run on an Amazon EC2 instance and that need access to AWS resources such as Amazon S3 buckets or an Amazon DynamoDB table must have security credentials in order to make programmatic requests to AWS. In this case, no other steps are necessary since the application running on the instance will have the necessary permissions by assuming the role attached to the EC2 instance. Since the developer is not using the bucket (the application on the instance is) granting access to the developer will have no impact. There is no need to share credentials with the bucket policy.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"d57505894b0e8e826335fc1b6ca1f88c","text":"No other steps are necessary. The application running on the instance will be able to access the bucket.","correct":true},{"id":"ff86c6c144ca49f130e8a6024c26d48c","text":"Create an IAM policy that allows the developer permissions to access the bucket. Attach the policy to the developer's IAM User.","correct":false},{"id":"1bc25b995801c49945fc1175ebfaf95d","text":"The administrator must grant the developer permissions to access the bucket.","correct":false},{"id":"723ec04523ad8f60803dd2ae402f886f","text":"The developer must share his/her credentials with the bucket policy.","correct":false}]},{"id":"51600664-99f9-48f5-97cc-ec860d378f89","domain":"development","question":"Which AWS service allows you to build and model your serverless application as a visual workflow consisting of a series of steps where the output of one stage can be input into another?","explanation":"Step Functions provide this functionality","links":[{"url":"https://aws.amazon.com/step-functions/faqs/","title":"Step Functions FAQ"}],"answers":[{"id":"42816db0ecfffdf3baff90b7f2545874","text":"Step Functions","correct":true},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":false},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"1f4072738a4917bea022b11256fb46a4","text":"Simple Workflow Service","correct":false}]},{"id":"86524d3b-b3e8-46ca-97a2-e12d4edfabed","domain":"development","question":"Which of the following best describes Amazon ECS?","explanation":"ECS stands for Elastic Container Service: It manages running containers on your EC2 instances. It does not act as a scheduler and it is neither serverless nor software that you manage.","links":[{"url":"http://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html","title":"About Amazon ECS"}],"answers":[{"id":"a966ed9a7fc5f750acbbef6754f3ad57","text":"The Elastic Container Scheduler is a serverless system to manage running many Docker containers in a flexible and cost-effective way.","correct":false},{"id":"f0fbcb4f668b638f39ce41a6972d9a94","text":"The Elastic Container Service is software that you can run and manage to orchestrate many running Docker containers.","correct":false},{"id":"d3958d5a87a697631979b920c68a9ae2","text":"The Elastic Container Service is a service that manages running Docker containers on a group of your EC2 instances.","correct":true},{"id":"8180f2f15ee5ff1c554855a0352e23bf","text":"The Elastic Container Scheduler is software that you can run and manage to orchestrate many running Docker containers.","correct":false}]},{"id":"97b2f9cc-962b-4c75-82c3-a44815644776","domain":"mon-trb","question":"You are developing a new application using Lambda, API Gateway, S3 and DynamoDB. You would like to record information about incoming and outgoing HTTP requests as well as latency incurred by each component. You have multiple versions of the application to cater for your Development, UAT, Performance Test and Production environments. What is the most efficient way to collect this information and group it according to which environment it relates to?","explanation":"AWS X-Ray is a service that collects data about requests that your application serves, and provides tools you can use to view, filter, and gain insights into that data to identify issues and opportunities for optimization. For any traced request to your application, you can see detailed information not only about the request and response, but also about calls that your application makes to downstream AWS resources, micro-services, databases and HTTP web APIs. When you instrument your application, the X-Ray SDK records information about incoming and outgoing requests, the AWS resources used, and the application itself. You can add other information to the segment document as annotations and metadata. Annotations are simple key-value pairs that are indexed for use with filter expressions. Use annotations to record data that you want to use to group traces in the console.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-concepts.html#xray-concepts-annotations","title":"X-Ray Annotations and Metadata"},{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-filters.html","title":"Searching for Traces in the AWS X-Ray Console with Filter Expressions"}],"answers":[{"id":"d2ae15c70b6c5a546c571203b1a18474","text":"Use CloudTrail to view the information, configure annotations to indicate which environment the traces relate. Group the data according to environment.","correct":false},{"id":"7596c1ed59077a183e47b002a53bb84a","text":"Use CloudFormation to view the information, configure annotations to indicate which environment the traces relate. Group the data according to environment.","correct":false},{"id":"8f0f2ab2fa58b6ddef1f41eb2fe56872","text":"Use CloudWatch to view the information, configure annotations to indicate which environment the traces relate. Group the data according to environment.","correct":false},{"id":"c57540f9c7ee62b718518b73d8ea536c","text":"Use X-Ray to view the information, configure annotations to indicate which environment the traces relate. Group the data according to environment.","correct":true}]},{"id":"60de4860-8791-4fd6-b3af-364209ceb5ab","domain":"mon-trb","question":"You are working on an application for an online training company which stores product data in DynamoDB. This week, the company is running a big promotion on a few courses and this is bringing lots of new traffic to your website, causing an increased number of queries to the database.  Database queries are now running much slower than usual and the Operations Team are concerned that the DynamoDB table is being throttled. Which of the following approaches would you recommend to improve read performance?","explanation":"Using DAX is the recommended approach to reducing response times for read-intensive applications, applications which read a small number of items frequently and also applications which perform repeated reads against a large set of data. Read Replicas are not a feature of DynamoDB. Configuring the application to use scans instead is not an efficient solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.html","title":"DynamoDB DAX"}],"answers":[{"id":"7d691dd8fcbce5a87b1211b09b47541a","text":"Add a Read Replica and point the DynamoDB API calls at the Read Replica","correct":false},{"id":"1fdd30d4d2259438830cf9536f3da218","text":"Configure a DAX cluster and point the DynamoDB API calls at the DAX cluster","correct":true},{"id":"c9e5713b3f811b188f8770ffd016beaf","text":"Configure the application to use scans rather than queries and run multiple scans in parallel","correct":false},{"id":"df31657d8e3247caf5b704d87a7fced3","text":"Redesign your table to use a more distinct partition key to enable the I/O load to be more evenly distributed across partitions","correct":false}]},{"id":"fcee1e83-0558-4267-ba27-58a978b7003c","domain":"deployment","question":"You are working on an application which is made up of a number of Lambda functions as well as API Gateway endpoints. Which of the following technologies would you use to build and deploy this application in AWS?","explanation":"CloudFormation and the AWS SAM CLI can be used to deploy serverless applications. Use the Transform section of the CloudFormation template to specify the serverless resources you would like to deploy. The other technologies cannot be used to deploy serverless applications. OpsWorks provides configuration management using managed instances of Puppet or Chef. Elastic Beanstalk is for deploying and scaling web applications on familiar servers such as Apache, Nginx, Passenger, and IIS. CodeBuild is an automated build system, and CodeDeploy deploys your built code to either EC2 or an on-premises server.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"What is the AWS Serverless Application Model?"},{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/appendix-appendix-sam-templates-and-cf-templates.html","title":"CloudFormation & the AWS Serverless Application Model"}],"answers":[{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"4d926e7259ad82fea671d810b2211451","text":"AWS Serverless Application Model CLI","correct":true},{"id":"c42aaccedc51aac929c8ae313066f320","text":"OpsWorks","correct":false}]},{"id":"0394976d-f5c9-489a-8411-0dca671a3f67","domain":"deployment","question":"An application connects to an external third-party service with API keys being managed by AWS Secrets Manager. The development team uses CodeBuild for source code compilation activities in their CI/CD process.   Where should the reference to the third-party service API keys be specified?","explanation":"CodeBuild uses the BuildSpec file as a specification of build commands and settings.  â€œsecrets-managerâ€ syntax can be used to retrieve API Keys stored in AWS Secrets Manager. Build Environment variables should NOT be used for storing sensitive information as they are displayed in plain text. AppSpec file is used by CodeDeploy to specify and manage deployments. CloudFormation templates are used by CloudFormation and not by CodeBuild.","links":[{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html","title":"Build Specification Reference for CodeBuild"}],"answers":[{"id":"47d4255c389a3bcdca135b3871c5238d","text":"CodeBuild Environment Variable","correct":false},{"id":"3e1115820889c27bfd8aca3774b9c1f0","text":"AppSpec file","correct":false},{"id":"ef56db4cbf113c83bf357241b3fe4418","text":"BuildSpec file","correct":true},{"id":"5bd169bcf0b77c844c2f4bf1bf3eac9d","text":"CloudFormation Template","correct":false}]},{"id":"42ff013e-95f1-4ead-958d-26a843b0b207","domain":"mon-trb","question":"Your security team have brought in an external auditor to review the security standards across your AWS account. They have identified that your development team have elevated privileges across a number of services, which according to company policy, they should not have access to. You have been asked to help work out which of the IAM policies are granting too much access to the team. Which of the following can you use to find out which policies are granting too many privileges?","explanation":"With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies attached to IAM users, groups, or roles in your AWS account. You can test which actions are allowed or denied by the selected policies for specific resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html","title":"Testing IAM Policies with the IAM Policy Simulator"}],"answers":[{"id":"fa535ffb25e1fd20341652f9be21e06e","text":"Config","correct":false},{"id":"b6632fa69795d5fabc908fe75210b177","text":"IAM Policy Simulator","correct":true},{"id":"0863526e514d88cd2d00b39f8dda0920","text":"X-Ray","correct":false},{"id":"df8a1f2103a58209a3008c02a93162b5","text":"Cognito","correct":false}]},{"id":"21efb969-377d-45b1-a907-8994e94aa26b","domain":"development","question":"An organization is considering making use of AWS Fargate in their next project. Which of the following statements best describes AWS Fargate?","explanation":"AWS Fargate is a compute engine for Amazon ECS that allows you to run containers without having to manage servers or clusters.","links":[{"url":"https://aws.amazon.com/fargate/","title":"AWS Fargate"}],"answers":[{"id":"9996f92567fdefae4123ba718e107bbf","text":"Deploys Compute logic to an AWS Edge location.","correct":false},{"id":"5c10facdecd8cb3ff129afb77d315739","text":"Deploys Docker containers within AWS, without having to manage underlying EC2 instances.","correct":true},{"id":"940863780b5c57669b92b1fc551543ca","text":"Automates management of the control plane within a Kubernetes cluster.","correct":false},{"id":"fbe3eadaa96811fdb58081b395eb6164","text":"Stores Docker containers within a registry, making them available for use by AWS ECS.","correct":false}]},{"id":"2689a73b-04ed-4719-9cdf-49c4ffe3eb17","domain":"deployment","question":"A developer is deploying a new application to ECS. The application requires permissions to send messages to an SQS queue. \n\nWhich role should the developer apply the policy to so that the application can access the SQS queue?","explanation":"The policy must be attached to the ECS Task's execution role to allow the application running in the container access SQS.","links":[{"url":"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html","title":"Amazon ECS Task Execution IAM Role"}],"answers":[{"id":"2d64ba22b9f8e2998aed499099374359","text":"The execution role attached to the ECS Service.","correct":false},{"id":"29aefbd6a89941ca26d2ef879d25237c","text":"The execution role attached to the ECS Task.","correct":true},{"id":"d89a15f255b7e5a2b6cfe8aa7d628173","text":"The execution role attached to the ECS Cluster.","correct":false},{"id":"2413a4993d7f9395b5ddf84bc7b51b62","text":"The execution role attached to the ECS Container.","correct":false}]},{"id":"5820892f-2759-4cd8-be11-8b2dbcc5d1b5","domain":"development","question":"Your Lambda function requires a few libraries which are not available as standard in the Lambda runtime environment. Which of the following is a recommended way to make the libraries available to your function?","explanation":"A deployment package is a ZIP archive that contains your function code and dependencies. You need to create a deployment package if you use the Lambda API to manage functions, or if you need to include libraries and dependencies other than the AWS SDK. You can upload the package directly to Lambda, or you can use an Amazon S3 bucket, and then upload it to Lambda. If the deployment package is larger than 50 MB, you must use Amazon S3.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html","title":"AWS Lambda Deployment Package"}],"answers":[{"id":"a74c95d1ac4aa0e191861afb10c345d4","text":"Create a deployment package containing your function code and libraries","correct":true},{"id":"f21d58a10f3609c9feab39647fa533cf","text":"Store the deployment package in an S3 bucket and then upload it to Lambda","correct":true},{"id":"585237ca133be02e26db990e229ab6f4","text":"Create a custom runtime which includes the libraries you need","correct":false},{"id":"d43e57bd5184ca5787e6827646b30fa5","text":"Create a handler function downloads the libraries you need","correct":false},{"id":"c5aba36fa7ce91daccd7cb3a4e3cf9a1","text":"Add the dependencies to S3 and create an environment variable to reference them","correct":false},{"id":"24030d747fefc92f6c68f2934974ba96","text":"Upload the deployment package to Lambda","correct":true}]},{"id":"364e3d34-4218-44f0-8a7b-40165724cfd8","domain":"development","question":"You want to deploy a docker image to ECS, which command would you use to add your image to the Elastic Container Registry?","explanation":"The docker push command will push the image to the registry","links":[{"url":"https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-push-ecr-image.html","title":"Pushing an Image to ECR"}],"answers":[{"id":"8e404964b0aacdf31fe02c48913ff3bd","text":"docker pull","correct":false},{"id":"9277ffcc0c6be41f97f1aa08b1217cb0","text":"docker tag","correct":false},{"id":"1915a0cd1649e80f5076619cfbc3f51d","text":"docker build","correct":false},{"id":"6a100fcee87852662d457afaa64af06f","text":"docker push","correct":true}]},{"id":"1a8f6ca4-1edf-4cb3-8dce-63550ef898d0","domain":"security","question":"You are working on a web application which handles confidential financial data. The application runs on a few EC2 instances which are behind an Elastic Load Balancer. How can you ensure the data is encrypted end-to-end in transit between your ELB and EC2 instances?","explanation":"Terminating secure connections at the load balancer and using HTTP on the backend might be sufficient for your application. However, if you are developing an application that needs to comply with strict external regulations, you might be required to secure all network connections. First, add a secure listener to your load balancer, then configure the instances in your environment to listen on the secure port and terminate HTTPS connections.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/configuring-https-endtoend.html","title":"Configuring End-to-End Encryption"}],"answers":[{"id":"2c26367f893c5f15ae242c1965051017","text":"Terminate HTTPS connections on your EC2 instances","correct":true},{"id":"c2bc73f05693654154a5a002cf77d3e1","text":"Configure a secure listener on your load balancer","correct":true},{"id":"9f4e11571be1c566b8e30fdd753f0802","text":"Configure the instances in your environment to listen on the secure port","correct":true},{"id":"ed90effd6942a7cffc042b6cb610b798","text":"Perform SSL termination on the load balancer","correct":false},{"id":"cb9dd4ff2be4893bd209d207f1898600","text":"Perform SSL termination using Lambda","correct":false}]},{"id":"025f7c87-6ee6-4dd9-8377-9a25598286ca","domain":"deployment","question":"Which of the following statements about a standard SQS queue is true:","explanation":"With standard queues, SQS will deliver each message at least once, but cannot guarantee the delivery order. Because each message may be delivered more than once, your application should be idempotent by design.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"Message Ordering"}],"answers":[{"id":"f7856994f49c750fb75cc2379898cc34","text":"Messages will be delivered one or more times and message delivery order is indeterminate.","correct":true},{"id":"af1d8b5f4bb474a7d10ddae90292194c","text":"Messages will be delivered exactly once, but message delivery order is indeterminate.","correct":false},{"id":"de5a3c6f37dfc6ac454ea58ff54607db","text":"Messages will be delivered exactly once in first-in, first-out order.","correct":false},{"id":"58a91ca2c04fba617acd128141d111fc","text":"Messages will be delivered one or more times in first-in, first-out order.","correct":false}]},{"id":"5f0e91e8-9de9-4bfe-b30d-6c00cb4e25ee","domain":"deployment","question":"Your application stores files in an S3 bucket located in us-east-1, however many of your users are located in ap-south-1. The files are less than 50MB in size, however users are frequently experiencing delays when attempting to upload files. Which of the following options will maximize the upload speed?","explanation":"S3 Transfer Acceleration is recommended to increase upload speeds and especially useful in cases where your bucket resides in a Region other than the one in which the file transfer was originated. Multipart upload is a good option for large files, e.g. >100MB in size.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html","title":"S3 Transfer Acceleration"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html","title":"Multipart Upload"}],"answers":[{"id":"27cbe99b103845434c5d99034be17b10","text":"Utilize S3 Transfer Acceleration.","correct":true},{"id":"34188758a0d842537d7d14f43c94c315","text":"Design the application to use multipart upload, so that the file is split in to multiple parts which are then uploaded simultaneously.","correct":false},{"id":"c1b6778485fc5a390b6a08f16f22afec","text":"Require the users to use Direct Connect in order to use to application so as to maximize the upload bandwidth.","correct":false},{"id":"137ef2be67b8313e80b25b2c3ea64ec0","text":"Implement a third party CDN solution.","correct":false}]},{"id":"2671403f-a54f-4822-8a1b-fd45645826fe","domain":"development","question":"A transport company uses a mobile GPS application to track the location of each of their 60 vehicles. The application records each vehicle's location to a DynamoDB table every 6 seconds. Each transmission is just under 1KB and throughput is spread evenly within that minute. How many units of write capacity should you specify for this table?","explanation":"Writing to the database every six seconds, there are 10 writes/minute/vehicle. There are sixty vehicles in the fleet, so there are 600 writes/minute overall. 600/60 seconds = 10 writes/second.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html","title":"Throughput Capacity for Reads and Writes"}],"answers":[{"id":"f899139df5e1059396431415e770c6dd","text":"100","correct":false},{"id":"d3d9446802a44259755d38e6d163e820","text":"10","correct":true},{"id":"d490d7b4576290fa60eb31b5fc917ad1","text":"600","correct":false},{"id":"072b030ba126b2f4b2374f342be9ed44","text":"60","correct":false}]},{"id":"51d0eac3-d55e-4a50-aa5b-c133add86037","domain":"refactoring","question":"A content publishing organization runs its own platform, which uses DynamoDB as its data store. A bug report has come in from the content team. They say that when two editors are working on the same content they frequently overwrite each other's changes.\n\nWhat DynamoDB feature would prevent the most number of overwrite bug reports?","explanation":"Using a condition-expression we can perform a conditional update to an item. The condition must evaluate to true; otherwise, the update operation fails. We can use this feature to make sure the content of an article has not changed since it was last read, before we update it.\n\nacid-expression is incorrect because there is no such expression.\n\nDynamoDB TTL is incorrect because it is for deleting items from DynamoDB after a given duration, not creating a lock.\n\nCalling GetItem immediately before calling UpdateItem would help mitigate the issue, but still leaves a small race condition where condition-expression does not. It is, therefore, not the best solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ConditionExpressions.html","title":"Condition Expressions in DynamoDB"}],"answers":[{"id":"9d2d53ddaae2b905e48ea3705529a19c","text":"Apply a time-limited lock to the item while an author is editing it using a DynamoDB TTL.","correct":false},{"id":"058706dd0f32f05aa73a515774a5dc2d","text":"Call GetItem immediately before calling UpdateItem to ensure the item has not changed.","correct":false},{"id":"b1d92ca8c7500f89cffdf0057251aec1","text":"Include a condition-expression in the UpdateItem command.","correct":true},{"id":"ddb55880d9b1b331207bcb38cebd6dbf","text":"Include an acid-expression in the UpdateItem command.","correct":false}]},{"id":"730a845f-ecf8-44f3-aedd-063e6c82f952","domain":"development","question":"A company is developing its first lambda function. The function needs access to their existing EC2 instances, which are all hosted in private subnets within their VPC.\n\nWhat must the company do to ensure their lambda can access the EC2 instances?","explanation":"To configure a lambda to connect to a VPC, one or more subnets into which it can connect must be defined.\n\nThe lambda function creates an Elastic Network Interface in one of the given subnets. It, therefore, needs an execution policy that allows it permissions to do so. The specific permissions required are in the attached AWS documentation link.\n\nThe Elastic Network Interface through which the lambda connects should then be associated with one or more security groups that allow network communication to the desired destinations, over the desired ports.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html","title":"Configuring a Lambda Function to Access Resources in a VPC"}],"answers":[{"id":"dff8a08528259b15e8eaa21fd941b858","text":"Configure lambda's security group, so it has access to the EC2 instances.","correct":true},{"id":"3c5b22594c1609c3eb107b6bb74dd18a","text":"Configure the lambda function to connect the private subnets used by the EC2 instances.","correct":true},{"id":"48e1378bc6d56c11575da9eaf6e585a1","text":"Configure lambda's execution role to have permissions for managing an ENI within the VPC.","correct":true},{"id":"b83e0ff6499487c14dfb5578bbd8f3d2","text":"Configure the lambda's execution role to match the role applied to your EC2 instances.","correct":false},{"id":"58f3dd590a2af5106b444d3ba4135b92","text":"Configure the lambda's function policy to allow EC2 to involve the function.","correct":false}]},{"id":"fef4400a-946f-4f47-8a06-1d8cac177396","domain":"mon-trb","question":"You are attempting to list the objects contained in an S3 bucket. The bucket contains over 3000 objects and the list-objects command times out and does not complete successfully, however when you run the same command on a different bucket, it works without errors. What could be the reason for this?","explanation":"If you see issues when running list commands on a large number of resources, the default page size of 1000 might be too high. This can cause calls to AWS services to exceed the maximum allowed time and generate a \"timed out\" error. You can use the --page-size option to specify that the AWS CLI request a smaller number of items from each call to the AWS service. The CLI still retrieves the full list, but performs a larger number of service API calls in the background and retrieves a smaller number of items with each call. This gives the individual calls a better chance of succeeding without a timeout. Changing the page size doesn't affect the output; it affects only the number of API calls that need to be made to generate the output.","links":[{"url":"https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-pagination.html","title":"AWS CLI Pagination"}],"answers":[{"id":"fe6ecb35fc38b38806053192af45aadd","text":"The command is generating too many API calls due to the large number of objects in the bucket.","correct":false},{"id":"12b3ee65ff4239dcb2e54ada9d0307d5","text":"You are running the command on a bucket which contains a large number of resources, and the default page size might be need to be increased.","correct":false},{"id":"abf2e493ee10caa92d340b7832cc908f","text":"You do not have the required permission to run the list-objects command on the bucket.","correct":false},{"id":"c105a5c0f66ee44cff21cb53bd7ec1e5","text":"You are running the command on a bucket which contains a large number of resources, and the default page size might be too high.","correct":true}]},{"id":"513198a9-39d6-4e0b-85d2-c774cef841a8","domain":"deployment","question":"Your 'forums' table has a primary key of 'comment_id'. Using DynamoDB, you're able to query the data based on the 'comment_id' primary key. You need to be able to query the forums table by userId. What would you add to the table during table creation time?","explanation":"The creation of a secondary index will allow you to sort by userId.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SecondaryIndexes.html","title":"DynamoDB Secondary Indexes"}],"answers":[{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"bfd6d3cd3f6cac9eb918e1ce84732f98","text":"A new table ordered by userId","correct":false},{"id":"153c557ab1353fc790ad20e9087663c7","text":"A secondary index","correct":true},{"id":"6640a5d74994ccaa1f30daef71496cfe","text":"A partition/sort primary key","correct":false}]},{"id":"4a430e9e-4943-4d13-9511-ba93d66d9eaf","domain":"development","question":"A developer is configuring CodeDeploy to deploy an application to an EC2 instance. The application's source code is stored within AWS CodeCommit.\n\nWhat permissions need to be configured to allow CodeDeploy to perform the deployment to EC2?","explanation":"CodeDeploy interacts with EC2 via the CodeDeploy Agent, which must be installed and running on the EC2 instance. During a deployment the CodeDeploy Agent running on EC2 pulls the source code from CodeCommit. The EC2 instance accesses CodeCommit using the permissions defined in its instance profile role; therefore, it is the EC2 instance itself that needs CodeCommit access.\n\nThe specific CodeCommit permission needed to pull code is `codecommit:GitPull`.","links":[{"url":"https://docs.aws.amazon.com/codecommit/latest/userguide/auth-and-access-control-permissions-reference.html","title":"CodeCommit Permissions"},{"url":"https://docs.aws.amazon.com/codedeploy/latest/userguide/instances-ec2-configure.html","title":"Configure an Amazon EC2 Instance to Work with CodeDeploy"}],"answers":[{"id":"a5f1b9fe7264b6a78932a24f195b1064","text":"Create an IAM Policy with an acton to allow `codecommit:CreatePullRequest` on the required repository. Attach the policy to CodeDeploy's Service role.","correct":false},{"id":"ae4d1eac013f4a67d18129084085b41b","text":"Create an IAM policy with an acton to allow `codecommit:CreatePullRequest` on the required repository. Attach the policy to the EC2 instance profile role.","correct":false},{"id":"dcaaa5b141981d140fe32ea458888500","text":"Create an IAM Policy with an acton to allow `codecommit:GitPull` on the required repository. Attach the policy to CodeDeploy's Service role.","correct":false},{"id":"3801756a25b44dc5e1eaaf3a55f6c0fe","text":"Create an IAM policy with an acton to allow `codecommit:GitPull` on the required repository. Attach the policy to the EC2 instance profile role.","correct":true}]},{"id":"9382a270-2c44-45b2-95f3-79d0cf319120","domain":"mon-trb","question":"A developer has been tasked with enabling Access Logs on the Application Load Balancer that sits in-front of their web services. As part of this task, they must configure a location to which the logs are delivered.\n\nTo what AWS service can Access Logs from an Application Load Balancer be delivered?","explanation":"S3 is the only service supported by AWS for receiving ALB access logs.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html","title":"Application Load Balancer Access Logs"}],"answers":[{"id":"594025cae6dfa6b9073dc25de93ddb56","text":"Kinesis","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false}]},{"id":"97d06b4f-a564-4de7-9faa-b4a421e676de","domain":"deployment","question":"You are developing a Serverless application written in Node.js, which will run on Lambda. During performance testing, you notice that the application is not running as quickly as you would like and you suspect that your Lambda function does not have enough CPU capacity. Which of the following options will improve the overall performance of your function?","explanation":"In the AWS Lambda resource model, you choose the amount of memory you want for your function, and are allocated proportional CPU power and other resources. For example, choosing 256MB of memory allocates approximately twice as much CPU power to your Lambda function as requesting 128MB of memory and half as much CPU power as choosing 512MB of memory. Lambda allocates CPU power linearly in proportion to the amount of memory configured.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html","title":"AWS Lambda Function Configuration"}],"answers":[{"id":"79ff2269ee5c54ff3301f83a7e9e763c","text":" Configure an ElastiCache cluster and place it in front of your Lambda function","correct":false},{"id":"0bfe8be5a6b97f1817eed73015acf072","text":"Configure more memory for your function","correct":true},{"id":"5f8bedb50d2fe04bbfba29e3f41e9cda","text":"Use API Gateway to expose the Lambda function in a more scalable way","correct":false},{"id":"0ee93a043ba5d3a9009482ac05272be4","text":"Configure more CPU capacity in the Lambda settings","correct":false}]},{"id":"daa8b2ee-b810-4e35-947d-9ad26196189d","domain":"mon-trb","question":"You can use X-Ray with applications running on which platforms? ","explanation":"X-Ray works with Lambda, EC2, API Gateway, Elastic Beanstalk and ECS","links":[{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":true},{"id":"c8f63ecaff5e983a2441126a241c4cfa","text":"ECS","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true}]},{"id":"a03dd6d9-131e-4ca1-8a32-ee232f5b1323","domain":"deployment","question":"Under what circumstances would you use an SQS Delay Queue?","explanation":"Delay queues let you postpone the delivery of new messages to a queue for a number of seconds. If you create a delay queue, any messages that you send to the queue remain invisible to consumers for the duration of the delay period.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"51338086c0084222e0b52b27cb080907","text":"To delay a message for a number of seconds until it has been processed","correct":false},{"id":"a767183a27b8a253d76902f6d6b5faca","text":"To delay a message for a number of seconds while it is being polled from the queue","correct":false},{"id":"325f46d52e7f4979ed4ac9b2f986a307","text":"To postpone the delivery of new messages to a queue for a number of seconds","correct":true},{"id":"ec05848fbc20fc135aba127ca16850f2","text":"To hide a message for a number of seconds after it has been consumed from the queue","correct":false}]},{"id":"d38a2534-f7bb-4cc2-9b9a-0c50dfb7707b","domain":"security","question":"You are attempting to analyse the CloudWatch metrics for a number of your application servers, however when you try to view the metrics you cannot access them, however one of your colleagues is able to access them without any issues. What could be the problem?","explanation":"Access to Amazon CloudWatch Logs requires credentials that AWS can use to authenticate your requests. Those credentials must have permissions to access AWS resources, such as to retrieve CloudWatch Logs data about your cloud resources.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/auth-and-access-control-cw.html","title":"CloudWatch Access Control"}],"answers":[{"id":"2578745b37e7d610c9f6227f920c4cb5","text":"CloudWatch doesn't have permission to collect the metrics","correct":false},{"id":"a0ff1e54243f914c3324d8826543cdd2","text":"Your IAM user doesn't have permission to view CloudWatch metrics","correct":true},{"id":"dcd1178c83830f41078c6b19fcd33f05","text":"The CloudWatch agent has stopped running","correct":false},{"id":"691a929a32273fce2328658fc4c41fa6","text":"Your EC2 instance role does not have permission to push the metrics to CloudWatch","correct":false}]},{"id":"0f02f4b2-9d11-4efb-b467-19bc558ef33d","domain":"security","question":"Your application on EC2 must write to an Aurora cluster to store user and purchasing data. Your CISO implements a new company-wide policy that requires all AWS credentials are encrypted and rotated monthly. How would you fulfill the new security policy with minimum administrative burden?","explanation":"AWS designed IAM roles so that your applications can securely make API requests from your instances, without requiring you to manage the security credentials that the applications use. IAM roles are based on temporary security tokens, so they are rotated automatically. Credentials embedded in source code cannot be rotated without it being an administrative burden, and is a bad practice. Itâ€™s impossible to retrieve credentials from an S3 bucket if you donâ€™t already have credentials for that bucket. IAM users cannot be associated with resources, and Active Directory authorization will not grant access to AWS resources.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html","title":"IAM Roles for Amazon EC2"}],"answers":[{"id":"c3e276ad3302f173e7d92b40534f2074","text":"Allow the application to fetch the credentials from an S3 bucket with SSE-S3. Upload new credentials monthly.","correct":false},{"id":"05a57da8fa8c802639a4f49ed0d59116","text":"Associate an IAM user with the application. Enroll that user with your Active Directory domain to use AD authorization.","correct":false},{"id":"fc14a6fe77ae1367c0f776ae96c7379c","text":"Attach an IAM role to the instance with proper credentials.","correct":true},{"id":"5fa27e0170ca1f467557d0d8db5502ff","text":"Encrypt the Aurora clusters' credentials using SHA-256 hash function in the application code, and schedule a CRON job to rotate monthly.","correct":false}]},{"id":"52809d95-a072-4314-8781-a45d93534ad5","domain":"development","question":"You are importing an existing API to API Gateway. Which format is supported for API definition files?","explanation":"The Import API feature supports OpenAPI v2.0 and OpenAPI v3.0 definition files. Swagger is a common tool set that is originally defined the OpenAPI v2.0 specification.  AWS use the name interchangeably with OpenAPI v2.0 .  RAML is supported in a different tool (API Gateway Importer).","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-import-api.html","title":"Importing APIs"},{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-export-api.html","title":"Export an API from API Gateway"},{"url":"https://en.wikipedia.org/wiki/OpenAPI_Specification#History","title":"Swagger & OpenAPI"}],"answers":[{"id":"51546bb736b0f9021b167202e967a6cb","text":"RAML","correct":false},{"id":"336ff1e9aa6177ea7a71984fa8c241b9","text":"Swagger","correct":true},{"id":"9a0df1d09b45d123c4f21aa4caf2c205","text":"OpenAPI v3.0","correct":true},{"id":"c31c335ef37283c451b18ba0dd317de1","text":"Angular","correct":false},{"id":"a15aa8cb8ce8298ee404e93ab4afdf0b","text":"OpenAPI v2.0","correct":true}]},{"id":"235fa5cd-42b5-4017-af9a-e62d0503651a","domain":"security","question":"You are working on a Lambda function which needs to access data in RDS, which of the below are valid approaches for securely storing the encrypted database connection strings and other secrets which your function needs to use?","explanation":"Parameter Store provides secure storage for configuration data, connection strings, passwords and secrets management. None of the other options are secure.","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html","title":"AWS Systems Manager Parameter Store"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/tutorial-env_console.html","title":"Create a Lambda Function Using Environment Variables To Store Sensitive Information"}],"answers":[{"id":"913d4a9f910c7f6b836d623b39131480","text":"Use Systems Manager Parameter Store","correct":true},{"id":"ca7c47bd30833fb42e5bc78f6c7583be","text":"Use Lambda Environment Variables","correct":true},{"id":"f2523ec5429fa4e1be124d650a69a0f5","text":"Store the encrypted connection string and other secrets in S3","correct":false},{"id":"53708b71a9f9d0c3994b3bd1d470b254","text":"Use DynamoDB to store the encrypted connection string and secrets","correct":false}]},{"id":"d32ba0f0-1563-4a30-9e61-b5edf82d628e","domain":"security","question":"You are developing a legacy application which handles confidential healthcare data. The application runs on two EC2 instances behind an Application Load Balancer. Because of the age of the application, you cannot perform TLS encryption on the EC2 instances themselves. What is the least complex way you can ensure data is encrypted in transit between your VPC, and the customer who will be accessing it?","explanation":"Handling the TLS termination process within each EC2 instance adds to the computational load on the instance as well as the operational overhead of installing an X.509 certificate on each instance. You can easily arrange for the entire HTTPS encryption and decryption process, generally known as TLS termination to be handled by an Elastic Load Balancer. Your users can benefit from encrypted communication with very little operational overhead or administrative complexity.","links":[{"url":"https://aws.amazon.com/blogs/aws/elastic-load-balancer-support-for-ssl-termination/","title":"AWS Elastic Load Balancing: Support for SSL Termination"}],"answers":[{"id":"4567a70530701c962bab095e279dfb3b","text":"Perform TLS termination using Lambda","correct":false},{"id":"ef68b9b0058c7aa4c84143939156e93b","text":"Perform TLS termination on the ALB","correct":true},{"id":"f81774e2c858b52c0321762e8489f624","text":"Require customers to connect through a VPN to a virtual private gateway","correct":false},{"id":"18c056fd0ece19fd238f6d245fe85321","text":"Upgrade the application to support TLS on the EC2 Instances","correct":false}]},{"id":"6e7680bf-f045-4583-b38b-b2ca3ae466ed","domain":"security","question":"An IT Auditor has started in your Security Team, they will need access to read files in S3 and DynamoDB as well as the ability to describe EC2 instances. You want to ensure that only the Auditor is granted this access and that the IAM policy you create cannot mistakenly be attached to any other user. Which IAM policy type should you use?","explanation":"When you use an inline policy, the permissions in the policy cannot be inadvertently attached to the wrong principal entity","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html","title":"Managed Policies and Inline Policies"}],"answers":[{"id":"449ff67db14fb547ec64ef11c4d33c40","text":"Inline Policy","correct":true},{"id":"05aaffc9a37013fcae1b36c4baffceff","text":"AWS Managed Policy","correct":false},{"id":"60a6d5742e8f4d09d2d0edb9b15fa80d","text":"Customer Managed Policy","correct":false},{"id":"ab18cb3ee046b7e5466057043f273700","text":"Custom Policy","correct":false}]},{"id":"6a5ea0b3-2527-4c20-9410-d8807d16fcd3","domain":"security","question":"An organization is hosting their static website on S3, using a custom domain name. Users have started reporting that their web browsers' are alerting them to the fact that the organization's website is \"Not Secure\" because it is not served via a secure HTTPS connection.\n\nWhat is the easiest way to start serving the website via HTTPS?","explanation":"S3 buckets do not directly support HTTPS with a custom domain name. The simplest solution is to create a CloudFront distribution and set its origin to the S3 bucket. CloudFront allows you to specify a custom domain name, and supports managed certificates via Amazon Certificate Manager.\n\nEnabling AES-256 Default Encryption on the S3 bucket only affects the object at rest.\n\nApplication Load Balancers do support SSL termination but do not support S3 as a target.\n\nAWS Shield relates to Distributed Denial of Service protection, not encryption over the wire.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-requests-s3/","title":"Use CloudFront to serve HTTPS requests for Amazon S3"}],"answers":[{"id":"674d0590e06799926f232e63b73894a8","text":"Add a CloudFront distribution in front of the S3 static website, which supports HTTPS with a custom domain name.","correct":true},{"id":"27631f4c194c5ea5116e308788e945f2","text":"Enable AES-256 Default Encryption on the S3 bucket, which ensures all content is delivered via HTTPS.","correct":false},{"id":"6d63f6dae98a20c7db6446021c83e7f5","text":"Enable AWS Shield on the S3 bucket. Browsers automatically detect that Shield is enabled and report that the website is secure.","correct":false},{"id":"d76d398f54d04a531867ae84eda26050","text":"Add an Application Load Balancer in front of the S3 bucket and enable SSL termination.","correct":false}]},{"id":"f2b792a0-0877-43cf-8c6f-be7efff79d01","domain":"refactoring","question":"You are designing a new web application and you need to find a solution to improve overall performance of your application. Which of the following services could you use in this situation?","explanation":"CloudFront and ElastiCache are both caching technologies which can be used to improve performance of web applications, by caching data and content. DynamoDB is a high performance NoSQL database however it will not necessarily improve the performance of your application. X-Ray can be used to detect bottlenecks and visualize distributed apps, but it will not improve performance of your application.","links":[{"url":"https://aws.amazon.com/ElastiCache/","title":"ElastiCache"},{"url":"https://aws.amazon.com/cloudfront/","title":"CloudFront"}],"answers":[{"id":"0863526e514d88cd2d00b39f8dda0920","text":"X-Ray","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":true},{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":true}]},{"id":"322048b9-4d49-4c64-8aca-c7479619982a","domain":"mon-trb","question":"Your company is reaching the end of the financial year and the Finance team are running a lot of large database queries and scans against your DynamoDB tables. The database queries and scans are taking much longer to complete than expected, how can you make them more efficient?","explanation":"Reducing page size for queries and running scans in parallel are both recommended approaches for making DynamoDB operations more efficient. DynamoDB uses eventually consistent reads by default and filtering the results will not improve efficiency","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Best Practices for Querying and Scanning Data"}],"answers":[{"id":"60e26c5aacc3bba5083560f51b354c87","text":"Reduce the page size to return fewer items per results page","correct":true},{"id":"c6c36956db297a402f3fef1bf83c4c7e","text":"Filter your results based on the Primary Key and Sort Key","correct":false},{"id":"e131078f81b76b76be2718610cc739a9","text":"Set your queries to be eventually consistent","correct":false},{"id":"867b7b3ff3ddfb076ff319ce80e543c5","text":"Run parallel scans","correct":true}]}]}}}}
