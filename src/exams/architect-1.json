{"data":{"createNewExamAttempt":{"attempt":{"id":"b3edc253-2d95-4fc8-8452-837b87264671"},"exam":{"id":"d665980e-3c0c-428f-848e-fbaf2048a329","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"2d119c6f-6abf-448e-b5ba-b88b900779d1","domain":"SecureSolutions","question":"Security Groups & Network ACLs are commonly used together. Which of the following are correct when talking about Network ACLs? (Pick 3)","explanation":"Network ACLs are applied to subnets and all instances within the subnet. Allow & deny rules are supported. They are stateless, traffic for ingress & egress must be declared in rules. Rules are processed in order to determine what traffic is permitted.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html#VPC_Security_Comparison","title":"Comparison of Security Groups and Network ACLs"}],"answers":[{"id":"8d5c2eb7c4dd63ae3fa2e9a75e4a5e10","text":"They automatically apply to all instances in the subnets they are associated with","correct":true},{"id":"25df1d7f960a612248956abe8fe9539a","text":"They evaluate all rules before deciding whether to allow traffic","correct":false},{"id":"89a47e225595f9bca3bba7dd537d822d","text":"Return traffic must be explicitly allowed by rules","correct":true},{"id":"33c4dd33929c4f5b78a9309eb521da7e","text":"They operate at the instance level","correct":false},{"id":"68d29f094012f88dc44bd13b89afee67","text":"They supports allow and deny rules","correct":true}]},{"id":"acea5c56-7b49-4c67-8989-4804df59c5c2","domain":"ResilientDesign","question":"You're building out a single-region application in us-west-2. However, disaster recovery is a strong consideration, and you need to build the application so that if us-west-2 becomes unavailable, you can fail-over to us-west-1. Your application relies exclusively on pre-built AMIs. In order to share those AMIs with the region you're using as a backup, which process would you follow?","explanation":"AMIs are not accessible across Regions, so you need to use the Console or CLI/SDK to copy AMIs between Regions.","links":[{"url":"http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"6d7b4db338035f5120178785949a0d5a","text":"Nothing: AMIs are specific to an account, and they can be used anywhere.","correct":false},{"id":"c88c001bf1285cf7ef868775ac041b61","text":"Create a new instance in us-west-1, making certain the instance in the failover region shares a security group with the instance in the default region.","correct":false},{"id":"a3bc2ecdcf2216f36fa55adedc6dd738","text":"Copy the AMI from us-west-2, manually apply launch permissions, user-defined tags, and Amazon S3 bucket permissions of the default AMI to the new instance, and launch the instance.","correct":true},{"id":"ed198fd876d3910a331d2f50110abfa7","text":"Copy the AMI from us-west-2 to us-west-1 and launch as-is.","correct":false}]},{"id":"56bf1d42-e120-46cf-8324-6b624b3c0beb","domain":"Performant","question":"Which of the following services can stream configuration changes and notifications recorded by AWS Config and use email as the endpoint?","explanation":"AWS Config records configuration changes in resources, and it streams those changes and notifications to an SNS topic. Users subscribed to the topic receive email notifications of the changes. Although SES is an email service, Config does not use it to send email notifications. CloudWatch is for monitoring resources, not for recording their configuration changes. SQS is a message queuing service and is not used with Config.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/notifications-for-AWS-Config.html","title":"Notifications that AWS Config Sends to an Amazon SNS Topic"}],"answers":[{"id":"64fdb9de34f1179f1b0a667717e6fba3","text":"Amazon Simple Queue Service (SQS)","correct":false},{"id":"f7be29c9a4de2fe0c3ced5ca83552403","text":"Amazon Simple Notification Service (SNS)","correct":true},{"id":"2e03b43594eb74bc8c1a23deeb4774ef","text":"Amazon Simple Email Service (SES)","correct":false},{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":false}]},{"id":"9fc041cf-1305-46e0-9851-bbf11b320f3c","domain":"Performant","question":"You need to develop an infrastructure that can be replicated and deployed in another AWS Region in a matter of minutes. Which AWS service might you use to build a reproducible, version-controlled infrastructure?","explanation":"AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"About CloudFormation"}],"answers":[{"id":"d8d0959d6dfc410044ed02441ee86c96","text":"EC2 AMIs with EBS snapshots","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"c0f075697e6a50da6356e4718f5a1de0","text":"CloudWatch Template","correct":false}]},{"id":"86d024c1-7027-401d-a4d2-5457b7f976a0","domain":"CostOptimized","question":"Your site uses machine learning algorithms to modify user-uploaded images in interesting ways, generating new images in under a second as a result. Both the original user image and the generated images are currently stored in S3 - but your site is currently growing with 50Gb of new content added per day, driving up your storage costs. Recent usage statistics have shown that both user uploaded and generated images are heavily accessed in the first 21 days after upload or creation, after which access sharply drops off. After 120 days they are never accessed again. You want to keep the good buzz you site has going and want to ensure that images are there when users need them, but at the same time you want to reduce storage costs to keep you site profitable. Which of the below is the best trade-off of the two?","explanation":"With a complex scenario like this, it's a good a to break it down into components. In the first 21 days, due to the high usage of the images any storage that includes retrieval costs will not be suitable - ruling out any IA storage. After 21 days as usage drops off significantly IA becomes a viable option. Taking it a step further - as your site is generating the images based on the user uploaded image, generated images are easily replaceable if lost, as long as you have the user image. This means that a reduced redundancy storage option is valid for generated images - S3-1Z-IA. Anything older than 120 days can be deleted as it is no longer needed.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"eccefc577b666cc3968032eb19067e5b","text":"Store all images on S3 in the first 21 days. After 21 days move them both to S3-IA with a lifecycle policy. Create Lambda function that runs daily that deletes anything older than 120 days","correct":false},{"id":"bcfb0baa0a994f7d1fc253718a0eb14a","text":"Store all images on S3-IA in the first 21 days. After 21 days move both user uploaded and generated images to S3-1Z-IA with a lifecycle policy, then after 120 days move them to Glacier for archival purposes","correct":false},{"id":"b3f69f81f2babbf2f17f845d1fcd4109","text":"Store all images on S3 in the first 21 days. After 21 days, move user images to S3-IA and generated images to S3-1Z-IA. Delete all content older than 120 days via lifecycle policy","correct":true},{"id":"afcd1b04e8899f07bdff4b5a7b6df83d","text":"Store all images on S3. After 21 days move them both user uploaded and generated images to S3-IA with a lifecycle policy, then after 120 days move them to Glacier for archival purposes","correct":false}]},{"id":"424b1344-ed2d-45df-8705-ccc54d235d1e","domain":"ResilientDesign","question":"You've been storing social media post information about your company's products for a little over two years. Most of the information is frequently used by the marketing department. The raw posts and some metadata are stored in an Amazon Aurora database. One day, the query application begins returning error messages. Marketing department users tell you they need the application available immediately for work on a campaign that's launching next week. Upon investigation you find that database storage has grown to the 64 TB limit for Aurora. What will be the most expeditious way to solve this issue?","explanation":"You can use AWS Database Migration Service (DMS) to migrate data from Aurora to S3 in CSV format, which can then be queried by Amazon Athena if needed. Creating a case with AWS Support won't resolve this issue since the Aurora storage limit is not an adjustable quota. Using the Aurora Global Database feature will not increase the maximum storage limit for a single database. While an EMR cluster may be a better solution for this use case, there is not time to perform such a migration in the time frame required by the marketing department","links":[{"url":"https://aws.amazon.com/rds/aurora/","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/dms/","title":"Amazon Database Migration Service"},{"url":"https://aws.amazon.com/blogs/database/archiving-data-from-relational-databases-to-amazon-glacier-via-aws-dms/","title":"How to archive data from relational databases to Amazon Glacier using AWS DMS"}],"answers":[{"id":"98787ed0461b156ab50abac0b75e22c4","text":"Use AWS Database Migration Service to move the least accessed data to Amazon S3","correct":true},{"id":"e9351ebb109e6e0e2d29eaa03a931116","text":"Open a case with the AWS Support Center to increase the Aurora database's storage quota","correct":false},{"id":"40f74ae9c39738abdadc3558462e1b39","text":"Turn on the Aurora Global Database feature and distribute part of the data to another AWS Region","correct":false},{"id":"deb5ee8cd76c99a18d1c712fa2fe45a5","text":"Migrate the database to an Amazon EMR cluster and use data mining tools for analyses going forward","correct":false}]},{"id":"9da56843-5a00-40d2-91e6-9043e665cd1d","domain":"ResilientDesign","question":"What type of replication is supported by Multi-AZ RDS instances?","explanation":"Multi-AZ deployments utilize synchronous replication, making database writes concurrently on both the primary and standby so that the standby will be up-to-date in the event a failover occurs.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"RDS Multi-AZ Synchronous Replication"}],"answers":[{"id":"18807bab4162a8219f67943263205f38","text":"Asynchronous replication","correct":false},{"id":"2dba9be51ba243660abd8717959eb4b3","text":"Sequential replication","correct":false},{"id":"b56265ceb6311e42003e668438136a59","text":"Synchronous replication","correct":true},{"id":"4350a58e8d877c13ae12d0a4aa1c3f2f","text":"Continuous replication","correct":false}]},{"id":"3f41cb1e-265b-11ea-978f-2e728ce88125","domain":"Performant","question":"You are setting up the properties of an S3 bucket created for storing monthly pie charts. You want to use a template that will serve as the pie chart for the month of January, and for making alterations corresponding with subsequent months. All charts will be stored in the same bucket. Which of the following options should you select to allow that to happen?","explanation":"Enabling the Versioning feature will enable you to keep multiple versions of the pie chart in the S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/enable-versioning.html","title":"Enable Versioning"}],"answers":[{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":false},{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":false},{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":true},{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false}]},{"id":"bccba3fe-36b1-4122-a4d9-dbdaced2250a","domain":"Performant","question":"Your supervisor wants you to specifically record the configuration changes of all the EC2 instances in the environment. Which of the following AWS services will do that?","explanation":"It can be easy to confuse Config and CloudTrail, since both are AWS management-and-governance tools. However, they operate differently. While CloudTrail provides event history of your AWS account activity, Config specifically focuses on listing the resources in your AWS account and presenting their configuration change history.","links":[{"url":"https://aws.amazon.com/config/","title":"AWS Config"}],"answers":[{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":false},{"id":"621f4719cc9f27432c4c095f76df474e","text":"Amazon GuardDuty","correct":false},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":false}]},{"id":"09223b1a-2169-4791-94b1-9ecf1716c8eb","domain":"Performant","question":"Which of the following AWS services store data as key-value pairs?","explanation":"Both DynamoDB and S3 use key-value pairs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html","title":"Working With S3 Objects"},{"url":"https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs","title":"DynamoDB Data Models"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false}]},{"id":"58af5529-d965-4ab9-ae2f-a906c0b8c41e","domain":"Performant","question":"You've enabled website hosting on a bucket called 'aspiring-guru' in the us-west-2 Region. Which of the following is the URL that will be assigned to your website?","explanation":"Your bucket name *always* comes first. 's3-website', followed by the Region, *always* comes next.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Website Hosting"}],"answers":[{"id":"b7ac852a2cf809dc4fb801df9b658c8a","text":"aspiring-guru.s3-website-us-west-2.amazonaws.com","correct":true},{"id":"eff2fbc9e562b82d9381082df00c92d6","text":"s3-website.aspiring-guru-us-west-2.amazonaws.com","correct":false},{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"09cbf53f89e143efb0fb279e5d14b9e8","text":"s3-website-us-west-2.aspiring-guru.amazonaws.com","correct":false}]},{"id":"800d5598-41b8-45b0-8ed1-282e298da6d1","domain":"SecureSolutions","question":"Your company hosts a popular web application that connects to an Amazon RDS MySQL DB instances running in a private subnet created with the default ACL settings. Your security department has identified a DoS attack originating from a suspicious IP address. How can you protect the subnets from this attack?","explanation":"A network access control list (ACL) is another layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. Network ACLs and security groups apply different types of filtering and can be used together.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"8dcd632682257a9e6db8658fd01c07f9","text":"Change the Outbound Security Groups to deny access from the suspicious IP address.","correct":false},{"id":"ba87fc8ccb2ecf3a22e7ec386b502f39","text":"Change the Inbound NACL to deny access from the suspicious IP address.","correct":true},{"id":"4f16db81b73ca177c79c3244e13c35a2","text":"Change the Inbound Security Groups to deny access from the suspicious IP address.","correct":false},{"id":"6ca751c9ece11db6ef98b0c5a39d0694","text":"Change the Outbound NACL to deny access from the suspicious IP address.","correct":false}]},{"id":"8c9f0c40-1d4b-4d37-a24a-9996d90c99c9","domain":"Performant","question":"You want to contact AWS Technical Support regarding ensuring enough capacity to autoscale for busy periods.  You remember that you have a Basic Support plan. Which of the following case types can you open with this support plan?","explanation":"There are three types of AWS Support cases you can open; they are Account and Billing Support, Service Limit Increase, and Technical Support. Customer Service does not exist as a case type, which eliminates 'Customer Service'. With the Basic plan, you can open either an Account and Billing Support or a Service Limit Increase case. To open a Technical Support case, you will need to get a Developer, Business, or Enterprise plan. So, 'Technical Support' is the wrong response; 'Account and Billing Support' and 'Service Limit Increase' are correct.","links":[{"url":"https://docs.aws.amazon.com/awssupport/latest/user/getting-started.html","title":"Features of AWS Support Plans"}],"answers":[{"id":"d5552e0564007d93ff5937a9cb3bc491","text":"Customer Service","correct":false},{"id":"fec5f90e9985e1f7b8cc6752739ce9b1","text":"Technical Support","correct":false},{"id":"d073dd2e04eae29e3dd076f213f01fe3","text":"Service Limit Increase","correct":true},{"id":"88d14dddd26c18290989cf3ac6ef6141","text":"Account and Billing Support","correct":true}]},{"id":"73e59bc1-e406-4646-ad2e-d3765a06eb8d","domain":"ResilientDesign","question":"You recently set up a website for customers to access over the Internet, but upon navigating to the URL, you keep getting a 'Connection timed out' error message. Which of the following answers will solve the problem?","explanation":"If you get a 'Connection timed out' error message when navigating to your website, you have to check the security group rules. You need rules that allow inbound and outbound traffic from the website’s address on the proper ports. In this case, since customers need to connect from the Internet, you will have to set inbound and outbound rules in the security group for an HTTP connection, which is through port 80. The Network Access Control List (NACLs) must also allow traffic to come in on port-80 and return back out on the ephemeral web ports. Enabling keepalives is for resolving the 'Server unexpectedly closed network connection' error, not 'Connection timed out'. Domain health checks is not a valid answer, since there’s no option to 'refresh' health checks.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide//TroubleshootingInstancesConnecting.html#TroubleshootingInstancesConnectionTimeout","title":"Troubleshooting Connecting to Your Instance"}],"answers":[{"id":"cafdf1a54332e17122cd6a3a8c9512ed","text":"The website domain’s health check is refreshed to generate a Healthy status.","correct":false},{"id":"1e05bb57b03ee35bd2b53b676eb09c48","text":"The inbound and outbound rules in the network access control list (network ACL) are edited to support a HTTP connection.","correct":true},{"id":"f33e790919aaac8f859da3bf62875772","text":"The inbound and outbound rules in the security group are edited to include an HTTP connection.","correct":true},{"id":"767754962f6fa24f143c1e223735ba12","text":"Keepalives is enabled.","correct":false}]},{"id":"62f8b91f-134a-4b12-85c0-a098fcb1a517","domain":"ResilientDesign","question":"Which of the following events would cause Amazon RDS to initiate a failover to the standby replica?","explanation":"The events would cause Amazon RDS to initiate a failover to the standby replica would be: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, Storage failure on primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"RFS High Availability"}],"answers":[{"id":"eb2fca77d143f8a2bf2c7a32db536671","text":"Loss of availability in the primary Availability Zone","correct":true},{"id":"545c9bfa770559efbeb1abda0d9c4077","text":"Complete failure of the primary instance","correct":true},{"id":"abad0c6f8f62519ab90e3756d116fc12","text":"Storage failure on the standby replica","correct":false},{"id":"0e11e486b98184268711d1c093bf5f68","text":"Loss of network connectivity to the primary instance","correct":true}]},{"id":"2466b024-1f81-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"You work as a website administrator at a real estate developer. The company’s website uses S3 to store pictures of the single-family homes it builds. The company recently released a brand-new elevation for one of its most popular models, which is called 'Greenberry C.' So far, there’s only one picture of the 'Greenberry C', so you want to ensure that it is not accidentally deleted by enabling the object lock feature. Which of the following actions will accomplish that?","explanation":"Amazon S3 object lock prevents an object from being deleted or overwritten. Object lock is enabled at the bucket level; when creating the bucket, you can select the feature to lock objects in it. However, once the bucket has been created, you cannot enable object lock, you will have to contact customer support to do so. Right-click is not a valid option - you must select the object then go to Properties, Object lock.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/object-lock.html","title":"How Do I Lock an Amazon S3 Bucket?"}],"answers":[{"id":"a92ccdd56e18b47fbb5d18c2c342ca6f","text":"Right-click the picture and choose the object lock option.","correct":false},{"id":"2c6b543047434bd3ad31060693bc8e5b","text":"Enable object lock at the object level.","correct":false},{"id":"49cd0706698c83f66fe5b9deb203a420","text":"Contact customer support.","correct":true},{"id":"84bd7d36c453cdfc1f04955deb54c376","text":"Enable object lock at the bucket level.","correct":true}]},{"id":"61549fca-bf43-4de6-a057-4539abb557f5","domain":"Performant","question":"Your business is evaluating several database technologies from AWS. It is expected that you will need to scale out the performance for read operations using read replicas. The business has decided to reduce management overheads as much as possible by using RDS for the database. Which of the following RDS Database engines would NOT be suitable in this scenario?","explanation":"MS SQL Server does not support Read Replicas when using RDS. MySQL, PostgreSQL, MariaDB and Aurora support Read Replicas to improve performance for Read Heavy applications.","links":[{"url":"https://aws.amazon.com/rds/details/read-replicas","title":"Amazon RDS Read Replicas"}],"answers":[{"id":"7f9733e208088b1ce6df3d4be1765396","text":"MariaDB","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"d2727816fa1087ddac7dff69e35c5536","text":"MS SQL","correct":true},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false}]},{"id":"c31b1522-5ef4-4e45-9847-53598677ae68","domain":"Performant","question":"What is the availability of S3 - IA?","explanation":"S3 - IA is 99.9% available. Do not confuse availability with durability.","links":[{"url":"https://aws.amazon.com/s3/faqs/#How_reliable_is_Amazon_S3","title":"S3 Availability"}],"answers":[{"id":"ebb51b0b7e8f1fcf89ef483709bd61c6","text":"99.9%","correct":true},{"id":"91009c0d8d2ec85d07a48cb81bfcfb0d","text":"99%","correct":false},{"id":"78262a35fc5fdefbb7740ac7102b8cc4","text":"99.999999999%","correct":false},{"id":"19fb9916968211db983d13bffe0cc6af","text":"99.99%","correct":false}]},{"id":"70c6a808-0d5d-40d3-9b62-aa2fd031a543","domain":"CostOptimized","question":"You have three AWS payer accounts consolidated under an AWS Organization . Which of the below statements is TRUE for purposes of volume discounts?","explanation":"If you have multiple accounts, your charges will decrease because AWS combines usage from all accounts in the organization to qualify you for volume pricing discounts.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html","title":"Consolidated Billing for Organizations"}],"answers":[{"id":"c9c2416d95c8112070b7a5b032629fdf","text":"Usage in each account will be evaluated individually to determine the volume discount it is individually entitled to","correct":false},{"id":"4fb1af36b069dca73268eedbfab53e7b","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled at the Organisation level","correct":false},{"id":"98e718508cd32b9ffb27d8648e9129d0","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to","correct":true},{"id":"a6cd99e8b1bbcfc82e184acc9f28eede","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled in each account","correct":false}]},{"id":"7ff46f0c-2e05-11ea-8a91-2e728ce88125","domain":"Performant","question":"You wish to exclusively use AWS services to buy a domain name and create a static website. Which of the following combinations will enable you to do so?","explanation":"You use Route 53 to register your domain and configure it so that Internet traffic is routed to your designated target. The target can be Amazon S3, where you can create a bucket, upload the HTML file that will function as the static website, configure the permissions for everyone to see the content, and configure the bucket for website hosting. Route 53 is missing from the other three choices; this omission makes these responses wrong.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html#root-domain-walkthrough-update-ns-record","title":"Setting Up a Static Website Using a Custom Domain"}],"answers":[{"id":"c3794257c21696f8d06348f26e2b81a9","text":"Amazon Lambda and Elastic File Service (EFS)","correct":false},{"id":"8399383b83ea44cd15f0f7f7f8d1fe6b","text":"Amazon API Gateway and Elastic Compute Cloud (EC2)","correct":false},{"id":"a119836cf024ddc24285f609454cf7bf","text":"Amazon Route 53 and Simple Storage Service (S3)","correct":true},{"id":"28968cd50e98048b344f0d7bd4fd54e6","text":"Amazon Virtual Private Cloud (VPC) and Relational Database Service (RDS)","correct":false}]},{"id":"c9683e3d-8753-425f-b254-6b05a82fe770","domain":"ResilientDesign","question":"Your company has a web application which runs on multiple on-premise Linux virtual machines, which needs to be migrated to AWS. The application relies on shared configuration files, currently hosted on an on-premise File Server, which are read each time the application handles a request. Any updates to the configuration files must be applied immediately. What would the most suitable solution be to store the configuration files?","explanation":"Amazon EFS is recommended here, since we are sharing a file between multiple Linux instances. Amazon S3 could be possible, but considering the requirements for immediate responses to configuration updates, the read-after-write consistency model of EFS is superior to the eventual consistency model of S3. Migrating the existing file server is possible, but excessive given the other options available, and would incur more costs than you would need. AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources, but does not have Configuration Management components as described in the scenario","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html","title":"EFS: How It Works"}],"answers":[{"id":"b77f0c550141c38ee398bb165b90ce6f","text":"Amazon S3 - Host the configuration file in an S3 bucket which can be read by the instances","correct":false},{"id":"f4933c135fea3fe19b79cc67ae011b12","text":"Amazon Elastic File System - Create an EFS Filesystem and mount to your instances","correct":true},{"id":"847f6bf6f9e24beea40dda8e7085bbaf","text":"AWS Config - Host the configuration files in AWS Config which can then be read by the instance","correct":false},{"id":"2e611648f7e940d657fd27711a55645b","text":"Amazon EC2 - Migrate the File Server to EC2 as well, keeping it as it is on-premise","correct":false}]},{"id":"5fac4bb4-d450-440d-bc31-62fd409b5bee","domain":"ResilientDesign","question":"A company has an LNMP (Linux, Nginx, MySQL, PHP) stack application deployed to AWS. The availability requirements for their backend database specify automatic failover in case of disaster recovery. What is the optimal solution that meets this requirement?","explanation":"Since the scenario calls for MySQL, we must choose a relational database for the backend database. This means that DynamoDB is not a correct option. With RDS Multi-AZ deployment, a primary DB instance is automatically and synchronously replicated to a secondary RDS instance in a different availability zone (AZ). In case of a disaster causing primary instance failure, RDS performs automatic failover to the secondary standby RDS instance. During the failover, the database endpoint remains the same. RDS Read-Replica provide secondary RDS instances that are asynchronous replicated from the primary. RDS read-replicas have different endpoints and do not provide automatic failover. Additionally, they only provide read (not write) operations. It is possible to use Route53 with Health-check and DNS failover configurations to route traffic to multiple RDS instances. However, this solution does not provide automatic data synchronization between instances.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"High Availability (Multi-AZ) for Amazon RDS"}],"answers":[{"id":"23f694af0e449b15b6fb26401d12eb0e","text":"DynamoDB with Global Tables deployment.","correct":false},{"id":"8a8d90b530fbd9c90820ca63425401b5","text":"Deploy multiple RDS instances. Use Route53 with Health-Check and DNS failover configured.","correct":false},{"id":"f38116f4410ef57b5ffc6e17d11b1721","text":"RDS with Multi-AZ deployment.","correct":true},{"id":"9e445d25eaf3cc7b2f2412dbf19e6e4b","text":"RDS with Read-Replica deployment.","correct":false}]},{"id":"7589448c-e00c-4c64-9d5f-04e10ac556e4","domain":"CostOptimized","question":"An enterprise is planning to move its on-premise application to AWS cloud. The enterprise planned to build the non-production applications first as a proof of concept, and the governance team has provided approval for downtime for a brief period if cost can be compensated. You recommend spot instances as this satisfies the scenario explained above. Do vCPU limits apply when requesting a spot instance?","explanation":"Amazon EC2 is transitioning on-demand instance limits from the current instance count-based limits to vCPU-based limits to simplify the limit management experience for AWS customers. Beginning September 24, 2019, customers can opt in to vCPU-based instance limits. Count-based instance limits will not be available or supported after November 8, 2019. The vCPU-based limits only apply to running on-demand instances and does not apply when purchasing reserved or spot instances.","links":[{"url":"https://aws.amazon.com/ec2/faqs/","title":"Amazon EC2 compute service features"}],"answers":[{"id":"a4fb94942aaa43d251b18a4126ce6d18","text":"In AWS, only instance count based limits exist and there is no concept of vCPU limits.","correct":false},{"id":"1fe04947ca4403eb3588fb87310de29e","text":"vCPU limits apply to reserved instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false},{"id":"34394b797e4a477511982b1ac4a38d19","text":"vCPU limits apply only to on-demand instances and do not apply for spot instances.","correct":true},{"id":"9bfb4cfa201ec7e2242c7df2c0d39906","text":"vCPU limits apply to spot instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false}]},{"id":"cdb5b6d9-37bb-41e5-bd69-985dabcc7bd0","domain":"SecureSolutions","question":"You are hosting a web application that runs on a number of Web Servers in public subnets and Database Servers in private subnets. A NAT Instance is being used for connectivity to the internet for the Private Subnets. The NAT Instance is now becoming a bottleneck, and you are looking to replace it with NAT Gateway. Which of the following would ensure high availability for the NAT Gateway?","explanation":"If you have resources in multiple Availability Zones and they share one NAT gateway, in the event that the NAT gateway’s Availability Zone is down, resources in the other Availability Zones lose internet access. To create an Availability Zone-independent architecture, create a NAT gateway in each Availability Zone and configure your routing to ensure that resources use the NAT gateway in the same Availability Zone.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","title":"NAT Gateways"}],"answers":[{"id":"8956081d09cf7a5203cbb2fe0a9cbd9e","text":"Deploy a NAT Gateway along with the NAT Instance","correct":false},{"id":"5ae78abee9f8fe1afe2ab443a4480098","text":"Disable source/destination check on the NAT Instances","correct":false},{"id":"b0b35801e71ae33d446780112d8438dc","text":"Deploy a NAT Gateway in 2 Availability Zones","correct":true},{"id":"18c2392152bcb34e4f0933dfcff0de2b","text":"Deploy a NAT Gateway in 2 Regions","correct":false}]},{"id":"955a81c8-335f-4c4c-9841-5092fb517bba","domain":"ResilientDesign","question":"A team is migrating a three-tier web application to AWS.  Currently the application runs from a single server which stores session information about user transactions.  As part of migration the team wants to take advantage of the High Availability that AWS provides by deploying on to simple low specification ec2 instances across multiple Availability Zones.  The team is aware that the application might provide an inconsistent experience if users are load-balanced between servers storing different state information.  Which options may allow you to move the application into AWS with minimal additional delay?","explanation":"The best answer here is to use sticky sessions on the ELB. This will route requests from a user to the same server every time, ensuring their session details are preserved.  Route 53 weighted or multi-value routing will not ensure routing to the same server each time. It is possible to share certain types of EBS volumes across ec2 instances, however they cannot be across AZs, and the EBS types would not fall into the description 'simple low specification'.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-target-groups.html#sticky-sessions","title":"Sticky Sessions"},{"url":"https://aws.amazon.com/blogs/aws/new-multi-attach-for-provisioned-iops-io1-amazon-ebs-volumes/","title":"Multi-Attach for Amazon EBS Volumes"}],"answers":[{"id":"f159b6f5434eb8067673b979c8b8bea6","text":"Deploy the application to two EC2 instances and enable sticky sessions on the Elastic Load Balancer","correct":true},{"id":"6f54375e0f74acb0a1a330c3bc2ec01a","text":"Deploy the application to two EC2 instances and use Route 53 to perform weighted routing of users to the same server each time","correct":false},{"id":"5617928a445d24401162686f8b7c099d","text":"Deploy the application to two EC2 instances and use Route 53 multi-value routing to send users to the same server each time","correct":false},{"id":"f6d1002ac85996490667b2b8fee9586d","text":"Deploy the application to two EC2 instances with shared EBS storage to share the session details between instances","correct":false}]},{"id":"d0946223-5972-4d84-b34d-e2529e3fc7e1","domain":"Performant","question":"You have a set of read only data on an EBS st1 volume which needs to be referenced by all the EC2 instances in an autoscaling groups.  Which of these are valid options ?","explanation":"Not all types of EBS volumes can be mounted to more than one instance at a time.  However Snapshots can be used to create copies. The better option would probably be EFS.  Storing the data set on S3 would also work, however the CLI script offered is not valid as the source and destination are reversed.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html#EBSFeatures","title":"EBS Volumes: Data Availability"},{"url":"https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html","title":"AWS S3 CLI cp"},{"url":"https://aws.amazon.com/blogs/aws/new-multi-attach-for-provisioned-iops-io1-amazon-ebs-volumes/","title":"Multi-Attach for Amazon EBS Volumes"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-restoring-volume.html","title":"Restore and mount a snapshot"}],"answers":[{"id":"db01b924625278a0a9fe4b1627595467","text":"Create a copy of the data set in an S3 bucket from time to time. Then use the script 'aws S3 cp <LocalPath> <S3Uri> --recursive' to copy the files onto the EC2 instances as they are brought on-line by autoscaling.","correct":false},{"id":"07edfbbebc085c363f396930d13af41c","text":"Mount the EBS volume to all the EC2 instances using 'Multi-Attach for EBS'.","correct":false},{"id":"2868667ad6244fef7d80dcf63a2ecf56","text":"Create an EFS volume and migrate the data to the EFS instance.  Then mount the EFS volume to the EC2 instances as they are brought on-line by autoscaling.","correct":true},{"id":"0f813c39a0b5e5a3c85eb5f9c6fa147f","text":"Create the a Snapshot of the Master copy at regular intervals.  Then restore and mount the latest snapshot to the EC2 instances as they are brought on-line by autoscaling.","correct":true}]},{"id":"04a5e1e1-9fc6-4371-a53c-cecc6fad3b2a","domain":"ResilientDesign","question":"Elasticity is a fundamental property of the cloud. Which of the following best describes elasticity?","explanation":"In cloud computing, elasticity is defined as 'the degree to which a system is able to adapt to workload changes by provisioning and de-provisioning resources in an autonomic manner, such that at each point in time the available resources match the current demand as closely as possible'.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html","title":"Scalable Computing Capacity"}],"answers":[{"id":"80b90762201e3ac35c7921416cc86c81","text":"The power to increase the number of resources at your hands at the click of a mouse.","correct":false},{"id":"2d60e660232553b4fb11100329fdb97e","text":"The power to scale resources both up and down with changes in demand.","correct":true},{"id":"71babaf2f5ed118cdbb0f5ff115354ce","text":"The ability to deploy managed services into your environment.","correct":false},{"id":"9b1cc2503b70776f795a2155b7f2e380","text":"The ability to manually deploy instances quickly in response to events.","correct":false}]},{"id":"ac8f79d2-72d6-4dcb-84c7-2ec0b61e48ca","domain":"Performant","question":"Power plant technicians at an electrical utility need to monitor equipment heat readings in real-time on their mobile devices. They would like to be able to see changing temperature values without refreshing the device's screen. Temperature sensors have already been installed on the equipment, and they've connected the sensors to AWS IoT Core. A mobile app has been developed in React Native to receive the temperature updates. An additional twenty percent more equipment will be installed at the plant over the next year. Which architecture will provide the most scalable solution for the utility?","explanation":"An AWS AppSync GraphQL update mutation will update a sensor's record in DynamoDB and broadcast updated data to mobile device clients. A Lambda function can initiate a connection to an AppSync GraphQL API endpoint. Each component of this architecture is a managed service that will scale with the power plant's growth plans. AWS Mobile Hub is used for building mobile applications, not for broadcasting messages to mobile devices. DynamoDB and Mobile Hub are not valid consumers of a Kinesis Data Streams stream. Amazon Pinpoint is used to send personalized communications, not forward data updates to mobile devices.","links":[{"url":"https://aws.amazon.com/appsync/","title":"AWS AppSync"},{"url":"https://aws.amazon.com/blogs/mobile/iot-with-aws-appsync/","title":"Monitoring IoT devices in real time with AWS AppSync"}],"answers":[{"id":"436ea268a30690aa25516a2df81f12f6","text":"Create an AWS IoT rule to forward messages to an Amazon Simple Queue Service queue. Have an EC2 instance read the queue and write the messages to DynamoDB, and forward the data to Amazon Pinpoint to broadcast the changed data to mobile device users.","correct":false},{"id":"fe256ea9199399aa63a19f558746acda","text":"Implement an AWS IoT rule to forward messages to a Lambda function. Have the Lambda function execute an AWS AppSync GraphQL mutation to write updates to Amazon DynamoDB and broadcast changed data to mobile device users.","correct":true},{"id":"f3d62c495d620412d9f919ff6f58fafc","text":"Have an AWS IoT rule forward messages to an Amazon Kinesis Data Streams stream. Create one consumer of the stream to be Amazon DynamoDB. Create a second consumer of the stream to be AWS Mobile Hub, which broadcasts the changed data to mobile device users.","correct":false},{"id":"0fea673c8089e1f7d3a591bdaa3af824","text":"Configure an AWS IoT rule to forward messages to a Lambda function. Have the Lambda function write the messages to DynamoDB, and to AWS Mobile Hub, which broadcasts the changed data to mobile device users.","correct":false}]},{"id":"18f5f9ac-72ae-44e6-a607-875acd4b7508","domain":"CostOptimized","question":"Your company is moving their entire 20 TB data warehouse to the cloud. With your current bandwidth, it would take 2 months to transfer the data. Which service would you use to quickly get your data into AWS?","explanation":"At that amount of data and those bandwidth restrictions, Snowball would be the most expedient choice.","links":[{"url":"https://aws.amazon.com/snowball/faqs/#when-to-use","title":"When to Use Snowball"}],"answers":[{"id":"c0429b6a658dd488f7262d983c7e02bb","text":"Snowball","correct":true},{"id":"cdd0d04de2b79c78e792aec6263d2d3d","text":"DirectConnect","correct":false},{"id":"a8e1dc43989241e706e31c52d23be15c","text":"S3 with Transfer Acceleration","correct":false},{"id":"25e163616bb5cc20c769ad3e8b7a0703","text":"Multipart Upload","correct":false}]},{"id":"f3e923a2-2e1a-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You want to track the amount of money you ideally want your company to spend for EC2 data transfers every month. Which of the following actions will accomplish that?","explanation":"AWS Cost Explorer is for providing information that you can use to track and manage costs, but it doesn’t enable the creation of budgets; that’s what AWS Budgets is for. If the question was strictly addressing cost, then creating a Cost budget with AWS Budgets would have been the correct answer. However, your concern is specifically with a usage type, which is EC2 data transfers. In this case, you would need to create a Usage budget with AWS Budgets and receive alerts when your defined threshold is met.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/budgets-managing-costs.html","title":"Managing Your Costs with Budgets"}],"answers":[{"id":"8d35bf16b7d263f4ab864e392d023e54","text":"Enable AWS Cost Explorer","correct":false},{"id":"e7f799a3bc73b229cd75d773a9d7f547","text":"Create a Usage budget with AWS Budgets.","correct":true},{"id":"41e006394cc745a90a25e57065b658c2","text":"Create a Cost budget with AWS Budgets.","correct":false},{"id":"4407cc58412e1c4727ad336bd8b8453f","text":"Create a Reservation budget with AWS Budgets.","correct":false}]},{"id":"da330db7-b053-45f5-99ab-ba3fa6fefb22","domain":"ResilientDesign","question":"You have a customer hosting their website on a cluster of web servers behind a internet facing load balancer. The web application interfaces with an RDS database. The management team has specified that the database service continue to function even in the event of failures on the primary database server. A secondary database needs to be available as quickly as possible. Which would provide that capability best?","explanation":"When you provision a Multi-AZ RDB Instance, AWS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ). Each AZ runs on its own physical infrastructure. In case of an infrastructure failure, AWS performs an automatic failover to the standby instance, so that you can resume database operations as soon as the failover is complete. Because the endpoint name for your DB Instance does not change, your application can resume database operation without the need for manual administrative intervention.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"Amazon RDS Multi-AZ Deployments"}],"answers":[{"id":"2520d830ba8afd37bebfd5a5f2aea3e5","text":"Create a read replica.","correct":false},{"id":"f4c140fff2bdaf5b2d5c81e729ad5d38","text":"Take a snapshot fo the database and stand up from that.","correct":false},{"id":"1de75de6e5a786fa36d2d0ef78720eb8","text":"Increase the RDS instance size.","correct":false},{"id":"be734592459b0bf2f17ea82bf9f6ea9f","text":"Create a Multi-AZ database.","correct":true}]},{"id":"daf1ffcc-1a26-4960-bd6f-750b4de8609c","domain":"SecureSolutions","question":"You want to encrypt the data in your S3 buckets. You intend on managing the encryption keys and using Amazon S3 to manage the encryption itself. Which of the following S3 encryption types support your requirements?","explanation":"Although Response A is correct in a general sense, the question is asking for a specific type of server-side encryption. SSE-C is what you need if you want to manage the encryption keys and have Amazon manage the encryption. Both SSE-S3 and SSE-KMS support the management of keys, which does not match the requirements of this application.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Server-Side Encryption"}],"answers":[{"id":"a8d0fb2ecae10336e81eec65375a4abe","text":"Server-Side Encryption","correct":false},{"id":"9b7e6d7280803d9f9a6072b4421611fc","text":"Server-Side Encryption with Customer-Provided Keys (SSE-C)","correct":true},{"id":"c76bcbd057118544ba0ccb76a8a22e46","text":"Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)","correct":false},{"id":"772996341baeebbfac39d70e8ed5a300","text":"Server-Side Encryption with AWS Key Management Service (SSE-KMS)","correct":false}]},{"id":"95ab1573-ff07-4e33-a7f9-2847945bda35","domain":"SecureSolutions","question":"Your company requires that all the data on your EBS-backed volumes for your EC2 instances be encrypted. How would you achieve this?","explanation":"Encryption is supported by all EBS volume types. You can expect the same IOPS performance on encrypted volumes as on unencrypted volumes, with a minimal effect on latency. You can access encrypted volumes the same way that you access unencrypted volumes. Encryption and decryption are handled transparently, and they require no additional action from you or your applications.You can configure your AWS account to enforce the encryption of the new EBS volumes and snapshot copies that you create. For example, Amazon EBS encrypts the EBS volumes created when you launch an instance and the snapshots that you copy from an unencrypted snapshot.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html","title":"EBS Encryption"},{"url":"https://aws.amazon.com/blogs/aws/new-encrypted-ebs-boot-volumes/","title":"EBS Encryption Boot Volumes"}],"answers":[{"id":"9e54463e6b60221114b73938f3d298f1","text":"Encryption is totally handled at the OS layer.","correct":false},{"id":"f49d586546b0e4a094812ec3492c6940","text":"You can configure encryption via KMS passthrough","correct":false},{"id":"8266443c60747acae9efd389e34e7e70","text":"AWS allows you to encrypt an EBS volume at the time of creation.","correct":true},{"id":"8c8e380abba308fa34145575f2e6f910","text":"You can toggle on EBS encryption post creation.","correct":false}]},{"id":"6f99dc29-9e5a-4d5c-9152-c4e9d5e2325c","domain":"SecureSolutions","question":"When making use of EC2 instances on Dedicated Hosting, which of the following modes are you able to transition between by stopping the instance and starting it again?","explanation":"The tenancy of an instance can only be change between variants of 'dedicated' tenancy hosting. It cannot be changed from or to default tenancy hosting.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-instance.html","title":"About Dedicated Instances and Tenancy"}],"answers":[{"id":"d31d964b101ff444e700016740c91a5e","text":"Default & Dedicated","correct":false},{"id":"d15424a6445328926f6ca57c29e143ca","text":"Host & Dedicated","correct":true},{"id":"aa095ba3b4f590c56ebe3dd7632cf1d4","text":"Host & Default","correct":false},{"id":"04459d2ad5ea321a35a184d5db44d7ec","text":"Dedicated & Host","correct":true}]},{"id":"096baab8-06c7-4b07-8e86-ba304b41102f","domain":"CostOptimized","question":"After migrating an application architecture from on-premise to AWS, you will not be responsible for the ongoing maintenance of which two of the following services.","explanation":"DynamoDB and Amazon RDS are managed services. As such, AWS handles the ongoing maintenance.","links":[{"url":"https://aws.amazon.com/rds/details/","title":"About RDS"},{"url":"https://aws.amazon.com/dynamodb/details/","title":"About DynamoDB"}],"answers":[{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true}]},{"id":"8d478f70-2e57-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"Your company wants the on-premises network of its nearby branch office to securely connect with the instances launched into the Amazon virtual private cloud (VPC) environment of its headquarters. Which of the following proposed solutions is the correct one?","explanation":"To establish a secure connection between the company’s branch office and the Amazon VPC of its headquarters, you will need to create a site-to-site VPN. This process includes creating a customer gateway for the branch office and a virtual private gateway for the headquarters, so responses A and C only provide part of the answer. Although you can establish a connection with AWS Direct Connect, the connection depends on the headquarters being a Direct Connect location for it to work.","links":[{"url":"https://docs.aws.amazon.com/vpn/latest/s2svpn/how_it_works.html","title":"What is AWS Site-to-Site VPN?"}],"answers":[{"id":"572a700c620a728ee9f12b0d7d4601fc","text":"Use AWS Direct Connect to create a connection.","correct":false},{"id":"1c83b0f1e61bd1a6e279dfd7f53aa406","text":"Create an AWS site-to-site VPN connection","correct":true},{"id":"6fc0482bf91e864524eeb8b99b8b1df9","text":"Create a virtual private gateway and a customer gateway and attach them to the headquarters VPC and the branch office on-premises network, respectively.","correct":false},{"id":"db905221240144105178d58376e68624","text":"Create a virtual private gateway and attach it to the headquarters VPC.","correct":false}]},{"id":"1ea8aa1e-9454-49b0-b4e2-379eadf674e0","domain":"CostOptimized","question":"You are an employee at a communications firm that is in the process of migrating its data to Amazon S3. The data will be stored in buckets and is sent to customers to do as they see fit. However, certain data is frequently changed when customers request revisions, while the rest of the data is rarely changed. You must be able to immediately access certain data while minimizing costs. Which S3 storage class should you choose?","explanation":"While S3 Glacier is a low-cost storage class, it is for data archiving and thus not ideal for frequent access or changes to data. And S3 One Zone-Infrequent Access is also low-cost, but it does not address the frequently changed data. Although S3 Standard is a suitable choice, since it addresses frequent access, it is not the least expensive choice for the less frequently accessed data. If it was hard to determine which data is frequently changed and which isn’t, S3 Standard might have been the most cost-effective choice. But in this case, S3 Intelligent Tiering is. Intelligent Tiering stores data in two access tiers: one tier is optimized for frequently accessed data while the other is a lower-cost tier for infrequent access.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"5605213ade8877d8d601580dbd0a8aa2","text":"S3 One Zone-Infrequent Access","correct":false},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":true},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false}]},{"id":"7bcf3cb7-6154-4148-96ca-7e9ff7c16f27","domain":"ResilientDesign","question":"Your company is a heavy user of CloudFormation to deploy standard websites using WordPress for Media, PR and Marketing clients. As your company grows you are repeating the same load balancer configuration for most of your stacks. Currently you are manually copying and pasting the same configurations from one template to another. You want to reduce the administrative overhead in deploying CloudFormation templates. What options are there to achieve this?","explanation":"Breaking large complex builds into sections gives you the advantage of being able to reuse common templates patterns with a known and proven configuration, plus being able to share responsibility to SME for their portion of the architecture.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html","title":"CloudFormation - Nested Stacks"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks.html","title":"CloudFormation - Stacks Updates"}],"answers":[{"id":"8511646bc9edf9631791dd72182f9c76","text":"Use AWS lambda to automatically deploy the load balancer once your CloudFormation Template has finished provisioning.","correct":false},{"id":"d605a2578632e3bf9fe88e8b645c335f","text":"Reference the template as part of a nested stack.","correct":true},{"id":"b8291da95d71714b3f5314572a6d5e47","text":"Create a dedicated template for the load balancer.","correct":true},{"id":"57bd133b2237789f413b1486e2bac4a5","text":"Create an Elastic Beanstalk Deployment stack.","correct":false}]},{"id":"0fa75b94-0aac-40ea-b312-cd38e8015b3c","domain":"SecureSolutions","question":"You need to add a route to your routing table that will allow connections to the internet from your subnet. Which of the following routes should you add?","explanation":"When setting a Custom Route Table, the destination should be 0.0.0.0/0, and the target should be the Internet gateway.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#CustomRouteTables","title":"Custom Route Tables"}],"answers":[{"id":"899b7e9080653ebca0ce71d40bec7471","text":"Destination: 0.0.0.0/0 --> Target: 0.0.0.0/24","correct":false},{"id":"c60df6d18e83ca3ad6180d0c6cbb3859","text":"Destination: 192.168.1.258/0 --> Target: your Internet gateway","correct":false},{"id":"a09fb8c63b2f9ad6d6cc5d6fa022a702","text":"Destination: 0.0.0.0/0 --> Target: your Internet gateway","correct":true},{"id":"0bd386dbb40d5a1d0a565535fd77209e","text":"Destination: 0.0.0.0/33 --> Target: your virtual private gateway","correct":false}]},{"id":"9e8fac4c-6095-468a-bc93-9a274047c7ad","domain":"SecureSolutions","question":"Your mobile app needs to have images uploaded to S3. You want to bypass the existing web server for the uploads to avoid increasing load on the server. How can this be accomplished?","explanation":"All objects and buckets by default are private. The pre-signed URLs are useful if you want your user/customer to be able to upload a specific object to your bucket, but you don't require them to have AWS security credentials or permissions.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/PresignedUrlUploadObject.html","title":"Uploading Objects Using Pre-signed URLs"}],"answers":[{"id":"8bf8469577529a39055c2f1b9a301286","text":"Upload the images to SQS and then push them to the S3 bucket.","correct":false},{"id":"83e87dae98de34e44fb616d962301f0d","text":"Create a second S3 bucket and use Lambda to sync the files to the primary bucket.","correct":false},{"id":"1768d724dcf884a855c2889522437fa6","text":"Use Pre-Signed URLs to upload the images.","correct":true},{"id":"5f088b72412d6935807479e2840f0b16","text":"Use ECS Containers to upload the images.","correct":false}]},{"id":"95089332-27f7-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"A company is open from 6 a.m. to 6 p.m. EST, with core business hours specified between 9 a.m. to 3 p.m. EST. It needs an AWS Support plan that provides email access to Cloud Support Associates during core business hours. Which of the following support plans would be most suitable?","explanation":"Although Business and Enterprise Support plans include email access to the AWS Support team, the company specifically expressed interest in business-hours email support from Cloud Support Associates. The Developer Support plan fulfils this need, and it is ultimately more cost-effective than either the Business or Enterprise option.","links":[{"url":"https://aws.amazon.com/premiumsupport/plans/","title":"AWS Support Plans"}],"answers":[{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":false},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":true},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":false}]},{"id":"4053d5c2-356f-4851-a9af-540b7131076d","domain":"SecureSolutions","question":"You have just started creating a new AWS environment for your organisation to use. Architecturally, this environment consists of 2 VPCs which are peered (VPC A and VPC B), plus some EC2 instances in each VPC. These instances are residing in the private subnet of each VPC and do not have an EIP or public IP attached. The EC2 instances can communicate with each other across the VPCs, however you realise that you have forgotten to deploy the required infrastructure to allow the instances to download updates from the internet. Which of the following would be the most cost effective method for enabling downloads from the internet?","explanation":"There are several elements to this question, so the easiest way to approach it is tackle them one by one. Straight away, two of the options can be eliminated - as the instances are on private IPs, any solution that doesn't include a NAT Gateway will not work. The choice between the two remaining options boils down to whether or not the NAT & Internet Gateway can be shared between two VPCs - to which the answer is no. VPC Peering does not support transitive peering (where traffic \"passes through\" the peered VPC on its way to its final destination). This leaves the correct answer as deploying 2 x IGWs, 2 x NGWs and having the instances use the NGW in the same VPC as them. Out of all the solutions listed it may be the most expensive, but it is the only one that will work.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html#nat-%20gateway-basics","title":"NAT Gateway Basics"}],"answers":[{"id":"cff5aae8f4630fbe7325c4dfed52b427","text":"Setup an Internet Gateway in VPC A, and route internet-bound traffic from the instances in both VPCs to the Internet Gateway in VPC A","correct":false},{"id":"b8fb1ee1585a8be8a92cfdc46ede67f5","text":"Setup an Internet Gateway in each VPC, and route internet-bound traffic from the instances to the Internet Gateway in the same VPC","correct":false},{"id":"dbd0ade9a841a5d0baa2108b3ff1fdfb","text":"Setup an Internet Gateway in VPC A, as well as a NAT Gateway in VPC A. Route the internet-bound traffic from instances in VPC A to the NAT Gateway in VPC A, and route the internet-bound traffic from instances in VPC B to the NAT Gateway in VPC A","correct":false},{"id":"71d4b3e59f026b6bfdf37a7cc5a8d8a2","text":"Setup an Internet Gateway in each VPC, then deploy a NAT Gateway in each VPC, routing traffic to the Internet Gateway contained in the same VPC. Internet-bound traffic from instances in each VPC to be routed to the NAT instance in the same VPC","correct":true}]},{"id":"db72323e-0c43-4542-9f6b-cd6136b5dcd8","domain":"ResilientDesign","question":"You have a production website for a car insurance company running on AWS. One of the important KPI’s for the company is the number of users on the website at any given time and you have been asked to track this. The website runs on a fleet of EC2 instances behind an application load balancer. What is the simplest way to track this metric.","explanation":"Be clear in yor own mind about the difference between CloudWatch & CloudTrail. An ELB is a service, you cannot install anything onto an ELB.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-cloudwatch-metrics.html","title":"CloudWatch Metrics for your ALB"}],"answers":[{"id":"dd97365a376f41ec276427520159fbd4","text":"Install the CloudWatch agent on the Application Load Balancer. After the agent is installed, look for the “ActiveConnectionCount” in CloudWatch.","correct":false},{"id":"1056f30813bb025d216b87a2fdd790d9","text":"Enable CloudTrail in the region that your ALB is in. Using CloudTrail metrics look for the “ActiveConnectionCount” metric.","correct":false},{"id":"0ea85fc826488c41b0f86072ac7fd0ad","text":"Install the CloudTrail agent on the Application Load Balancer. In CloudTrail look for the “ActiveConnectionCount” metric.","correct":false},{"id":"98c71b3c230ff081ea967bf92fad4707","text":"In CloudWatch metrics look for the “ActiveConnectionCount”","correct":true}]},{"id":"da14a91d-ff38-4ee2-976e-87ab89ed2b57","domain":"Performant","question":"You are attempting to move data from one EBS volume to a duplicate volume in a separate region. Which of the following methods will do this best?","explanation":"After you've created a snapshot and it has finished copying to Amazon S3, you can copy it from one AWS region to another, or within the same region.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-copy-snapshot.html","title":"Copying an EBS Snapshot"}],"answers":[{"id":"f1ce9b0c80209553a22ede320d2ce91f","text":"Use a Linux tool like rsync to sync the volume to the other region.","correct":false},{"id":"7ed5cf49719e006c801d0e6fe0f4cf7e","text":"Allow a VPC peering connection to pull the data over.","correct":false},{"id":"2d58342b23166c9f5556bbe76440bd28","text":"Move the data to S3 and enable cross-region replication.","correct":false},{"id":"cf0d4fd3cb2d1497b6e5699ec4ee8ed5","text":"Take a snapshot of the EBS volume and copy it to the desired region.","correct":true}]},{"id":"61614ffb-1208-4742-9ff9-c8b316f13cc4","domain":"Performant","question":"When coding a routine to upload to S3, you have the option of using either single part upload or multipart upload. Identify all the possible reasons below to use Multipart upload.","explanation":"Multipart upload provides options for more robust file upload in addition to handling larger files than single part upload.","links":[{"url":"http://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html","title":"Uploading Objects Using Multipart Upload"}],"answers":[{"id":"fceeb753e12f0056c923fc9115be9472","text":"Multipart upload delivers quick recovery from network issues.","correct":true},{"id":"561cf9617064d07d28982fa0a4c4a5a3","text":"Multipart upload delivers improved security in transit.","correct":false},{"id":"d935110c327634d57b66601e6957ed42","text":"Multipart upload delivers improved throughput.","correct":true},{"id":"b2b49e9141fe4ce7eb0932d9c62a38b8","text":"Multipart upload delivers the ability to pause and resume object uploads.","correct":true},{"id":"df10e1b59a623a1543c4343ace225b87","text":"Multipart upload delivers the ability to append data into an open data file.","correct":false},{"id":"61f9f705b4dc688b86e0b25708cb7d88","text":"Multipart upload delivers the ability to begin an upload before you know the final object size.","correct":true}]},{"id":"86bc5815-e2a2-435d-b36a-de0291f03384","domain":"ResilientDesign","question":"A company disaster recovery policy requires that all RDS backups are retained in a secondary AWS region. What is the optimal solution to meet this requirement?","explanation":"RDS automated backups store backup data in the same region as the RDS instance. It is not possible to configure RDS automated backups to store data in a different region. The correct solution to meet the requirement is to copy RDS snapshots to the secondary region. It is not possible to copy RDS DB snapshots to an S3 bucket. Although it is possible to configure an RDS read-replica with automated backups in the secondary region, this is not an optimal solution as it involves additional costs associated with the running RDS instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html","title":"Working With Backups"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html","title":"Creating a DB Snapshot"}],"answers":[{"id":"6cb16d4a90eb4167d69dad6d62a4afa0","text":"Create an RDS DB snapshot. Copy the RDS DB snapshot to an S3 bucket. Enable Cross-Region replication on the S3 bucket.","correct":false},{"id":"1575bfe0f50108d320a7b04107a11d21","text":"Configure an RDS automated backups target region to the secondary region.","correct":false},{"id":"bc87f2bd894c0887220a36be79571629","text":"Create an RDS DB snapshot. Copy the RDS DB snapshot to the secondary region.","correct":true},{"id":"0ffef8639c8e9a75fa845bb6e9e6488b","text":"Configure RDS Read-Replica instance in the secondary region. Enable RDS automated backups on the read-replica instance.","correct":false}]},{"id":"065cc94c-c2aa-4473-a91b-da36edf81dd9","domain":"CostOptimized","question":"You are about to create an Amazon Elastic File Service (EFS) file system for your EC2 instances, and you don’t anticipate frequent access of its files. So, you decide to choose a lifecycle policy that will automatically move the files to the Infrequent Access (IA) storage class after a certain period of time. Which of the following options is the most cost-effective lifecycle management policy?","explanation":"When an EFS file system is created, it stays in the Standard storage class and you will be charged accordingly. By choosing a lifecycle management policy that automatically moves the file system to the IA storage class after a certain period of time since last accessed, you will be charged a significantly lower rate. So, the longer you have the file system in the Standard storage class, the more you will spend. That’s why 7 days since last access is the right answer; you would be charged Standard rates in just 7 days since last access, instead of 14 or 30 days. 'Move files to Infrequent Access Storage after 7 days' is not a valid lifecycle policy.","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html","title":"What Is Amazon Elastic File System?"}],"answers":[{"id":"32f28c9de44e4f47556341ce4e025177","text":"7 days since last access","correct":true},{"id":"535e339a0c1c98846e7c69391f7e1d69","text":"30 days since last access","correct":false},{"id":"525de4bc0ec90825ec4c5ed5e89d8308","text":"14 days since last access","correct":false},{"id":"20e40903e738930282c41b8a8e54d78e","text":"Move files to Infrequent Access Storage after 7 days","correct":false}]},{"id":"07689304-6bbb-46ce-ba91-08edaeee087a","domain":"ResilientDesign","question":"You are creating an RDS database for your production environment and it needs to be highly available and continue to function in the event of an outage to the Primary database. Which of the following options will best meet this requirement?","explanation":"Multi-AZ deployment involves the creation of a standby replica in a different Availability Zone (AZ) from the primary database. A standby replica cannot serve read traffic, it is used to synchronously replicate data from the primary database. AZs are isolated from one another to prevent failure from spreading to them all. So, if the location of the primary database has issues, Amazon RDS automatically fails over to the standby replica. Read replicas are used to scale out to cater for high volumes of read requests - not automated failover. Multi-region deployment is not a valid RDS option and Cross-region deployments enable support for scaling of Read replicas and can be used for cross-region DR, but don't support the automatic failover due to a Primary DB outage.","links":[{"url":" https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Concepts.RegionsAndAvailabilityZones.html","title":"Choosing the Regions and Availability Zones"}],"answers":[{"id":"9256e377c39a64274bd60ff4916a4cb9","text":"Multi-AZ deployment","correct":true},{"id":"794e9156bdd31164380a7005f8599e08","text":"Cross-region deployment","correct":false},{"id":"a9fa9ab64858fe533c9b65e9b8ba2fb9","text":"Multi-region deployment","correct":false},{"id":"b75ef1477da122d3b8733ab5da141356","text":"Read replicas","correct":false}]},{"id":"2bf99c9d-4fc2-409d-b791-c6c4a0768549","domain":"Performant","question":"Which of the following are true about Amazon S3 - OneZone-IA?","explanation":"S3 - OneZone-IA enables customers to reduce their costs by storing non-critical, reproducible data at lower levels of availability than Amazon S3’s standard storage.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/?nc=sn&loc=3","title":"S3 - Storage Classes Overview"}],"answers":[{"id":"ddd83209deb4bf5fdc24d22fb5e12c3c","text":"S3 - OneZone-IA is most often used with objects that are easy to re-create.","correct":true},{"id":"80e69120164bdeae440ac4a4af1b973d","text":"S3 - OneZone-IA is designed for 99.99% durability","correct":false},{"id":"d1a5624e6fbe325e3889a95a62c96184","text":"S3 - OneZone-IA is designed for 99.90% availability.","correct":false},{"id":"dc2b74cf19d83fee510b2c972d70db9a","text":"S3 - OneZone-IA is designed for 99.999999999% durability.","correct":true},{"id":"d18f42bdcdbac2b13beeadb7f15654a6","text":"S3 - OneZone-IA is designed for 99.50% availability.","correct":true}]},{"id":"c69a71a5-d528-482b-9ef5-2f64f2254885","domain":"SecureSolutions","question":"You are trying to establish a VPC peering connection with another VPC, and you discover that there seem to be a lot of limitations and rules when it comes to VPC peering. Which of the following is not a VPC peering limitation or rule?","explanation":"Cluster Placement Groups can span VPCs, but not AZs.  In Jan 2018 AWS introduced inter-Region VPC Peering.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html","title":"Invalid VPC Peering Connection Configurations"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"Placement Groups & VPC Peering"},{"url":"https://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-basics.html","title":"VPC Peering Basics"}],"answers":[{"id":"aad59f4740462dc95a91a5dbd4566dae","text":"You cannot create a VPC peering connection between VPCs in different regions.","correct":true},{"id":"bec3523f7df93984456e0a052b188d49","text":"A cluster placement group cannot span peered VPCs.","correct":true},{"id":"d5940d56f69290da66e11ce1d3447839","text":"You cannot create a VPC peering connection between VPCs with matching or overlapping CIDR blocks.","correct":false},{"id":"8c6e6421dad18dba855b5e3a330db13a","text":"You cannot have more than one VPC peering connection between the same VPCs at the same time.","correct":false}]},{"id":"2d66a68a-db0b-46af-93f2-8fbb712d7f8d","domain":"ResilientDesign","question":"Which of the following are the application integration services enable communication between decoupled components in order to build a scalable and more resilient solution?","explanation":"Amazon SQS, Amazon MQ and Amazon App Sync are AWS application integration services. Application integration services enable communication between decoupled components within micro-services, distributed systems, and serverless applications so you can easily build scalable and more resilient solutions. Amazon DataSync is AWS Migration and Transfer service and is not an integration service. AWS SES is a cloud-based email sending service designed for customer engagement.","links":[{"url":"https://aws.amazon.com/products/application-integration/?nc2=h_m1","title":"AWS Application Integration Services"}],"answers":[{"id":"b65c2d4cd3e247c1554f92a08e6ea48b","text":"Amazon App Sync","correct":true},{"id":"335523617c1b39d5772d3e75b7da2014","text":"AWS Simple Email Service (SES)","correct":false},{"id":"71f398f7b21d60364b4a577a13a1271f","text":"Amazon Data Sync","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true},{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":true}]},{"id":"446d12ef-f212-4d80-8b31-ca65204c3b45","domain":"Performant","question":"The AMI ID used in an AutoScaling policy is specified in the_____.","explanation":"The Launch Configuration contains most of the parameters that you would set for a manual EC2 launch, and these are applied to each automatic launch.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/LaunchConfiguration.html","title":"Launch Configurations"}],"answers":[{"id":"415107f62d630ab0aa3de0b6ed75a3dd","text":"Launch configuration","correct":true},{"id":"af25a68505a64d038c5cc6de686880af","text":"AutoScaling Policy","correct":false},{"id":"5fdc7c9d0a9fcbddd7977b2d69ce392a","text":"AutoScaling group","correct":false},{"id":"6bbdc6787549994c5be17383cfea4a40","text":"Security Group","correct":false}]},{"id":"e7ba33b8-6d4c-428b-a57a-dcfbf9fcf616","domain":"ResilientDesign","question":"When considering the SQS Standard queues. Which of these describe the design concern or limit that you need to manage in your application design?","explanation":"With Standard Queues, each message will be delivered at least once, this ensures that no message is lost, but leaves you t manage duplicates. SQS standard queues will process messages in a loosely sequential order, due to the number of SQS nodes and that some may be restarting or load splitting the order is not guaranteed.  You should recognize that all the others are related FiFo queues.","links":[{"url":"https://aws.amazon.com/sqs/details/","title":"SQS Product Details"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-how-it-works.html","title":"How SQS works"},{"url":"https://aws.amazon.com/blogs/developer/how-the-amazon-sqs-fifo-api-works/","title":"How SQS FiFo works (blog)"}],"answers":[{"id":"a0792aa56343575141024087ca38fb6a","text":"If a log contains identical log entries 'ContentBasedDeduplication' will see duplicate messages and prevent messages other than the 1st being processed until the index expires.","correct":false},{"id":"74cf0b557de0daa58606a28a96003a22","text":"You need to process more than 300 messages per second, per action and cannot use Batching","correct":false},{"id":"4db8fff01bf1b1d61c2df74ac7c2c9a2","text":" If multiple threads in a message creating process generates messages with the same 'message group ID' at the same time the order of processing may be uncertain.","correct":false},{"id":"6568af366d80b8c8c4df81e76cd92948","text":"The product design indicates that you will need be between 30,000 and 100,000 inflight messages at any one time.","correct":false},{"id":"7c287e3e01eabc58b4984f14b0fe6683","text":"The order that messages are processed is loosely sequential, but this cannot be relied on ","correct":true},{"id":"23f8f465ecf2aae88fc210a3d7bf5181","text":"If a message creating system restarts a queue or reprocesses a log, duplicate messages may be generated, sent to SQS and processed.","correct":true}]},{"id":"2f18032b-ba16-4cf1-a9f4-0ee458e316bb","domain":"ResilientDesign","question":"Your development team have created a cloud specific application which is decoupled from other services.  You have been tasked with choosing an AWS service to use as message queue in this service.  The developers have specified that the chosen service must cope with at least 5000 transactions per second, guarantee delivery of each message but allows for the message being sent a number of times.","explanation":"The Standard SQS Queue meets all of the goals listed in the question, each message will be delivered at least once, but may be sent more than once. It can also cope with almost unlimited number of transactions per second. The FIFO queue can guarantee to deliver messages at least once, but can only handle 300 transactions per second.  Amazon MQ is specifically developed to move existing applications to the cloud without changing your code and it may work in this context, but it is not recommended.  SNS is a notification service not a messaging queue.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"Amazon SQS FAQs"},{"url":"https://aws.amazon.com/sqs/features/","title":"Amazon SQS features"}],"answers":[{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":false},{"id":"0a4adfe9c9d87e31e94e1e13e2f44441","text":"SQS Standard","correct":true},{"id":"6d0cf8e6998da0736797ae76fc1b5071","text":"SQS FIFO","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":false}]},{"id":"bc814aa4-03e8-4a64-aa0e-84f22d812a95","domain":"SecureSolutions","question":"Which of the following DNS record types does Route 53 not support?","explanation":"Route 53 is a scalable and highly available DNS service and it currently supports 13 different DNS record types including; AAAA, CNAME and SPF.  However, Route 53 does not support DNSSEC (other than during domain registration) and therefore any DNSSEC related records, such as DNSKEY, are also not supported.","links":[{"url":"https://aws.amazon.com/route53/faqs/","title":"Amazon Route 53 FAQs"}],"answers":[{"id":"098890dde069e9abad63f19a0d9e1f32","text":"AAAA","correct":false},{"id":"b4efb35349e5d93905531be07dbacd6d","text":"SPF","correct":false},{"id":"548deb43a9afe4abcde34a605eb44700","text":"DNSKEY","correct":true},{"id":"adc4bfdb0829dae99e3699393e3fbaa4","text":"CNAME","correct":false}]},{"id":"5c6ec542-13ec-47b0-90b9-747eba40a8dd","domain":"CostOptimized","question":"What main functions can Route 53 perform? Select the best answer from the following options.","explanation":"Route53 is Amazons DNS web service that delivers the domain registration, DNS routing and health checking function in any combination.","links":null,"answers":[{"id":"20cda55464d105018afc584dcdbc80fe","text":"Domain registration, DNS routing, and health checking in any combination","correct":true},{"id":"24f6183de033dcaee97747be7c92a9f3","text":"Amazon Route 53 is a highly available and scalable cloud Domain Name System (DNS) web service that is designed to give developers and businesses an extremely reliable and cost-effective way to route end users to Internet applications. It can be used together with CloudWatch, a service which allows you to monitor and manage applications. While Route 53 is not a domain reseller, it allows customers to bring their own domain names with them.","correct":false},{"id":"fd7a725638e536df09c6ea5a5d0f2b46","text":"DNS routing and health checking for domains hosted on AWS","correct":false},{"id":"207068b486e311e8fedb355a6c2edcff","text":"Domain registration and DNS routing","correct":false}]},{"id":"d27e19ed-c0a1-430f-b5df-5e792077aaa4","domain":"Performant","question":"Your existing on-premise servers rely on Memcached to provide memory object caching. If you were to move to AWS, how might you preserve this functionality?","explanation":"ElastiCache is a web service that makes it easy to set up, manage, and scale a distributed in-memory cache environment in the cloud. It provides a high-performance, scalable, and cost-effective caching solution, while removing the complexity associated with deploying and managing a distributed cache environment.","links":[{"url":"https://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/WhatIs.html","title":"About ElastiCache"}],"answers":[{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":true},{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"8f3e091d35aa63444fb3aeeecc74eaf3","text":"Elastic MapReduce","correct":false},{"id":"769c10500364777e54f2a7c646b7c699","text":"Install Memcached on EC2","correct":false}]},{"id":"6a16844d-d855-43f6-a902-f63500dee2e0","domain":"CostOptimized","question":"What determines the cost of using CloudFormation templates?","explanation":"There is no additional charge for AWS CloudFormation. You pay for AWS resources (such as Amazon EC2 instances, Elastic Load Balancing load balancers, etc.) created using AWS CloudFormation in the same manner as if you created them manually.","links":[{"url":"https://aws.amazon.com/cloudformation/pricing/","title":"CloudFormation Pricing"}],"answers":[{"id":"3c3c1e619043162fee31256e48a4749f","text":"The published rate of $.10 per template per month","correct":false},{"id":"68c5db0c017756a888527d5562b6b1f9","text":"The resources the AWS infrastructure uses to build your environment","correct":false},{"id":"fb810c61b145968086aade2e993c67b4","text":"There is a cost for CloudFormation only after you have exceeded the 20 free templates you are allowed per month.","correct":false},{"id":"ece43bafdf05c285f1bf3f2ba74d26a5","text":"There is no cost to using CloudFormation, but you are charged for the resources the template builds.","correct":true}]},{"id":"6d5d2303-29b6-4e31-96a7-b4067a191b9e","domain":"Performant","question":"You have an application that requires that 500 messages per second be sent and processed in order. Which service should be used to accomplish this?","explanation":"SQS FIFO queues are designed to enhance messaging between applications when the order of operations and events is critical, or where duplicates can't be tolerated. SQS Standard queues can process the messages, but cannot guarantee order.  SNS is used to send the messages, but does not process them. SES is an email service.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html","title":"Amazon SQS FIFO Queues"}],"answers":[{"id":"cdc05958362b09ba911028eaf41c71d5","text":"AWS SQS","correct":false},{"id":"53a5cedcd58452f2752a4cf26d0c79b7","text":"AWS SQS FIFO","correct":true},{"id":"74e06b58e00302916a205d2bf24e9837","text":"AWS SNS","correct":false},{"id":"17d68573ef0a017c323182d2cf4e7477","text":"AWS SES","correct":false}]},{"id":"c2e05533-6321-46fa-a778-47c27ca274d5","domain":"CostOptimized","question":"Your co-worker is about to create a new EC2 instance, and would like to know from what point your company will be billed for it. You tell them that it will be billed from: ","explanation":"In EC2, Instance-hours are  billed only for time your instance is in the \"Running\" state.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-instance-hour-billing/","title":"Instance-Hour Billing"}],"answers":[{"id":"c40f2931153694959f22d5efc95b2a45","text":"When it is in the \"Running\" state","correct":true},{"id":"92f171915935cf43d7367038a0ceb076","text":"When it is in the \"Pending\" state","correct":false},{"id":"61b5406c1efb94f47d6a875a56ac05c4","text":"When it is in the \"Stopped\" state","correct":false},{"id":"6672e2e78662b895923af9d5f73207be","text":"When it is in the \"Provisioned\" state","correct":false}]},{"id":"00be4bb5-a556-48d8-a95c-cac6852e76ba","domain":"CostOptimized","question":"You are operating a popular TV Show news website using a static site generator (SSG) with the resulting HTML pages being served from S3. The vast majority of pages are less than 85 KB in size. After 60 days, new episode page access drops off significantly. Which of the following statements are true?","explanation":"Similar to the STANDARD storage class, STANDARD_IA objects are available for millisecond access.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html","title":"Storage Classes"}],"answers":[{"id":"ff55b529dbaaea1355acdc097ad29298","text":"The ONEZONE_IA storage class is as durable as STANDARD_IA, but it is less available and less resilient.","correct":true},{"id":"0c8d66b9d1503b991d171f09f8943ee1","text":"Using the STANDARD_IA storage class, these older pages are stored redundantly across 3 or more geographically separated facilities.","correct":true},{"id":"a32b993ff0fa61fd0da4533f7fc8f1be","text":"Using the STANDARD_IA storage class, Amazon S3 charges you for 128 KB per object if it is less than 128 KB in size.","correct":true},{"id":"b84620799ba94f53d53c1aa19f69bb8a","text":"While objects in the STANDARD storage class are available for millisecond access, accessing STANDARD_IA objects is slightly slower.","correct":false}]},{"id":"e8d097c8-1789-4684-a73f-f00c261d1c55","domain":"ResilientDesign","question":"You need to find both the Public and Private IP addresses of an instance. Which of the following URLs should you query?","explanation":"Be careful on the exam to read the numbers and not assume what they are. The octet 254 is transposed into 524 in two of the answers, and two are user-data and two are meta-data. ","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html#instancedata-data-retrieval","title":"Retrieving Instance Meta-Data"}],"answers":[{"id":"a8a9e51abf5c6064eb3d890d974f3e21","text":"http://169.254.169.524/latest/meta-data/","correct":false},{"id":"2ac0e8450882e7026fe16254736b901f","text":"http://169.254.169.254/latest/meta-data/","correct":true},{"id":"60d4c7e460aafc0be725859f467e2178","text":"http://169.254.169.524/latest/user-data/","correct":false},{"id":"2e987eca0f9afee62ad0f6deb9d1f59e","text":"http://169.254.169.254/latest/user-data/","correct":false}]},{"id":"7dafc126-8f93-4ac8-97ba-01818de79dc1","domain":"SecureSolutions","question":"As a junior Cloud Engineer, you receive a CloudWatch alarm indicating that there might be a layer 7 attack of your environment. You recall that your company has an AWS Shield Advanced subscription. Which of the following options is the best response?","explanation":"You *can* investigate and mitigate the DDoS attack on your own, so that is a potentially correct answer. Similarly, requesting internal assistance is another possible answer because of your tech lead’s expertise. However, the best course of action is to take advantage of your AWS Shield Advanced subscription, which routes you to true DDoS experts. In this case the *most correct* answer is to work with AWS Support. Doing nothing should never be considered as an answer.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-responding.html","title":"Responding to DDoS Attacks"}],"answers":[{"id":"e13ab7a7dcc291aa8a8f5e4e1c3a8646","text":"Do nothing; it is an AWS issue that will resolve itself.","correct":false},{"id":"43d522d2e9a722af4df45616e09e2ff4","text":"Contact AWS Support Center.","correct":true},{"id":"b62d821db1c6397935c957ddd8214d47","text":"Request assistance from tech lead.","correct":false},{"id":"0b9ac6496fca4f50d60b7665f91d9209","text":"Investigate and mitigate the attack on your own.","correct":false}]},{"id":"3072d04e-e5b2-42a6-97d7-dbb17155071d","domain":"SecureSolutions","question":"You have an EC2 Instance with an EIP allocated sitting in a Public subnet in your VPC. This instance is serving web content, and you want to make sure that users on the Internet can only access it via ports 80 and 443. Which of the below options lets you achieve this?","explanation":"DENY Rules cannot be created for security groups - so all options where this is mentioned can be ignored. With inbound traffic, NACLs are evaluated first - so an NACL with a default deny rule will block all incoming traffic before it reaches the instance - so this is not the correct option. This leaves creating an allow rule for the instance's security group as the correct answer.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"68d0d074ef501849c8908fe33b77b37f","text":"Create a security group with an ALLOW rule for ports 80 & 443 and attach it to the instance","correct":true},{"id":"f57136f22cc8a2fb5ed83f93962dd750","text":"Create an NACL with a default allow rule on incoming traffic. Create a security group with a DENY rule for all ports except 80 & 443 and attach it to the instance.","correct":false},{"id":"3802db4fb97fa84757d5b21b38464fc4","text":"Create a security group with an ALLOW rule for ports 80 & 443, and a DENY Rule for all other ports. Attach it to the instance","correct":false},{"id":"a910e411655dbf1d19c15b2690076861","text":"Create and NACL with a default deny rule on incoming traffic. Create a security group with an ALLOW rule for ports 80 & 443 and attach it to the instance.","correct":false}]},{"id":"52cf0185-4629-47ac-8779-4ec4ffd9cc06","domain":"SecureSolutions","question":"You have an EC2 instance with a Security Group attached. This security group is configured to only allow inbound traffic from 192.168.0.0/24. A collegue has also configured a NACL on the subnet that the instance resides on, and this NACL is configured to block all traffic, except where the source or destination is in 192.168.0.0/24. What will happen when an instance with an IP of 192.168.1.12 tries to connect to your instance on port 80?","explanation":"With inbound traffic, NACLs are evaluated before Security Groups. As the NACL is configured to only allow traffic from 192.168.0.0/24 and the IP 192.168.1.12 does not fall within that range, it will be blocked by the NACL before reaching the Security Groups.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"5298f0866dac220c6bbad6d2da2163d8","text":"The traffic will be allowed as it is still within a private range","correct":false},{"id":"d3d7c67e2cf8c1d1cb89971fd90c2b72","text":"The security group will block the traffic before it is evaluated by the NACL","correct":false},{"id":"eb5d4be456a62dd4f884a4b47c45fd46","text":"The traffic will be blocked simultaneously by the Security Group and NACL","correct":false},{"id":"c885215eb76a3baac02ca8ea6da9a7b4","text":"The NACL will block the traffic before it is evaluated by the security group","correct":true}]}]}}}}
