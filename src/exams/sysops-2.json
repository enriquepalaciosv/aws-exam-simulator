{"data":{"createNewExamAttempt":{"attempt":{"id":"574dd019-1316-4a44-8033-f3a76f3a0d49"},"exam":{"id":"2929bb26-cabf-4e8a-85b9-dabc17b51f33","title":"AWS Certified SysOps Administrator - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"076713dd-bc2b-4460-ae94-9d3df45eaa08","domain":"dep-prov","question":"You are an engineer for a large publishing firm.  You have been asked to deploy a new EC2 instance in your VPC to act as a bastion host. After running the EC2 launch wizard and selecting your public subnet you received an error: InstanceLimitExceeded. What could be the cause of this issue?","explanation":"When the InstanceLimitExceeded error is returned, you have reached the limit on the number of instances that you can launch in a region. When you create your AWS account, AWS set default limits on the number of instances you can run on a per-region basis.  The solution to this would be to raise a Support request with AWS to raise the instance limit.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html","title":"Troubleshooting EC2 Launch"}],"answers":[{"id":"242e116ec33eeede66cc4f85212ce4b7","text":"Your account does not have the EC2 Run Instance permission for that Region","correct":false},{"id":"80c5d5df6225f5583c39e71966ddad02","text":"You have exceeded the limit for the number of that instance type which you can launch in that Region","correct":true},{"id":"2b0e392d011048a6e9bffa6106ce57cf","text":"You have not enabled Source/Destination Checks in the public subnet","correct":false},{"id":"a96267034b308f86823a30ab2cb3de84","text":"You have selected an EC2 instance type that is not available in that Availability Zone","correct":false}]},{"id":"3f8d157d-c9a7-4e65-81ca-23495248c13a","domain":"high-avail","question":"Which of the following is part of the failover process for a Multi-Availability Zone RDS instance","explanation":"The DNS record for the RDS endpoint is changed from primary to standby.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"The Multi-AZ Failover Process"}],"answers":[{"id":"d0bb9a7c3d4da6a24f1f7d977b81210c","text":"The IP of the primary DB instance is switched to the standby DB instance.","correct":false},{"id":"aa56a93d275a00fbbc67b186e8b7683c","text":"The DNS record for the RDS endpoint is changed from primary to standby.","correct":true},{"id":"837a3731c4c25be7e91a8d02984a08fd","text":"A new DB instance is created in the standby availability zone.","correct":false},{"id":"7150d3c0aa88b4f548178e7ee6748ce3","text":"The failed RDS DB instance reboots.","correct":false}]},{"id":"3961852e-ae3a-4ba3-bcea-d64a50a414fb","domain":"networking","question":"You have migrated your website to AWS and have placed it behind an Application Load Balancer and are just about to update your Route 53 records to point to the new site in AWS - Which record type do you need to create so that people browsing to \"myawssite.com\" are directed to the Application Load Balancer in AWS?","explanation":"As the URL is the Zone Apex, as CNAME record will not be allowed - requiring you to use the Alias record type. As an A record maps directly to an IP is in not appropriate to use in this case, and the CAA record type relates to certificate authorities and is not relevant in this case","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/ResourceRecordTypes.html","title":"Route 53 Supported Record Types"}],"answers":[{"id":"5a5b76c46054d7db63019bc89f3b9171","text":"Route 53 CNAME Record","correct":false},{"id":"0e9d0445230399eb6230618d20500356","text":"Route 53 CAA Record","correct":false},{"id":"1ff0a251aaa48c9626266f0a5b0181e1","text":"Route 53 A Record","correct":false},{"id":"9e7e22b05e283291537669ab0bc663be","text":"Route 53 Alias Record","correct":true}]},{"id":"2bd13304-db2d-4120-9487-7e13d7008a63","domain":"dep-prov","question":"EC2 instances are launched from Amazon Machine Images (AMIs). A given public AMI:","explanation":"An AMI cannot be launched into another region. To launch an AMI into a region other that the one in which it was created, the AMI must be copied to that other region first.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"9ba6ee29e152b251b8fc17d5d2aca126","text":"Can be used to launch EC2 instances in any AWS region.","correct":false},{"id":"3b690d9883c0bbec853ffdc3be150208","text":"Can only be used to launch EC2 instances in the same AWS country as the AMI is stored.","correct":false},{"id":"7096f3da806d7b3014ab808eb74d213a","text":"Can only be used to launch EC2 instances in the same AWS region as the AMI is stored.","correct":true},{"id":"5a70861f841598d574b8ebd61e20cfc1","text":"Can only be used to launch EC2 instances in the same AWS Availability Zone (AZ) as the AMI is stored.","correct":false}]},{"id":"5dc94849-7cfe-45fd-ae52-8e634c5e7d04","domain":"mon-rep","question":"Which of the following services does CloudWatch use to send you an email following an alarm event?","explanation":"Amazon EC2, S3 and CloudWatch, can all publish messages to your SNS topics to trigger event-driven computing and workflows. Amazon CloudWatch uses SNS to send email.","links":[{"url":"https://docs.aws.amazon.com/sns/latest/dg/welcome.html","title":"About SNS"}],"answers":[{"id":"8513f757701b24dbadad3df74e817df5","text":"SES","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":true},{"id":"ef4ba2f338cdf4b615ed280ff0b2777d","text":"SQS","correct":false},{"id":"f62772d94b939126ee608465cf5e0881","text":"SWF","correct":false}]},{"id":"2db1ee7d-fe0a-4556-ad28-5731b36c2eca","domain":"networking","question":"You need a load balancer with support for TCP connections and preserving the source IP address. What load balancer should you choose?","explanation":"Proxy Load balancer isn't a real thing. Network Load Balancer and Classic Load Balancer both support TCP connections. However, only Network Load Balancer supports preserving the source IP address. ","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/","title":"Elastic Load Balancing features"}],"answers":[{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false},{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":true},{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":false},{"id":"898665d0778b0435cd2b64ff8a8512c2","text":"Proxy Load balancer","correct":false}]},{"id":"67a5ebe3-a3e7-426e-b6f1-ae8e7e58ba45","domain":"dep-prov","question":"You're using AWS CloudFormation template to provision an environment that consists of Amazon EC2 instances behind a load balancer. You want to output the DNS name of the load balancer in the Outputs section. Which intrinsic function should you use?","explanation":"The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. To return a string containing the DNS name of the load balancer with the logical name myELB, you could use \"Fn::GetAtt: [ myELB, DNSName ]\" in a YAML template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getatt.html","title":"Fn::GetAtt"}],"answers":[{"id":"fdf1a9a682e23e506b7afbdd8a427126","text":"Fn::GetAtt","correct":true},{"id":"9755e3403594515213433801d07f5476","text":"Fn::Select","correct":false},{"id":"f39ff73d166b2d89703ba99b860cc1d2","text":"Fn::Join","correct":false},{"id":"45e374d45acef37653e6212bf389674d","text":"Fn::FindInMap","correct":false}]},{"id":"0aec7415-8b29-457e-b3f1-155c5bb8cb86","domain":"security-comp","question":"A company is developing a photo sharing application. The frontend and backend are hosted on EC2 instances managed by Auto Scaling groups. The instances reside in a customer VPC. An Amazon Aurora database is created in RDS for the application. The DB instance is put in the same customer VPC and should only allow inbound traffic from the backend servers. Which method would you use to control the access for the database?","explanation":"RDS instances use VPC security groups to control the inbound and outbound access. You can configure a rule by specifying the backend server VPC security group as the source. You cannot attach a network control list to an RDS instance. An EC2 security group is associated with an EC2 instance and cannot be attached in an RDS database.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.RDSSecurityGroups.html","title":"Controlling access with security groups for RDS"}],"answers":[{"id":"38d438dc12bb1dc8fcf3ecd2cab2b66f","text":"Configure an EC2 security group and attach it to the database. The inbound rule allows the IP range used by the backend EC2 instances.","correct":false},{"id":"a0fe13c612a2532365d4ef7cc72df516","text":"Attach a network control list to the RDS database. In the NCL, allow inbound traffic from the backend network control list.","correct":false},{"id":"c9d929435a86501ae9e08194715efb79","text":"Configure a VPC security group in the DB instance and the inbound rule allows the security group of the backend server.","correct":true},{"id":"b0d35520a9a26c27b68a88876f158ee2","text":"Set up a network control list in the RDS instance. Only allow the inbound traffic from the backend Auto Scaling group.","correct":false}]},{"id":"fae36faf-783b-4c76-83ed-511f56063f62","domain":"mon-rep","question":"A MySQL database is created in AWS RDS. The DB instance stores sensitive customer data and its running status needs to be closely monitored. You want to use the Amazon Simple Notification Service (SNS) to receive notifications whenever there is a configuration change for the instance such as when the master password for the DB instance has been reset. How would you meet this requirement?","explanation":"Amazon RDS uses the Amazon SNS to provide notifications. You can create an event subscription and subscribe to specific event categories. RDS does not have streams and you cannot register a DB instance in an AWS Config rule. Lambda function makes things complicated and is not as simple as Event Subscription in RDS.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_Events.html#USER_Events.Messages","title":"Using Amazon RDS event notification"}],"answers":[{"id":"a70af04178c8de89d82a07fef3eb2d30","text":"Register the RDS instance in an AWS Config rule. Whenever there is a configuration change, the rule triggers a notification to an SNS topic.","correct":false},{"id":"80e872148df53129ffa1664bafab3bdd","text":"Enable the RDS streams to save the configuration events. Configure an SNS topic to receive notifications.","correct":false},{"id":"29c262e90545613cde223c6ace0c200a","text":"Create a Lambda function to monitor the configuration change events for the DB instance. Send a notification to an SNS topic whenever such an event happens.","correct":false},{"id":"6321b05f3e9c6a31e5173e1e87d3aa62","text":"Configure an event subscription in RDS and subscribe to the “configuration change” event category. Use an SNS topic to receive notifications.","correct":true}]},{"id":"y895ku45-wsg2-9rye-087a-zdmu2wd7qtr8","domain":"mon-rep","question":"Which AWS service can be used to log API calls from the AWS console, the EC2 CLI, the AWS CLI, or the AWS SDKs.","explanation":"CloudTrail captures API calls and delivers the log files to an Amazon S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/APIReference/using-cloudtrail.html","title":"Logging API Calls Using AWS CloudTrail"}],"answers":[{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false}]},{"id":"3af6fa26-fd1c-4df8-9cbd-1b09cb27b058","domain":"high-avail","question":"You deploy a Lambda function as the backend service to process requests from end users. Due to a recent market activity, the incoming requests get much higher than before. After monitoring the service for several days, you notice that there are lots of requests that fail with a throttling error (429 status code). How would you resolve the issue?","explanation":"The concurrency limit of the Lambda function should be increased through AWS support center. The reserved concurrency cannot be higher than the limit itself so it does not help. If the failed requests are put in the SQS queue, users are still impacted. This scenario utilises a Lambda function, so it is not relevant to modify the API gateway. And the API gateway traffic may not reach the limit yet.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/scaling.html","title":"AWS Lambda function scaling"}],"answers":[{"id":"76a6affef46852926b4ffbab868e6dff","text":"For the particular Lambda function, reserve a higher amount of concurrency.","correct":false},{"id":"afd1504172407f21b8671eadec82ead0","text":"Request to increase the API gateway limit in AWS support center console.","correct":false},{"id":"326750c51756ebed25ac138a6c3d8415","text":"Route the failed requests to an SQS queue. Resubmit the queue items to the Lambda function after 1 minute.","correct":false},{"id":"3bdad2b7a566c133c99a06077bed7f7f","text":"Increase the concurrency limit of the Lambda function by submitting a request in AWS support center.","correct":true}]},{"id":"44b4605e-3e4b-4762-8db1-29f4d8bdadb1","domain":"data-man","question":"Your team has come to you for advice on finding the best storage solution on AWS. Your team's application runs on a load balanced pool of web servers and needs to store frequently changing data like buffers, caches, and other interim data. What AWS storage solution would you recommend to maximize performance and minimize costs?","explanation":"An instance store provides temporary block-level storage for your instance. This storage is located on disks that are physically attached to the host computer. Instance store is ideal for temporary storage of information that changes frequently, such as buffers, caches, scratch data, and other temporary content, or for data that is replicated across a fleet of instances, such as a load-balanced pool of web servers. Amazon Instance Store is best used for temporary storage. The other options would incur additional storage costs.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","title":"Amazon EC2 Instance Store"}],"answers":[{"id":"f7b96044a16becafecad63df1725e9c8","text":"Amazon EFS","correct":false},{"id":"270fcb785810d0206945029bb05f4e97","text":"Amazon S3","correct":false},{"id":"e2b73d2522b2b07ac67d36de7ac51b75","text":"Amazon EC2 Instance Store","correct":true},{"id":"e58f9c51d5656ba7cd0d4796730248a7","text":"Amazon EBS. Read contents on the EBS volume to improve performance.","correct":false}]},{"id":"f77c40bd-922a-4bd5-8688-355a24e5b7f4","domain":"mon-rep","question":"As a SysOps Administrator you are auditing the patches across all the RDS instances within the us-east-1 Region of your AWS environment. You need to check the OS of the instances to ensure that the latest patches are installed and that the proper security requirements are being met. What AWS service could you use to complete your task?","explanation":"You can view whether a maintenance update is available for your DB instance by using the RDS console, the AWS CLI, or the Amazon RDS API. If an update is available, it is indicated in the Maintenance column for the DB instance on the Amazon RDS console. You can use Amazon Inspector service to create and run security assessments for your Amazon EC2 instances. AWS Artifact is used for gathering central compliance-related information that matters to you. Trusted Advisor online tool that provides you real time guidance to help you provision your resources following AWS best practices and would not necessarily provide OS patching related recommendations. These are best viewed directly in the RDS console.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Maintenance.html","title":"Maintaining a DB Instance"}],"answers":[{"id":"f5182b63a0b85cdb1fba4efaac2c38d6","text":"Use Amazon Inspector to run a report that shows the current security status of your RDS instances.","correct":false},{"id":"af6beaf0a652352efd6b43acbef87765","text":"Check AWS Artifact to view the patch requirements of the instances in your AWS environment.","correct":false},{"id":"289e4c4b17e574f33583898b34a8f37a","text":"Check maintenance of the instances on the Amazon RDS console.","correct":true},{"id":"d289311b7f2b2249f93a154c2a78e69a","text":"Use the AWS Trusted Advisor dashboard to view recommendations.","correct":false}]},{"id":"8f2d3d61-092d-429c-a109-69ab00fa4065","domain":"mon-rep","question":"AWS Cost Management encompasses a number of services to help you to organize, control and optimize your AWS costs and usage.  Which of the following Cost Management related tools gives you the ability to set alerts when costs or usage are exceeded?","explanation":"The correct answer is AWS Budgets.  AWS Cost Explorer lets you visualize, understand, and manage your AWS costs and usage over time. AWS Cost & Usage Report lists AWS usage for each service category used by an account and its IAM users and finally, Reserved Instance Reporting provides a number of RI-specific cost management solutions to help you better understand and manage RI Utilization and Coverage.","links":[{"url":"https://aws.amazon.com/aws-cost-management/aws-budgets/","title":"AWS Budgets"}],"answers":[{"id":"824fd559c917b4ae56f36787b886eb81","text":"AWS Cost & Usage Report","correct":false},{"id":"e32a801c8e0beab6abb9361e937365be","text":"AWS Budgets","correct":true},{"id":"c7f176d72688fd87853e31b84159d541","text":"AWS Cost Explorer","correct":false},{"id":"eef79d956328d5e4ec426d448cc53c74","text":"Reserved Instance Reporting","correct":false}]},{"id":"592837f2-71d3-4e62-a250-9318ea373e4f","domain":"security-comp","question":"You are a Cloud Administrator for your company. You have many employees who need to run internal applications that access the company's AWS resources. The employees already have user identities in the company's identity and authentication system, and your CISO doesn't want to create a separate IAM user for each company employee. You've confirmed with your developers that the applications' identity stores are not compatible with SAML 2.0. How would you implement a secure solution for your employees to access AWS resources?","explanation":"If your identity store is not compatible with SAML 2.0, then you can build a custom identity broker application to perform a similar function. The broker application authenticates users, requests temporary credentials for users from AWS, and then provides them to the user to access AWS resources. Creating IAM Users for each employee is not an option. Amazon Cognito is for mobile and web-based application scenarios. A permissions boundary is not a viable solution.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_federated-users.html","title":"Providing Access to Externally Authenticated Users (Identity Federation)"}],"answers":[{"id":"e59f83de64b3549683dca23ce954c76f","text":"Create IAM Users for the employees and group them into IAM Groups for administrative purposes since your identity provider is incompatible with SAML 2.0.","correct":false},{"id":"04b52fca3576444ec1bdbe890cb9b2c8","text":"Use Amazon Cognito with public identity provider services for your employees. Link your employees' credentials with a third-party IdP that is compatible with OpenID Connect (OIDC) to grant access to AWS resources.","correct":false},{"id":"b24b7cff8ae14f5cf1fabc8e93a55cec","text":"Build a custom identity broker application to verify that employees are signed into the company's authentication system, then obtains temporary security credentials for the employees.","correct":true},{"id":"65e9ecf1544f3bd1ca9f6dce4aef9dcf","text":"Create a permissions boundary around a role that correspondence to the allowed actions for your company's employees. Allow each employee to assume that role. Create a Lambda function that will automatically deny allow if the employee's permissions exceed the boundary.","correct":false}]},{"id":"01c5ef85-f86c-4577-a360-c95f8b18f0b4","domain":"networking","question":"A company is using AWS CloudFormation to manage its infrastructure resources. The resources in the CloudFormation template include a web application EC2 instance in the public subnet, a database RDS instance and a background worker instance in the private subnet, and a NAT gateway in the private subnet. Upon launching the resources with CloudFormation, the background worker instance could not perform the required patching operations. How can the team resolve this issue?","explanation":"NAT gateways need to be in the public subnet in order for the resources in the private subnet to have internet connectivity. Usually, the default route for a private subnet points to the NAT gateway. If the NAT gateway is in a private subnet, then the traffic cannot reach the internet and the resources in the private subnet won't have internet connectivity.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html","title":"VPC - Scenario"}],"answers":[{"id":"85ed6715d192d5fa6f511643f57bbc3d","text":"Run the CloudFormation template in a public subnet.","correct":false},{"id":"020488512a65f6ba76a54fe218be0393","text":"Run the CloudFormation template in a private subnet.","correct":false},{"id":"0dd5664349040ac37294cf1395f180f0","text":"Launch the NAT gateway in the public subnet.","correct":true},{"id":"eab056f2f227b9e8b14f19de962820d4","text":"Replace the NAT gateway with a NAT instance.","correct":false}]},{"id":"b439f1df-a83a-47d6-96a0-c14944daeaff","domain":"networking","question":"A UK company is building its presence in India. It has decided to deploy dedicated infrastructure in India for the local market.  How can the company seamlessly route its Indian users to the load balancer located in ap-south-1 instead of the UK?","explanation":"Route53 geolocation routing is the only answer here which will return a different DNS record based on the source IP address of the DNS request.  The other answers would not route users correctly based on their country.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/geolocation-routing-policy/","title":"How do I direct traffic to specific resources or AWS regions based on the query's geographic location?"}],"answers":[{"id":"1844cecdf015b88aef8e88746b321731","text":"Use Route53 latency routing","correct":false},{"id":"055d83107cd15485df5c1f48c53f1758","text":"Use Route53 geolocation routing policy","correct":true},{"id":"ebeefbe1e321377375eb3065b4a2fc20","text":"Use Route53 failover routing","correct":false},{"id":"816c21d5068061f198f8df28aaf61e0d","text":"Use Route53 multi-answer routing","correct":false}]},{"id":"95b5fb6b-4742-4c0a-8563-4dc9dc116700","domain":"mon-rep","question":"You have been asked to monitor custom metrics generated by your own applications and services. There is a need for these metrics to be collated and returned to the product owner each week so they can plan for the following sprint's requirements. What services would you use to be able to provide this automated report?","explanation":"You can set up monitoring of custom metrics in CloudWatch, from this you can use CloudWatch also to trigger a Lambda Function at a scheduled time, which will collect use AWS SDK to pull the metrics into a report that will be sent via email using the SNS service","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html","title":"Publishing Custom Metrics"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/with-scheduled-events.html","title":"Using AWS Lambda with Amazon CloudWatch Events"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/with-sns-example.html","title":"Tutorial: Using AWS Lambda with Amazon Simple Notification Service"}],"answers":[{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":true},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":true},{"id":"f79368a88745f4dba5e0fc92aa545c61","text":"EKS","correct":false}]},{"id":"70431b97-0c8f-4053-8f08-39a853c40574","domain":"mon-rep","question":"An insurance company has a serverless application setup utilizing API Gateway, AWS Lambda, and DynamoDB for its web application. The engineering manager of the company has instructed the team to identify, track, and detect all potential bottlenecks related to POST method calls being performed by the AWS Lambda functions. How can the team accomplish this?","explanation":"By modifying the code to use the X-Ray snippets, potential bottlenecks accessing different resources and endpoints can easily be detected. CloudTrail is used for auditing API call logs. CloudWatch is used for monitoring resource usage and metrics. X-Ray is a distributed tracing system. Using AppSync instead of the API Gateway would not solve the monitoring and tracing requirements.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html","title":"AWS X-Ray"}],"answers":[{"id":"ade3d51642e3463e7659ec0f6b480094","text":"Use AWS CloudWatch","correct":false},{"id":"ac6d6d3d9e1a43f18cb5cf78b181951b","text":"Use AWS X-Ray","correct":true},{"id":"79b2cfe0b560a65754739eed236044d0","text":"Use AWS CloudTrail","correct":false},{"id":"ec9e1adbee82bfcb915a1773a27a9a43","text":"Use AppSync instead of API Gateway","correct":false}]},{"id":"wprzr3tn-okej-0h4b-ndf8-ap946jyfvo5r","domain":"automation","question":"Your company has moved to AWS so it can use \"scripted infrastructure\". You would like to apply version control to your infrastructure, so that you can roll back infrastructure to a previous stable version if needed. You would also like to quickly deploy testing and staging environments in multiple regions. What services should you use to achieve this?","explanation":"CloudFormation, plus a version control system such as GitHub, would be the correct choice if the goal was to employ infrastructure-as-code.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"About CloudFormation"}],"answers":[{"id":"a9b7ffe77958257f25106e8512657c4c","text":"CloudWatch, plus a version control system such as GitHub.","correct":false},{"id":"0fe9a555daecf33ab759c807a79e3027","text":"Opsworks, plus a version control system such as GitHub.","correct":false},{"id":"9c90a68675503a6fe9fa5d118c48fa11","text":"Elastic BeanStalk, plus a version control system such as GitHub.","correct":false},{"id":"3944bd95d89aa956870cc4058a727391","text":"CloudFormation, plus a version control system such as GitHub.","correct":true}]},{"id":"3eaf9c7f-ec35-42cb-af59-f26b9b358432","domain":"automation","question":"Which of the following sections is required for a CloudFormation template to be valid?","explanation":"The Resources section is the only required section. It specifies the stack resources and their properties, such as an Amazon Elastic Compute Cloud instance or an Amazon Simple Storage Service bucket.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/resources-section-structure.html","title":"CloudFormation - Resources"}],"answers":[{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"229eb04083e06f419f9ac494329f957d","text":"Conditions","correct":false}]},{"id":"eb2317bb-3bd4-4593-b217-e0610e79e106","domain":"mon-rep","question":"A critical application which runs on an EC2 instance behind an ELB is experiencing occasional outages. Associated with the outages are Windows event log entries. How can you detect these events and alert your team?","explanation":"CloudWatch Logs let you to stream logs from your EC2 instances to the CloudWatch service. A log filter on a Log Group allows you to detect occurrences of a key word or phrase. SNS can then deliver alerts for these alarms. ELB logs would not contain the keyword/phrase, nor would CloudTrail or the Autoscaling activity history.","links":[{"url":"https://docs.aws.amazon.com/en_pv/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html","title":"What Is Amazon CloudWatch Logs?"},{"url":"https://docs.aws.amazon.com/en_pv/AmazonCloudWatch/latest/logs/CountOccurrencesExample.html","title":"Example: Count Occurrences of a Term"}],"answers":[{"id":"cff2a2162045687c91304445129e482d","text":"Use CloudWatch logs with a log filter to alarm on an occurrence of the event then message the team using SNS","correct":true},{"id":"d0520b3777e34e62b94d0046d78ec3b3","text":"Use CloudTrail logs and message the team using SNS","correct":false},{"id":"a325e8469dc87698c1ba13863e512af5","text":"Use Autoscaling activity logs and message the team using SNS","correct":false},{"id":"33e9387fac100300d7d2d03d2561f1f4","text":"Use ELB logs and a filter to alarm on the event then message the team using SNS","correct":false}]},{"id":"6b54e986-f59f-4e75-9c40-c6bc649fab55","domain":"dep-prov","question":"You need to create a new trail in AWS CloudTrail service. You want the new trail to capture all management events through AWS API or console. The trail should also capture the data events that are performed within the resources. Which types of resources can be configured in the trail for the data events? (Select TWO.)","explanation":"With CloudTrail, you can collect data events that happen within the resources of S3 or Lambda Function. Data events are disabled by default. You can explicitly add the supported resource types when configuring a trail.","links":[{"url":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-management-and-data-events-with-cloudtrail.html?icmpid=docs_cloudtrail_console#logging-data-events","title":"Logging Data and Management Events for Trails"}],"answers":[{"id":"5480a17f5758c852bd04b2f161ff0292","text":"S3 buckets.","correct":true},{"id":"cebb61de76a9f200611a3ba82b466b74","text":"Lambda Functions.","correct":true},{"id":"789e00e8a87626604884b3f6914ef4af","text":"EC2 EBS volumes.","correct":false},{"id":"acb5990f113ecf1bd53980965afac0d2","text":"RDS instances","correct":false},{"id":"38a35b30a2aefbe82c671f0441c0fd5b","text":"DynamoDB tables.","correct":false}]},{"id":"f94237f9-9b2f-48f3-9a0a-cd4a8350cead","domain":"networking","question":"Your department has made a decision to migrate a number of applications to AWS to reduce operational costs. These applications will need connectivity from your corporate network. Multiple AWS accounts and VPCs within accounts are needed. You currently contract with a single carrier for WAN services, and this carrier is an AWS Direct Connect Partner. Your manager has tasked you with creating a highly reliable networking solution between AWS and the corporate network. Which architecture will provide a highly reliable solution with the best cost efficiency?","explanation":"A single Direct Connect with VPN backup provides highly reliable connectivity between a corporate network and AWS at a lower cost than deploying two Direct Connects. Direct Connect Gateway is not required to achieve cross-account connectivity. Public Virtual Interfaces will not provide connectivity to VPCs. Private Virtual Interfaces are used for that.","links":[{"url":"https://aws.amazon.com/directconnect/","title":"AWS Direct Connect"},{"url":"https://aws.amazon.com/answers/networking/aws-multiple-data-center-ha-network-connectivity/","title":"Multiple Data Center HA Network Connectivity"}],"answers":[{"id":"49ba7d5b47cab8f1b382c99edd2f513a","text":"Deploy a single AWS Direct Connect through your current carrier. Monitor the Direct Connect connection with Amazon CloudWatch and invoke AWS Lambda to failover traffic to an IPSec VPN tunnel if there are any issues.","correct":true},{"id":"e406e073341c09e80aff0244163394af","text":"Implement two AWS Direct Connects through your current carrier to a single Direct Connect location to be provisioned on redundant Amazon routers. Create Private Virtual Interfaces across the different accounts and VPCs.","correct":false},{"id":"d99e60f7ff5145b088e827b533122d02","text":"Employ a single AWS Direct Connect through your current carrier. Implement a second AWS Direct Connect through another Direct Connect Partner to another Direct Connect location in the same AWS region. Use Direct Connect Gateway to bridge across the multiple accounts.","correct":false},{"id":"d4025e698a2432c8861799040385c885","text":"Employ a single AWS Direct Connect through your current carrier. Implement a second AWS Direct Connect through another Direct Connect Partner to the same Direct Connect location. Create Public Virtual Interfaces across the different accounts and VPCs.","correct":false}]},{"id":"32db26ef-70e3-4541-b3e5-7cde3ad73c9e","domain":"dep-prov","question":"In order to enable encryption at rest using EC2 and Elastic Block Store,  you must ________.","explanation":"To enable encryption, you must specify encryption when creating the EBS volume.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html","title":"About EBS Encryption"}],"answers":[{"id":"aaed5dee4871b8256093659e8bbeba4a","text":"Configure encryption using the appropriate Operating Systems file system","correct":false},{"id":"64237cc9809266ebc9fb12b6cede9aa8","text":"Configure encryption using X.509 certificates","correct":false},{"id":"d8e355c7726e173ad29951d3461865d6","text":"Configure encryption when creating the EBS volume","correct":true},{"id":"4bd8d581e477097d1396901aab8b3cf4","text":"Mount the EBS volume in to S3 and then encrypt the bucket using a bucket policy","correct":false}]},{"id":"e105d8a7-6333-48d8-9610-7c2f9ad73991","domain":"mon-rep","question":"There has been a steady rise in costs with your AWS bill, and the security team has noticed that there has been an increase in the number of requests, even though the number of IAM users has decreased due to employee turnover and down-sizing. The CISO has tasked you with identifying whether recent requests to the AWS account's environment were made with temporary security credentials for a role or federated user. How would you go about identifying this?","explanation":"A trail enables CloudTrail to deliver log files to an Amazon S3 bucket. By default, when you create a trail in the console, the trail applies to all AWS Regions. The trail logs events from all Regions in the AWS partition and delivers the log files to the Amazon S3 bucket that you specify. Additionally, you can configure other AWS services to further analyze and act upon the event data collected in CloudTrail logs. The userIdentity element contains details about the type of IAM identity that made the request, and which credentials were used. If temporary credentials were used, the element shows how the credentials were obtained. Identify Federation is used for access to an account. Config will not log API activity. Lambda cannot scrape an entire account; it needs to access an S3 bucket of CloudTrail logs to take any action.","links":[{"url":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-user-identity.html","title":"CloudTrail userIdentity Element"},{"url":"https://docs.aws.amazon.com/config/latest/developerguide/log-api-calls.html","title":"Logging AWS Config API Calls with AWS CloudTrail"}],"answers":[{"id":"97ddb7778b0f9f5decefb8013df4d710","text":"Set up Identity Federation with SAML. Create IAM roles and create policies for employees to assume with the correct permissions. Log all requests using the Credential report.","correct":false},{"id":"73e4bf9add9c239534c52f8a03fb95fb","text":"Create a CloudTrail log to deliver files to an Amazon S3 bucket. Use Amazon Athena to query the logs to search for the userIdentity element.","correct":true},{"id":"41e73582d973a777c1838270973c1a5a","text":"Create a Lambda function that is triggered daily that scrapes the account for requests from any assumed roles. Have the Lambda function revoke access if any requests are non-compliant.","correct":false},{"id":"4ffef50c6af5fe0e395fb58ca8319f05","text":"Record all ongoing events in the AWS account using AWS Config. Create a CloudWatch alarm to send an SNS topic when an identity under AssumeRole makes a request to the account.","correct":false}]},{"id":"ba52dee8-0d6c-4faf-9121-0e64c18bbf1a","domain":"high-avail","question":"Your website is evenly distributed across 10 EC2 instances in 5 AWS regions. How could you configure your site to maintain high-availability with minimum downtime if one of the 5 regions was to lose network connectivity for an extended period of time?","explanation":"If you are designing to check for loss of contact with the instances you need to use \"Evaluate Target Health\" to confirm connectivity.  The Latency policy will eventually detect the unavailability; however it is not a real-time test.","links":[{"url":"http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html","title":"How Health Checks Work in Complex Amazon Route 53 Configurations"}],"answers":[{"id":"b5494c49d052d62119e11eab7d8499c7","text":"Create an Elastic Load Balancer to place in front of each EC2 instance. Set an appropriate health check on each ELB.","correct":false},{"id":"90875d19db265ba7b3931ecbd5a5d813","text":"Establish VPN Connections between the instances in each region. Rely on BGP to failover in the case of a region-wide connectivity outage.","correct":false},{"id":"dc1f9d897e82bca789bb2983fa7ce22d","text":"Create a Route 53 Latency-based Routing Record Set that resolves to an Elastic Load Balancer in each region. Set an appropriate health check on each ELB.","correct":false},{"id":"0e2faa25f8eb6371b513d8d442513b10","text":"Create a Route 53 Latency-based Routing Record Set that resolves to Elastic Load Balancers in each region and has the Evaluate Target Health flag set to \"True\".","correct":true}]},{"id":"05e4d4e8-28e3-4373-bbbd-06c207454310","domain":"data-man","question":"What is the first thing you should do to prevent your users from accidentally deleting objects in an S3 bucket?","explanation":"When a user performs a DELETE operation on an object, subsequent simple (un-versioned) requests will no longer retrieve the object. However, all versions of that object will continue to be preserved in your Amazon S3 bucket and can be retrieved or restored. Only the owner of an Amazon S3 bucket can permanently delete a version. You can set Lifecycle rules to manage the lifetime and the cost of storing multiple versions of your objects.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"Using Versioning"}],"answers":[{"id":"0b291595e5f35c7ba8fed39ca7464577","text":"Enable Versioning on the bucket.","correct":true},{"id":"4640422acdab41a13ddc95492dc9c60d","text":"Distribute objects via CloudFront.","correct":false},{"id":"534876320349a72fec1b677bbcc87c53","text":"Change all users' IAM permissions so they can only s3:Get*, s3:List* and s3:Put*.","correct":false},{"id":"7ce4f0314f67bee93968904b2ab51ac3","text":"Allow objects to be accessed only with signed URLs.","correct":false}]},{"id":"3714015f-1a0e-4b58-b904-42d21b082ce4","domain":"dep-prov","question":"You are running an EC2 instance with an attached EBS volume. Which of the following applies to EBS volumes?","explanation":"You cannot create snapshots from EBS volumes when hibernation is enabled on an instance. You can take a snapshot of an attached root volume, however this is not recommended as it may result in data inconsistency. If a snapshot is taken of an encrypted volume, it is automatically encrypted. Encrypted snapshots can be shared with other users of specific AWS accounts. For others to use your shared, encrypted snapshot, you must also share the CMK key that was used to encrypt it. Users with access to your encrypted snapshot must create their own personal copy of it and then use that copy to restore the volume.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html","title":"Creating Amazon EBS Snapshots"}],"answers":[{"id":"615c6b61cf777a5a029a4d97f7e0d897","text":"You cannot take a snapshot of an attached root volume.","correct":false},{"id":"ce3d4a8b603387b4c447b51080ecb934","text":"Encrypted snapshots cannot be shared with other users.","correct":false},{"id":"be7cc695163e3cfbe4fce331a5431ffe","text":"Snapshots that are taken from encrypted volumes are automatically encrypted.","correct":true},{"id":"f1854d1c449a2c9492159c401571eb3e","text":"You can create snapshots from instances for which hibernation is disabled.","correct":true},{"id":"d433815b2c570bc61e97ae01aad4e24c","text":"You can create snapshots from instances for which hibernation is enabled.","correct":false}]},{"id":"31081113-ca90-46fd-b9de-b0d861af38ab","domain":"automation","question":"A sports company has migrated systems to AWS but has not implemented any patching policy. A SysOps administrator has been hired to understand the current state of patching and help plan remediation. Which service can they use to understand the patch level of the EC2 instances?","explanation":"AWS Systems Manager provides a centralised location to view patching status of all Managed EC2 and on-prem instances. AWS Inspector, AWS Config and Macie are not services that can provide patch status reports.","links":[{"url":"https://docs.aws.amazon.com/en_pv/systems-manager/latest/userguide/systems-manager-patch.html","title":"AWS Systems Manager Patch Manager"}],"answers":[{"id":"113b1ad9ce6cdc3a37ad8475bc9bb2b2","text":"AWS Systems Manager","correct":true},{"id":"7c90c8f2a24f3a1a28525f19fb2c75ab","text":"AWS Inspector","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":false},{"id":"fefa18704e871eb671528fd4b7bc6ca2","text":"AWS Macie","correct":false}]},{"id":"d1f23ad4-6255-449e-ba3e-93f4ea692185","domain":"dep-prov","question":"You encounter problems while detaching an EBS volume through the Amazon EC2 console. What can help you diagnose the issue?","explanation":"The 'describe-volumes' CLI command can be used to gather further information to help with diagnosing volume issues and is therefore the most appropriate. The 'detach-volume --force' CLI command forces detachment if the previous detachment attempt did not occur cleanly (for example, logging into an instance, unmounting the volume, and detaching normally). This option can lead to data loss or a corrupted file system. Use this option only as a last resort to detach a volume from a failed instance. The 'Dismount-EC2Volume' PowerShell command will perform the same action as the EC2 console and will therefore not help with additional diagnosis. The 'fix-volumes' command is not a valid CLI command.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-detaching-volume.html","title":"Detaching an Amazon EBS Volume from an Instance"}],"answers":[{"id":"6dab4100f13c64be47fc0b254385f5ab","text":"Run the 'describe-volumes' CLI command.","correct":true},{"id":"75f13dd600a356952c8f887bd5bcb626","text":"Run the 'Dismount-EC2Volume' PowerShell command.","correct":false},{"id":"8f52ce0a3a674b594aaed05357a3d828","text":"Run the 'detach-volume --force' CLI command.","correct":false},{"id":"8f6461e3ace3c5f5cab7f6c269e12420","text":"Run the 'fix-volumes' CLI command.","correct":false}]},{"id":"78ad6dfb-14bd-44bf-a5a4-4af2076aae23","domain":"networking","question":"As your company's lead network administrator, you are helping the development team set up a VPC for an application in their AWS account. The application requires a network configuration such that the web servers of the application have connectivity to the Internet, and the database servers have VPN-only connectivity to the corporate network servers. What VPC set up would support this desired configuration? (Select all that apply)","explanation":"The scenario requires a VPC with an internet gateway, a virtual private gateway, a public subnet, and a VPN-only subnet. One route table has a route to the virtual private gateway in a private subnet. Another route table is explicitly associated with the public subnet. The custom route table has a route to the internet (0.0.0.0/0) through the internet gateway. A NAT instance in another private subnet would not allow Internet connectivity. The Direct Connect connection is unnecessary. The requirements does not allow placing database servers in public subnets.","links":[{"url":"https://docs.aws.amazon.com/en_pv/vpc/latest/userguide/VPC_Route_Tables.html","title":"Route Tables"}],"answers":[{"id":"31d58d613e8532ad19cdb0c73912f36d","text":"Place the database servers in a private subnet. Associate a route table to the private subnet that has a route to a virtual private gateway.","correct":true},{"id":"d7235003c798151a119f9b00b31cce7f","text":"Place the database servers in a public subnet with Direct Connect. Set up a Direct Connect connection to the servers in your on-premises environment.","correct":false},{"id":"4d167d5d0ddda70960f354da47b72e33","text":"Place the web servers in a private subnet. Associate a route table to the private subnet that has a route to a NAT instance in another private subnet.","correct":false},{"id":"f8f4044343da77cd7ab9710d8b6f5067","text":"Place the web servers in a public subnet. Associate a route table to the public subnet that has a route to the Internet through the Internet Gateway.","correct":true},{"id":"ac748fb5daa7fcaff151922fb2c482a4","text":"Place the database servers in a public subnet. Associate a route table to the public subnet that has a route to the Internet through the Internet Gateway.","correct":false}]},{"id":"c1701920-538e-488e-bbb1-d94d9bc2c547","domain":"data-man","question":"You are managing an S3 bucket containing confidential financial information for your finance department. The CFO downloads a reporting file but notifies you saying the data on the file is wrong. He claims the report should show updated numbers. You are sure you uploaded the most up-to-date file just moments ago. How would you explain the situation to your CFO?","explanation":"Amazon S3 offers eventual consistency for overwrite PUTS and DELETES in all Regions. Amazon S3 achieves high availability by replicating data across multiple servers within AWS data centers. If a PUT request is successful, your data is safely stored. However, information about the changes must replicate across Amazon S3, which can take some time. IAM user policies would not get around eventual consistency. The HEAD operation retrieves metadata from an object without returning the object itself. This implementation of the GetObjectTagging operation returns the tags associated with an object.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Amazon S3 Data Consistency Model"}],"answers":[{"id":"f9c3ce12a732ecf526c8cb22da10a5f6","text":"Explain to the CFO that he needs to perform the s3:GetObjectTagging action to specify the right version of the object.","correct":false},{"id":"0bb0509d4fa0d3e4e91e07eb79dabb78","text":"Explain to the CFO you need to the update the IAM user policy to allow GET requests for new versions.","correct":false},{"id":"6ae999a93c1570782ac4d7afbe01bfdc","text":"Explain to the CFO that Amazon S3 offers eventual consistency for overwrite PUTS and DELETES in all Regions.","correct":true},{"id":"e194d5d020090f2f6e93c362d734b897","text":"Explain to the CFO that he needs to retrieve the object using the HEAD request.","correct":false}]},{"id":"0a54c671-954d-4e52-8a46-83eadcf029cd","domain":"mon-rep","question":"Which of the following are valid alarm statuses in CloudWatch?","explanation":"The three alarm statuses are OK, INSUFFICIENT_DATA and ALARM.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html","title":"About CloudWatch Alarms"}],"answers":[{"id":"e0aa021e21dddbd6d8cecec71e9cf564","text":"OK","correct":true},{"id":"f5d0aa0db6ffc40d938f1412b89d946c","text":"INSUFFICIENT_DATA","correct":true},{"id":"9de6d0a670ae5a0dee31a6318aa00e8d","text":"ALARM","correct":true},{"id":"320f86f60f25459ba5550e000b2c3929","text":"ALERT","correct":false}]},{"id":"463d990a-0af1-4e11-ad8a-c379444c02fd","domain":"automation","question":"A government agency currently runs all of their AWS workloads in a single region. Services utilized include S3, EC2, ECS, RDS, CloudFront, and Route 53 in multiple accounts. Their new business continuity plan calls for readiness in a separate AWS region in case disaster recovery is needed. Which approach will provide them with the most efficient way to manage their primary and business continuity environments?","explanation":"By default, CloudFormation templates are tied to a single account and a single region. However, CloudFormation allows for the creation of a custom resource that can launch a nested stack in another account or region with the appropriate IAM roles setup. The CloudFormation parameter and mappings sections don't provide cross-region functionality. Creating templates in each account would also work, but will require significant maintenance to keep resource definitions in-sync across all the templates.","links":[{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/multiple-account-multiple-region-aws-cloudformation/","title":"Multiple-account, multiple-Region AWS CloudFormation"}],"answers":[{"id":"12eb00153c980c0e9e1fec8d03035f78","text":"Create AWS CloudFormation templates in each account and each region that provision stacks with the resources for their specific accounts/regions","correct":false},{"id":"fabf8fa8f7205c00448ae603a1d1af90","text":"Create AWS CloudFormation templates in a single account and configure the CloudFormation mappings section for the appropriate primary and business continuity regions","correct":false},{"id":"b3128e59899200446191df0bbc118793","text":"Create AWS CloudFormation templates in each account that provision stacks with resources into the primary and business continuity regions using the CloudFormation 'Region' parameter","correct":false},{"id":"21d658a249d3a95d1de0860519bd585b","text":"Create an AWS CloudFormation template in a single account that defines custom resources to launch nested stacks into the other accounts and regions","correct":true}]},{"id":"be30bba9-7133-43b6-b1b9-a21de73dbf17","domain":"dep-prov","question":"You have created a new Auto Scaling group and you discover that your instances are not launching in to it. Which of the following is not a reason that this might be happening?","explanation":"The instance type specified is not supported for Auto Scaling","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/ts-as-instancelaunchfailure.html#ts-as-instancelaunchfailure-6","title":"Troubleshooting Auto-Scaling"}],"answers":[{"id":"04c0d163b1711459d69938ad0495fba5","text":"The security group does not exist.","correct":false},{"id":"2094f86fb69fd7383b4a5b26e6fa5f65","text":"The associated Key Pair does not exist.","correct":false},{"id":"6788d6762b58bb5d71fe6d713712ca09","text":"The requested configuration is currently not supported.","correct":false},{"id":"21ff5db3973f2b3f7cf4a218ae1bb59f","text":"The instance type specified is not supported for Auto Scaling.","correct":true}]},{"id":"5ceb6c5a-1a50-493f-8b62-f46ff8ad6bbc","domain":"mon-rep","question":"You have a new manager who would like to talk about ideas for optimizing your AWS environment as well as increasing performance and improving security. Which AWS tool can you use to get insights into your environment to help determine what should be done?","explanation":"Trusted Advisor can help you reduce cost, increase performance and improve security by optimizing your AWS environment, Inspector allows you to perform vulnerability assessments on applications running on EC2, AWS Shield provides DDOS protection, Systems Manager is an Operational Management tool","links":[{"url":"https://aws.amazon.com/premiumsupport/trustedadvisor/","title":"Trusted Advisor"}],"answers":[{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":true},{"id":"8e75b153e61c22a8ea4e14aadc7cb4ee","text":"Systems Manager","correct":false},{"id":"9deb03cd21d41a691cdc24bfaab2820c","text":"Inspector","correct":false},{"id":"637d82e8a7206e87344161109cf7112d","text":"AWS Shield","correct":false}]},{"id":"cecf0320-a724-4341-a1c2-597f1f45ee50","domain":"security-comp","question":"A development company has been given the task of designing and building a mobile application along with a backend server for a charity event. The photos taken using the mobile application need to be directly uploaded to S3. The appropriate security controls must be implemented, in that the photos can only be accessed by the users who uploaded them. In addition to this, the charity event is expected to host hundreds of users who will use the mobile application. The engineering manager has mandated that the designed solution must be as secure and scalable as possible. How can the development company accomplish this?","explanation":"AWS STS is used to request temporary credentials for IAM entities such as IAM roles. It does not create IAM users as the operations available focus on assuming the role. When the AssumeRole operation is used with an IAM role with the appropriate permissions, a set of temporary credentials is available to be used to perform the needed operations.","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html","title":"API Assume Role"},{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_use-resources.html","title":"ID Credential Temporary Use Resources"}],"answers":[{"id":"341595f8a8029ec2428a765f8afe97d8","text":"Create an IAM user using AWS STS for each user with the appropriate permissions to the S3 bucket. Store the user's information and generated credentials in DynamoDB. Upon using the mobile application, load the credentials mapped to the corresponding IAM user in order to access S3. Generate new credentials every time the application is used.","correct":true},{"id":"5fb28fa0a1ba63fdc85716ab1b6d0e10","text":"Generate long-term credentials using AWS STS for each user. Store the user's information and generated credentials in DynamoDB. Upon using the mobile application, load the credentials mapped to the corresponding user in order to access S3.","correct":false},{"id":"81bf4204e57252aea98b18f2d2eef4a8","text":"Store the user's information in DynamoDB. Create an IAM role for each user with the appropriate permissions to the S3 bucket. Upon using the mobile application, generate temporary credentials using AWS STS's AssumeRole operation in order to access S3. Generate new credentials every time the application is used.","correct":false},{"id":"5e96ca666fbc203287ba81688806b0a7","text":"Create an IAM user using AWS STS for each user with the appropriate permissions to the S3 bucket. Store the user's information and generated credentials in AWS ElastiCache. Upon using the mobile application, load the credentials mapped to the corresponding IAM user in order to access S3.","correct":false}]},{"id":"fcfd9e09-dd0c-45a2-abb0-a6d92297ef92","domain":"security-comp","question":"You have just been hired as a CISO at a space exploration company that makes rockets. The company has contracts with the US airforce and has very strict IT requirements. You discover that on your first day a third party IT auditing company is on site and they are after security and compliance documents such as AWS ISO certifications, Payment Card Industry (PCI), and Service Organization Control (SOC) reports. Which AWS service can help you meet this need?","explanation":"All AWS accounts can get access to AWS compliance documentation using AWS Artifact","links":[{"url":"https://aws.amazon.com/artifact/","title":"Artifact FAQs"}],"answers":[{"id":"fa092ee9faf62930336257691a3dbfe8","text":"AWS Config Manager","correct":false},{"id":"05a080cb7d6b6da90ca133767496ccb0","text":" AWS Artifact","correct":true},{"id":"7c90c8f2a24f3a1a28525f19fb2c75ab","text":"AWS Inspector","correct":false},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":false}]},{"id":"4e911348-5056-4ece-a91d-ce96b619578f","domain":"automation","question":"The DevOps team of an insurance company has been instructed to use CloudFormation to manage the different environments of the company. Due to the size of the templates prepared exceeding the limit, the CloudFormation service rejected the processing of the template. How can the DevOps team resolve this issue?","explanation":"Due to the size of the templates exceeding the limit, dividing the CloudFormation template into smaller subparts is the solution. With this in mind, CloudFormation nested stacks will yield to the same template behavior but will involve different files","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html","title":"Using CloudFormation Nested Stacks"}],"answers":[{"id":"e29c7f5b3439e3e8355a1e6bede51fa1","text":"Minify the CloudFormation template","correct":false},{"id":"d4838aa62aeb5717c4100906a75dea2d","text":"Use CloudFormation nested stacks","correct":true},{"id":"f163f3aff96f7db10bfa4b93ed9a0a67","text":"Use CloudFormation wait handlers","correct":false},{"id":"1d75dba4b52318bdc075c815a7690e4c","text":"Use CloudFormation custom resources","correct":false}]},{"id":"745e3728-9374-48a2-b7ab-7ee0c4ad4ad6","domain":"security-comp","question":"Your AWS Organization includes multiple AWS accounts. To meet the security compliance, AWS Config should be enabled in all accounts. The data needs to be recorded in all regions as well. You prefer using a central place to view all the resource configurations and compliance data recorded in AWS Config. How would you configure it?","explanation":"An aggregator is an AWS Config resource type that collects AWS Config data across multiple accounts and multiple regions. You can easily add an AWS Organization and select all regions in the aggregator. After that, you can get an aggregated view of the configuration information of AWS resources, an overview of Config rules and their compliance state. You do not need to manually enable AWS Config in all regions and all accounts. And AWS Config cannot be enabled in the AWS Organizations panel.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/setup-aggregator-console.html","title":"Setting up an aggregator in AWS Config"}],"answers":[{"id":"2317a132eeda89bc0a88eb9b628b6d06","text":"In AWS Organizations panel, enable AWS Config for all the regions. View the centralized configuration data in AWS Organizations.","correct":false},{"id":"6bfb56d27b2d920c4cc3001c82233f29","text":"Create an aggregator in AWS Config. Add the AWS Organization to the aggregator and select all AWS regions.","correct":true},{"id":"a856258c8005e338f9c1b40c80449899","text":"Enable AWS Config in all regions and all accounts. Select an S3 bucket to store all the configuration data.","correct":false},{"id":"4787f6c13efd28a83db2125402fa372b","text":"Enable AWS Config in all regions for each account. Configure AWS QuickSight to view the aggregated data.","correct":false}]},{"id":"4f95f73a-fabd-44b4-a043-0bdee8159a99","domain":"security-comp","question":"You are a SysOps Administrator running security checks throughout your AWS environment. Your AWS account recently launched a new application and you need to ensure access to the application's web servers is restricted to certain ports. How would you implement a policy so that SSH traffic from port 3389 is restricted?","explanation":"The restricted-common-ports checks whether the incoming SSH traffic for the security groups is accessible to the specified ports. The rule is COMPLIANT when the IP addresses of the incoming SSH traffic in the security group are restricted to the specified ports. This rule applies only to IPv4. Amazon Inspector helps to identify security vulnerabilities as well as deviations from security best practices in applications, but not for security groups.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/restricted-common-ports.html","title":"AWS Config rules"}],"answers":[{"id":"3bd73de961085bba965e8589f52a6c08","text":"Install the Amazon Inspector agent on your application to run automated security assessments to identify and restrict any SSH traffic originating from port 3389.","correct":false},{"id":"c2e5ba2c7f9b96b874027fd22e836d7d","text":"Restrict the application to run only on Linux/Unix instances.","correct":false},{"id":"6e274e1e00f14fe4302875974cf5b4c1","text":"Architect your application using the IPv6 communications Internet Protocol.","correct":false},{"id":"3783cbf28ccda5bf3b6aa20d913bb34e","text":"Set up and activate the restricted-common-ports AWS Config rule.","correct":true}]},{"id":"571b9603-45b6-45b1-aa47-68849ac814bb","domain":"automation","question":"A big-box retailer runs their in-store point-of-sale system on EC2 linux instances. All of the infrastructure is managed as part of a CloudFormation stack. The web servers are part of an Auto Scaling Group. The application only needs to be available during business hours from 9:00am until 6:00pm. What would be the best way to scale the web servers cost efficiently based on demand?","explanation":"Authoring the CloudFormation template to include an AutoScaling:ScheduledAction resource to increase the Auto Scaling Group's MinSize and MaxSize values at 9:00am, and another AutoScaling:ScheduledAction resource to decrease the Auto Scaling Group's MinSize and MaxSize values at 6:00pm will save costs for the retailer during non-business hours. CloudFormation conditions control whether certain resources are created or whether certain resource properties are assigned a value during stack creation or update, but don't control the actions of an Auto Scaling Group. Using an Auto Scaling Group scheduled action provides more streamlined automation than using a Lambda function. CloudFormation mappings are key/value pairs that can be used to specify conditional parameter values, but they have no impact on the Auto Scaling Group unless they are used to create a resource.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"What is AWS CloudFormation?"},{"url":"https://s3-us-west-2.amazonaws.com/cloudformation-templates-us-west-2/AutoScalingScheduledAction.template","title":"Cloud Formation Sample Template for Time-based Auto Scaling"}],"answers":[{"id":"0db6203397832efddcbca893f96ba1b6","text":"Include AutoScaling:ScheduledAction resources in the CloudFormation template that change Maxsize, MinSize, and Recurrence values based on business hours","correct":true},{"id":"765dccb8332e2036eb70a0b6276e7285","text":"Use CloudWatch Events to trigger a Lambda function at business opening and closing that adjusts the Auto Scaling Group's MinSize and MaxSize accordingly","correct":false},{"id":"725933a9f7ea7ef281e2decf6cefadae","text":"Configure AutoScaling:ScheduledAction mappings in the CloudFormation template with Maxsize, MinSize, and Recurrence values based on business hours","correct":false},{"id":"a0f99978bb65910b10b75a32e1b92a2a","text":"Create AutoScaling:ScheduledAction conditions in the CloudFormation template that change Maxsize and MinSize values based on business hours","correct":false}]},{"id":"1a45301ef-de9d-42bb-842d-8c1a42220a08","domain":"mon-rep","question":"There is increasing demand of your application running on EC2, and you need to monitor available memory space to ensure you can scale with demand. How would you monitor this on AWS?","explanation":"Memory and disk space utilization is a custom metric that is CloudWatch does NOT collect natively. Users must install the CloudWatch agent to collect metrics for memory and disk space. Neither the EC2 Dashboard nor the CloudWatch Dashboard natively provides the ability to monitor memory. You much install the CloudWatch Agent on your instances. AWS would not provide this report as these are specific to your EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html & https://aws.amazon.com/blogs/aws/amazon-cloudwatch-user-defined-metrics/","title":"CloudWatch Custom Metrics"}],"answers":[{"id":"4a31b453359b5547f03d47279651a6c7","text":"Install the CloudWatch Agent on your instance to monitor memory metrics.","correct":true},{"id":"fcf91ec5e036123e3b515882a4d079eb","text":"Create a Support Case to AWS and request a report on available memory space on your instances.","correct":false},{"id":"f5537acc0c2715be1415c64741ce5ed7","text":"Check the EC2 Dashboard to monitor instance metric details.","correct":false},{"id":"25084caeeca98bb0ed5317e16eb25f5b","text":"Utilize the CloudWatch Dashboard to view memory and disk metrics that are available by default.","correct":false}]},{"id":"2b08815b-ca6c-44ed-969b-8cc0dfc22faf","domain":"data-man","question":"A large real estate broker wants to provide a mobile device dashboard of home sales trends by geographic area for its agents. Dashboard metrics will be updated three times each day based on recent activity. The backend application will run on Linux servers in the company data center. Minimizing operational costs is a priority, so they've decided to store the application's data on AWS. Which storage solution will be the most cost effective?","explanation":"A Storage Gateway Volume Gateway in cached mode uses S3 as it's primary storage and caches frequently accessed data locally. A Volume Gateway in cached mode will be more cost effective than one in stored mode because only 20% of the storage capacity needs to be purchased for the on-premises Storage Gateway server in cached mode, whereas the full storage capacity needs to be purchased for a stored mode gateway. Amazon EFS Standard storage is currently $0.30 per GB per month, whereas Storage Gateway Volume Gateway pricing is currently $0.023 per GB per month. EBS volumes can only be accessed by EC2 instances, not remotely as iSCSI devices.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/StorageGatewayConcepts.html","title":"How AWS Storage Gateway Works (Architecture)"}],"answers":[{"id":"1510097be2cd1ce079dfc261617a8176","text":"Store the data on Amazon Elastic Block Store volumes. Mount the volumes as iSCSI devices through a VPC endpoint","correct":false},{"id":"f79405543a29779912fb22c1d8fd858f","text":"Deploy an Amazon Elastic File System file system and mount it via NFS","correct":false},{"id":"eca78458c820df850fbb09ee72a3cabe","text":"Implement an AWS Storage Gateway Volume Gateway in cached mode. Mount the volumes as iSCSI devices on the servers","correct":true},{"id":"6179b86bded76a4fa17bb52009d596e7","text":"Use an AWS Storage Gateway Volume Gateway in stored mode. Mount the volumes as iSCSI devices on the servers","correct":false}]},{"id":"8938dba3-4740-4cfa-9226-f27006233c27","domain":"security-comp","question":"You work for a large multi-national corporation who has literally 100’s of AWS accounts. Some of these accounts belong to subsidiary companies, some to departments and some to individual teams. You need to implement a strategy so that when a new account is created you can lock down which AWS services are available to that account on an account by account basis. What is the easiest way to do (and manage) this?","explanation":"SCPs enable you to restrict, at the account level of granularity, what services and actions the users, groups, and roles in those accounts can do.","links":[{"url":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html","title":"Service Control Policies"}],"answers":[{"id":"55006bb8960ca3bd15aedc34fc19c9fe","text":"Using AWS Organizations Service Control Policies (SCP)","correct":true},{"id":"27f329a839e5b524103723898c84aaf4","text":" Using AWS Cognito","correct":false},{"id":"74765eedd0b4460b44e6233fb940b347","text":"Using IAM Policies within each individual AWS account","correct":false},{"id":"55b133327fbc344978b0c06c0821cf5f","text":"Using AWS Inspector with Lambda Integration in to Athena","correct":false}]},{"id":"8dade21b-c268-4ccd-af0a-18c01cd2c638","domain":"automation","question":"You check the last bill of your AWS account and find that the storage of EBS snapshots charges a lot. A large number of EBS snapshots are very old and can be deleted. You want to keep 10 snapshots for an EBS volume and old snapshots are deleted automatically. The strategy should also help you to create a snapshot every 24 hours. Which is the best way of implementing this strategy?","explanation":"The Amazon EBS Snapshot Lifecycle can automate the creation, retention, and deletion of EBS snapshots. You only need to configure a lifecycle policy in the Lifecycle Manager. You do not need to configure a Lambda Function or a Cron job in an EC2 instance to implement the same policy.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html","title":"Automating the Amazon EBS Snapshot Lifecycle"}],"answers":[{"id":"ac159fa50438475f44d25f96b6a2bea4","text":"Configure a Lambda Function that runs every 24 hours to create a snapshot and delete the old snapshot.","correct":false},{"id":"e711537d471732823f103b6f63ab96c2","text":"Configure a Cloudwatch Event rule to execute every 24 hours. The target is a Lambda Function that creates a new snapshot and deletes the old one.","correct":false},{"id":"630f293528bb790c603b2f77b266a56d","text":"Use a Cron job that runs in an T2.micro EC2 instance. The job creates a new snapshot and deletes the old one every day.","correct":false},{"id":"6e23ea86e4cf4e8929aa5b846a7e5ad4","text":"Create a Snapshot Lifecycle Policy to automatically create new snapshots and delete old snapshots.","correct":true}]},{"id":"939386e8-1d77-444a-a32f-4191025a74e2","domain":"networking","question":"You are working on a project to launch a new online trading application. Many of your competitors have already suffered DDOS attacks and your Security Architect wants to know how you can mitigate against these sorts of attacks. What do you suggest?","explanation":"AWS Shield is a managed Distributed Denial of Service (DDoS) protection service that safeguards applications running on AWS. AWS WAF provides protection against different types of attack like SQL injection and cross-site scripting but not specifically DDOS.","links":[{"url":"https://aws.amazon.com/shield/faqs/","title":"AWS Shield FAQs"}],"answers":[{"id":"83ad2fe9589162c814a040ab0d753c45","text":"Use AWS Shield","correct":true},{"id":"8517d0c67040a9d1b4358594409eeae0","text":"Use Security Groups and Network ACLs","correct":false},{"id":"059fc274da3193f55a6bb268b21e06ce","text":"Host based IDS / IPS","correct":false},{"id":"f0f0e94fb03611cf4f38fe1117e6e76e","text":"Use AWS WAF","correct":false}]},{"id":"9978967d-f05e-4b23-8986-7da169fd0cc2","domain":"security-comp","question":"Your Security Officer is concerned about the possibility of a malicious attack where the attacker encrypts your S3 data to prevent you from accessing it. What can you do to mitigate against this sort of attack?","explanation":"S3 versioning allows you to keep multiple copies of your S3 objects and also allows you to restore to any previous version.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"S3 Versioning"}],"answers":[{"id":"c096c42714a02baa6f6564ecf6b18170","text":"Back up your data to Glacier","correct":false},{"id":"9812b667f70a93c61305e39d4f5273a8","text":"Enable Bucket Polcies","correct":false},{"id":"7a3ff06e3e1f727a50908c5a048bd560","text":"Enable S3 versioning","correct":true},{"id":"81ae2d173c6b51a849ce2b9f23e93948","text":"Enable MFA delete","correct":false}]},{"id":"3d005524-36c5-4851-8500-665f29e4c0b7","domain":"networking","question":"A team of engineers has set up a VPC with EC2 web instances in the public subnets and the RDS instances, EC2 background worker instances and the NAT Gateways in the private subnets. The team has noticed that the background worker instances do not have internet connectivity and the issue might be due to the VPC setup. How can the team resolve this issue?","explanation":"NAT gateways need to be in the public subnet in order for the resources in the private subnet to have internet connectivity. Usually, the default route for a private subnet points to the NAT gateway. If the NAT gateway is in a private subnet, then the traffic cannot reach the internet and the resources in the private subnet won't have internet connectivity.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html","title":"VPC Scenario"}],"answers":[{"id":"85f3551b459e74e7bf48aa77dbe7a729","text":"Create a new VPC with only private subnets. Transfer the background worker instances to the new VPC. Set up a peering connection to the new VPC from the original VPC.","correct":false},{"id":"73cbf7879ad8bbb9f58a4e7bb9a999c9","text":"Turn off the NAT Gateways in the private subnets. Create new NAT Gateways in the public subnets.","correct":true},{"id":"210235cf61b065b37cf583e72630e77c","text":"Create a new VPC with only private subnets. Transfer the background worker instances and the NAT Gateways to the new VPC.","correct":false},{"id":"4fd2e84c5c3112b4c0f92f51aed239f1","text":"Set up new NAT Gateways in the private subnets until the background worker instances start getting internet connectivity.","correct":false}]},{"id":"b84511ce-eca6-4a78-8b45-e76b4a0f37af","domain":"data-man","question":"An organization is moving its existing data lake from on-premises SAN storage to AWS.  You have 30TB of data to move. Your new cloud footprint includes an AWS Direct Connect link of 200Mbps, which is used for the mission critical link between your offices and the new systems in Production in AWS. Which of the below options would you recommend for the fastest transfer to AWS S3?","explanation":"With such a large amount of data to transfer it makes sense to use the AWS Snowball service.  Additionally flooding the Direct Connect connection with such a lot of traffic for several weeks would be a high risk to Production.  Snowball will provide a reliable and quick way to move the data. AWS DataSync is another possible candidate but it will place a heavy load on the Direct Connect link.","links":[{"url":"https://aws.amazon.com/snowball/faqs/#when-to-use","title":"AWS Snowball FAQs"}],"answers":[{"id":"c2d838ea2b9043be2161255da328dc60","text":"AWS Snowball","correct":true},{"id":"56169776bdeba6f7384a8ad473b0fc72","text":"AWS Data Sync","correct":false},{"id":"64bf8ac94115dbfb0847b75ceda67d5a","text":"AWS S3 Accelerated Transfer","correct":false},{"id":"0d9da8d932c0312c10d819af40de0ba8","text":"AWS Snowball Edge","correct":false}]},{"id":"cf072a65-cda4-492e-b42a-7ee7305bb9b6","domain":"high-avail","question":"You have a web application with the front end hosted on EC2 and the database hosted on RDS in a single Availability Zone. You notice that when backups are taken from your RDS instance, your applications performance is severely degraded. Your boss asks you to fix the issue. What should you do?","explanation":"You should create a multi-AZ RDS instance and migrate your DB to it. This way, when the backups are taken, they will be taken from the secondary -- not the primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"Multi-AZ RDS"}],"answers":[{"id":"ebcb098cff009244307167ae9489e2b1","text":"Create a multi-AZ RDS instance and migrate your DB to it. This way, when the backups are taken, they will be taken from the secondary -- not the primary.","correct":true},{"id":"82ca3fd61d44001c088391d1a6af1442","text":"Upgrade your RDS instance to an instance that has better disk IO. This way, the IO suspension from the back up will be \"equaled out\" by the increase in the new IO from the upgraded instance.","correct":false},{"id":"531a46711a70d61a60f10cf29f31171b","text":"Move your RDS instance to an in-house SQL server that has Netbackup installed.","correct":false},{"id":"ff7e77cc465d1a0285e8ea4c236bee2c","text":"Turn off backups for RDS. This will fix the performance issue immediately.","correct":false}]},{"id":"762031fb-db4e-4e09-bab4-09bf0fc50472","domain":"high-avail","question":"You run a very popular fashion blog and during a major event your wordpress site struggles immensely with the amount of traffic that you are receiving. The wordpress site sits across a fleet of EC2 instances in an autoscaling group which scales based on CPU utilization. You notice from your CloudWatch metrics that your webservers appear fine, however your back end Aurora database is running at 100% CPU Utilization. What can you do to alleviate the situation?","explanation":"Aurora Replicas are independent endpoints in an Aurora DB cluster, best used for scaling read operations and increasing availability","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html","title":"Aurora Read Replicas"}],"answers":[{"id":"98a15d02b2c6ead5dff3036e99269acd","text":"Place the Aurora database in to a the same Autoscaling group as the EC2 instances and configure the launch configuration to deploy new Aurora instances whenever a node capacity reaches 80% for 5 minutes","correct":false},{"id":"f663aa878eb8286dbadf97aa0f95be56","text":"Add additional Aurora Read Replica Nodes and update your connection string on the webservers to point to the new nodes to spread the load","correct":true},{"id":"10239931e046b099c14736b5b9c422d0","text":" Place the Aurora database in to a separate Autoscaling group and configure the launch configuration to deploy new Aurora instances whenever a node capacity reaches 80% for 5 minutes","correct":false},{"id":"e38c819297b357216e3ddc63cecd22ec","text":"Migrate from Aurora to MySQL RDS instance with multi-AZ turned on to better handle the load","correct":false}]},{"id":"e6e97329-0325-41bb-99cd-95f73d8cbf7b","domain":"security-comp","question":"You are running a public facing website which is hosted on 6 EC2 instances across 2 AZs. Your security team have identified some suspicious traffic originating from a public IP address outside your organisation, and you have been asked to block this IP from your public website. What is the quickest and simplest way to achieve this?","explanation":"Of all the options, using subnet NACLs is the quickest and easiest. Security Groups do not allow block rules so can be discounted. AWS Firewall Manager is used to manage multiple instances of AWS WAF and Shield Advanced, and neither of those are mentioned in this scenario. Although using iptables would work for linux EC2 instances, it adds unneeded complexity to the issue.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"AWS Network Access List"}],"answers":[{"id":"e4603e8c6c15ef19dd3adf7da6725d16","text":"Use the System Manager to run the \"iptables -A INPUT -s <IP-ADDRESS> -j DROP\" on all the servers,","correct":false},{"id":"672072a1bc5bd9c47eb8de77e500d285","text":"Add a block rule to the security group of your web EC2 instances","correct":false},{"id":"fd8b9b77d42ae65ac062f3da9516a18c","text":"Add a block rule to AWS Firewall Manager","correct":false},{"id":"a1286c8d10d0d6ae23294cfd877c9f5b","text":"Add a block rule to the NACLs on the public subnets","correct":true}]},{"id":"d172a098-e8e9-4981-87fc-40928c69b876","domain":"data-man","question":"In order to reduce spending on AWS services, you are checking if some CMKs (Customer Managed Keys) can be deleted in KMS. There is one CMK that you are unsure which services it is used for so it may be unsafe to simply delete it. What is the best way to deal with this situation?","explanation":"If you are unsure if a CMK is used, you should consider disabling the CMK instead of deleting it. There is no method to delete the key metadata. CMK has a monthly cost even if there is no API request to it. So unused CMK should still be deleted.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/deleting-keys.html","title":"Deleting Customer Master Keys"}],"answers":[{"id":"f8b96cef3d30ff7e4cac2bedd042a583","text":"Schedule the deletion of key metadata associated with the CMK instead of key material.","correct":false},{"id":"176c2c627c3957be4132c811103faacc","text":"Do not delete the key as there is no cost if the key is not used.","correct":false},{"id":"4bbaecfad45762c81721e6ba32ca7779","text":"Schedule the key deletion with a waiting period of 3 days. Cancel the key deletion if it influences any service.","correct":false},{"id":"d7e6e2722199a0f88bf08a617703a934","text":"Disable the key first. If it does not impact any service, schedule the key deletion with a default waiting period.","correct":true}]},{"id":"dc1b5bc1-79d0-49ab-9c2f-e0dea66f0361","domain":"dep-prov","question":"You are helping to migrate a customer from their on-premise data center to AWS. The customer has over 1,000 users in their Active Directory service and wants to be able to using their existing on-premise directory to quickly and easily log into AWS. The customer wants to be able to continue using Microsoft Active Directory with AWS. How would you configure this set up for the customer?","explanation":"AD Connector helps connect your on-premises Microsoft Active Directory to the AWS cloud. AD Connector is designed to give you an easy way to establish a trust relationship between your Active Directory and AWS. With AD Connector, you can streamline identity management by sourcing and managing all your user identities from Active Directory. It also enables you to reuse your existing Active Directory security policies such as password expiration, password history, and account lockout policies. Also, your users will no longer need to remember yet another user name and password combination. SimpleAD does not connect existing on-premises AD to AWS. SimpleAD is a Microsoft Active Directory compatible directory from AWS Directory Service and supports common features of an active directory. AWS Directory Service for Microsoft AD is an AWS managed service that is hosted on the AWS cloud, it does not connect your AD with AWS. Creating IAM users, groups, and roles would not be feasible with 1,000 users and is not best practice.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/active-directory-ds/architecture.html","title":"Deployment Scenarios and Architecture"}],"answers":[{"id":"63140d266692d56af00a75ac1e583ff5","text":"Use AWS Directory Service for Microsoft AD to connect the on-premise Microsoft Active Directory to AWS.","correct":false},{"id":"3d15e64aa60139df5f0cd74532823f6f","text":"Create IAM users, groups, and roles based on the current on-premise users to mirror their permissions on AWS.","correct":false},{"id":"59dc56b1ea5b335ecde98e0658573ae3","text":"Use SimpleAD to connect the on-premise Microsoft Active Directory to AWS.","correct":false},{"id":"2b121dea9ea29a83bc210acdacd096e4","text":"Use AD Connector to connect the on-premise Microsoft Active Directory to AWS.","correct":true}]},{"id":"4672c614-c5ab-464a-9de0-5ef85a8d081e","domain":"automation","question":"You are a SysOps Administrator for your company. The company's CIO was on vacation and didn't know that there was an AWS Region outage during her time off. She returned having no idea of the impact and wants to be alerted the next time an outage occurs whether or not she is on vacation. How would you implement a solution?","explanation":"You can use Amazon CloudWatch Events to detect and react to changes in the status of AWS Personal Health Dashboard (AWS Health) events. Then, based on the rules that you create, CloudWatch Events invokes one or more target actions when an event matches the values that you specify in a rule. Depending on the type of event, you can send notifications, capture event information, take corrective action, initiate events, or take other actions. Creating a Lambda function may be possible but is overly complicated. An AWS Config rule may also work but is not as efficient as using AWS Health directly. Amazon Inspector is used to assess security for applications deployed on EC2 and is not appropriate for this case.","links":[{"url":"https://docs.aws.amazon.com/health/latest/ug/cloudwatch-events-health.html","title":"Monitoring AWS Health Events with Amazon CloudWatch Events"}],"answers":[{"id":"984716f59e8039a5c670fd67e008a4e7","text":"Create a Lambda function that parses through the AWS Service Health Dashboard to identify outages in certain Regions. Have the Lambda function email the CIO using SES.","correct":false},{"id":"d34ecb714b1da223e3ec16bc80d4193b","text":"Configure an AWS Config rule that checks to see if any Regions are suffering outages. Have the configure trigger a Lambda function that will send an email to the CIO.","correct":false},{"id":"0825ebcd89b98147868bbea3888611bd","text":"Use Amazon Inspector to assess service health. Have Amazon Inspector produce reports for you to review and forward these reports to the CIO for those containing outages.","correct":false},{"id":"74245b5d3f6507fb9fbf04a80d0edc0a","text":"Send custom text or SMS notifications to the CIO with Amazon SNS when an AWS Health event happens by using Lambda and CloudWatch Events.","correct":true}]},{"id":"cc89c061-ab6b-4cb4-8809-12daecdbc5b4","domain":"networking","question":"A SaaS company has an existing web application set up in the AWS Singapore Region. The company created a new web application setup in the Tokyo Region. The company decided to host an active-active setup with the traffic evenly distributed between the Singapore region setup and the Tokyo region setup. The company currently uses Route 53 to manage the routing policies. How can the company accomplish this?","explanation":"Route 53 Weighted Routing Policy can distribute traffic evenly between two application environments. The Failover routing policy is only used for routing requirements involving a primary setup and a backup / failover setup. Creating and adding load balancers in the architecture will not solve the problem.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Route 53 - Routing Policy"}],"answers":[{"id":"71053c311ca592ed50fdc7ec6c5a98f5","text":"Create an Application Load Balancer in the Singapore Region. Register the two web application environments in the Application Load Balancer. Point the Route 53 record set to the Application Load Balancer.","correct":false},{"id":"c6c1e82d29d79462db966c3f61ab6b84","text":"Use the Route 53 Failover Routing Policy","correct":false},{"id":"ad3851f2c1fb167d0adcff683b66ac90","text":"Use the Route 53 Weighted Routing Policy","correct":true},{"id":"b050fdf9ffd82093c1a184237e0849ca","text":"Create a Network Load Balancer in the Singapore Region. Register the two web application environments in the Network Load Balancer. Point the Route 53 record set to the Network Load Balancer.","correct":false}]},{"id":"557a8cbf-ffb7-492a-b24a-7662b95c6269","domain":"automation","question":"A startup is planning to migrate their existing on-premise application to AWS. The company is already using Chef as the configuration management tool to manage their on-premise application and is looking to continue using Chef to manage their AWS resources. In addition to this, the team is looking to use a managed service to reduce the overhead of managing its PostgreSQL databases. How can the team accomplish this?","explanation":"OpsWorks is a managed service for Chef and Puppet and can easily be used to deploy and manage resources utilizing the Chef recipes already prepared. CloudFormation uses AWS's own engine to process and convert JSON or YAML templates to AWS resources. For requirements involving Chef and Puppet, OpsWorks is the primary (and only) managed service. For managed database service requirements, Aurora, RDS, and DynamoDB can be used as the managed database.","links":[{"url":"https://aws.amazon.com/opsworks/","title":"OpsWorks"}],"answers":[{"id":"ce66fcb736d2db75172e1c56777a36e1","text":"Use CloudFormation for the configuration management requirements. Use Aurora for the database management requirements.","correct":false},{"id":"378e25243c4a87f77553aed4ddbb2808","text":"Use ECS for the configuration management requirements. Use Athena for the database management requirements.","correct":false},{"id":"5b18a2364c2c69356af48e23e5347e81","text":"Use Elastic Beanstalk for the configuration management requirements. Use DynamoDB for the database management requirements.","correct":false},{"id":"33b2bf9a830d2dddb0570706a774902f","text":"Use OpsWorks for the configuration management requirements. Use RDS for the database management requirements.","correct":true}]},{"id":"55e3410c-cf36-4a46-948a-95e2440003fd","domain":"mon-rep","question":"You are running an Application Load Balancer (ALB) in front for a fleet of web servers running on EC2. These servers are in a public subnet. Your customers connect to the ELB domain name to access web servers using HTTP. You want to know your customers' IP addresses to gain metrics into where your customers are located. This information will be helpful for improving your application based on the location of your customers. How would you collect log data for your ELB?","explanation":"The X-Forwarded-For request header helps you identify the IP address of a client when you use an HTTP or HTTPS load balancer. Because load balancers intercept traffic between clients and servers, your server access logs contain only the IP address of the load balancer. Elastic Load Balancing stores the IP address of the client in the X-Forwarded-For request header and passes the header to your server. If you were using TCP protocol (rather than HTTP), no additional configuration would be needed. CloudTrail is not appropriate as it only shows data regarding API requests sent within your AWS account. CloudWatch and Lambda would be an administrative burden and are not necessary.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html","title":"HTTP Headers and Classic Load Balancers"}],"answers":[{"id":"0fcaa257260dc2e705852935fcc43979","text":"Modify the application code to pull the client IP into the X-Forwarded-For header so the web servers can parse the information.","correct":true},{"id":"db95fed268eaf12b5b9c069f8256be2f","text":"Enable CloudTrail on your ELB and push the logs to an S3 bucket. Search the logs using Athena or download them as a CSV to identify the IP addresses of your customers.","correct":false},{"id":"c790427146d378ddfcfb7c4e0821a00c","text":"No additional configuration is needed. The proxy protocol will pass the client IP automatically, and you can check the ELB logs to find this information.","correct":false},{"id":"ee23873239420b48da4e1d7e54294f34","text":"Enable CloudWatch logs for your application and push the logs to a custom CloudWatch metric. Use Lambda to parse through the log files to search and extract the client IP addresses into a DynamoDB table.","correct":false}]},{"id":"d585a94b-6bfb-47bf-83b2-d92525fa925b","domain":"security-comp","question":"Your CFO would like to hire a consulting company called CostControl Corp to monitor your AWS account and help optimize costs. In order to track your daily spending, CostControl Corp needs to access your AWS resources. CostControl Corp also monitors many other AWS accounts for other customers. How would you grant CostControl Corp access to your account in a secure and administratively efficient way?","explanation":"Do not give CostControl Corp access to an IAM user and its long-term credentials in your AWS account. Creating an IAM Group would still require long-term credentials. Instead, use an IAM role and its temporary security credentials. An IAM role provides a mechanism to allow a third party to access your AWS resources without needing to share long-term credentials. You can use an IAM role to establish a trusted relationship between your AWS account and a third party. After this relationship is established, a member of the exteranl account can call the AWS STS AssumeRole API to obtain temporary security credentials. Cognito is a web service that delivers scoped temporary credentials to mobile devices and other untrusted environments.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html","title":"How to Use an External ID When Granting Access to Your AWS Resources to a Third Party"}],"answers":[{"id":"511bbeb0af589b7478846f2bc4488bb7","text":"Identify a secure user within CostControl Corp. Create an IAM user in your AWS account with the necessary permissions and grant access to that securely identified user.","correct":false},{"id":"2df4700c329bc33dc8133ca8de8c37ad","text":"Create an IAM role. Allow CostControl Corp users to assume this role for access to AWS resources in your account.","correct":true},{"id":"0e0f124a17ea65e797f45765d7fac5a1","text":"Create an IAM Group for CostControl Corp users. Give this group limited AWS permissions. Create CloudTrail log for this group to ensure their API calls in your AWS are within the realm of their scope of work.","correct":false},{"id":"ef9e894add84e3a1607217b2cfa0f98d","text":"Use Amazon Cognito User Pools to enable authentication with the external party. Cognito will create a unique identifier for each user in CostControl Corp to access temporary, limited-privilege AWS credentials.","correct":false}]},{"id":"23e299c8-e80d-4333-b726-4f8ef1e89cfc","domain":"security-comp","question":"You want to restrict who can access a specific bucket that the development team use to store artifacts from their development pipeline. What kind of in-line policy will you need to use to insure this access","explanation":"Resource based policies are inline policies that restrict access to a specific resource, a good example of this is an S3 bucket policy.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html","title":"Policies and Permissions"}],"answers":[{"id":"33b02b9157e2a10758df1edb0fa38865","text":"Service Control Policy","correct":false},{"id":"eeec60437e6675cbd890b5f482628cfc","text":"Identity-based Policy","correct":false},{"id":"2d53d9afa60c8a03ddae8baa0cb72fb2","text":"Resource-based Policy","correct":true},{"id":"8e2ddf5878aac8b5d22a6acab856040d","text":"Access Policy","correct":false}]},{"id":"095bed19-081d-4865-acff-d6f9bc29eb7c","domain":"automation","question":"Which of the following is the only required component of a CloudFormation template?","explanation":"As the primary purpose of CloudFormation is to create a collection of related AWS resources, the Resources section is the only required section of a CloudFormation template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"}],"answers":[{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false},{"id":"7df96b18c230f90ada0a9e2307226338","text":"Templates","correct":false},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true}]},{"id":"e7703705-dc16-4a4f-a8d3-98e3577e942a","domain":"data-man","question":"You plan to deploy a MySQL 5.6 database in AWS RDS and you have some specific database parameter settings that must be applied, such as: AUTOCOMMIT, which should be disabled on the RDS instance. You may need to create additional DB instances with the same settings in the future. Which method would you use to configure the parameters?","explanation":"As there are specific parameters that need to be modified, the best way is to create a customized parameter group. You can associate any additional DB instances you launch with this parameter group so ensure they have a consistent configuration. You should not change the default parameter group as it may affect other existing or new instances unexpectedly. Creating and maintaining a JSON file for launching a DB instance via the AWS CLI adds unnecessary complexity. Systems Manager Run Command is used for EC2 instances instead of RDS DB instances.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithParamGroups.html","title":"RDS parameter groups"}],"answers":[{"id":"44708ac216e24969b934ef95be540000","text":"In AWS Systems Manager Run Command, execute the AWS-ConfigureDBParameter command to customize the DB parameters.","correct":false},{"id":"1c4b963beae658001b275abdaf38f116","text":"Create a custom parameter group for MySQL 5.6. Modify parameters accordingly and associate the parameter group with a DB instance.","correct":true},{"id":"41b0cd4c9b1c355a7119f0645ce643b9","text":"Modify the default MySQL 5.6 parameter group and all MySQL 5.6 DB instances will update parameters automatically.","correct":false},{"id":"168989a72a2725d264ca14b78d381d73","text":"Create a JSON file with customized DB parameters. Pass in the JSON file as an option when creating the DB instance via AWS CLI.","correct":false}]},{"id":"0c3624fc-3f1d-4663-9593-d1b228afb36b","domain":"mon-rep","question":"An organisation has been notified of an issue with their website loading slowly.  On investigation your autoscaling group has been scaled down to two servers, when it usually operates with two. Your CTO wants you to get to the bottom of this as quickly as possible. Which service in the Console will help you understand where the reconfiguration came from?","explanation":"AWS Config logs all changes to your configuration on a timeline, and it also allows you to retrace the steps via CloudTrail to see associated events with the configuration changes. In this case you could check the autoscaling group in AWS Config and would be able to see exactly when the number of servers was changed, and who performed the change.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/TrackingChanges.html","title":"Tracking Configuration Changes with AWS Config"}],"answers":[{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false},{"id":"7c90c8f2a24f3a1a28525f19fb2c75ab","text":"AWS Inspector","correct":false},{"id":"fefa18704e871eb671528fd4b7bc6ca2","text":"AWS Macie","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true}]}]}}}}
