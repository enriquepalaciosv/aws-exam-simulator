{"data":{"createNewExamAttempt":{"attempt":{"id":"e9e6a8d4-c41c-4358-8a2e-022d553bd35b"},"exam":{"id":"a6578492-aeb7-40c8-a3ba-e7d05e93cc95","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"516c16a0-3100-45f1-9b36-fe2cef037119","domain":"SecureSolutions","question":"You have an EC2 instance with a Security Group attached. This security group is configured to only allow traffic to/from 10.0.0.0/16. A colleague has also configured a NACL on the private subnet that the instance resides on, and this NACL is configured to block all traffic, except where the destination is in 10.0.1.0/24. What will happen when the instance attempts to access IP 192.168.0.12 on port 80?","explanation":"With outbound traffic, Security Groups are evaluated first, then NACLs. The security group is configured to only allow traffic where the destination is 10.0.0.0/16, and as 192.168.0.12 does not fall within this range it will be blocked by the security group before it reaches the NACL.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"c885215eb76a3baac02ca8ea6da9a7b4","text":"The NACL will block the traffic before it is evaluated by the security group","correct":false},{"id":"eb5d4be456a62dd4f884a4b47c45fd46","text":"The traffic will be blocked simultaneously by the Security Group and NACL","correct":false},{"id":"d3d7c67e2cf8c1d1cb89971fd90c2b72","text":"The security group will block the traffic before it is evaluated by the NACL","correct":true},{"id":"5298f0866dac220c6bbad6d2da2163d8","text":"The traffic will be allowed as it is still within a private range","correct":false}]},{"id":"62ce46dc-9858-4179-b84a-49f85cddb413","domain":"Performant","question":"You maintain an application which needs to store files in a file system which has the ability to be mounted on various Linux EC2 Instances. Which of the following would be an ideal storage solution?","explanation":"Amazon EFS provides scalable file storage for use with Amazon EC2. You can create an EFS file system and configure your instances to mount the file system. You can use an EFS file system as a common data source for workloads and applications running on multiple instances.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEFS.html","title":"Amazon Elastic Files System (Amazon EFS)"}],"answers":[{"id":"a0d5b037004b9bef739343edbcb14326","text":"Amazon EC2 Instance store","correct":false},{"id":"516729a7c0562425406a22cfe6a2c163","text":"Amazon EBS","correct":false},{"id":"f7b96044a16becafecad63df1725e9c8","text":"Amazon EFS","correct":true},{"id":"270fcb785810d0206945029bb05f4e97","text":"Amazon S3","correct":false}]},{"id":"8c8d1581-f004-4d00-a8a0-503b69a1f4d7","domain":"Performant","question":"You've migrated a legacy workflow application that is written in Java 1.4 from an on-prem server to a single M5 EC2 instance configured in an auto scaling group with a max-size of 1 across multiple AZs in the Asia Pacific (Sydney) region. It periodically checks a database for new and updated records and sends out email notifications. In the logs, you see frequent timeout errors. What could be a possible cause and how can you fix this?","explanation":"Amazon EC2 throttles traffic on port 25 of all EC2 instances by default, but you can request for this throttle to be removed or change to another port. In this example, you are not using SES and therefore, its endpoints or sending limits are irrelevant.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-port-25-throttle/","title":"How do I remove the throttle on port 25 from my EC2 instance?"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-connect.html","title":"Connecting to the Amazon SES SMTP Endpoint"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/regions.html","title":"Regions and Amazon SES"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-issues.html","title":"Amazon SES SMTP Issues"}],"answers":[{"id":"8a122c9945f5b1a081e098fdeadc94fe","text":"You might have reached your Amazon email sending limits. To increase that, open a Sending Limit case in the AWS Support Center.","correct":false},{"id":"385f853c6ca8754ad8dc4289fd42413e","text":"The app uses the standard JavaMail API on port 25. Amazon EC2 throttles traffic on that port of all EC2 instances by default, but you can request for this throttle to be removed.","correct":true},{"id":"cdf61badb6564eb5121bb15b0dba57d6","text":"You change an application properties file and update the currently used port from 25 to 2587, build a new AMI with that new version and configure your launch configuration to use that.","correct":true},{"id":"3d9ae95c23fe7b09220f12c62ff95f17","text":"Amazon SES Endpoints are only available in the US East (N. Virginia), US West (Oregon) and EU (Ireland) regions. You cannot migrate your legacy app until SES becomes available in Australia.","correct":false}]},{"id":"10118f04-2d87-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You wish to delete an EC2 instance that you no longer use. However, you realize that you can’t do so. Which of the following actions in the EC2 dashboard will you need to execute to enable the deletion?","explanation":"If you can’t delete the instance, click the 'Change Termination Protection' to disable termination protection, which prevents anyone from unintentionally deleting it. Once Termination Deletion is disabled, you can delete the instance. 'Attach to Auto Scaling Group' enables automatic scaling for your EC2 instance, and 'Get System Log' pulls up the history of actions in the instance; both have nothing to do with its termination. 'Change Shutdown Behavior' is for determining whether the EC2 instance is terminated or stopped when the shutdown command is used from within the instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html","title":"Terminate Your Instance – Amazon Elastic Compute Cloud"}],"answers":[{"id":"91a6832787d50d959e40e389e5ac6b7e","text":"Change Shutdown Behavior","correct":false},{"id":"5d4bd148bcf891ce27ceffce5be92781","text":"Get System Log","correct":false},{"id":"e815242d6e8235575d2814adbe2439dc","text":"Change Termination Protection","correct":true},{"id":"d1168fface65b719f1378443cee9d883","text":"Attach to Auto Scaling Group","correct":false}]},{"id":"f50eca72-215c-11ea-978f-2e728ce88125","domain":"Performant","question":"EC2 includes instances like i3.xlarge, which are designed to provide high sequential read and write access to very large data sets on local storage. Which of the following EC2 instance types does i3.xlarge fall under?","explanation":"An EC2 instance like i3.xlarge delivers high sequential read and write access, a characteristic that is ideal for large data sets. Data is stored in the instance’s solid-state drive, a type of storage renowned for quick access time and low latency. As a result, i3.xlarge is classified as a storage optimized instance.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"Amazon EC2 Instance Types"}],"answers":[{"id":"b26f852f8cf53bd055d76deddcadf155","text":"Compute Optimized","correct":false},{"id":"fb152ac1edfe96da5fe255e395003b0d","text":"Memory Optimized","correct":false},{"id":"94a1a3953054d8ece597f4f69bb343d4","text":"General Purpose","correct":false},{"id":"ea999a66bf3ccfec4616d5be49348665","text":"Storage Optimized","correct":true},{"id":"2f925ef0b67b13f124d684b4e0ca9682","text":"Accelerated Computing","correct":false}]},{"id":"5d2b3bb0-3bb8-41e0-9e90-7fd70629b5f3","domain":"CostOptimized","question":"You’re researching third-party backup solutions to backup 10 TB of data nightly to Amazon S3. File restores won’t be needed often, but when they are, they’ll need to be available in under five minutes. Your analysis shows that you will exceed your budget for backup storage and you need to find a way to reduce the estimated monthly costs. How should you modify the solution to achieve the cost reduction needed?","explanation":"Most third-party backup solutions write data to S3, but not all write directly to Glacier via the API. This is the most direct solution, and you’ll want to choose one that does. Moving data with S3 lifecycle rules probably won’t be recognized by the third-party software, creating an out of sync situation, and Glacier is more cost effective than the S3-Standard-Infrequent Access storage class.","links":[{"url":"https://aws.amazon.com/glacier/","title":"Amazon S3 Glacier"}],"answers":[{"id":"61439f45264a1150586115b18980c024","text":"Create an S3 lifecycle rule to move the data immediately to Amazon S3 Glacier","correct":false},{"id":"e4e3dfa7fa011d21f5b7a4182f3c4d4a","text":"Choose a third-party backup solution that leverages AWS Storage Gateway to write data to Amazon S3 Glacier","correct":false},{"id":"c883be39f5cb08a918d59df1f92a1bed","text":"Write the data directly to the S3 Standard-Infrequent Access Storage Class","correct":false},{"id":"e7a458c861e5ca337fcdc05bf5a06004","text":"Choose a third-party backup solution that writes directly to the Amazon S3 Glacier API","correct":true}]},{"id":"a33133b0-1731-4f6e-b38b-4aaf31d64a45","domain":"Performant","question":"You currently have a web app that is using a Microsoft SQL Server database hosted in RDS, using a db.m5.xlarge instance. This application is read-heavy, and as the number of users of the app has increased, you have noticed a gradual degradation of performance. With a recent marketing push, you are at the stage where performance is no longer acceptable and something needs to be done to improve it. At this stage cost is not an issue, and you are looking for the option which will give the best performance increase. Which option would you choose?","explanation":"Although read replicas are usually the correct choice when discussing read performance, RDS Read Replicas are not available for Microsoft SQL, ruling this option out. Moving from a memory optimized (M-class) to a compute optimized (C-class) would only help in this case if the size of the Compute instance was larger - since the primary concern here is reads, extra memory will provide a better outcome. As there is a similar sized M-class option available as one of the answers, a C-class instance is not the answer. Not to mention that moving from RDS to an EC2 instance would introduce a lot of management overhead. Throughput Optimized disk is backed by standard hard drives (non-SSD), and will therefore give worse performance that General Purpose as these are SSD backed. This leaves the resizing to an db.m5.2xlarge instance as the best of the options provided.","links":[{"url":"https://aws.amazon.com/rds/details/read-replicas/","title":"Amazon RDS Read Replicas"},{"url":"https://aws.amazon.com/ebs/features/?nc=sn&loc=1","title":"EBS Volume Types"},{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types"}],"answers":[{"id":"dd2623a54a7d521619db9426332d60a0","text":"Change the underlying instance type to a db.m5.2xlarge instance","correct":true},{"id":"187905872afd5e73e4d0760c852fa482","text":"Migrate the database to a c5.2xlarge EC2 instance","correct":false},{"id":"55d73c9a33e38a32b3a2dabd8d1d9cb0","text":"Deploy an RDS Read Replica for the database","correct":false},{"id":"d25db331f475d77fa6cbbbdd0fd04670","text":"Change the underlying EBS volume from General Purpose to Throughput Optimised type","correct":false}]},{"id":"40c8ad54-f968-412c-a7e0-9732db1d93ae","domain":"Performant","question":"You have a small database workload with infrequent I/O. Which storage medium would the most cost-effective way to meet these requirements?","explanation":" The question is specific that you are evaluating for RDS. Cold Storage is not a valid option for RDS. of the three valid types for RDS, Magnetic is still the cheapest","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","title":"RDS Storage Types"},{"url":"https://aws.amazon.com/rds/pricing/","title":"RDS pricing"},{"url":"http://calculator.s3.amazonaws.com/index.html#s=RDS","title":"AWS pricing calculator"}],"answers":[{"id":"0db6de47eed9671e44098c2117fe8916","text":"Amazon RDS Cold Storage","correct":false},{"id":"a257df0abf37db5da9b921f8222eab2a","text":"Amazon RDS General Purpose (SSD) Storage","correct":false},{"id":"4d548ff7278077c929b63c67f768cc97","text":"Amazon RDS Provisioned IOPS (SSD) Storage","correct":false},{"id":"e774a96af9adfaa2402148c9828271e7","text":"Amazon RDS Magnetic Storage","correct":true}]},{"id":"546c3d7f-0bb0-4de0-9442-43c0a8537511","domain":"ResilientDesign","question":"You have a web application being hosted on EC2 instances in a couple of regions. Users in certain regions have been reporting extreme slowness. How could this be architected better to improve the experience for users?","explanation":"Amazon CloudFront is a service that speeds up distribution of static and some dynamic web content.  Such as .html, .css, .js, and image files. CloudFront delivers your content through a worldwide network of facilities called edge locations. When a user requests content that you're serving through CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html","title":"What Is Amazon CloudFront?"}],"answers":[{"id":"dbab33ab37becc0a05ea59a20c78e360","text":"Place the EC2 instance behind CloudFront.","correct":true},{"id":"3d41bec1360974dbd7ddf7015f834d96","text":"Add Route 53 health checks to improve the performance.","correct":false},{"id":"180c5083827844575f12b2700cf184da","text":"Change the Instance Type to a higher type.","correct":false},{"id":"67b20a8653585f33002f903f06b7336d","text":"Add more EC2 instances to support the load.","correct":false}]},{"id":"4053d5c2-356f-4851-a9af-540b7131076d","domain":"SecureSolutions","question":"You have just started creating a new AWS environment for your organisation to use. Architecturally, this environment consists of 2 VPCs which are peered (VPC A and VPC B), plus some EC2 instances in each VPC. These instances are residing in the private subnet of each VPC and do not have an EIP or public IP attached. The EC2 instances can communicate with each other across the VPCs, however you realise that you have forgotten to deploy the required infrastructure to allow the instances to download updates from the internet. Which of the following would be the most cost effective method for enabling downloads from the internet?","explanation":"There are several elements to this question, so the easiest way to approach it is tackle them one by one. Straight away, two of the options can be eliminated - as the instances are on private IPs, any solution that doesn't include a NAT Gateway will not work. The choice between the two remaining options boils down to whether or not the NAT & Internet Gateway can be shared between two VPCs - to which the answer is no. VPC Peering does not support transitive peering (where traffic \"passes through\" the peered VPC on its way to its final destination). This leaves the correct answer as deploying 2 x IGWs, 2 x NGWs and having the instances use the NGW in the same VPC as them. Out of all the solutions listed it may be the most expensive, but it is the only one that will work.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html#nat-%20gateway-basics","title":"NAT Gateway Basics"}],"answers":[{"id":"cff5aae8f4630fbe7325c4dfed52b427","text":"Setup an Internet Gateway in VPC A, and route internet-bound traffic from the instances in both VPCs to the Internet Gateway in VPC A","correct":false},{"id":"b8fb1ee1585a8be8a92cfdc46ede67f5","text":"Setup an Internet Gateway in each VPC, and route internet-bound traffic from the instances to the Internet Gateway in the same VPC","correct":false},{"id":"dbd0ade9a841a5d0baa2108b3ff1fdfb","text":"Setup an Internet Gateway in VPC A, as well as a NAT Gateway in VPC A. Route the internet-bound traffic from instances in VPC A to the NAT Gateway in VPC A, and route the internet-bound traffic from instances in VPC B to the NAT Gateway in VPC A","correct":false},{"id":"71d4b3e59f026b6bfdf37a7cc5a8d8a2","text":"Setup an Internet Gateway in each VPC, then deploy a NAT Gateway in each VPC, routing traffic to the Internet Gateway contained in the same VPC. Internet-bound traffic from instances in each VPC to be routed to the NAT instance in the same VPC","correct":true}]},{"id":"8a4cd8a8-183f-11ea-8d71-362b9e155667","domain":"CostOptimized","question":"Your company recently expressed interest in upgrading to an AWS Support plan that provides infrastructure event management and incident response for the launch of a business-critical application. Which of the following support plans will satisfy your company's requirements?","explanation":"Each AWS account comes with Basic Support, so Basic is not the answer. Either the Business or the Enterprise plan grants access to AWS Infrastructure Event Management, the program your company needs for assistance with launching the application. The Enterprise plan, however, provides up to a 15-minute response time if the business-critical application goes down; the Business plan does not offer this option. In addition, the Busines Plan does not include Infrastructure Event Management - you need to pay an additional fee for this. Therefore the Enterprise plan is the only option that provides the appropriate level of incident response and infrastructure event management required.","links":[{"url":"https://console.aws.amazon.com/support/plans/home?#/","title":"AWS Support Plans"},{"url":"https://aws.amazon.com/premiumsupport/programs/iem/","title":"AWS Infrastructure Event Management"}],"answers":[{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":false},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false}]},{"id":"b974c044-33bf-4fe8-9edd-1cdac5b32fa5","domain":"Performant","question":"Your new cost tracking application runs on AWS Lambda and Amazon RDS PostgreSQL. All testing has shown that the software is ready for production. Shortly after launch, users begin complaining about performance issues. After some investigation, you suspect a database query problem. What approach will you take to diagnose and resolve the problem in the most operationally efficient way?","explanation":"RDS Performance insights provides an easy-to-understand dashboard for detecting performance problems on both RDS and Aurora database instances. You can monitor SQL queries that caused load and I/O waits, and you can identify the users and hosts through which the queries ran. A slow running query using a DISTINCT clause for a one-to-many join will benefit from removing the DISTINCT clause and adding an EXISTS qualifier to the WHERE clause. Using a native PostgreSQL tool like pgBadger will work, but it requires extra work to set logging parameters in the RDS parameter group. Adding a GROUP BY clause will not improve performance in this case.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.html","title":"Using Amazon RDS Performance Insights"},{"url":"https://aws.amazon.com/blogs/database/optimizing-and-tuning-queries-in-amazon-rds-postgresql-based-on-native-and-external-tools/","title":"Optimizing and tuning queries in Amazon RDS PostgreSQL based on native and external tools"}],"answers":[{"id":"04ad0f28212ab7830934651ac9ec003b","text":"Install a PostgreSQL native tool like pgBadger on an EC2 instance to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to add a GROUP BY clause.","correct":false},{"id":"cb046ece5a7170684077db42c1f41742","text":"Use RDS Performance Insights to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to remove the DISTINCT clause and add an EXISTS qualifier to the WHERE clause.","correct":true},{"id":"2b25e3600ffb4b52d5931af53bb18834","text":"Use RDS Performance Insights to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to add a GROUP BY clause.","correct":false},{"id":"436d7294f9c14ac6bd54f376404a16f3","text":"Install a PostgreSQL native tool like pgBadger on an EC2 instance to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to remove the DISTINCT clause and add an EXISTS qualifier to the WHERE clause.","correct":false}]},{"id":"09223b1a-2169-4791-94b1-9ecf1716c8eb","domain":"Performant","question":"Which of the following AWS services store data as key-value pairs?","explanation":"Both DynamoDB and S3 use key-value pairs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html","title":"Working With S3 Objects"},{"url":"https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs","title":"DynamoDB Data Models"}],"answers":[{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false}]},{"id":"e33d4c87-1230-4f2b-88b2-effd138ff06a","domain":"ResilientDesign","question":"Your legal company is moving its production estate to AWS. They currently have a private cloud platform with VMDK files as their virtual machines. You need to move these files to AWS and create EC2 instances using the VMDK files. Which AWS service would help you achieve this goal?","explanation":"","links":[{"url":"https://docs.aws.amazon.com/vm-import/latest/userguide/what-is-vmimport.html","title":"VM Import/Export"}],"answers":[{"id":"7445033ef83270814e799cba3c9fb637","text":"CloudMigration","correct":false},{"id":"42966c9ba8482ffc6ec12178fc18895c","text":"VM Import/Export","correct":true},{"id":"87703e16953f8b2edf255258a29aa823","text":"Data Pipeline","correct":false},{"id":"06a107211eb5871f858a954edc47c1eb","text":"VM Migrate","correct":false}]},{"id":"7ad502a4-1c97-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"A Fortune 500 company is currently migrating to AWS. The organization has determined that it needs an AWS Support plan that can mitigate failure or disruption of processes essential to its operation. Which of the following plans is most suitable for this purpose?","explanation":"Basic Support is included with each AWS account, so that automatically rules it out as the correct answer. Based on the description of the company’s needs and size, Enterprise Support is strongly recommended. This plan is ideally designed for organizations that have business or mission-critical workloads in AWS. Developer is geared towards those who experiment or test in AWS, and Business is ideal for production workloads. Neither of them is as robust as the Enterprise offering.","links":[{"url":"https://aws.amazon.com/premiumsupport/plans/","title":"Compare AWS Support Plans"}],"answers":[{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":false},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false}]},{"id":"27f1f472-2ea9-43e0-b75d-6be01c620049","domain":"CostOptimized","question":"You have a website that allows users in third world countries to store their important documents safely and securely online. Internet connectivity in these countries is unreliable, so you implement multipart uploads to improve the success rate of uploading files. Although this approach works well, you notice that when an object is not uploaded successfully, incomplete parts of that object are still being stored in S3 and you are still being charged for those objects. What S3 feature can you implement to delete incomplete multipart uploads?","explanation":"You can create a lifecycle policy that expires incomplete multipart uploads, allowing you to save on costs by limiting the time non-completed multipart uploads are stored.","links":[{"url":"https://aws.amazon.com/blogs/aws/s3-lifecycle-management-update-support-for-multipart-uploads-and-delete-markers/","title":"S3 Lifecycle Management - Incomplete Multipart Uploads"}],"answers":[{"id":"86d93427d74df0b30713341818e3d556","text":"S2 Reduced Redundancy Storage","correct":false},{"id":"ee966c2ebd84a4f7add1d9ceabe082c9","text":"Have S3 trigger DataPipeling Auto-delete.","correct":false},{"id":"5ff7e884d027004938c218aafa63c215","text":"S3 Lifecycle Policies","correct":true},{"id":"bc5e8477b1dde2747a8cb281160b01f7","text":"Have CloudWatch trigger a Lambda function that deletes the S3 data.","correct":false}]},{"id":"22315d49-9040-4de7-ae4f-ead04e5b4966","domain":"CostOptimized","question":"An application that performs statistical analysis on weather data receives files once a week. It assimilates the data in these files with previously collected data via its algorithms, and publishes a report at the end of each month. At unspecified times during the week, interim results need to be made available to meteorologists within minutes. Which architecture will meet the data availability requirements for the solution at the least cost, and with the simplest application code?","explanation":"Hibernating an EC2 instance provides a warm-start capability. When an EC2 instance is hibernated, RAM contents are saved to the EBS root volume. RAM contents are reloaded when the instance is restarted. AWS doesn't charge for the time that an instance is in the hibernated state. Storing data in Amazon DynamoDB costs more than EBS. EMR clusters cost more than EC2 instances. Stopping an EC2 instance clears RAM and requires the application to reload the data from a storage source when the instance is restarted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html","title":"Hibernate Your Instance"}],"answers":[{"id":"591c99dbc7dc2331d09abbc9ee1fb721","text":"Process the data on EC2 and hibernate the instance until new data files arrive or an interim results request is made","correct":true},{"id":"1270950fb1ac5049d96bd1c8633745fe","text":"Process the data on EC2 and stop the instance until new data files arrive or an interim results request is made","correct":false},{"id":"79010e5d6c3a7a1b4739890ce79939bd","text":"Process the data on EC2 and store temporary results in Amazon DynamoDB","correct":false},{"id":"e45f5352867fe69bdbc5efaad38e34b2","text":"Process the data on a transient EMR cluster and store temporary results in S3","correct":false}]},{"id":"446d12ef-f212-4d80-8b31-ca65204c3b45","domain":"Performant","question":"The AMI ID used in an AutoScaling policy is specified in the_____.","explanation":"The Launch Configuration contains most of the parameters that you would set for a manual EC2 launch, and these are applied to each automatic launch.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/LaunchConfiguration.html","title":"Launch Configurations"}],"answers":[{"id":"6bbdc6787549994c5be17383cfea4a40","text":"Security Group","correct":false},{"id":"415107f62d630ab0aa3de0b6ed75a3dd","text":"Launch configuration","correct":true},{"id":"5fdc7c9d0a9fcbddd7977b2d69ce392a","text":"AutoScaling group","correct":false},{"id":"af25a68505a64d038c5cc6de686880af","text":"AutoScaling Policy","correct":false}]},{"id":"ae6654da-753e-498d-a2ea-b1e21e295fa7","domain":"Performant","question":"You are considering moving an on-premise SQL Server cluster into AWS, using EC2 instances rather than RDS.  You need to recommend the most suitable EBS volume type for the cluster to use, but also pair it with a suitable EC2 instance type.  You know that the throughput must be good, but the most important thing is to maintain a consistent level of IOPS under normal load which can increase to a much higher level at busy times.  Choose the best option from the following EC2 and EBS pairings.","explanation":"The question states that you require consistent IOPS which means the io1 Provisioned IOPS type is the best choice of the two EBS types available, and therefore the correct answer must have io1 as an option.  Of the remaining two answers, either EC2 families would work.  We know from experience that databases do utilise as much memory as is available, so choosing an r5 family is plausible, however we need to use our extended knowledge of EC2 families to know that X1e was specifically created to run high performance databases and the final answer will therefore contain an io1 EBS volume and the X1e EC2 option.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"Amazon EC2 Instance Types"},{"url":"https://aws.amazon.com/ebs/features/","title":"Amazon EBS features"},{"url":"https://aws.amazon.com/blogs/database/new-memory-optimized-amazon-ec2-instance-types-drive-database-workloads/","title":"New, Memory-Optimized Amazon EC2 Instance Types Drive Database Workloads"}],"answers":[{"id":"7b472a990561e6ad0996ca48c955594b","text":"Provisioned IOPS (io1) EBS volumes with r5 EC2 instances","correct":false},{"id":"b28dd6770d9036a2f719c5f4cfc7cecc","text":"Throughout Optimised (st1) EBS volumes with X1e EC2 instances","correct":false},{"id":"78c33d688d1822c44c657b33bb0e5080","text":"Throughout Optimised (st1) EBS volumes with c5 EC2 instances","correct":false},{"id":"27e1d3ca80c5e8a728f7916a73f98ec4","text":"Provisioned IOPS (io1) EBS volumes with X1e EC2 instances","correct":true}]},{"id":"6360570c-c801-4b78-a0ba-7860817cb309","domain":"ResilientDesign","question":"You have a busy media website that runs on a fleet of EC2 instances behind an application load balancer. You have a number of different target groups for different purposes. One of these target groups is a fleet of EC2 instances which contains the images for your website. When ever a user visits www.yoursite.com/images/ you need your application load balancer to direct the request to the images target group. How do you configure this rule on your application load balancer?","explanation":"One of the major benefits of teh ALB is that it supports 'path-based' routing which allows you to direct the traffic based on the content of the URL path.  In this case /images/ can be directed to a specific target group.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-update-rules.html","title":"ALB Listener Rules"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html","title":"What Is an Application Load Balancer?"}],"answers":[{"id":"002f909cd633d40a7e860e8793272fe4","text":"Using Cross Zone Load Balancing.","correct":false},{"id":"4d15809e9acf1ee9617c2e118157323e","text":"Using Query String Parameters.","correct":false},{"id":"86e943f32a460169646a1a9a54de8934","text":"Using Sticky Sessions.","correct":false},{"id":"5a3ddbcafc8cd528ecdb152c181daba6","text":"Using Path Patterns.","correct":true}]},{"id":"6d368e1f-484b-4536-91ec-6055d5916c49","domain":"Performant","question":"You have developed a file-sharing website for a large corporate entity. They require that the site to be protected from a regional failure. Which S3 service should you use to achieve this? ","explanation":"S3 with Cross-Region Replication automatically replicates data across AWS regions. With CRR, every object uploaded to an S3 bucket is automatically replicated to a destination bucket in a different AWS region that you choose.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 - Cross-Region Replication"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr-what-is-isnot-replicated.html","title":"S3 - Replication guidelines"}],"answers":[{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"73d38a622e5878dd1ecfb83678260bd5","text":"S3 - Cross-Region Replication","correct":true},{"id":"431cc9c5e56b3f9120509ea377024fbc","text":"Configure S3 to trigger a Lambda function, which will take an object uploaded to S3 and automatically replicate it to an EBS volume.","correct":false},{"id":"5bd8bda263020cb57b990acb7d5d7218","text":"S3 - RRS with Data Pipeline to DynamoDB","correct":false}]},{"id":"88cebc81-c2b2-4e50-a1b5-c7113093be09","domain":"ResilientDesign","question":"Your image manipulation application allows users take a picture, upload it to your app, and request filters to be added to the image. You need to decouple the application so your users are not waiting for the image processing to take place. How would you go about doing this?","explanation":"SQS is the cornerstone of a decoupled application.","links":[{"url":"https://aws.amazon.com/sqs/details/","title":"SQS Product Details"}],"answers":[{"id":"6507d2b72600ba27f69e572ece518b7f","text":"Use Amazon SQS to store the requests using metadata and JSON in the message, use S3 to store the image, and Auto Scaling to determine when to fire off more worker instances based on queue size.","correct":true},{"id":"34a217bc4a845cabb574e3e1c6d25d34","text":"Use S3 to store the images and EC2 to process the requests.","correct":false},{"id":"81c855d77cf31549e9433174eb4c3aa2","text":"Integrate with DynamoDB to allow messages to be sent back and forth between worker instances and EC2 instances.","correct":false},{"id":"54f142fa12b78e2a46b9599210b9829b","text":"Use Lambda to process the images.","correct":false}]},{"id":"37bacf63-a62f-4f99-a0b0-6bf9bf5a5210","domain":"CostOptimized","question":"You have a series of websites hosted in AWS. You need to ensure that users from Europe are directed to www.my-gdpr-site.com for regulatory purposes. What could help accomplish this?","explanation":"Geolocation routing lets you choose the resources that serve your traffic based on the geographic location of your users, meaning the location that DNS queries originate from. For example, you might want all queries from Europe to be routed to an ELB load balancer in the Frankfurt region.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"3efbfae41092bb136dee3c26de7750f1","text":"Using the Route 53 service.","correct":true},{"id":"4b3ecb216d2654061f67ae382d891333","text":"Using the Autoscaling service.","correct":false},{"id":"adba6b9b5a5387ec8af8d012d272715b","text":"Using the AWS Config service.","correct":false},{"id":"2b840caf003f35a0ca6a82ea4d66b8a8","text":"Using the Elastic Load Balancer service.","correct":false}]},{"id":"eb7c5d7d-09d6-4dee-bf55-d97a53af72f2","domain":"SecureSolutions","question":"Your organisation is about to deploy a new website into their AWS environment that will publish news articles created by your content team, which will reside on the URL “www.cloud-news.com”. This website makes use of two EC2 austoscaling groups to serve content - one is for publicly accessible content and one for members-only content. An in-house developed authentication mechanism redirects users to “members.cloud-news.com” to access the members-only content. Which load balancer configuration is most appropriate for this architecture?","explanation":"The load balancer needs to be able to look at the hostname of the request and redirect it to the appropriate EC2 Autoscaling group - this requires the ability to do host-based routing, which is a feature of ALBs and is not available in NLBs. As we are routing to a different hostname, the path is irrelevant - only host-based will work, and the condition for this on an ALB is \"host-header\"","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/ ","title":"Load Balancing Features"}],"answers":[{"id":"1d8d6c68ab28d0288ad4747f3e53f1e4","text":"Use a Network Load Balancer in a public subnet, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the \"path-pattern\" condition on each listener rule to redirect users to the appropriate target group.","correct":false},{"id":"9748d8cbee76d8e5ee49130319e6dabc","text":"Use an Application Load Balancer, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the “path-pattern” condition on each listener rule to redirect users to the appropriate target group.","correct":false},{"id":"512616e676f1cc76a267567948528f9e","text":"Use an Application Load Balancer, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the \"host-header\" condition on each listener rule to redirect users to the appropriate target group.","correct":true},{"id":"c6e704e1b985b6cd50ffe0d7750681ff","text":"Use a Network Load Balancer in a public subnet, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the \"host-header\" condition on each listener rule to redirect users to the appropriate target group.","correct":false}]},{"id":"b7f28443-c2d5-4605-be5a-960171a70ab0","domain":"Performant","question":"You are auditing your RDS estate and you discover an RDS production database that is not encrypted at rest. This violates company policy and you need to rectify this immediately. What should you do to encrypt the database as quickly and as easy as possible.","explanation":"At the present time, encrypting an existing DB Instance is not supported. To use Amazon RDS encryption for an existing database, create a new DB Instance with encryption enabled and migrate your data into it.  Alternately you can encrypt a copy of a Snapshot and restore the encrypted copy.  However you cannot encrypt as you are restoring from a snapshot.  A key point is that an outage will be required either way.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html","title":"Encrypting RDS Resources"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html#Overview.Encryption.Limitations","title":"Encrypting RDS Resources - Limitations"}],"answers":[{"id":"ee1313fab08c86cd71ec82d1ef4ccf05","text":"Create a new DB Instance with encryption enabled and then manually migrate your data into it.","correct":true},{"id":"4d7c7e6fcbf43a4e3cb390d6b8f4e775","text":"Use AWS Database Migration Service","correct":false},{"id":"23f20d1a056e924aa8bcce37914200c4","text":"Use the RDS Import/Export Wizard to migrate the unencrypted RDS instance across to a new encrypted database.","correct":false},{"id":"e3b45db054ee4c24e48b8fa4288bc219","text":"Take a snapshot of your unencrypted DB Instance and then restore it making sure you select to encrypt the new instance.","correct":false}]},{"id":"eba390fe-7699-47c0-b51f-f38cbc948112","domain":"CostOptimized","question":"What is the 'first-byte' latency when retrieving data from Glacier?","explanation":"You should expect data retrieval latency of 3-5 hours when retrieving data from Glacier.","links":[{"url":"https://aws.amazon.com/glacier/faqs/#dataretrievalpolicies","title":"Glacier Data Retrieval Policies"}],"answers":[{"id":"72ab9d0304d3e84c6aa2dd15eda282f2","text":"1 hour","correct":false},{"id":"6619a70f8ab8877e4131643fb8ded723","text":"2 hours","correct":false},{"id":"b86a4270946442f3b17bd51e3aa226ce","text":"> 5 hours","correct":false},{"id":"99d888e6893ac480abd21ecb8a18e060","text":"3-5 hours","correct":true}]},{"id":"c5cc330a-0f8f-11ea-8d71-362b9e155667","domain":"ResilientDesign","question":"You recently got hired by a sole proprietor specializing in baking and selling oatcakes within the state of Maryland, which is in the East Coast of the United States. The sole proprietor is ready to launch a website to expand her business online and sell on a national scale. She wants assurance that the website is always available to customers throughout the United States. Using Amazon Route 53 and EC2, which of the following is the best course of action?","explanation":"Ideally, you should architect AWS usage to take advantage of multiple Regions and Availability Zones. Based on the client’s demands, you need an active-passive failover configuration within the United States — not between the United States and Singapore, for example.  So, setting up a failover routing policy for the website with both EC2 instances in North American Regions and Availability Zones is the correct option. With Maryland falling within the US East Region, the secondary resources can be deployed in the US West Region for coast-to-coast national coverage. A simple routing policy won’t work, since it distributes web traffic randomly. And while geolocation routing can address the client’s national reach plans, it will not address the website’s resiliency.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html#dns-failover-types-active-passive","title":"Active-Passive Failover"}],"answers":[{"id":"80fe4ea40ff6dc32a5c8e993ca1f435c","text":"Set up a geolocation routing policy in Route 53 for the website that directs traffic to the EC2 instance in the us-east 1 Availability Zone as the area where the company is based. It will failover to the EC2 instance in the ap-southeast-1 Availability Zone as the secondary resource when necessary.","correct":false},{"id":"67671c325b8941bda2a15e76be801e2d","text":"Set up a failover routing policy in Route 53 for the website that has an EC2 instance in the us-east-1 Availability Zone as the primary resource and another EC2 instance in the us-west-1 Availability Zone as the secondary resource.","correct":true},{"id":"eb41eb5a739a5015ab0b9122db69f20a","text":"Set up a simple routing policy in Route 53 for the website that switches between the EC2 instance launched in the us-east 1 Availability Zone and a second EC2 instance launched in the us-west-1 Availability Zone.","correct":false},{"id":"00bd2e799600e5dc9ac2ed23e17b593a","text":"Set up a failover routing policy in Route 53 for the website that has an EC2 instance in the us-east-1 Availability Zone as the primary resource and another EC2 instance in the eu-west-2 Availability Zone as the secondary resource.","correct":false},{"id":"5aa9a31751ffd108c0b6c3dd7bf7a4c2","text":"Set up a geolocation routing policy in Route 53 for the website that directs traffic to the EC2 instance in the us-east 1 Availability Zone as the area where the company is based. It will failover to the EC2 instance in the us-west-1 Availability Zone as the secondary resource when necessary.","correct":false}]},{"id":"ccdbbdf9-e9b6-4255-bed7-4e5f65b8c940","domain":"SecureSolutions","question":"You are deploying an application on to EC2 instances. The application must make AWS API calls. What is the most secure method to pass credentials to the application?","explanation":"You can use roles to delegate access to users, applications, or services that don't normally have access to your AWS resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html","title":"IAM Roles"}],"answers":[{"id":"98e2209690b12719fd4018b9176c77a9","text":"Assign an IAM role to the EC2 instances.","correct":true},{"id":"431d737549954a94c084b6c8532b8670","text":"Embed the API credentials in the application.","correct":false},{"id":"59bdef2986f5b1db72e3113469a3f6d6","text":"Store the API credentials as an object in S3.","correct":false},{"id":"4fe6cac2e87dc307c93a2b029e6ae5dc","text":"Pass API credentials to the instance using userdata.","correct":false}]},{"id":"bdfff765-ad59-45a9-9e3c-605a3d2ad9d7","domain":"ResilientDesign","question":"You have been asked to set up an EFS storage solution for a project team.  Which of the following tasks do you need to complete ?","explanation":"It is necessary to set up the bi-directional network permissions, normally with Security Groups. You will connect the EFS Target to your EC2 instance with a 'mount' statement. You do not need to stipulate the size or format the volume. AWS provide a nominally unlimited file system ready for you to use.  As normal under the shared security model AWS will ensure that the EFS system is secure, but you are responsible for the access control security inside the EFS file space provided to you.","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html","title":"EFS - How It Works"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/limits.html","title":"EFS limits"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/security-considerations.html","title":"EFS Security"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/accessing-fs-create-security-groups.html","title":"EFS Security Groups"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/wt1-getting-started.html","title":"Mounting and EFS target"}],"answers":[{"id":"30f2e62c04d187f6e6f58e730e462680","text":"Configure a Security Group to allow admin traffic on port 22 to connect to the EFS system.","correct":false},{"id":"9bc552892ca2c2c5be9e7c352fc0cdc8","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EC2 server.","correct":true},{"id":"9a0eabcd19e62a99932848808a473c0f","text":"mount EFS vol to your EC2 instance using 'mount -t nfs -o xxxx '.","correct":true},{"id":"7f41c759c946659e0ef49f87f6684503","text":"Set Linux file system permissions on the presented EFS volume using 'chmod' and 'chown'.","correct":true},{"id":"8388b16ddec8dec25d6caba4dbe7f8cb","text":"specify and provision disk capacity on the EFS system using 'fdisk' and 'mkfs -t xfs'.","correct":false},{"id":"417164507c199eb8b0fb1daa3bae285c","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EFS target","correct":true}]},{"id":"52cf0185-4629-47ac-8779-4ec4ffd9cc06","domain":"SecureSolutions","question":"You have an EC2 instance with a Security Group attached. This security group is configured to only allow inbound traffic from 192.168.0.0/24. A collegue has also configured a NACL on the subnet that the instance resides on, and this NACL is configured to block all traffic, except where the source or destination is in 192.168.0.0/24. What will happen when an instance with an IP of 192.168.1.12 tries to connect to your instance on port 80?","explanation":"With inbound traffic, NACLs are evaluated before Security Groups. As the NACL is configured to only allow traffic from 192.168.0.0/24 and the IP 192.168.1.12 does not fall within that range, it will be blocked by the NACL before reaching the Security Groups.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"d3d7c67e2cf8c1d1cb89971fd90c2b72","text":"The security group will block the traffic before it is evaluated by the NACL","correct":false},{"id":"c885215eb76a3baac02ca8ea6da9a7b4","text":"The NACL will block the traffic before it is evaluated by the security group","correct":true},{"id":"5298f0866dac220c6bbad6d2da2163d8","text":"The traffic will be allowed as it is still within a private range","correct":false},{"id":"eb5d4be456a62dd4f884a4b47c45fd46","text":"The traffic will be blocked simultaneously by the Security Group and NACL","correct":false}]},{"id":"213b0cbc-3d9c-47f8-8c55-021aded457be","domain":"SecureSolutions","question":"A retailer has begun building applications in AWS. Their most critical application needs to read and write objects containing details of their customers to an S3 bucket 'customer-details'. They have come to you for some guidance around security and performance.  What recommendations would you make to the company in order to secure the application's access to S3?","explanation":"Using an S3 endpoint allows you to keep the traffic between your web servers and the S3 buckets entirely within the VPC, improving security of the S3 service as well as application performance.  You can restrict access to the S3 buckets by VPC Endpoint by using the aws:sourceVpce policy.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints-s3.html","title":"Endpoints for Amazon S3"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints-s3.html#vpc-endpoints-policies-s3","title":"Endpoints for Amazon S3 - VPC Endpoint Policies"}],"answers":[{"id":"aa1e8ef467c30e9e0c9045c70ae8551d","text":"Enable the S3 endpoint within the VPC","correct":true},{"id":"ab1da7267174c389f64c3d724660c0bc","text":"Restrict access to the bucket to the application's VPC CIDR using aws:SourceIp","correct":false},{"id":"557b8c9c9acc9febf73b1e2da52bde5a","text":"Create an IAM user to act as a service account for S3 access and use the access keys to access S3, limit access to the bucket to that IAM user","correct":false},{"id":"ab97884d5f3dc6971366b88dd0ba8b06","text":"Restrict access to the bucket to the S3 endpoint using aws:sourceVpce","correct":true}]},{"id":"c487c002-443f-4d86-bdde-a915adb7924d","domain":"ResilientDesign","question":"You have chosen to use S3 - OneZone-IA with your cloud application. Which limitations have you considered in doing so?","explanation":"In exchange for a significant cost savings, 1Zone-IA has the same Durability as S3, but a lower Availability SLA.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/?nc=sn&loc=3","title":"S3 Storage Classes"}],"answers":[{"id":"a86f1cf2d99a9643587b837f464b5ef8","text":"1Zone-IA offers only 99.50% availability. Therefore you have to design your application to re-create any objects that may be temporally unavailable.","correct":true},{"id":"4068f35933f215b2818a03234567736a","text":"1Zone-IA requires supplementary Access Control Lists.","correct":false},{"id":"bcddbe2d89ec46d45172296d890040c3","text":"1Zone-IA is available only in the US-STANDARD region.","correct":false},{"id":"e0a1c69e07da2a370da0dedf28084491","text":"1Zone-IA offers only 99.50% durability. Therefore you have to design your application to re-create any objects that may be lost.","correct":false},{"id":"3ffe3458e13ccc426e49a1893b78a3f3","text":"1Zone-IA has a 3 - 5 hour data recovery windows.","correct":false}]},{"id":"c31b1522-5ef4-4e45-9847-53598677ae68","domain":"Performant","question":"What is the availability of S3 - IA?","explanation":"S3 - IA is 99.9% available. Do not confuse availability with durability.","links":[{"url":"https://aws.amazon.com/s3/faqs/#How_reliable_is_Amazon_S3","title":"S3 Availability"}],"answers":[{"id":"ebb51b0b7e8f1fcf89ef483709bd61c6","text":"99.9%","correct":true},{"id":"78262a35fc5fdefbb7740ac7102b8cc4","text":"99.999999999%","correct":false},{"id":"91009c0d8d2ec85d07a48cb81bfcfb0d","text":"99%","correct":false},{"id":"19fb9916968211db983d13bffe0cc6af","text":"99.99%","correct":false}]},{"id":"04057da1-5386-4f99-80b3-72799b07694b","domain":"ResilientDesign","question":"Your manager has approached you about storing some old media files in AWS. These files need to be stored at the lowest cost possible. It is acceptable to wait for files to become available. Which of the following S3 Storage Tiers is best suited for this request?","explanation":"S3 Glacier is a secure, durable, and low-cost storage class for data archiving. You can reliably store any amount of data at costs that are competitive with or cheaper than on-premises solutions. To keep costs low yet suitable for varying needs, S3 Glacier provides three retrieval options that range from a few minutes to hours.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#Archive","title":"Amazon S3 Storage Classes - Glacier"}],"answers":[{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"2513141525c4ac25f9f2c687ed0f588c","text":"S3 One Zone - Standard-Infrequent Access","correct":false},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":true},{"id":"a4172aee8a692bd73f2781afe65fda72","text":"S3 Infrequently Accessed","correct":false}]},{"id":"dd6d1773-3b16-4ee2-9766-c5ccbe8fbc8e","domain":"ResilientDesign","question":"Which of the following database engines support read replicas?","explanation":"Read Replicas are supported by Amazon Aurora, Amazon RDS for MySQL, MariaDB, PostgreSQL, and most recently Oracle.","links":[{"url":"https://aws.amazon.com/rds/faqs/#replication","title":"Multi-AZ Deployments and Read Replicas"},{"url":"https://aws.amazon.com/about-aws/whats-new/2019/03/Amazon-RDS-for-Oracle-Now-Supports-In-region-Read-Replicas-with-Active-Data-Guard-for-Read-Scalability-and-Availability/","title":"RDS Oracle now Supports In-region Read Replicas"}],"answers":[{"id":"a71f76c3256e4c206a4841d8eb0fed35","text":"SQL Server","correct":false},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":true},{"id":"30162ed78b6c10f731411f2fc440c24f","text":"Oracle","correct":true},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":true}]},{"id":"8dea5b5e-453e-4dda-883d-e390d14a8c83","domain":"ResilientDesign","question":"You have chosen to use S3-RRS with your cloud application. Which limitations have you considered in doing so?","explanation":"The use of RRS is being phased out. In exchange for a significant cost savings, RRS offers only 99.99% durability.","links":[{"url":"https://aws.amazon.com/s3/reduced-redundancy/","title":"About S3-RRS"}],"answers":[{"id":"7ae25c780e69aeb7ac28e7b25b79873f","text":"RRS is not recommended for new projects in some AWS regions.","correct":true},{"id":"da6d1d0f493d75bccd625f920a3b8b35","text":"RRS offers only 99.99% durability, so you have to design your application to re-create any objects that may be lost.","correct":true},{"id":"07f7d94a1360ae1987207ba589182e55","text":"RRS  is available only in the US-STANDARD region.","correct":false},{"id":"7e2b64603db15867a5b488818ec6d9f3","text":"RRS has a 4-hour data recovery time.","correct":false},{"id":"83091b498f26985700b51b43e93fb462","text":"RRS requires supplementary Access Control Lists.","correct":false}]},{"id":"62f8b91f-134a-4b12-85c0-a098fcb1a517","domain":"ResilientDesign","question":"Which of the following events would cause Amazon RDS to initiate a failover to the standby replica?","explanation":"The events would cause Amazon RDS to initiate a failover to the standby replica would be: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, Storage failure on primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"RFS High Availability"}],"answers":[{"id":"545c9bfa770559efbeb1abda0d9c4077","text":"Complete failure of the primary instance","correct":true},{"id":"eb2fca77d143f8a2bf2c7a32db536671","text":"Loss of availability in the primary Availability Zone","correct":true},{"id":"0e11e486b98184268711d1c093bf5f68","text":"Loss of network connectivity to the primary instance","correct":true},{"id":"abad0c6f8f62519ab90e3756d116fc12","text":"Storage failure on the standby replica","correct":false}]},{"id":"3b937104-1853-11ea-8d71-362b9e155667","domain":"Performant","question":"An automotive research data company is currently running its data store on a MySQL database engine. However, its CTO is not satisfied with the database’s performance, noting that the data sets are rather large. He firmly believes that the company can use a better solution for its analytical workloads. Which of the following AWS services would be best suited for this application?","explanation":"Amazon Redshift is a data warehouse service, which makes it ideal for processing large data sets, and also reporting and data analysis. Based on the provided scenario, the company’s data has clearly outgrown its database solution; consequently, none of the other responses—DynamoDB, RDS, and Aurora—are correct.","links":[{"url":"https://docs.aws.amazon.com/redshift/latest/gsg/getting-started.html","title":"Getting Started with Amazon Redshift"}],"answers":[{"id":"69670a9d53817d1ec89e685997343ce2","text":"Amazon Aurora","correct":false},{"id":"35686630aa3baddc18c904374e570233","text":"Amazon RDS","correct":false},{"id":"f7415e33f972c03abd4f3fed36748f7a","text":"Amazon Redshift","correct":true},{"id":"ecafbaed9f41dac736e496a7cd234ce4","text":"Amazon DynamoDB","correct":false}]},{"id":"38ef90f0-2aba-4d4b-ada7-da42c65e057b","domain":"SecureSolutions","question":"There is a requirement to launch an AWS EC2 instance. The instance went from pending state to terminated state immediately after restarting it. What could be possible reasons for the instance termination?","explanation":"An instance could get terminated during launch or restart if: the EBS Volume Limit exceeded; an EBS Snapshot is corrupt; an EBS root volume is encrypted and does not have permission to access the KMS Key for decryption; and, the instance store-backed AMI that is used to launch the instance is missing a required part file.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html","title":"Amazon EC2 Launch Issues"}],"answers":[{"id":"8abfca6f4f8d89032e129b9f9ca43fa1","text":"An EBS Snapshot is corrupt.","correct":true},{"id":"695e9653895aaae42d926723df22c02b","text":"Only on-demand and reserved instance can be restarted. Spot instances cannot be restarted.","correct":false},{"id":"b892c187f86580b57d005289701fa8d5","text":"EBS volume has reached its limit.","correct":true},{"id":"a1c2596d4b7f0ed157ccc7ea980c7b3b","text":"The root EBS volume is encrypted and missing permissions to access the KMS key for decryption.","correct":true},{"id":"85d6641bc71a96c5d17ebf9073fbef70","text":"Data in the AWS EC2 instance store does not persist across reboot, it was terminated.","correct":false}]},{"id":"90ace2f7-d81c-4553-ab4a-3f15dec1af4a","domain":"SecureSolutions","question":"You have a legacy web application that is using an RDS MySQL 5.5 back end. A recent vulnerability scan of you infrastructure has highlighted that this particular application is vulnerable to SQL Injection attacks. Unfortunately, due to it being a legacy application, none of the developers in your team have the ability to make any changes to the application. What can you do to help remediate this security concern?","explanation":"One of the use cases for WAF is an extra layer of protection for applications which are susceptible to common known attacks, including SQL Injection, making this the correct answer. A load balancer cannot help here, and AWS Shield Standard does not include protection against this type of attack. Similarly, updating MYSQL will not help as it does not offer built in protection for SQL Injection.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/web-acl-sql-conditions.html/","title":"Working with SQL Injection Match Conditions"},{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/waf-block-common-attacks/","title":"Blocking common attacks with WAF"}],"answers":[{"id":"47fdfce5dfad3ff4c85f96146e989ba0","text":"Deploy AWS WAF with SQL injection match conditions","correct":true},{"id":"80d6705d46732c1d72a653836c4d7423","text":"Upgrade MYSQL to version 8, which has protections built in against SQL Injection attacks","correct":false},{"id":"63ce0e907e173dc3773b6ca869379da6","text":"Do nothing - by default AWS Shield Standard protects against SQL Injection attacks","correct":false},{"id":"3033b37c4898ebbaff9e37b63b5a3e56","text":"Deploy an Application Load Balancer with SQL Injection Filtering enabled","correct":false}]},{"id":"4eb40e8a-8251-44ca-a55f-7a2d2e39a78c","domain":"CostOptimized","question":"A large company is running multiple Amazon EC2 and Amazon RDS services across several AWS Regions. You are an AWS consultant and the company approaches you to provide recommendations on how to reduce operational cost without any major changes. The company confirms that certain instances are required to be run only during business hours from 8AM to 6PM on weekdays and can be shutdown on weekends and non-business hours. Which of the following automated solutions best matches the requirements?","explanation":"AWS offers infrastructure on demand so that customers can control their resource capacity and pay only for what they consume. One simple method to reduce costs is to stop resources that are not in use, and then start those resources again when their capacity is needed. The AWS Instance Scheduler is a simple AWS-provided solution that enables customers to easily configure custom start and stop schedules for their Amazon EC2 and Amazon RDS instances. The solution is easy to deploy and can help reduce operational costs for both development and production environments. Customers who use this solution to run instances during regular business hours can save up to 70% compared to running those instances 24 hours a day. AWS Auto Scaling is not a correct solution as auto-scaling groups can contain Amazon EC2 instances from multiple Availability Zones within the same Region and cannot contain instances from multiple regions. As the company confirms that the instances are required to be run during Business hours, Spot Instance is not a good choice as spot instances may be terminated if the spot price is higher than the bid price. Also, moving AWS Instances to lesser configurations is neither an automated solution nor guarantees saving operational cost if run 24 hours.","links":[{"url":"https://docs.aws.amazon.com/solutions/latest/instance-scheduler/overview.html","title":"AWS Instance Scheduler"}],"answers":[{"id":"f4bf61a51bd424cab4d9129fd4f2ef6a","text":"Move Instances to Spot Instances","correct":false},{"id":"f657bd5509ffc79a6cb033747ff52f50","text":"Move AWS instances to lesser configuration Instance Type","correct":false},{"id":"c9eccc5399c22049703ce9be447d23d7","text":"AWS Instance Scheduler","correct":true},{"id":"2f766b7c3ac605171e839f447d7e239c","text":"AWS Auto Scaling","correct":false}]},{"id":"79861610-5123-41e0-b0ff-52cee5365540","domain":"SecureSolutions","question":"You are about to encrypt the data in your S3 buckets, and you need a solution to enable the use of a customer master key (CMK) as an added layer of protection against unauthorized access. In addition, this solution must provide you with an audit trail that shows you when and who used the CMK. Which of the following choices denote this type of encryption?","explanation":"Generally speaking, SSE is actually correct. However, the question is asking for a specific type of server-side encryption. SSE-S3 is another possible answer, since it encrypts the objects in the S3 buckets and Amazon S3 manages the encryption keys. However, the CMK and audit trail attributes are missing from this choice. With SSE-KMS, you get the CMK addition for added protection, as well as the audit trail, which is why SSE-KMS is the right answer. SSE-C is not the right choice because you, rather than Amazon, would manage the keys.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Server-Side Encryption"},{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html","title":"Server-Side Encryption: Using SSE-KMS"}],"answers":[{"id":"772996341baeebbfac39d70e8ed5a300","text":"Server-Side Encryption with AWS Key Management Service (SSE-KMS)","correct":true},{"id":"c76bcbd057118544ba0ccb76a8a22e46","text":"Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)","correct":false},{"id":"9b7e6d7280803d9f9a6072b4421611fc","text":"Server-Side Encryption with Customer-Provided Keys (SSE-C)","correct":false},{"id":"a8d0fb2ecae10336e81eec65375a4abe","text":"Server-Side Encryption","correct":false}]},{"id":"327b05c9-9075-44f6-aa13-2256b224ddd0","domain":"SecureSolutions","question":"You work for a famous bakery who are deploying a hybrid cloud approach. Their legacy IBM AS400 servers will remain on premise within their own data center. However, they will need to be able to communicate to the AWS environment over a site-to-site VPN connection. What do you need to do to establish the VPN connection?","explanation":"A virtual private gateway is the VPN concentrator on the Amazon side of the VPN connection. You create a virtual private gateway and attach it to the VPC from which you want to create the VPN connection.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html#VPNGateway","title":"Virtual Private Gateways"}],"answers":[{"id":"4ee8aaa281d6b39d679d377e073cb093","text":"Update your route table to add a route for the NAT to 0.0.0.0/0.","correct":false},{"id":"4854a199e41f20aaa56b2eb9ec81163a","text":"Connect to the environment using AWS Direct Connect.","correct":false},{"id":"0d9b1a79d184042e38ad85fb92194245","text":"Assign a public IP address to your Amazon Virtual Private Gateway.","correct":true},{"id":"7183da525dce8df94a54eeefb5c8e963","text":"Create a dedicated NAT and deploy this to the public subnet.","correct":false}]},{"id":"22b1c6a0-1e15-4a38-8a17-4a90fa381ffa","domain":"ResilientDesign","question":"Your business is evaluating several database technologies from AWS - one of the major requirements is the ability to withstand an Availability Zone outage within a single database cluster. Which of the following AWS Database services does NOT meet this requirement?","explanation":"A RedShift DB cluster can only be deployed in a single AZ. All other RDS Databases: MS SQL, PostgreSQL, MySQL, Oracle and MariaDB natively support Multi-AZ deployments. Although Redshift can be architected in a way that has Availability Zone level redundancy, this requires the use of multiple RedShift clusters, and manually setting up DB to DB replication across AZ’s, and therefore does not satisfy the requirement.","links":[{"url":"https://aws.amazon.com/redshift/faqs/","title":"Amazon Redshift FAQs"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"Amazon Relational Database Service"}],"answers":[{"id":"d2727816fa1087ddac7dff69e35c5536","text":"MS SQL","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false},{"id":"35f802e4a5e1cbdf3f99a71a86ae3153","text":"RedShift","correct":true}]},{"id":"272bc71b-a481-4c8a-ba09-0789c7f4c693","domain":"ResilientDesign","question":"You work for a large software company in Seattle. They have their production environment provisioned on AWS inside a custom VPC. The VPC contains both a public and private subnet. The company tests their applications on custom EC2 instances inside a private subnet. There are approximately 500 instances, and they communicate to the outside world via a proxy server. Each day at 3:00 am, the EC2 instances pull down OS updates of approximately 150MB. They then apply these updates and reboot: if the software has not downloaded within half an hour, then the update will attempt to download the following day. You notice that a number of EC2 instances are continually failing to download the updates in the allotted time. Which of the following answers might explain this failure?","explanation":"Network throughput is the obvious bottleneck. You are not told in this question whether the proxy server is in a public or private subnet.  If it is in a public subnet, the proxy server instance size itself may not be large enough to cope with the current network throughput. If the proxy server is in a private subnet, then it must be using a NAT instance or NAT gateway to communicate out to the internet. If it is a NAT instance, this may also be inadequately provisioned in terms of size. You should therefore increase the size of the proxy server and or the NAT solution.","links":[{"url":"https://aws.amazon.com/articles/2781451301784570","title":"High Availability for Amazon VPC NAT Instances"}],"answers":[{"id":"53f909d07a066b5cff25165851871c87","text":"The proxy server is in a private subnet and uses a NAT instance to connect to the internet. However, this instance is too small to handle the required network traffic. You should re-provision the NAT solution so that it's able to handle the throughput.","correct":true},{"id":"eb18e44669101e1100b3ebc420d5ec85","text":"The proxy server has an inadequately sized EBS volume attached to it. The network buffer is stored on the EBS volume, and it is running out of disk space when trying to buffer the 500 simultaneous connections. You should provision an EBS volume with provisioned IOPS.","correct":false},{"id":"43dc1512ca14b92d2eb68313d4ca3177","text":"Your proxy server is blacklisting the address in which the updates are being downloaded from, resulting in failed downloads.","correct":false},{"id":"472f8c7b44becee56eae4978366fb891","text":"The proxy server has only one elastic IP address added to it. To increase network throughput, you should add additional elastic IP addresses.","correct":false},{"id":"152f892f225fb2bec87a7a17f05ad20f","text":"The proxy server is on an inadequately sized EC2 instance and does not have sufficient network throughput to handle all updates simultaneously. You should increase the instance size or type of the EC2 instance for the proxy server.","correct":true}]},{"id":"c67d3b2b-2a42-4093-af94-3336110e8c4e","domain":"SecureSolutions","question":"A human resources consulting company has recently implemented Amazon Redshift to perform analytics on customer engagements. A number of departments have been given the ability to query the data. The operations team needs to be able to monitor and terminate queries as needed, but they should not have the ability to modify or delete any other Redshift resources. Which approach will provide the operations team with the access they require?","explanation":"A policy with the redshift:Describe*, redshift:CancelQuerySession, and redshift:ViewQueriesInConsole actions will provide an IAM user with the ability to select a Redshift cluster, list all running queries, and terminate a query if needed. The redshift:DeleteQueries action does not exist. The AmazonRedshiftOperations and AmazonRedshiftQueryAdministrator managed policies do not exist.","links":[{"url":"https://docs.aws.amazon.com/redshift/latest/mgmt/redshift-iam-access-control-identity-based.html","title":"Using Identity-Based Policies (IAM Policies) for Amazon Redshift"},{"url":"https://aws.amazon.com/blogs/big-data/granting-fine-grained-access-to-the-amazon-redshift-management-console/","title":"Grant fine-grained access to the Amazon Redshift Management Console"}],"answers":[{"id":"1c9dea7ba839156d4a9974ba5fb8b5eb","text":"Assign the AmazonRedshiftOperations managed policy to the users on the operations team.","correct":false},{"id":"b69684debc1d2f03125faa0a3a2c466c","text":"Assign the AmazonRedshiftReadOnlyAccess and AmazonRedshiftQueryAdministrator managed policies to the users on the operations team.","correct":false},{"id":"313e53fee44351534143a5526b03f8b1","text":"Create a custom IAM policy that includes the redshift:Describe*, redshift:View* and redshift:DeleteQueries actions. Assign the policy to the users on the operations team.","correct":false},{"id":"13679882b475c07d8adca4e6fa29df4f","text":"Create a custom IAM policy that includes the redshift:Describe*, redshift:CancelQuerySession, and redshift:ViewQueriesInConsole actions. Assign the policy to the users on the operations team.","correct":true}]},{"id":"dbb146aa-ae1d-411e-82be-4777bd07c916","domain":"Performant","question":"A financial market dashboard needs to update asset values almost instantaneously for customers across the United States. Updates will be written to the primary application instance which resides in the AWS us-east-1 region. Which database architecture will provide the best performance for consumers of the dashboard's information?","explanation":"With Aurora MySQL you can configure cross-region Aurora Replicas using logical replication to up to five secondary AWS regions. Aurora PostgreSQL currently does not support cross-region replicas. Aurora Replica physical replication can only replicate to one secondary region. Using Aurora over RDS provides multiple read replicas in the deployment region and other benefits automatically without having to configure them.","links":[{"url":"https://aws.amazon.com/rds/aurora/?nc=sn&loc=0","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/?nc=sn&loc=6","title":"Amazon Aurora FAQs - High Availability and Replication"}],"answers":[{"id":"91857d4bed60ff0818ab1d95e0314b9c","text":"Deploy Amazon Aurora MySQL with Aurora Replicas using cross-region logical replication. Create the replicas in the AWS us-east-2 and us-west-2 regions.","correct":true},{"id":"f95722da1c54e4a7b38d775dec9d3952","text":"Implement Amazon Aurora MySQL with Aurora Replicas using cross-region physical replication. Create the replicas in the AWS us-east-2 and us-west-2 regions.","correct":false},{"id":"a3f216bc2a3134a725e71894673ef3cd","text":"Deploy Amazon Aurora PostgreSQL with Aurora Replicas using cross-region logical replication. Create the replicas in the AWS us-east-2 and us-west-1 regions.","correct":false},{"id":"31441ec91d70f043876be523dca440b3","text":"Use Amazon RDS PostgreSQL with read replicas. Create the replicas in the AWS us-east-1, us-east-2, and us-west-2 regions.","correct":false}]},{"id":"85006d63-82b7-45dc-88c6-0baddad33725","domain":"ResilientDesign","question":"Which of the following is true with regards to a private IP address of an EC2 instance?","explanation":"Multiple IP addresses (IPv4 or IPv6) can be specified for an Instance depending upon Instance Types. Multiple IP addresses can be assigned and unassigned to network interfaces attached to running or stopped instances. An instance receives a static private IPv4 address from the address range within a VPC. Private IP address remains associated with the Network Interface when the instance is stopped and restarted, and is released when the instance is terminated. A secondary private IPv4 address can be assigned to any network interface. The network interface need not be attached to the instance. A secondary private IPv4 address that is assigned to a network interface can be reassigned to another one if you explicitly allow it. Although the primary network interface cannot be detached from an instance, the secondary private IPv4 address of the primary network interface can be reassigned to another network interface.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/MultipleIP.html","title":"Instance IP Addressing"}],"answers":[{"id":"c8eaf93ec90c897e9475642c70e3e7d2","text":"A secondary private IPv4 address cannot be detached or reassigned from the primary network interface to another network interface","correct":false},{"id":"8b90202f343b063cae25d7b89efaa9b1","text":"A secondary private IPv4 address can be reassigned from the primary network interface to another network interface","correct":true},{"id":"9846d1971f5a7fb2fea9fcc99d4cc93d","text":"Private IP address remains associated with the Network Interface when the instance is restarted, and is released when the instance is stopped or terminated","correct":false},{"id":"08ce21259a0fb5332a9f8cf840942c51","text":"Private IP address remains associated with the Network Interface when the instance is stopped and restarted, and is released when the instance is terminated","correct":true}]},{"id":"c4f7d0f0-4b57-41b4-a5b1-109004f29af1","domain":"Performant","question":"A CRM application runs in your data center and you have disaster recovery instances running in the AWS cloud. The on-premises CRM application requires low-latency access to all of the storage, as the entire dataset is accessed frequently. Which architecture will provide the highest performance efficiency for your business?","explanation":"Storage Gateway Volume Gateway in the stored volume configuration keeps the entire dataset on-premises and asynchronously backs up point-in-time snapshots to Amazon S3. This provides low-latency access to the entire dataset on-premises. The snapshots can be recovered to EC2 instances. Storage Gateway Volume Gateway in cached mode keeps frequently accessed data on-premises, so it would perform many S3 reads to access the entire dataset. Using an on-premises backup solution or a Storage Gateway file gateway would require the EC2 instances to use different storage access techniques than the on-premises environment.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html","title":"What Is AWS Storage Gateway"}],"answers":[{"id":"2913578801d8d764ddbef31fe86af4b2","text":"Deploy a Storage Gateway file gateway as a network file share","correct":false},{"id":"27f55f1ffd3c7df753670476a47be8d9","text":"Use your on-premises backup solution to move the data to S3 each night for use by the EC2 instances in a disaster scenario","correct":false},{"id":"6c5b3c0e5b4db806f92ab9d4ab500667","text":"Implement a Storage Gateway Volume Gateway in stored mode and perform snapshots","correct":true},{"id":"86480a8866121094f21ba24ad4a8c13c","text":"Implement a Storage Gateway Volume Gateway in cached mode and perform snapshots","correct":false}]},{"id":"922ca882-d73b-4685-acf4-7c0827021c2b","domain":"ResilientDesign","question":"The customer service organization at your company just told you that a client purchase from your website was processed twice. Your order process involves EC2 instances processing messages from an SQS queue. What changes might you make to ensure this does not happen again?","explanation":"An SWF workflow ensures that actions are executed only once.","links":[{"url":"https://aws.amazon.com/documentation/swf/","title":"SWF Documentation"}],"answers":[{"id":"da3af33124cb0627efe41ca5c7617ddf","text":"Increase the visibility timeout on the SQS queue.","correct":false},{"id":"24e1d12f9d1b3de53719bbd5341fbdf1","text":"Rewrite the order-processing workflow to use SWF, rather than SQS.","correct":true},{"id":"bacf185330f80f745f66f02bab85053a","text":"Manually delete the order after processing.","correct":false},{"id":"ae73003f30fc75b349d6c7e1407060ca","text":"Switch to long-polling.","correct":false}]},{"id":"f1715a54-ef4a-4912-9093-e8e36698b0c9","domain":"CostOptimized","question":"Your company needs to run several monthly workloads that will each take several hours to complete. Although critical, these workloads can be stopped and restarted without adversely affecting the outcome of the job. Which pricing model would you use to deliver the most economical solution?","explanation":"Spot instances are a cost-effective choice if you can be flexible about when your applications run and if your applications can be interrupted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html","title":"About Spot Instances"}],"answers":[{"id":"026db7f2265667575c05772f32778b8a","text":"Spot Instances","correct":true},{"id":"29068f6044e3fedf44165e646a2d2bb1","text":"Reserved Instances","correct":false},{"id":"de53d38fe38e0fce729f15c292a59891","text":"Free-Tier Instances","correct":false},{"id":"c658c72ec41cc513ad91a3f3e6d2c060","text":"On-demand Instances","correct":false}]},{"id":"655aca00-21a4-11ea-978f-2e728ce88125","domain":"Performant","question":"A wealth intelligence software company currently uses Oracle 12c as its database solution. However, it wants to move its databases to the AWS Cloud. Which of the following services will accommodate the migration?","explanation":"The hint to the answer lies in the company’s current database software. Oracle 12c is a relational database solution, which is what Amazon RDS is. The company can run its Oracle databases using RDS instances. Amazon DynamoDB is a non-relational DB solution and Amazon Redshift is for Big Data and Data Warehouse solutions. Amazon ElastiCache is used to increase DB performance through caching DB data to improve application performance.","links":[{"url":"https://aws.amazon.com/rds/oracle/","title":"Amazon RDS for Oracle"}],"answers":[{"id":"ecafbaed9f41dac736e496a7cd234ce4","text":"Amazon DynamoDB","correct":false},{"id":"f7415e33f972c03abd4f3fed36748f7a","text":"Amazon Redshift","correct":false},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false},{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":true}]},{"id":"5712ec99-b3af-4d82-b84a-df05e409621d","domain":"ResilientDesign","question":"CRR replicates every object-level upload that you make directly to your source bucket. Which of the following also forms a part of that replication?","explanation":"CRR replicates every object-level upload that you make directly to your source bucket. The metadata and ACLs associated with the object are also part of the replication.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"Cross-Region Replication"}],"answers":[{"id":"c714b06e394553e1a742c4cc57283c19","text":"The object's checksum encryption data","correct":false},{"id":"1ba665145e77bd9b0e924ded0df30e71","text":"The object ACLs","correct":true},{"id":"89d24ab4a65b804a6135f5acb693d32b","text":"The object metadata","correct":true},{"id":"5edbf9551ae3711bad871e0301e7612a","text":"The object's SSL certificate","correct":false}]},{"id":"a37fb7a3-3a49-40f0-b688-1d34af35855e","domain":"SecureSolutions","question":"Contractual requirements mandate the use of AWS CloudHSM as an encryption solution. Application performance is a secondary, but important, concern. Where within your AWS infrastructure should you place the HSM appliances?","explanation":"To decrease latency (and improve application performance), it's best to place your HSMs as close to your EC2 instances as possible.","links":[{"url":"https://aws.amazon.com/cloudhsm/details/#Secure_VPC_access","title":"HSMs and Latency"}],"answers":[{"id":"9df85d664730c5be05001eb90f0aca61","text":"To increase performance, you should locate the HSM as close to the majority of your customers as is possible.","correct":false},{"id":"65c5c381d9312c40bb261deb3ddc7bcd","text":"To increase security, you should place the CloudHSM appliances in their own, private subnet.","correct":false},{"id":"81903e4cb00fb844367c771fd69072e7","text":"Locating HSM appliances near your EC2 instances decreases network latency, which improves application performance.","correct":true},{"id":"b1b0304054038e008892902f9ecb32b6","text":"To increase security, you should place the HSM appliances on your side of the VPN that connects to AWS.","correct":false}]},{"id":"28b03a03-1f36-4a9d-97e2-921457895c4c","domain":"SecureSolutions","question":"Which of the following statements is FALSE regarding the role of a bastion host?","explanation":"A Bastion Host is a hardened instance accessible from a less secure environment (Internet) and used as a secure platform to administer a more secure environment which will typically be in a private subnet.  The Bastion host normally sits in a public subnet, but with a route to the private subnet. (Also known as a Jump Box in some places.)","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html","title":"Linux Bastion Hosts on AWS"}],"answers":[{"id":"d6a9fb6da4dc9422be75916f103ebafe","text":"A bastion host should be protected in a private subnet.","correct":true},{"id":"065f5801e2d2aa076a66624ef3fd35cd","text":"As a bastion host is exposed to the Internet, it should be hardened.","correct":false},{"id":"e9e698f0ed17e25fb3b6f7676d66c090","text":"A bastion host sits outside a private subnet and is used as a secure gateway to that internal network.","correct":false},{"id":"6fca98f904dc4ff43fa1650e5e739446","text":"A bastion host can be used to SSH into an EC2 instance.","correct":false}]},{"id":"99b3a227-a362-456e-8474-dba3e0b3f6ff","domain":"Performant","question":"You are developing a video conferencing service that translates spoken language to sign language in near real time using AWS Lambda. One of your functions does the heavy video/audio lifting by using common utilities including FFmpeg, Sound eXchange (SoX) and ImageMagick - each provided as a separate layer. Your function is also connected to nltk, the Python Natural Language Toolkit library and your own custom archive with some shared code - both provided as additional layers. You encounter a problem after you've updated your function's configuration to change to the latest version of your code. What are possible reasons for that and how can you resolve that issue?","explanation":"You can specify up to 5 layers in your function's configuration, during or after function creation.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html","title":"AWS Lambda Layers"}],"answers":[{"id":"00133f9caaca04cea058c5ceb62d5a8a","text":"You have gone over the 250MB unzipped deployment package size limit. Remove some unused libraries from your own archive.","correct":true},{"id":"dbc5c5e38dfb1c3c8d8f6d0a1d1ca917","text":"Layers are extracted to the /opt directory in the function execution environment and applied in the order that's specified, merging any folders with the same name. If the same file appears in multiple layers, the version in the last applied layer is used. Rename the conflicting file in your archive.","correct":true},{"id":"4a90d094e62078f6c53fa5c71052b723","text":"You reached the 50MB zipped deployment package size limit for direct uploads. Refactor your function and move some code into a new layer.","correct":false},{"id":"14a4dc8ed5178c4185b29595e49de3df","text":"When you added the last layer to your function, the previous list was overwritten by the new one. Include all layers every time you update the layer configuration.","correct":true}]},{"id":"f3d178d0-2157-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"Which of the following AWS Support elements provide the assessment of how ready your AWS environment is for your application prior to launch?","explanation":"If you need an assessment of your AWS environment to help identify and mitigate risks that can affect your application prior to launch, you need an AWS Support plan that includes Infrastructure Event Management. The other elements mentioned here are not event or launch focused; Technical Account Managers handle more technical issues. The Support Concierge is a team of enterprise account specialists dedicated to billing and account issues, and Trusted Advisor is all about helping you reduce cost, increasing performance, and improving security.","links":[{"url":"https://aws.amazon.com/premiumsupport/programs/iem/","title":"AWS Infrastructure Event Management"},{"url":"https://aws.amazon.com/premiumsupport/plans/enterprise/","title":"AWS Enterprise Support"}],"answers":[{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"af8f25ab81f04f0feba2075a09b65389","text":"Infrastructure Event Management","correct":true},{"id":"3d582ac943b9ba9113651d26bdee7a79","text":"Technical Account Managers","correct":false},{"id":"33b19f092c13caec1202c108b57d2bc1","text":"Support Concierge","correct":false}]},{"id":"04a5e1e1-9fc6-4371-a53c-cecc6fad3b2a","domain":"ResilientDesign","question":"Elasticity is a fundamental property of the cloud. Which of the following best describes elasticity?","explanation":"In cloud computing, elasticity is defined as 'the degree to which a system is able to adapt to workload changes by provisioning and de-provisioning resources in an autonomic manner, such that at each point in time the available resources match the current demand as closely as possible'.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html","title":"Scalable Computing Capacity"}],"answers":[{"id":"80b90762201e3ac35c7921416cc86c81","text":"The power to increase the number of resources at your hands at the click of a mouse.","correct":false},{"id":"71babaf2f5ed118cdbb0f5ff115354ce","text":"The ability to deploy managed services into your environment.","correct":false},{"id":"9b1cc2503b70776f795a2155b7f2e380","text":"The ability to manually deploy instances quickly in response to events.","correct":false},{"id":"2d60e660232553b4fb11100329fdb97e","text":"The power to scale resources both up and down with changes in demand.","correct":true}]},{"id":"70c6a808-0d5d-40d3-9b62-aa2fd031a543","domain":"CostOptimized","question":"You have three AWS payer accounts consolidated under an AWS Organization . Which of the below statements is TRUE for purposes of volume discounts?","explanation":"If you have multiple accounts, your charges will decrease because AWS combines usage from all accounts in the organization to qualify you for volume pricing discounts.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html","title":"Consolidated Billing for Organizations"}],"answers":[{"id":"a6cd99e8b1bbcfc82e184acc9f28eede","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled in each account","correct":false},{"id":"98e718508cd32b9ffb27d8648e9129d0","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to","correct":true},{"id":"4fb1af36b069dca73268eedbfab53e7b","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled at the Organisation level","correct":false},{"id":"c9c2416d95c8112070b7a5b032629fdf","text":"Usage in each account will be evaluated individually to determine the volume discount it is individually entitled to","correct":false}]},{"id":"5deb4341-6227-4888-a90f-7d60c7a1d98b","domain":"SecureSolutions","question":"From the command line, which of the following should you run to get the public hostname of an EC2 instance?","explanation":"You would use the command: curl http://169.254.169.254/latest/meta-data/public-hostname","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html","title":"Instance Metadata and User Data"}],"answers":[{"id":"6c35b09a9009a5dac8ac16ad9b47b8f4","text":"curl http://254.169.254.169/latest/meta-data/public-hostname","correct":false},{"id":"c956ddf5572e1ce76e0c9822361df9d6","text":"curl http://169.254.169.254/latest/user-data/public-hostname","correct":false},{"id":"c3d29bd94a60071732654a962c3f9893","text":"curl http://254.169.254.169/latest/user-data/public-hostname","correct":false},{"id":"1d247c911fbeac310a9432b2783691a1","text":"curl http://169.254.169.254/latest/meta-data/public-hostname","correct":true}]},{"id":"065cc94c-c2aa-4473-a91b-da36edf81dd9","domain":"CostOptimized","question":"You are about to create an Amazon Elastic File Service (EFS) file system for your EC2 instances, and you don’t anticipate frequent access of its files. So, you decide to choose a lifecycle policy that will automatically move the files to the Infrequent Access (IA) storage class after a certain period of time. Which of the following options is the most cost-effective lifecycle management policy?","explanation":"When an EFS file system is created, it stays in the Standard storage class and you will be charged accordingly. By choosing a lifecycle management policy that automatically moves the file system to the IA storage class after a certain period of time since last accessed, you will be charged a significantly lower rate. So, the longer you have the file system in the Standard storage class, the more you will spend. That’s why 7 days since last access is the right answer; you would be charged Standard rates in just 7 days since last access, instead of 14 or 30 days. 'Move files to Infrequent Access Storage after 7 days' is not a valid lifecycle policy.","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html","title":"What Is Amazon Elastic File System?"}],"answers":[{"id":"20e40903e738930282c41b8a8e54d78e","text":"Move files to Infrequent Access Storage after 7 days","correct":false},{"id":"535e339a0c1c98846e7c69391f7e1d69","text":"30 days since last access","correct":false},{"id":"32f28c9de44e4f47556341ce4e025177","text":"7 days since last access","correct":true},{"id":"525de4bc0ec90825ec4c5ed5e89d8308","text":"14 days since last access","correct":false}]},{"id":"1ea8aa1e-9454-49b0-b4e2-379eadf674e0","domain":"CostOptimized","question":"You are an employee at a communications firm that is in the process of migrating its data to Amazon S3. The data will be stored in buckets and is sent to customers to do as they see fit. However, certain data is frequently changed when customers request revisions, while the rest of the data is rarely changed. You must be able to immediately access certain data while minimizing costs. Which S3 storage class should you choose?","explanation":"While S3 Glacier is a low-cost storage class, it is for data archiving and thus not ideal for frequent access or changes to data. And S3 One Zone-Infrequent Access is also low-cost, but it does not address the frequently changed data. Although S3 Standard is a suitable choice, since it addresses frequent access, it is not the least expensive choice for the less frequently accessed data. If it was hard to determine which data is frequently changed and which isn’t, S3 Standard might have been the most cost-effective choice. But in this case, S3 Intelligent Tiering is. Intelligent Tiering stores data in two access tiers: one tier is optimized for frequently accessed data while the other is a lower-cost tier for infrequent access.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"5605213ade8877d8d601580dbd0a8aa2","text":"S3 One Zone-Infrequent Access","correct":false},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":true}]},{"id":"6a2430bd-d84d-4d98-948b-c1f9e4130752","domain":"Performant","question":"Which of the following protocols is not supported with an Classic Load Balancer?","explanation":"Amazon's Classic ELB supports the following protocols: HTTP, HTTPS, TCP, and SSL.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html","title":"Listeners for Your Classic Load Balancer"}],"answers":[{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":false},{"id":"293c9ea246ff9985dc6f62a650f78986","text":"HTTP","correct":false},{"id":"c728a49363c9a93a43a7e7f232b5a54a","text":"FTP","correct":true},{"id":"765553e6c7ac8592c389acb9878a050a","text":"SSH","correct":true}]},{"id":"b21cf2a7-0cf1-47d4-a0c2-60403bb9cf37","domain":"CostOptimized","question":"To stay within the AWS Free Tier using Amazon EC2 for the first 12 months of having an AWS account, which of the following instance types should you use?","explanation":"One of the EC2 requirements for staying within the AWS Free Tier is using EC2 micro instances only. That makes t2.micro and t3.micro the correct responses.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc","title":"AWS Free Tier"}],"answers":[{"id":"1d4f2c610dbeb44e7ba09fed19564c76","text":"t2.micro","correct":true},{"id":"ab61127647912c159c3fc08e9a102efc","text":"t2.small","correct":false},{"id":"7d3869f3c790e32d408d21d331095b0b","text":"t3.micro","correct":true},{"id":"affa6cb0576af5aa6e603780fe7b203c","text":"t3a.small","correct":false}]},{"id":"fa42251d-b1dd-4f48-89e3-9b2d380cd7e7","domain":"SecureSolutions","question":"As a follow up to a recent security breach you have been asked what steps can be taken to ensure that System Administrators always use signed communication when interacting with your AWS account via the API interface.  Which statements are most accurate?","explanation":"AWS use the signing hash to identify the requester.  The signing hash is unique and is generated from the access key ID and secret access key downloaded from IAM.","links":[{"url":"https://docs.aws.amazon.com/general/latest/gr/signing_aws_api_requests.html","title":"Signing AWS API Requests"},{"url":"https://docs.aws.amazon.com/general/latest/gr/signature-version-4.html","title":"Version 4 Signing Process"}],"answers":[{"id":"2fc0c0ad8f8d7b7e96e9c55eddad0a66","text":"All http requests to the API must be manually signed via the process documented by AWS.","correct":false},{"id":"5fc787c76af6f67cedad71fe3d613e5c","text":"The process of manually signing requests is only needed when writing bespoke low level connections with the API.","correct":true},{"id":"ccfd209f6df2f05725814983d4c59a38","text":"You must advise that this is an area over which customers have little control. The signing of all but anonymous requests is enforced by AWS.","correct":true},{"id":"6ed674cf84d9fda42ef11dfe73378e07","text":"It will be necessary to install signing utilities provided by openssl.org to generate personalized signing certificates signed by the Secret key downloaded from IAM.","correct":false},{"id":"c151166b8406fba447b3bd441ed7982c","text":"AWS advise against signing HTTP API traffic as the capability is redundant when communicating with the AWS API.","correct":false}]}]}}}}
