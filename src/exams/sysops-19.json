{"data":{"createNewExamAttempt":{"attempt":{"id":"e2421a20-a71a-45f9-8ab8-26d9eae30051"},"exam":{"id":"92eb47fa-e510-464e-b41d-92915b0c43d5","title":"AWS Certified SysOps Administrator - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"78cce7a4-ca99-425a-9b76-cc6d6dea1ce3","domain":"mon-rep","question":"For which of the following would you need to create a custom metric in order to monitor it in CloudWatch?","explanation":"By default, CloudWatch will provide metrics on Network, Disk and CPU. You will need to use a custom metric if you want to gather memory metrics","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html","title":"Monitoring Memory in CloudWatch"}],"answers":[{"id":"eec89088ee408b80387155272b113256","text":"Network","correct":false},{"id":"4789f23283b3a61f858b641a1bef19a3","text":"Memory","correct":true},{"id":"380dbc8d9d2c8a17f6ebb0b2c62d3e85","text":"Disk","correct":false},{"id":"2b55387dd066c5bac646ac61543d152d","text":"CPU","correct":false}]},{"id":"c7e5ebf3-7eae-45bf-a02b-28bc06a6d575","domain":"mon-rep","question":"You have several CloudWatch Log Groups and Lambda Functions send logs to them. You need to use a tool to quickly search and analyze the log data in the log streams. The tool should automatically discover information in the Lambda logs such as the timestamp, max memory used and execution duration. It should also help you to perform the query using simple and pre-built query languages. Which tool is the best one for you to choose?","explanation":"CloudWatch Logs Insights is the most suitable tool to perform pre-build queries on CloudWatch Logs. Users do not need to transfer or transform the log streams. The log fields contained in the Lambda logs are automatically discovered. AWS Athena only performs queries on S3 objects. For Amazon ElasticSearch or Kinesis stream, extra configuration steps are required.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html","title":"Analyze log data with CloudWatch Logs Insights"}],"answers":[{"id":"2c4abdd6514dcf68f6bace3f1a769e4f","text":"Stream the log data to an Amazon Kinesis stream and perform real time queries or analysis in the stream.","correct":false},{"id":"01551b4fd4b50ed9ceb2be1d0e338932","text":"Use AWS Athena to run queries on the log streams. The query language of Athena is based on SQL.","correct":false},{"id":"7edc1b3e500b915d821d4db1db01280c","text":"Use CloudWatch Logs Insights to select the log groups and perform queries.","correct":true},{"id":"79930c2280cb2398212ed1465b34b81e","text":"Export the log data to an Amazon ElasticSearch Service. Use ElasticSearch to perform queries or analysis.","correct":false}]},{"id":"4553a766-ae3d-4a15-a0cd-8f7617510415","domain":"security-comp","question":"You work at a pharmaceutical company who has just deployed a new web application in to their development environment. The webapp sits inside a single Availability Zone inside a public subnet and runs on PHP. It connects in to an RDS instance which is in a private subnet running MySQL. You load the webapp’s DNS address in your browser and you get the following error “Database Connection Error” what might be the cause of the problem?","explanation":"You need to configure the Security Group to allow ingress access to allow inbound connections to the RDS instance","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups"}],"answers":[{"id":"30e5bf736c605d975c83d2bc39ba2e63","text":" The security group for the RDS instance does not allow ingress access to the RDS instance","correct":true},{"id":"4cbe0aae95d4b87bb274b250394fcd6c","text":"The security group for the Webserver does not allow ingress SSH access to the instance","correct":false},{"id":"c343ffd845f05787efb4ada77e096f99","text":"The security group for the RDS instance does not allow egress access to the RDS instance","correct":false},{"id":"c9f3da4211e1e93ebb9d49ee8c2a0bd6","text":"The security group for the Webserver does not allow egress SSH access to the instance","correct":false}]},{"id":"f5213e28-c41d-4552-810a-7aa8f5ba2a1c","domain":"networking","question":"A Developer is unable to connect to an EC2 instance in a VPC. A SysOps Administrator investigates the connectivity issue. Going through a troubleshooting checklist, which conditions should be checked? Select two.","explanation":"Internet gateways allow all traffic and that cannot be configured. EC2 instances always have a private IP but a public IP is required for internet access. Security groups are stateful so only an allow rule for incoming traffic is required.","links":[{"url":"","title":""}],"answers":[{"id":"50be1cda181093d2df7e72aed5f80ab8","text":"The instance has a public IP address.","correct":true},{"id":"f9b2c3489abcbefefb1b289a51e33ccb","text":"The internet gateway associated with the VPC allows incoming traffic.","correct":false},{"id":"692e30da816ea07b3744e393cbbd28cd","text":"The instance has a private IP address.","correct":false},{"id":"578d4a14aed3e21944a0f081460e32af","text":"The security group has an allow rule for outgoing traffic.","correct":false},{"id":"08eefee7811ea91e42e46ba287ff5d6a","text":"The security group has an allow rule for incoming traffic.","correct":true},{"id":"8b476944980fce87668c22d0c40470e9","text":"The internet gateway associated with the VPC allows outgoing traffic.","correct":false}]},{"id":"6f301a69-46dd-413e-a666-a2aca6828271","domain":"dep-prov","question":"A developer created a Docker image for a web application and pushed the image to a repository in the Amazon Elastic Container Registry (ECR). Now you need to build a Jenkins pipeline to deploy the application using the Docker image from the ECR repository. You want to write a shell script to login to the ECR, get the image and create a Docker container for the application. Which method would you use to login to the ECR service?","explanation":"The Docker CLI does not support native IAM authentication methods. The AWS CLI \"get-login\" command helps to retrieve a base64-encoded authorization token for Amazon ECR. The token contains the username AWS and an encoded password. Access key ID and secret access key are not used to login to the ECR service. With the IAM role configured, the Jenkins server still needs to call the AWS CLI \"get-login\" command to get the authorization token.","links":[{"url":"https://docs.aws.amazon.com/AmazonECR/latest/userguide/registries.html#registry_auth","title":"Amazon ECR registries"}],"answers":[{"id":"8d9152f9448cb85f7b3deac151d341aa","text":"Use GetAuthorizationToken API to get the secret access key and use it to login to ECR.","correct":false},{"id":"99fc40663b5b3c2abf029a6b7b5bd390","text":"Use \"aws ecr get-login\" to get an authorization token and use the token to login to ECR.","correct":true},{"id":"16e76565bf3e62750eba81ac0d2dafe0","text":"Create an IAM role that has the permission of \"AmazonEC2ContainerRegistryReadOnly\". Configure the Jenkins server with the IAM role to login to ECR service.","correct":false},{"id":"cfa0472ed8b5ebf9cfd0cfa4baf196fd","text":"Use the IAM user access key ID and secret access key to login to ECR service.","correct":false}]},{"id":"c9f0e61e-627b-421e-8a57-0d04983c25c4","domain":"security-comp","question":"You are a consultant working for a company who has recently completed their migration from an on-premise data centre to AWS. Most of the migration has been for EC2 instances, which have been sized to match the specifications they were originally using on-premise (CPU, memory, etc.). They have setup a Business Support plan with AWS. The technical manager is unhappy with the high costs, and wants to find ways to reduce them. What would the simplest way be to find ways to reduce their AWS costs in the short-term?","explanation":"This is a very common scenario for businesses migrating to the cloud, and discovering the operational expenditure (OPEX) costs of AWS. AWS Trusted Advisor has a lot of simple and effective recommendations for Cost Optimization. Some may not be applicable in your case, but it is a very easy way to find potential options for reducing your costs. These features are unlocked with the AWS Support Plans of Business or Enterprise. CloudWatch metrics can be very useful for right-sizing your instances (aligning the needs of the application workload with the instance specifications), but CloudWatch will also automate this to an extent as well by finding under-utilized instances. Reducing your support plan is usually an unwise move for production workloads, despite their cost, as they can be very important when outages are experienced. Advocating for a transition to PaaS and SaaS is definitely a strategic cost-saving measure, but it forms part of a long term business strategy, since it involves significant resources, both in time and money","links":[{"url":"https://aws.amazon.com/premiumsupport/technology/trusted-advisor/","title":"AWS Trusted Advisor"},{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Cost-Optimization-Pillar.pdf","title":"AWS Whitepaper - Cost Optimization Pillar"}],"answers":[{"id":"b4e67747b2a23a55a53554b964d1ab9b","text":"Reduce the expensive AWS Support Plan to lower costs","correct":false},{"id":"39788d9f10797f3b8c876dbe95022c0d","text":"Advocate a transition to more cost-effective PaaS and SaaS solutions","correct":false},{"id":"52107942e028b953519341a78f6815ca","text":"Inspect the CloudWatch metrics to better right-size the instances","correct":false},{"id":"55af961ef2471aec130c45657098b110","text":"Investigate recommendations from AWS Trusted Advisor's automated checks","correct":true}]},{"id":"ba52dee8-0d6c-4faf-9121-0e64c18bbf1a","domain":"high-avail","question":"Your website is evenly distributed across 10 EC2 instances in 5 AWS regions. How could you configure your site to maintain high-availability with minimum downtime if one of the 5 regions was to lose network connectivity for an extended period of time?","explanation":"If you are designing to check for loss of contact with the instances you need to use \"Evaluate Target Health\" to confirm connectivity.  The Latency policy will eventually detect the unavailability; however it is not a real-time test.","links":[{"url":"http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html","title":"How Health Checks Work in Complex Amazon Route 53 Configurations"}],"answers":[{"id":"90875d19db265ba7b3931ecbd5a5d813","text":"Establish VPN Connections between the instances in each region. Rely on BGP to failover in the case of a region-wide connectivity outage.","correct":false},{"id":"0e2faa25f8eb6371b513d8d442513b10","text":"Create a Route 53 Latency-based Routing Record Set that resolves to Elastic Load Balancers in each region and has the Evaluate Target Health flag set to \"True\".","correct":true},{"id":"b5494c49d052d62119e11eab7d8499c7","text":"Create an Elastic Load Balancer to place in front of each EC2 instance. Set an appropriate health check on each ELB.","correct":false},{"id":"dc1f9d897e82bca789bb2983fa7ce22d","text":"Create a Route 53 Latency-based Routing Record Set that resolves to an Elastic Load Balancer in each region. Set an appropriate health check on each ELB.","correct":false}]},{"id":"a8d6d4f3-6877-4e89-9e7c-c6f83b83e1de","domain":"automation","question":"A small business has a monolithic application utilizing several EC2 instances. The technology consultant has suggested to the engineering team of the business that the application is containerized to improve the deployment and scaling processes of the team. The engineering team processes both critical and non-critical workloads within the application. Given the size of the application and the number of transactions being processed by the system, the CFO has instructed the engineering team to ensure that the setup must be as cost-effective as possible without introducing the risk of data loss for critical workloads. How can the engineering team accomplish this?","explanation":"On-demand EC2 instances should be used for critical workloads and spot instances can be used for non-critical workloads. ECR (Elastic Container Registry) is not used to run container processes. Instead, it is used to store container images. For containerization requirements, ECS (Elastic Container Service) is used to manage container workloads. Step Functions is used for orchestrating different processes and can not be used by itself to manage the workloads.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-high-scale-web-on-spot-instances/","title":"Running High-Scale Web Applications on Spot Instances"}],"answers":[{"id":"1d3682fdb0beec13b13a37502cfb3108","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use Step Functions and on-demand EC2 instances for non-critical workloads.","correct":false},{"id":"b8864524b96a467a8f1023b5a2c9f003","text":"Use Step Functions and on-demand EC2 instances for the critical workloads. Use Step Functions and spot EC2 instances for non-critical workloads.","correct":false},{"id":"ddf2c2e29f2118061f6a160054593338","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECR and spot EC2 instances for non-critical workloads.","correct":false},{"id":"47e42a6e665f0a913236e5580553e3ad","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECS and spot EC2 instances for non-critical workloads.","correct":true}]},{"id":"bf96ed55-16e4-466e-af19-219458837cba","domain":"security-comp","question":"Which of the following is not a possible use case for AWS inspector","explanation":"Amazon Inspector in an agent-based service which allows you to automate security vulnerability assessments throughout your development and deployment pipeline or against static production systems. You cannot install the Inspector agent on an RDS instance.","links":[{"url":"https://aws.amazon.com/inspector/faqs/","title":"Inspector FAQs"}],"answers":[{"id":"2c7f5727b64a2fdb39bb7c27b505ad87","text":"The inspection of an RDS instance","correct":true},{"id":"8543a5ae6daf2a49147c11e5e7422e9f","text":"Use a CloudWatch Event to trigger AWS inspector to run an assesment","correct":false},{"id":"c0f6489b2e3fb0571e505c7a5560a3c3","text":"To scan your EC2 instances for Common Vulnerabilities and Exposures ","correct":false},{"id":"80b4d5c55b7c39f3d2aa5c485154a2a8","text":"Automate the assessment of your EC2 instance on a regular basis","correct":false}]},{"id":"983c6fbc-20eb-4389-a91f-491d1f1e230b","domain":"networking","question":"You have a simple VPC with a single public subnet and a security group that allows access from source 0.0.0.0/0. Although you have both an Internet Gateway and Elastic IP specified for your instance, you are still unable to reach the instance via SSH. What have you forgotten to do?","explanation":"For the outside world to be able to communicate with your instance, you must allow inbound traffic on both the Security Group and the Route Table.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#AddRemoveRoutes","title":"Adding and Removing Routes from a Route Table"}],"answers":[{"id":"93b61a7d33d3f54dee0f2c7dfd033254","text":"You haven't associated the Internet Gateway with the Security Group.","correct":false},{"id":"1e8881ac02fb21089d364fb6f88436a7","text":"You have forgotten to associate the Elastic IP with the private IP.","correct":false},{"id":"cb7394a526c29652c88dc22d58ad386a","text":"You have failed to associate the Internet Gateway with the custom Route Table.","correct":true},{"id":"9c4da4b8220f1bcf509bc4cd3ccd943f","text":"You forgot to associate the Security Group with the Route Table.","correct":false}]},{"id":"c4f661ee-5ea1-4e69-9440-52bea0321a6a","domain":"mon-rep","question":"You have set CloudWatch billing alarms for your instances running in eu-west-2. However, when you try to access the billing information and alarms, no information is visible. Why might this be?","explanation":"Billing and Alarm data can be accessed only from the us-east-1 region.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/free-tier-alarms.html","title":"Creating a Billing Alarm"}],"answers":[{"id":"7f3a3688c3f0cddb24c07255b9d13767","text":"Billing and Alarm data can be accessed only from the us-west-1 region.","correct":false},{"id":"cd2c9fa4324b5861276dbbf7f4f593a8","text":"You need to login as the root user to see such information.","correct":false},{"id":"b5ff6f2dfd759f7e70f27d7529e4462b","text":"You need to login as the account owner to see such information.","correct":false},{"id":"fb7a7d16c3f39960e7afde6babd422e1","text":"Billing and Alarm data can be accessed only from the us-east-1 region.","correct":true}]},{"id":"f0c47538-7997-40fc-9c82-27eea818fac2","domain":"security-comp","question":"A company has started running its e-commerce application in container workloads in AWS. The e-commerce application is running its web tier in Amazon ECS and the database tier in RDS all inside a VPC. Under the AWS shared responsibility model, which activities is AWS NOT responsible for?","explanation":"AWS takes care of the underlying software for managed services. For services such as EC2, the instance hypervisor and underlying hardware are managed and maintained by AWS. It is the customer's responsibility to monitor and manage the memory utilization of the containers in services such as ECS and EKS.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"1dfb8644f2cce2dca687a152b45b7d54","text":"Patching the database instance software of RDS","correct":false},{"id":"9abfc73643ea9090379aae3cd89400d1","text":"Patching the instance hypervisor","correct":false},{"id":"b7a8057898c923210f320a3bcccbcbca","text":"Maintaining the underlying hardware infrastructure of the instances used by ECS","correct":false},{"id":"ac7ca331a57c32d9975616bf91327c82","text":"Monitoring and managing the memory utilization of the containers","correct":true}]},{"id":"f43c1eae-280e-4f5b-bd96-0620dcf7ad48","domain":"data-man","question":"A company has a new Internet of Things project. You need to create a database in AWS to store customer data for further analysis. The database does not require a relational model and the data could be served using a key-value pair. You wish to quickly configure a fast and high performing database without worrying about hardware provisioning, setup and configuration, software patching or scaling. Which of the following database types would you choose?","explanation":"As the database does not require a relational model, NoSQL databases such as DynamoDB should be considered. DynamoDB offloads the administrative burdens and AWS helps to manage the DynamoDB table including provisioning, configuration, patching, etc. Amazon Aurora and QLDB do not belong to NoSQL databases. ElastiCache is a caching solution for high throughput and low latency which are not required in this scenario.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html","title":"Amazon DynamoDB introduction"}],"answers":[{"id":"69670a9d53817d1ec89e685997343ce2","text":"Amazon Aurora","correct":false},{"id":"a9d83c7f8f0b0f2a8f67b7097ee73e3a","text":"Amazon QLDB","correct":false},{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true}]},{"id":"43f0527f-8ffc-49c2-8dd8-f55203c05f15","domain":"data-man","question":"A company has a local data center that stores satellite images and the company plans to migrate the image files to AWS S3 or Glacier. The total amount of data is about 100TB. The local network speed is slow so it is not applicable to transfer the files over the internet. Which of the provided options is the best to migrate the data to AWS?","explanation":"AWS Snowball is a recommended data transport solution that accelerates moving terabytes to petabytes of data to AWS. AWS Transfer for SFTP uses the internet so it is eliminated. VPN also relies on the network connection and it cannot accelerate the data transfer. AWS Storage File Gateway is a storage service to integrate with on-premises server. It is not used to migrate data to AWS.","links":[{"url":"https://docs.aws.amazon.com/whitepapers/latest/aws-overview/migration-services.html#aws-snowball","title":"Migration and Transfer solutions"}],"answers":[{"id":"49088421573ec1c3f93f7588fb78704f","text":"Create an AWS Snowball job and transfer files to the Snowball hardware. After the device is shipped back, AWS is in charge of storing data in S3 or Glacier.","correct":true},{"id":"8ebed8f00ea6cd51a35c7bfbc4a1b000","text":"Create a high speed AWS Storage File Gateway to map all the local files to S3 or Glacier.","correct":false},{"id":"d21889436bedfa9ee6bd66e73efdc3f0","text":"Configure the AWS Transfer for SFTP service to seamlessly migrate files to AWS S3 or Glacier.","correct":false},{"id":"4713a94f713bbca5a4e46d58447eb1cf","text":"Configure the VPN direct connection from the local data center to AWS VPC. Copy over the files using the high speed intranet.","correct":false}]},{"id":"daea596c-77ce-4763-bc26-c7eabbeb3fed","domain":"automation","question":"The CTO of an e-commerce company has mandated the use of Infrastructure as Code (IaC) services and tools to manage the application resources and processes. The engineering team has divided the resources into two groups: application resources and network (VPC) resources. The engineering team lead has been instructed to transform the configuration of these resources into templates that can easily be configured to prepare different environments. How can the engineering team lead accomplish this?","explanation":"CloudFormation can be used for the IaC requirements in provisioning and managing AWS resources including VPC resources and other managed services. Out of all the options, only OpsWorks can be used as a Configuration Management service for the management application level processes and workloads inside EC2 instances. OpsWorks is not used for provisioning network resources. Amazon EKS is for managing and orchestrating containers using Kubernetes.","links":[{"url":"https://docs.aws.amazon.com/opsworks/latest/userguide/welcome.html","title":"OpsWorks"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc.html","title":"EC2 VPC"}],"answers":[{"id":"450822349ee2cf9d667ee39de6b39f39","text":"Use CloudFormation for the network resources. Use AppSync for the application resources.","correct":false},{"id":"1148de578466f53ad53ec6613254366b","text":"Use CloudFormation for the network resources. Use OpsWorks for the application resources.","correct":true},{"id":"17ad6545a81ec8297ada8e103fe040f9","text":"Use OpsWorks for the network resources. Use CloudFormation for the application resources.","correct":false},{"id":"9328d9954617430931d24f7812f5d613","text":"Use Amazon EKS for the network resources. Use OpsWorks for the application resources.","correct":false}]},{"id":"04595a27-6a9a-413a-aac3-bfa950ff8a84","domain":"networking","question":"You need to enable internet access to your EC2 instances in a private subnet, what is the most secure way to provide egress only internet access?","explanation":"A NAT gateway provides egress (outgoing) internet access for hosts in a Private subnet, you will also need to add a route to the internet via the NAT Gateway. Internet gateways allow ingress and egress internet traffic for hosts attached to Public subnets","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","title":"NAT Gateways"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html","title":"Internet Gateways"}],"answers":[{"id":"d60b4e40b731d4c21b78e8a35b139cc9","text":"Add an Internet Gateway to the Private Subnet","correct":false},{"id":"0beea13fa9f8b9da7131d1dff9d7cdd6","text":"Configure a Public IP address or Elastic IP for the hosts which need internet access","correct":false},{"id":"e61b3a55a64158231956847ef848272f","text":"Configure a NAT gateway and add a route to the internet via the NAT in your route table","correct":true},{"id":"5f748ece0d81aee4b596a0065b82c992","text":"Move the instances which need internet access to a Public subnet","correct":false}]},{"id":"41260d7b-e3b1-4ba3-81e2-f8f441b798e6","domain":"security-comp","question":"When providing mobile apps with temporary security credentials for access to AWS services, which of the following methods is best?","explanation":"AWS strongly recommends that you do not embed or distribute long-term AWS credentials with apps that a user downloads to a device, even in an encrypted store. Instead, build your app so that it requests temporary AWS security credentials dynamically when needed using web identity federation. The supplied temporary credentials map to an AWS role that has only the permissions needed to perform the tasks required by the mobile app.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html","title":"About Web Identity Federation"}],"answers":[{"id":"d48ff95a8acfcaabeb2f6a3f070af924","text":"LDAP with IAM","correct":false},{"id":"d6b9a7c9c7e8cd3c41fd1ebeae2fa4ef","text":"IAM credentials alone","correct":false},{"id":"9d5170dbe7d5ca2ce9011d9234fc376a","text":"Web Identity Federation with Cognito","correct":true},{"id":"0bcfd08b38a1d0c297fd1f4dc597a81a","text":"Active Directory with IAM","correct":false}]},{"id":"05d71be4-026e-433e-bd8b-eb4a3929ba63","domain":"automation","question":"A development team wants to use the latest Windows AMI whenever they launch an EC2 instance. Which service will allow them to query the AWS-managed Parameter Store namespace to retrieve the newest AMI for their CloudFormation template?","explanation":"AWS publish the latest AMI IDs for Operating Systems in AWS-managed parameters in the Parameter Store.  By using a Custom Resource in Lambda you can retrieve the relevant AMI ID and return it to the CloudFormation service, that way ensuring that your templates always use the newest AMI.","links":[{"url":"https://aws.amazon.com/blogs/mt/query-for-the-latest-windows-ami-using-systems-manager-parameter-store/","title":"Select AMI using Systems Manager Parameter Store"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources-lambda.html","title":"AWS Lambda-backed Custom Resources"}],"answers":[{"id":"cdf3a2f6faa3abf891b952dde17eb469","text":"CloudFormation Template Transformation","correct":false},{"id":"8c19fb5ff9d451c3f315e96ca8563b84","text":"CloudFormation Linked Parameters","correct":false},{"id":"dc0efa07b1be89f7cfd1ab666df2f949","text":"CloudFormation Custom Resource using Lambda","correct":true},{"id":"7eb8f6238570dc713a360eae3029648f","text":"CloudFormation Mappings","correct":false},{"id":"2751cfe1530d4333f0bdac2d7b7c21bd","text":"CloudFormation using AWS Systems Manager Parameter Store","correct":true}]},{"id":"b2d3b949-889b-4bbd-8ec9-c65b764c47c3","domain":"mon-rep","question":"You are a SysOps Administrator monitoring a web app that lets users upload high-quality images and use them online. Each image requires resizing and encoding. The images are placed in an Amazon SQS queue for processing by an EC2 instance. It processes the images and then publishes the processed images where they can be viewed by users. When you monitor the EC2 instance you see that the CPU utilization is consistently at 90% and that image processing time is being delayed. The team is looking for a cost-effective solution. What would you recommend?","explanation":"You can use an Auto Scaling group to manage EC2 instances for the purpose of processing messages from an SQS queue. Set a custom metric to send to Amazon CloudWatch that measures the number of messages in the queue per EC2 instance in the Auto Scaling group, and then set a target tracking policy that configures your Auto Scaling group to scale based on the custom metric and a set target value. CloudWatch alarms invoke the scaling policy. Increasing the size of the instance may work but is not a cost-effective solution since Auto Scaling gives you the option to scale down during low demand. Kinesis Data Streams are best suited for real-time data processing, and they have a size limit of 1MB which would be too low for high-quality images. Migrating the data to DynamoDB would not be a viable, let alone cost-effective, solution.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html","title":"Scaling Based on Amazon SQS"}],"answers":[{"id":"3a781b7e075f07b31a51c98b18d84a2e","text":"Increase the size of the instance and ensure that it is compute-optimized to boost it's capacity to process the images.","correct":false},{"id":"40fe2365fa7bae167e628c9ef29bd6ca","text":"Move the images into Kinesis Data Streams where you'll be able to process the data in real time.","correct":false},{"id":"c1c44e18b3c0f81b8ec026e9e1ab5b38","text":"Place the instance in an Auto Scaling group. Use CloudWatch metrics to scale out the Auto Scaling group depending on the size of the SQS queue.","correct":true},{"id":"52bcbdff61b39eafa67d9496dc77ee09","text":"Migrate the image data into DynamoDB. Attach a role to the instance to be able to access the data from DynamoDB and process the images.","correct":false}]},{"id":"7a7b01a3-cf61-4bbc-89f5-99065fc48b61","domain":"dep-prov","question":"Which of the following might help resolve an InsufficientInstanceCapacity error when launching an instance?","explanation":"If you get an InsufficientInstanceCapacity error when you try to launch an instance or restart a stopped instance, AWS does not currently have enough available On-Demand capacity to service your request. To resolve the issue, you can: wait a few minutes and then submit a launch request again; submit a new launch request without specifying an Availability Zone; or submit a new launch request using a different instance type. Requesting an instance limit increase will help with resolving an InstanceLimitExceeded error but will not help with an InsufficientInstanceCapacity error. Requesting an increase to an Amazon EBS volume limit will help with a VolumeLimitExceeded error but will not help with an InsufficientInstanceCapacity error.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity","title":"Troubleshooting Instance Launch Issues"}],"answers":[{"id":"6466bc1f56521a662522f33ad6f71f30","text":"Request an increase to the Amazon EBS volume limit","correct":false},{"id":"154758dad301ec2c98aa017346291b16","text":"Submit a new launch request using a different instance type","correct":true},{"id":"8ed67781418ab44be37b294251671f76","text":"Submit a new launch request without specifying an Availability Zone","correct":true},{"id":"07c7108aae2d4850d8cd2e2e92a24cad","text":"Wait a few minutes and then submit a launch request again","correct":true},{"id":"c7a40da6d0e8fc9e5508f87e2279a25a","text":"Request an instance limit increase on a per-region basis","correct":false}]},{"id":"de2610da-0b20-4258-b215-146e96c134d3","domain":"automation","question":"Which section of a CloudFormation template allows you to set up differing instance types based on environment type (e.g. 'Production' or 'QA')?","explanation":"","links":[{"url":"http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"}],"answers":[{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":false},{"id":"229eb04083e06f419f9ac494329f957d","text":"Conditions","correct":true}]},{"id":"3f2da740-c544-4f1e-91c5-82a11619c457","domain":"automation","question":"An engineer has been instructed to generate a CloudFormation template that creates an ElastiCache cluster automatically when in production mode. How should the engineer accomplish this?","explanation":"This use case involves the use of a parameter (input) and a condition that changes the behavior of the template depending on the parameter. With the use of CloudFormation conditions, only one template is used instead of multiple similar templates","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/conditions-section-structure.html","title":"CloudFormation - Conditions Section Structure"}],"answers":[{"id":"59d4d9c4627999c1d25bf01e7b161b6b","text":"Create two templates. One for the production template with the ElastiCache cluster and another without the ElastiCache cluster.","correct":false},{"id":"7c59d26f19f71a761bc0b00e8194713f","text":"Use SAM templates instead of CloudFormation templates to manage the differences between environments.","correct":false},{"id":"778d1401e9dd6d35d4355b56d7c12d3f","text":"Use a parameter for the environment. Add a condition in the CloudFormation template to create the ElastiCache resource only when environment = production.","correct":true},{"id":"944e9640a5444863d4993d2e7da7719e","text":"Use nested CloudFormation stacks with one stack creating an ElastiCache resource and another without the ElastiCache resource.","correct":false}]},{"id":"d5760f8d-25af-48b0-8e78-5d8d3d1e91cc","domain":"dep-prov","question":"You have a DynamoDB table in region ap-southeast-2 that stores users’ subscription data. As more and more users come from Europe, you want to configure a replica table that has the same name and schema in region eu-central-1. When the application writes data to a replica table, DynamoDB should automatically propagate the write to the other one. How should you implement this?","explanation":"Global Table in DynamoDB is a feature that configures DynamoDB as a fully-managed, multi-region and multi-master database. The global table consists of one replica table per Region and DynamoDB automatically keeps the table data in sync between replicas.","links":[{"url":"https://docs.aws.amazon.com/en_pv/amazondynamodb/latest/developerguide/globaltables_HowItWorks.html","title":"DynamoDB Global Tables"}],"answers":[{"id":"82b856354099b33a5dbb0b6e1a12b264","text":"Create a new table in region eu-central-1 with the same name and schema. Sync the original table with the new table.","correct":false},{"id":"4de5416858aeddf52eafd42cce3ef87f","text":"Configure a read replica in region eu-central-1.","correct":false},{"id":"dafd6112e9fb08d950b54c7836f9805a","text":"Configure automatic backups for the table in another region.","correct":false},{"id":"849e48fd8762258d9c7afa5c95203db0","text":"Configure a global table in region eu-central-1.","correct":true}]},{"id":"3xre6hrv-j02a-kj8k-nkyn-5951wwipzpzd","domain":"automation","question":"Which service can you use to enable configuration management using Chef or Puppet?","explanation":"OpsWorks is a configuration management service that provides managed instances of Chef and Puppet. Config allows you to record and evaluate configuration but doesn't use Chef or Puppet, Systems Manager is an operational insights tool and Athena is used to run SQL queries on data held in S3.","links":[{"url":"https://aws.amazon.com/opsworks/","title":"OpsWorks"}],"answers":[{"id":"c42aaccedc51aac929c8ae313066f320","text":"OpsWorks","correct":true},{"id":"582ca45acfd3e21caca8b786c1413850","text":"Athena","correct":false},{"id":"8e75b153e61c22a8ea4e14aadc7cb4ee","text":"Systems Manager","correct":false},{"id":"fa535ffb25e1fd20341652f9be21e06e","text":"Config","correct":false}]},{"id":"fe87b3bd-e952-4f75-9b0e-3583fe879ad6","domain":"data-man","question":"Your manager has informed you that due to compliance issues, all data stored in company S3 buckets must be encrypted as soon as possible.  What is the quickest way to ensure all of this data is encrypted to meet the requirements?","explanation":"The easiest and quickest way to encrypt data in a bucket is to use Server Side Encryption, because Client Side Encryption will encrypt the files before sending to S3 and therefore will only work on newly uploaded files, we can discount any Client Side Encryption options first.  Of the remaining Server Side Encryption options, we can remove any method of managing keys ourselves, as this creates an overhead, so using S3 Managed Keys (SSE-S3) will be the quickest way to encrypt objects in a bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Server-Side Encryption"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Client-Side Encryption"}],"answers":[{"id":"873764e12ed3764f29ba07e9fcdb622a","text":"Enable Server-Side Encryption with S3-Managed Keys on each S3 bucket","correct":true},{"id":"56f875bcb7f1ca2bd789c15f1cdc5c37","text":"Enable Server-Side Encryption with AWS KMS-Managed Keys on each S3 bucket","correct":false},{"id":"1a4d7384bee05f19390352598fbc5fb6","text":"Enable Server-Side Encryption with Customer-Provided Keys on each S3 bucket","correct":false},{"id":"d16f34464ccb19afe4b04ca69703c59e","text":"Encrypt new data using AWS KMS–Managed Customer Master Key and add to S3 bucket","correct":false}]},{"id":"f77c40bd-922a-4bd5-8688-355a24e5b7f4","domain":"mon-rep","question":"As a SysOps Administrator you are auditing the patches across all the RDS instances within the us-east-1 Region of your AWS environment. You need to check the OS of the instances to ensure that the latest patches are installed and that the proper security requirements are being met. What AWS service could you use to complete your task?","explanation":"You can view whether a maintenance update is available for your DB instance by using the RDS console, the AWS CLI, or the Amazon RDS API. If an update is available, it is indicated in the Maintenance column for the DB instance on the Amazon RDS console. You can use Amazon Inspector service to create and run security assessments for your Amazon EC2 instances. AWS Artifact is used for gathering central compliance-related information that matters to you. Trusted Advisor online tool that provides you real time guidance to help you provision your resources following AWS best practices and would not necessarily provide OS patching related recommendations. These are best viewed directly in the RDS console.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_UpgradeDBInstance.Maintenance.html","title":"Maintaining a DB Instance"}],"answers":[{"id":"289e4c4b17e574f33583898b34a8f37a","text":"Check maintenance of the instances on the Amazon RDS console.","correct":true},{"id":"af6beaf0a652352efd6b43acbef87765","text":"Check AWS Artifact to view the patch requirements of the instances in your AWS environment.","correct":false},{"id":"f5182b63a0b85cdb1fba4efaac2c38d6","text":"Use Amazon Inspector to run a report that shows the current security status of your RDS instances.","correct":false},{"id":"d289311b7f2b2249f93a154c2a78e69a","text":"Use the AWS Trusted Advisor dashboard to view recommendations.","correct":false}]},{"id":"daab371e-09f1-4d56-ae18-ac01147c8d31","domain":"automation","question":"Your organisation is growing their AWS footprint and wants to build a dashboard for their hybrid infrastructure.  They use a mix of on-premises Linux and Windows machines, and new AWS EC2 instances. There are around 1500 on-premises VMs which your CTO ambitiously wants to manage with a centralised configuration tool.  How can your organization simplify the management of the patching and inventory of both the on-premises and cloud instances from one central AWS account?","explanation":"Microsoft patching is only available for on-premises instances under the 'advanced-instances' tier of Systems Manager.  The standard Systems Manager tier also only enables you to register a maximum of 1,000 servers per AWS account per AWS Region. If you need to register more than 1,000 servers or VMs in a single account and Region, then you need to use the advanced-instances tier. Since there are over 1,000 servers, and a mix of Windows and Linux workloads, the organisation needs to enable Systems Manager Advanced-Instances before it can perform inventory and patching of the whole hybrid fleet using SSM.","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-managedinstances.html","title":"Setting Up AWS Systems Manager for Hybrid Environments"}],"answers":[{"id":"b99a0eb336123271439fdc9e65a6eace","text":"You can patch on-premises Linux VMs using AWS Systems Manager, however patching of on-premises Windows instances is not supported using AWS Systems Manager.","correct":false},{"id":"dc3a64c07de1193f3276dfd13990fbc3","text":"Enable AWS Systems Manager Enterprise to inventory and patch instances via the SSM agent.","correct":false},{"id":"34c2b7a9390e3561fd7641103bc12575","text":"Use AWS Systems Manager Managed Instances to inventory and patch instances via the SSM agent.","correct":true},{"id":"59d2c9186d25dac05a2935b57bd9c708","text":"Enable AWS Systems Manager Advanced-Instances and use Systems Manager to inventory and patch the instances via the SSM agent.","correct":false}]},{"id":"3af6fa26-fd1c-4df8-9cbd-1b09cb27b058","domain":"high-avail","question":"You deploy a Lambda function as the backend service to process requests from end users. Due to a recent market activity, the incoming requests get much higher than before. After monitoring the service for several days, you notice that there are lots of requests that fail with a throttling error (429 status code). How would you resolve the issue?","explanation":"The concurrency limit of the Lambda function should be increased through AWS support center. The reserved concurrency cannot be higher than the limit itself so it does not help. If the failed requests are put in the SQS queue, users are still impacted. This scenario utilises a Lambda function, so it is not relevant to modify the API gateway. And the API gateway traffic may not reach the limit yet.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/scaling.html","title":"AWS Lambda function scaling"}],"answers":[{"id":"326750c51756ebed25ac138a6c3d8415","text":"Route the failed requests to an SQS queue. Resubmit the queue items to the Lambda function after 1 minute.","correct":false},{"id":"3bdad2b7a566c133c99a06077bed7f7f","text":"Increase the concurrency limit of the Lambda function by submitting a request in AWS support center.","correct":true},{"id":"afd1504172407f21b8671eadec82ead0","text":"Request to increase the API gateway limit in AWS support center console.","correct":false},{"id":"76a6affef46852926b4ffbab868e6dff","text":"For the particular Lambda function, reserve a higher amount of concurrency.","correct":false}]},{"id":"914fc47e-b5c0-4656-a8c0-720a9be77de2","domain":"dep-prov","question":"The SysOps Administrator is asked to move an EBS backed EC2 instance to another subnet located in the same availability zone and VPC. What are the steps for doing this?","explanation":"After an instance is created, it's subnet, availability zone (AZ) or VPC cannot be changed. To move the instance to another subnet, AZ or VPC, the procedure is the same. You need to create an Amazon Machine Image (AMI) from the instance and use it to launch a new instance in the other subnet/AZ/VPC.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/move-ec2-instance/","title":"How do I move my EC2 instance to another subnet, Availability Zone, or VPC?"}],"answers":[{"id":"0ab0e29fee22da4e840b20464d3bd8d8","text":"First stop the instance. Then change the subnet setting of the instance and the EBS volume. Finally, start the instance.","correct":false},{"id":"8ba2cf71046c99797161e9373617c3c5","text":"First stop the instance. Then change the subnet setting of the instance. Finally, start the instance.","correct":false},{"id":"21c28e8b82fc7f82eb14a0c2ebd7be5e","text":"First change the subnet setting of the instance and the EBS volume. Then reboot the instance for the setting to take effect.","correct":false},{"id":"89ea00d59c1d39acb0c3e0d0a86499a8","text":"First create a new Amazon Machine Image (AMI) from the instance. Then use the AMI to launch a new instance in the other subnet. Finally, terminate the old instance.","correct":true}]},{"id":"6afb3149-0215-4a56-871a-ba55ad07fa07","domain":"security-comp","question":"To meet the security compliance, all the EBS volumes in your AWS account need to be encrypted. The encryption key should have the key material imported from a local server. And the key material is required to be maintained outside of AWS. Which of the below options should you choose?","explanation":"By using Customer Managed Key in KMS, you can import your own key material into the CMK. Then the key can be used to encrypt EBS volumes. You cannot modify the key material for AWS Managed Keys such as aws/ebs.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/importing-keys.html","title":"Importing key material in AWS Key Management Service (AWS KMS)"}],"answers":[{"id":"18d880df394bfc8553f32d13907972d2","text":"Configure a Customer Key Store with imported key material in KMS to encrypt the EBS volumes.","correct":false},{"id":"6252a38ce08f0db1b36876f30b0fe352","text":"Use the AWS Managed Key (aws/ebs) with imported key material for the encryption.","correct":false},{"id":"4b7aa43955ca963689c5753479d1d2d5","text":"Use a Customer Managed Key with imported key material to encrypt the EBS volumes.","correct":true},{"id":"c9d513eb9767845d56d1808f962eae22","text":"Configure a custom key with imported key material in AWS ACM to encrypt all EBS volumes.","correct":false}]},{"id":"55cd4e20-346b-4ab5-920b-bf4720db7ee5","domain":"automation","question":"You are working as a SysOps Administrator for your company and are working on writing a CRON job on an application running on EC2. The CRON expression requires the instance to provide its public IP address to pass to another application running on a second EC2 instance. How would you obtain the IP address?","explanation":"Because your instance metadata is available from your running instance, you do not need to use the Amazon EC2 console or the AWS CLI. This can be helpful when you're writing scripts to run from your instance. For example, you can access the local IP address of your instance from instance metadata to manage a connection to an external application. User data are the parameters you specify when configuring your instance. Instance store is a type of instance and the AMI does not contain the IP address.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html","title":"Instance Metadata and User Data"}],"answers":[{"id":"6248d35cdbd86a27a1dd1517a621d1d2","text":"From the instance AMI data.","correct":false},{"id":"6544d86f167272ed59ebf831074f047f","text":"From the instance store data using the curl command.","correct":false},{"id":"263ce3ebb0453f2bf28edc6a6d3bbf05","text":"From the instance user data using the curl command.","correct":false},{"id":"45dbd3d67172bc00ea7cf86e81faf0f5","text":"From the instance metadata using the curl command.","correct":true}]},{"id":"f58e7b6a-5516-478d-a844-e4608b1f806f","domain":"data-man","question":"A new employee has accidentally deleted an important file from S3. What's the best way to recover from accidental deletions like this in the future?","explanation":"Enabling versioning is the simplest way. Versioning provides the ability to recover from both unintended user actions and application failures. You can use versioning to preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket. Deleting a file from a versioning-enabled bucket simply sets a delete marker which can be removed to recover the file.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/undelete-objects.html","title":"How do I undelete a deleted S3 object?"}],"answers":[{"id":"dc2505a1fd1d3de79b0541ff7bc80d43","text":"Write a Lambda function that copies the objects periodically to a backup EBS volume.","correct":false},{"id":"dc44c1c88bef6b1b4ddafd1f22a12289","text":"Enable cross-region replication on the S3 bucket to backup the objects to a different region.","correct":false},{"id":"d31598f049bfcd9b0c8bd1da569ee7bb","text":"Write a Lambda function that copies the objects periodically to a backup bucket.","correct":false},{"id":"253efe32850426ce32c509612536c798","text":"Enable versioning on the bucket.","correct":true}]},{"id":"1a37a76e-3c69-4ae6-8ae3-5b0db850807c","domain":"mon-rep","question":"You need to monitor memory utilization of an EC2 instance. How could you achieve this?","explanation":"Monitoring memory utilization requires the installation of the CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html","title":"Collecting Metrics and Logs from Amazon EC2 Instances and On-Premises Servers with the CloudWatch Agent"}],"answers":[{"id":"30041d2fc11ea9b43497c2fe847b6461","text":"From the EC2 console, enable memory ulitization metric for the instance.","correct":false},{"id":"c5d4aec73235f6dc0fda6738ef7c93f9","text":"Install CloudWatch Agent on the instance and have it collect memory utilization metrics.","correct":true},{"id":"e1771db5f560892163019427b6f3742c","text":"From the CloudWatch console, enable memory ulitization metric for the instance.","correct":false},{"id":"8b901f2e0a6136525aaf5ffcb881b223","text":"EC2 instance memory utilization is monitored by default.","correct":false}]},{"id":"7432af70-890b-411b-abbb-6b0b403aa3f5","domain":"mon-rep","question":"You're an ops manager and you want one of your AWS accounts to receive the price breaks associated with Consolidated Billing for Organizations. What needs to happen for you to be included in the Organization and receive the discounted pricing?","explanation":"You can invite existing AWS accounts to join your organization. When you start this process, AWS Organizations sends an invitation to the account owner, who then decides whether to accept or decline the invitation. You can use the AWS Organizations console to initiate and manage invitations that you send to other accounts. You can send an invitation to another account only from the master account of your organization.","links":[{"url":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_invites.html","title":"Inviting an AWS Account to Join Your Organization"}],"answers":[{"id":"8cacf7f83f0c9a58c2e264de726c764f","text":"You must ask AWS to associate your account with the Master account.","correct":false},{"id":"5f46574bd37f7ef74f5a95c1debbad29","text":"The Master account must ask AWS to associate your account with theirs.","correct":false},{"id":"3b0f522229b67ca4ea9eb21840d96e41","text":"The Master account must send you an invitation to join your account with theirs and you must accept.","correct":true},{"id":"8a358ee9ae18997a0c91f0541fad6f77","text":"You must request to be added to consolidated billing.","correct":false}]},{"id":"d0b24152-771d-489e-8853-7221454dbcdb","domain":"networking","question":"You are running a Python Flask application on a private subnet in your Amazon VPC. The web application has been running into some issues, and you need to re-code the application to include more robust Python libraries. When you try to install Python libraries you get a network error but you are able to install these packages on your public-facing servers. How would you allow your private servers to download and install these libraries in the most effective manner?","explanation":"To enable instances in a private subnet to connect to the internet, you can create a NAT gateway or launch a NAT instance in a public subnet. Then add a route for the private subnet that routes IPv4 internet traffic (0.0.0.0/0) to the NAT device. To create a NAT gateway, you must specify the public subnet in which the NAT gateway should reside. Copying files in an EBS volume for installation is administratively not a good idea if Internet connectivity is going to be persistent. A Bastion Host is not the required service to connect to the Internet.","links":[{"url":"https://docs.aws.amazon.com/en_pv/vpc/latest/userguide/route-table-options.html","title":"Routing Options"}],"answers":[{"id":"24db8e12a44c9ec6662d67dca5687d5b","text":"Launch a NAT instance in a public subnet. Add a route for the private subnet that routes IPv4 0.0.0.0/0 traffic to the NAT device.","correct":true},{"id":"30d834ca94e17c6e2e40caf78391e8e9","text":"Launch a Bastion Host in a public server. Open port 80 on the Bastion Host to the IP range of your private web servers. Access downloadable libraries from your Bastion Host via SSH.","correct":false},{"id":"cf4856324ef6b157b83f98f140d49f7b","text":"Copy the Python libraries on your public servers unto an EBS volume. Detach the EBS volume and attach them to the private servers. Install the packages from the EBS volume.","correct":false},{"id":"273a72b9d0bfd2145fb5f6c102cdae13","text":"Launch a NAT Gateway in a private subnet. Add a route for the web servers in the private subnet to 0.0.0.0/0 through the NAT device.","correct":false}]},{"id":"fcfd9e09-dd0c-45a2-abb0-a6d92297ef92","domain":"security-comp","question":"You have just been hired as a CISO at a space exploration company that makes rockets. The company has contracts with the US airforce and has very strict IT requirements. You discover that on your first day a third party IT auditing company is on site and they are after security and compliance documents such as AWS ISO certifications, Payment Card Industry (PCI), and Service Organization Control (SOC) reports. Which AWS service can help you meet this need?","explanation":"All AWS accounts can get access to AWS compliance documentation using AWS Artifact","links":[{"url":"https://aws.amazon.com/artifact/","title":"Artifact FAQs"}],"answers":[{"id":"fa092ee9faf62930336257691a3dbfe8","text":"AWS Config Manager","correct":false},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":false},{"id":"7c90c8f2a24f3a1a28525f19fb2c75ab","text":"AWS Inspector","correct":false},{"id":"05a080cb7d6b6da90ca133767496ccb0","text":" AWS Artifact","correct":true}]},{"id":"y895ku45-wsg2-9rye-087a-zdmu2wd7qtr8","domain":"mon-rep","question":"Which AWS service can be used to log API calls from the AWS console, the EC2 CLI, the AWS CLI, or the AWS SDKs.","explanation":"CloudTrail captures API calls and delivers the log files to an Amazon S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/APIReference/using-cloudtrail.html","title":"Logging API Calls Using AWS CloudTrail"}],"answers":[{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false}]},{"id":"5e40fe16-8d0b-485b-8a2b-c387b1421d8b","domain":"data-man","question":"A DynamoDB table is created to store data for a project. The table is configured with the default encryption type. As part of the disaster recovery plan, the DynamoDB table needs to have backups for at least 30 days. In the event of incorrect data being accidentally written to the table, you need to be able to restore to a given date and time when the data was correct. Which method should you use to configure the backups?","explanation":"You can enable Point-in-time Recovery so that DynamoDB maintains continuous backups of the table for the last 35 days. By default, this feature is turned off. CloudWatch Event rule is not as efficient as Point-in-time Recovery and you cannot restore to a given time with on-demand backups. And there is no Lifecycle Policy in Systems Manager. Lifecycle Policy is an EC2 feature for EBS snapshots instead of DynamoDB backups.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/PointInTimeRecovery_Howitworks.html","title":"DynamoDB Point-in-time Recovery"}],"answers":[{"id":"e2b30e30db99c37dd774db01c430cb6f","text":"Set up a CloudWatch Event rule that is triggered every one hour. When the rule is triggered, create an on-demand backup for the DynamoDB table.","correct":false},{"id":"6e496dbe5059cd5960f002dbdc2650c9","text":"By default, DynamoDB tables have continuous backups for 90 days. Within the time, the table can be restored at any given date and time.","correct":false},{"id":"90b7a4b9354bec0cc794a38060532c70","text":"Enable the Point-in-time Recovery for the table. It provides continuous backups of your DynamoDB table. When enabled it maintains incremental backups of your table for the last 35 days until you explicitly turn it off.","correct":true},{"id":"7c280b0f0f681085429067cdab9bb76e","text":"Use Systems Manager Lifecycle Policy to automatically create backups for the table. The table can be restored to any time within 30 days.","correct":false}]},{"id":"e8355e44-b357-48de-b17b-b2373c316edd","domain":"networking","question":"An organization runs a website on an Autoscaling Group behind an Application Load Balancer (ALB). During deployments the application team creates a new ASG and Load Balancer. Which DNS service can you use to flip between the two environments in a Blue/Green manner and direct all users to the new environment?","explanation":"Route53 allows various routing policies to direct users to one or more resources.  In this case all users must be directed from one Load Balancer to another.  A simple routing policy would fulfil this requirement as it will completely replace the DNS pointer from the 'blue' load balancer with the 'green'. All other routing policies perform more complicated routing based on other variables such as healthchecks or country of origin which is not needed here.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-simple","title":"Amazon Route 53 Simple Routing"}],"answers":[{"id":"1844cecdf015b88aef8e88746b321731","text":"Use Route53 latency routing","correct":false},{"id":"816c21d5068061f198f8df28aaf61e0d","text":"Use Route53 multi-answer routing","correct":false},{"id":"ebeefbe1e321377375eb3065b4a2fc20","text":"Use Route53 failover routing","correct":false},{"id":"3299777a46e7aa18ad281b2a40bf2894","text":"Use Route53 simple routing","correct":true}]},{"id":"86596bb1-b46e-449f-889d-b5d830ca4f2e","domain":"dep-prov","question":"The development team in your company has finished developing a proof-of-concept of a new Ruby web application. The management wants to show it to a customer quickly, so they ask you to deploy it as soon as possible. You choose to use Elastic Beanstalk. What are the steps required to deploy the application with it?","explanation":"The benefit of deploying with Elastic Beanstalk is that you don't have to worry about provisioning and managing the infrastructure and application stack. You don't have to create EC2 instances or load balancers. Elastic Beanstalk does it all for you. You simply upload your code.","links":[{"url":"https://aws.amazon.com/elasticbeanstalk/faqs/","title":"AWS Elastic Beanstalk FAQs"}],"answers":[{"id":"5057183b7131b6d33dab6404e3169e16","text":"Upload your code.","correct":true},{"id":"4bc0f60972b5b7a69a1cca6e12facb39","text":"Provision an EC2 instance. Upload your code.","correct":false},{"id":"4cefa75ab7d2e02f84528f56fe7b9646","text":"Provision an EC2 instance and an Elastic Load Balancer. Upload your code.","correct":false},{"id":"845d1a709577cc630a50cd331d24103c","text":"Provision an Elastic Load Balancer. Upload your code.","correct":false}]},{"id":"e105d8a7-6333-48d8-9610-7c2f9ad73991","domain":"mon-rep","question":"There has been a steady rise in costs with your AWS bill, and the security team has noticed that there has been an increase in the number of requests, even though the number of IAM users has decreased due to employee turnover and down-sizing. The CISO has tasked you with identifying whether recent requests to the AWS account's environment were made with temporary security credentials for a role or federated user. How would you go about identifying this?","explanation":"A trail enables CloudTrail to deliver log files to an Amazon S3 bucket. By default, when you create a trail in the console, the trail applies to all AWS Regions. The trail logs events from all Regions in the AWS partition and delivers the log files to the Amazon S3 bucket that you specify. Additionally, you can configure other AWS services to further analyze and act upon the event data collected in CloudTrail logs. The userIdentity element contains details about the type of IAM identity that made the request, and which credentials were used. If temporary credentials were used, the element shows how the credentials were obtained. Identify Federation is used for access to an account. Config will not log API activity. Lambda cannot scrape an entire account; it needs to access an S3 bucket of CloudTrail logs to take any action.","links":[{"url":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-user-identity.html","title":"CloudTrail userIdentity Element"},{"url":"https://docs.aws.amazon.com/config/latest/developerguide/log-api-calls.html","title":"Logging AWS Config API Calls with AWS CloudTrail"}],"answers":[{"id":"73e4bf9add9c239534c52f8a03fb95fb","text":"Create a CloudTrail log to deliver files to an Amazon S3 bucket. Use Amazon Athena to query the logs to search for the userIdentity element.","correct":true},{"id":"41e73582d973a777c1838270973c1a5a","text":"Create a Lambda function that is triggered daily that scrapes the account for requests from any assumed roles. Have the Lambda function revoke access if any requests are non-compliant.","correct":false},{"id":"4ffef50c6af5fe0e395fb58ca8319f05","text":"Record all ongoing events in the AWS account using AWS Config. Create a CloudWatch alarm to send an SNS topic when an identity under AssumeRole makes a request to the account.","correct":false},{"id":"97ddb7778b0f9f5decefb8013df4d710","text":"Set up Identity Federation with SAML. Create IAM roles and create policies for employees to assume with the correct permissions. Log all requests using the Credential report.","correct":false}]},{"id":"7fc0d8c0-5fc9-463e-94ff-54f852f1d819","domain":"data-man","question":"An S3 bucket stores some files for an application. As the files need to be read from users on the internet, the bucket should have Public Access. However when you modify the Bucket Policy to be public in AWS console, the operation is blocked with an \"Access denied\" error. Your IAM user has enough permissions to modify Bucket Policies. How would you troubleshoot the issue?","explanation":"Users can configure S3 buckets to block public access. When users try to enable the public access through Access Control Lists or Bucket Policies, the operation is denied. In this scenario, you should check if the public access through Bucket Policy is blocked.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/block-public-access.html","title":"Block Public Access to S3 Buckets"}],"answers":[{"id":"92ffb0eb54566b1970433d74106174e3","text":"Use AWS CLI s3api put-bucket-policy to modify the Bucket Policy.","correct":false},{"id":"2e51a73ed0e5f8cf18b5f4047b358a94","text":"User should configure the public access in S3 Access Control List rather than Bucket Policy. In ACL, enable the read access to the group of Everyone.","correct":false},{"id":"416e41b2d06f37e643dd26b55ea9bc53","text":"Check the syntax of Bucket Policy and ensure that the Action field only contains s3:GetObject and the Principal field is a wildcard.","correct":false},{"id":"ba324e78ebf4d884332673942ca4bee0","text":"Check the bucket public access settings to see if the public access through Bucket Policy is blocked. Make sure the public access is not blocked by the settings.","correct":true}]},{"id":"571b9603-45b6-45b1-aa47-68849ac814bb","domain":"automation","question":"A big-box retailer runs their in-store point-of-sale system on EC2 linux instances. All of the infrastructure is managed as part of a CloudFormation stack. The web servers are part of an Auto Scaling Group. The application only needs to be available during business hours from 9:00am until 6:00pm. What would be the best way to scale the web servers cost efficiently based on demand?","explanation":"Authoring the CloudFormation template to include an AutoScaling:ScheduledAction resource to increase the Auto Scaling Group's MinSize and MaxSize values at 9:00am, and another AutoScaling:ScheduledAction resource to decrease the Auto Scaling Group's MinSize and MaxSize values at 6:00pm will save costs for the retailer during non-business hours. CloudFormation conditions control whether certain resources are created or whether certain resource properties are assigned a value during stack creation or update, but don't control the actions of an Auto Scaling Group. Using an Auto Scaling Group scheduled action provides more streamlined automation than using a Lambda function. CloudFormation mappings are key/value pairs that can be used to specify conditional parameter values, but they have no impact on the Auto Scaling Group unless they are used to create a resource.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"What is AWS CloudFormation?"},{"url":"https://s3-us-west-2.amazonaws.com/cloudformation-templates-us-west-2/AutoScalingScheduledAction.template","title":"Cloud Formation Sample Template for Time-based Auto Scaling"}],"answers":[{"id":"a0f99978bb65910b10b75a32e1b92a2a","text":"Create AutoScaling:ScheduledAction conditions in the CloudFormation template that change Maxsize and MinSize values based on business hours","correct":false},{"id":"0db6203397832efddcbca893f96ba1b6","text":"Include AutoScaling:ScheduledAction resources in the CloudFormation template that change Maxsize, MinSize, and Recurrence values based on business hours","correct":true},{"id":"765dccb8332e2036eb70a0b6276e7285","text":"Use CloudWatch Events to trigger a Lambda function at business opening and closing that adjusts the Auto Scaling Group's MinSize and MaxSize accordingly","correct":false},{"id":"725933a9f7ea7ef281e2decf6cefadae","text":"Configure AutoScaling:ScheduledAction mappings in the CloudFormation template with Maxsize, MinSize, and Recurrence values based on business hours","correct":false}]},{"id":"b5cf6800-4ce3-4d24-8eaa-a1279c1c6409","domain":"mon-rep","question":"An insurance company has a monolithic application hosted in an EC2 instance and a serverless application hosted in AWS Lambda. After a few months of running the application, the customers have raised multiple delays and performance issues from the applications. The Operations Engineer responsible has mentioned that the latency issues might have been caused by code-level performance issues and the Head of Operations has instructed the team to add code-level monitoring support. How can the team accomplish this?","explanation":"X-Ray can be used for adding code tracing support for both monolithic application code (e.g. a large Django monolithic project) and serverless (Lambda function) code. CloudTrail is used for auditing API call logs. CloudWatch is used for monitoring resource usage and metrics. X-Ray is a distributed tracing system.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html","title":"AWS X-Ray"}],"answers":[{"id":"2eb097422fa45d569c37d094428d9a9d","text":"Use AWS CloudWatch for the monolithic application code. Use AWS X-Ray for the serverless application code.","correct":false},{"id":"359f4dd3d7689aca37514e23a8781431","text":"Use AWS X-Ray for both the monolithic application code and the serverless application code.","correct":true},{"id":"7d3a7bc0301958a4e3ad624f70b462d4","text":"Use AWS CloudTrail for the monolithic application code. Use AWS X-Ray for the serverless application code.","correct":false},{"id":"ab066c8d1096ed9b7b49b4637589b201","text":"Use AWS X-Ray for the monolithic application code. Use AWS CloudTrail for the serverless application code.","correct":false}]},{"id":"81ef2ee0-06b2-4d5e-8316-6c4839e8bfc4","domain":"mon-rep","question":"Your organization is running EC2 instances in AWS as well as some VMs in your own datacentre - Both are being monitored by a 3rd party solution running in the non-AWS datacentre but offers an fully functional API that can return statistics and status values. You would like to be notified via SMS of any issues identified by your 3rd party monitoring system if anything goes wrong with either the instances in AWS or the VMs in your DC - Which AWS service can help with this? ","explanation":"AWS SNS is AWS's fully managed push notification system, and can be integrated into 3rd party apps via API, and is therefore the correct answer. SQS is used for creating, managing and using queues and is not relevant by itself here. AWS SMS is actually a server migration service.","links":[{"url":"https://aws.amazon.com/sns/faqs/","title":"AWS SNS"}],"answers":[{"id":"cdc05958362b09ba911028eaf41c71d5","text":"AWS SQS","correct":false},{"id":"74e06b58e00302916a205d2bf24e9837","text":"AWS SNS","correct":true},{"id":"0d681c4f2ebaca40d81399ace225fa7b","text":"None - as the monitoring system is 3rd party and not hosted on AWS it cannot integrate with AWS services","correct":false},{"id":"7b21a7f2969497577b6023f19ba52a9a","text":"AWS SMS","correct":false}]},{"id":"eee921f8-2761-41ca-9e3a-d92097e53bf9","domain":"automation","question":"You would like to run a Lambda function at the same time every night. Which of the following tools could you use to configure this?","explanation":"You can create rules that self-trigger on an automated schedule in CloudWatch Events using cron or rate expressions.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html","title":"CloudWatch Scheduled Events"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/with-scheduled-events.html","title":"Using Lambda with CloudWatch Events"}],"answers":[{"id":"9535623ef961c06aa4c1567e4caf2fdb","text":"Use SES to send a notification every night to trigger the function","correct":false},{"id":"6cee3cba6e3661d0f97640c21953e6e2","text":"Use SQS to send a notification every night to trigger the function","correct":false},{"id":"0d22c1f845fb2bb5740847afadb3d4f6","text":"Use SNS to send a notification every night to trigger the function","correct":false},{"id":"afdfd739747e5925ab6d039107cf70ba","text":"Schedule an event in CloudWatch to trigger the function","correct":true}]},{"id":"8c197177-2b38-41eb-9b6c-d7c52de0808c","domain":"security-comp","question":"Which of the following statements is correct?","explanation":"AWS is responsible for physical controls, you are responsible for patching and updating your own operating systems","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"d891cc198c4681e4512d4855f795f22e","text":"AWS is responsible for the hardware, software, networking and facilities that run AWS Cloud services","correct":true},{"id":"25147b4a8382ebb44937e157a61975fc","text":"You are responsible for Physical and Environmental controls for your AWS infrastructure","correct":false},{"id":"be49b24b55936f276a5224988013f961","text":"You are responsible for the security configuration and management tasks for any VPCs, EC2 instances and S3 buckets you create","correct":true},{"id":"0f245a67bb96c5c2cfe2a8892b81a868","text":"AWS is responsible for patching and updates of any Operating System you install on your EC2 instances","correct":false}]},{"id":"f1f36583-612f-4946-ac77-a6e78aede912","domain":"networking","question":"You have an Amazon VPC with one private subnet, one public subnet and one network address translation (NAT) server. You are creating a group of EC2 instances that configure themselves to deploy an application via GIT. Which of the following setups provides the highest level of security?","explanation":"You should use EC2 instances in private subnet; no EIPs; and route outgoing traffic via the NAT.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_NAT_Instance.html#basics","title":"NAT Instance Basics"}],"answers":[{"id":"03808744fcc2ec07927563e827ba457a","text":"Amazon EC2 instances in private subnet; no EIPs; route outgoing traffic via the NAT.","correct":true},{"id":"9767e7ce6f652652e1ec42f2d2a48af1","text":"Amazon EC2 instances in public subnet; no EIPs; route outgoing traffic via the internet gateway (IGW).","correct":false},{"id":"1f9416e0df4342a7c5298d9f43d4d392","text":"Amazon EC2 instances in a private subnet; assign EIPs; route outgoing traffic via the internet gateway (IGW).","correct":false},{"id":"6a084c8ddbef4573cc627373b1a04456","text":"Amazon EC2 instances in public subnet; assign EIPs; route outgoing traffic via the NAT.","correct":false}]},{"id":"113a7914-1249-4e12-a748-03392c0570e8","domain":"high-avail","question":"You are a Security Administrator for your company. Your CIO wants to ensure that company data is highly available in multiple AWS Regions. What would you suggest to your CIO as the most effective approach?","explanation":"Deploying a multi-AZ RDS instance would only make it fault tolerant between Availability Zones, and not AWS Regions. Creating a Lambda function and creating/deploying EBS snapshots into different AWS Regions would both be an administrative and operational burden. The easiest, most effective, way is to utilize S3 Cross Region Replication","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 Cross Region Replication"}],"answers":[{"id":"fbde7989c5f0da5bb91bb5593f9c8e4e","text":"Create a Lambda function that downloads data from your S3 Bucket and executes a PUT operation to upload copied objects into a new bucket in a new Region.","correct":false},{"id":"f876473fb6289d5a1e3e6d449713b0e7","text":"Copy the company data to an RDS instance. Deploy a multi-AZ configuration for your RDS instance to make it highly available.","correct":false},{"id":"a4ca2ada50730e36dd0f3302f60ab0dc","text":"Create multiple snapshots of your company data on EBS volumes. Deploy those EBS volumes on EC2 instance in different AWS Regions.","correct":false},{"id":"6e22da724261694b4ecf8fa105ef5174","text":"Enable Cross-Region Replication on your bucket to copy objects to a destination bucket in another AWS Region.","correct":true}]},{"id":"8473f19c-c3f7-4f2b-93a5-55ed10d99f83","domain":"mon-rep","question":"You run a hybrid environment with some servers in AWS and other Servers on Premise. Your boss has been impressed with your CloudWatch dashboard which shows the performance of all your EC2 instances around the world, however it does not show any metrics for your on premise servers. What could you do to rectify this?","explanation":"AWS Systems Manager Agent (SSM Agent) is Amazon software that runs on your Amazon EC2 instances and your hybrid instances that are configured for Systems Manager (hybrid instances). You can manually install SSM Agent on servers or virtual machines in your on-premises environment","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html","title":"SSM Agent"}],"answers":[{"id":"2b914a41bdba2bd7ceb93d6306696cd4","text":"Use AWS Storage Gateway and configure Gateway Monitoring Mode. Publish the monitoring statistics to S3 and use AWS Datapipeline to import this data in to CloudWatch","correct":false},{"id":"5aa17ac5ff5e522d0cbd19818e8b854d","text":"It is not yet possible to monitor on premise servers using AWS CloudWatch","correct":false},{"id":"38763eaec7d5f8126a56abeb236b9d27","text":"Install and run the SSM agent on your on premise servers. Once finished, install and run the CloudWatch agent on the on premise servers. Create the required role in IAM and verify that the agent is publishing data to CloudWatch. Add the widget for the on premise tools","correct":true},{"id":"02a9311d5b1ac89de02acaf3c528c90a","text":"Install a third party monitoring agent and export performance data to the third party platform. Use AWS datapipeline to create a pipeline of this data from the third parties platform, in to CloudWatch","correct":false}]},{"id":"64ee23de-9703-4090-983d-d36552dac361","domain":"networking","question":"You are a SysOps Administrator running security checks throughout your AWS environment. One of your tasks is to clean up the environment and remove any idle resources that are no longer in use. You identify a VPC that was configured and used by a team that no longer works at the company and you are looking to delete the VPC. The VPC has a few running instances, a route table, a NAT Gateway, and an Internet Gateway. When you try to delete the VPC you get an error. How would you troubleshoot this situation?","explanation":"In AWS, you will get the following error if you attempt to delete the VPC with a network interface in-use: 'The VPC contains one or more in-use network interfaces, and cannot be deleted until those network interfaces have been deleted. View in-use network interfaces in the VPC.' Moreover, you cannot delete a subnet that has instances in it. The best answer would be to terminate the instances before deleting the VPC. There is no need to take snapshots before deleting a VPC (unless for backup purpose), and detaching the Internet Gateway is unnecessary as well. Assuming the role of the VPC creator is unnecessary if you already have the proper IAM permissions to do so.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html","title":"VPCs and Subnets"}],"answers":[{"id":"bdba6bd2f5a22439d78f3ae5512c9213","text":"Detach the Internet Gateway from the VPC. Delete the Internet Gateway to restrict public traffic into the VPC. Delete the VPC.","correct":false},{"id":"64ab90b44ef9b90a49072f93bb50a615","text":"Assume the role of the creator of the VPC. The credentials for the VPCs creator is required to delete the VPC.","correct":false},{"id":"dc869ce95aa68ff14f2265e56e10d33d","text":"Stop and terminate the running instances. Delete all the resources in the VPC before deleting the VPC itself.","correct":true},{"id":"4fd6f1d4acf6323fa52621653e2a6150","text":"Take a snapshot of the EBS volumes before deleting the VPC. Upload the snapshots into S3 and proceed deleting the VPC.","correct":false}]},{"id":"fcccd90f-956b-41b6-b618-bc81dade5d80","domain":"security-comp","question":"You have an EC2 instance in a private subnet. You connect to this instance via SSH using a bastion host in a public subnet. You notice from the logs that other SSH connections are being made from other private IP addresses, which is strange because only the bastion host should be able to connect to this instance. The private IP address of the bastion host is 10.0.1.117. You review the security group, which of the following rules could be causing the unauthorised SSH connections?;","explanation":"By allowing access to port 22 for SGXXXXXXXX this allows any host configured with this security group to access the instance using SSH","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups"}],"answers":[{"id":"c3b35087d573e2c25bc7f358f1bf77d0","text":"MySQL 1433 10.0.1.117/32","correct":false},{"id":"b0172715fbf8cb2b18f5db13e284ca91","text":"SSH 22  SGXXXXXXXX","correct":true},{"id":"80fb1a7299d4a1135830c6f51a49fe82","text":" SSH 22 10.0.1.117/32","correct":false},{"id":"f7bc2e53005e98bab5ea06b5b23bfcf7","text":" HTTP 80 10.0.1.117/32","correct":false}]},{"id":"694223e9-400f-46d9-b113-d770e9d509b8","domain":"dep-prov","question":"Your organization provides a service using an Application Load Balancer with both HTTP and HTTPS listeners. The business no longer needs to provide the service so you attempt to delete the ALB via the AWS CLI. What will happen to the listeners?","explanation":"You can delete a listener at any time. When you delete a load balancer, all its listeners are deleted.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/delete-listener.html","title":"Delete a Listener for Your Application Load Balancer"}],"answers":[{"id":"8eaee7de96060692c6500d1043fae9d5","text":"The ALB will be deleted but both listeners will remain","correct":false},{"id":"c9e9a56599d874c979dc81169f0eb659","text":"The ALB and both listeners will be deleted","correct":true},{"id":"3a830da2fbcf5c10870200329e2a0bdc","text":"The ALB will be deleted but the HTTPS listener will remain","correct":false},{"id":"104a10917908f00eeccd5369b1ac85da","text":"It is not possible to delete an ALB with active listeners attached","correct":false}]},{"id":"3b299de7-5eed-4f52-b332-e58a1788d451","domain":"networking","question":"You plan to use a placement group for separating important systems running on a small number of EC2 instances. For compliance reasons, every instance must be in a separate rack. Which of the following placement groups are the most suitable?","explanation":"Spread placement groups are recommended for applications that have a small number of critical instances that should be kept separate from each other. Launching instances in a spread placement group reduces the risk of simultaneous failures that might occur when instances share the same racks. Spread placement groups provide access to distinct racks, and are therefore suitable for mixing instance types or launching instances over time. Partition cluster groups are suitable for separating groups of instances on distinct hardware. Cluster placement groups are designed to place hardware as close as possible to increase performance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html#concepts-placement-groups","title":"Placement Groups"}],"answers":[{"id":"ea65fadc86756ddcd18793374fe31349","text":"A Cluster Placement Group","correct":false},{"id":"5b108266549d80fa8e65d875a00a8213","text":"A Spread Placement Group","correct":true},{"id":"93a08fc1ff6bbf8d8ea03e58b442f724","text":"A Dedicated Instance Placement Group","correct":false},{"id":"e0f55d640e28ee8139799619632e4a68","text":"A Partition Placement Group","correct":false}]},{"id":"bd76b805-8568-4083-a962-3eebb610d4fc","domain":"dep-prov","question":"You've been given the responsibility for creating an automated deployment approach to provision EC2 instances for every application in your department's portfolio. Each application requires a different set of software libraries, and all EC2 instances are members of Auto Scaling Groups. Deployments must complete within a limited time window as part of the department's overall DevOps strategy, and AWS CloudFormation will be used for infrastructure-as-code. Which architecture will provide for the fastest deployments in the most operationally efficient manner?","explanation":"Creating an AMI at the time of CloudFormation stack creation or update helps to ensure that the latest binaries are included in an Auto Scaling Launch Configuration while avoiding potentially long waits for Auto Scaling instances to be provisioned. Bootstrapping software downloads during Auto Scaling instance launch will potentially result in long wait times. Using CloudFormation metadata to indicate which software binaries need to be used in Auto Scaling Launch Configurations is not supported functionality. Not automatically keeping the AMIs up to date means that a significant level of effort will be needed to keep AMIs current with new software releases in each EC2 instance configuration.","links":[{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/enable-fast-bootstrapping-of-your-auto-scaled-instances-using-dynamically-created-images/","title":"Speed up instance bootstrapping by using dynamically created images"}],"answers":[{"id":"d53fd253be12fb9ac6c1f9d04b0590f3","text":"Create base Amazon Machine Images for each application's EC2 configuration. Use CloudFormation to specify that the Auto Scaling Launch Configuration use the base AMIs, and bootstrap software downloads from public sources for each application at the time of instance launch","correct":false},{"id":"ff704c3738fe0246d98c17f8a497e999","text":"Create an EC2 instance for each application's full software configuration. For each application, have CloudFormation invoke an AWS Lambda function that creates an Amazon Machine Image for the EC2 instance. Include the AMI in the Auto Scaling Group Launch Configuration specified by CloudFormation","correct":true},{"id":"df623f37652f3a2b4441a7c1de625ab8","text":"Create base Amazon Machine Images for each application's EC2 configuration. Use CloudFormation to specify that the Auto Scaling Launch Configuration use the base AMIs, and use CloudFormation metadata to indicate which software binaries need to be used in Auto Scaling Launch Configurations during CloudFormation stack creations and updates","correct":false},{"id":"02bf56251e14a50de6e835ecd38ab66a","text":"Create complete Amazon Machine Images for each application's EC2 configuration. Configure a CloudFormation Stack for each application that creates Auto Scaling Groups for each instances corresponding AMI","correct":false}]},{"id":"10c87ec7-567f-4119-8817-e484af01182e","domain":"high-avail","question":"Your development team has written an application to pick up and process images taken from an SQS queue. The app is growing in popularity and your manager wants to do this as cheaply as possible. What is the best way to achieve cheap and timely processing?","explanation":"The solution must respond in a timely manner to increases in workload and running during ‘off-peak’ hours is not appropriate. Using a lambda to perform the scaling is not necessary since it is supported out-of-box by AWS’ Autoscaling service. Since the application is growing in demand there isn’t a defined capacity to pre-purchase via Reserved Instances.  Therefore the best solution is to use Autoscaling to scale in and out based on queue length.","links":[{"url":"https://docs.aws.amazon.com/en_pv/autoscaling/ec2/userguide/as-using-sqs-queue.html","title":"Scaling Based on Amazon SQS"}],"answers":[{"id":"905df3db934191d38ccbd1dbec2e459a","text":"Deploy the app to EC2 and use lambda to stop and resize the instance based on the SQS queue length","correct":false},{"id":"d3dd710c9e556214f0ae216bd74a6982","text":"Deploy the app into an Autoscaling Group and use reserved instances (RI) to pre-purchase a year’s worth of processing capacity","correct":false},{"id":"a9f53d8ff41f6f104afe7dfd446f8cf0","text":"Deploy the app into an Autoscaling Group and scale in and out based on an SQS queue length","correct":true},{"id":"e00965d574d10c8a9d991c96eb786139","text":"Deploy the app into an Autoscaling Group and run the processing during off-peak hours","correct":false}]},{"id":"af9e096c-e1b0-4f1e-9102-84dac1fab349","domain":"dep-prov","question":"You are trying to delete an EBS volume with the volume ID of vol-129df77122c4d7208 using the AWS CLI. You need to make sure that you have the required permissions before you perform the delete action. Which of the following commands will achieve this?","explanation":"The '--dry-run' parameter checks whether you have the required permissions for the action, without actually making the request, and provides an error response. If you have the required permissions, the error response is DryRunOperation. Otherwise, it is UnauthorizedOperation. The '--generate-cli-skeleton' parameters prints a JSON skeleton to standard output without sending an API request. If provided with no value or the value 'input', it prints a sample input JSON that can be used as an argument for the '--cli-input-json' flag. '--dryrun' and '--perform-action no' are not valid parameters.","links":[{"url":"https://docs.aws.amazon.com/cli/latest/reference/ec2/delete-volume.html","title":"EC2 CLI documentation: delete-volume"}],"answers":[{"id":"21a0e55daf1816e8554b456fd8f16f9d","text":"aws ec2 delete-volume --volume-id vol-129df77122c4d7208 --dryrun","correct":false},{"id":"efbae1a8e8a0b8190dfd2fcc000acff5","text":"aws ec2 delete-volume --volume-id vol-129df77122c4d7208 --dry-run","correct":true},{"id":"7b8ce5990ccec3f3375d86cb12a57fa4","text":"aws ec2 delete-volume --volume-id vol-129df77122c4d7208 --generate-cli-skeleton","correct":false},{"id":"153993f9bb7a685925820e05c073cffd","text":"aws ec2 delete-volume --volume-id vol-129df77122c4d7208 --perform-action no","correct":false}]},{"id":"d584866c-4884-40ad-a263-94eaad98f894","domain":"mon-rep","question":"AWS Config is a managed service which is part of the AWS Management & Governance portfolio of services.  Which of the following options are functions of the AWS Config service?","explanation":"AWS Config is a service that provides access to resource configuration history, an inventory of resources and alerts on any configuration changes, however it doesn't log API calls as this is the function of CloudTrail.","links":[{"url":"https://aws.amazon.com/config/faq/","title":"AWS Config FAQs"}],"answers":[{"id":"511bc797ffd63fd0702e8632fb5156db","text":"Provides a log of all configuration related API calls","correct":false},{"id":"46057f48c99511ac9dfb7fe92df1aefa","text":"Provides notification of configuration item changes","correct":true},{"id":"77eef0aefcbae3f15cc5ce086d0bff63","text":"Provides access to resource configuration history","correct":true},{"id":"b3a15d8a30c303c913c4b2976f61f5c7","text":"Provides an inventory of all AWS resources","correct":true}]},{"id":"46d872a7-bf30-4880-9cbd-3a63c50fb75e","domain":"mon-rep","question":"You need to enable a CloudWatch alarm to alert you if an EC2 instance which holds a key customers database goes over 100% CPU Utilization for more than two minutes. Which service should you use?","explanation":"Detailed Monitoring collects data at 1 minute intervals, whereas Basic or Standard Monitoring is every 5 minutes. Artifact allows you to check which industry and regulatory compliance standards AWS adheres to.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html","title":"CloudWatch Detailed Monitoring"}],"answers":[{"id":"3d3e141cae28c035547bafe32dea1423","text":"CloudTrail Expedite","correct":false},{"id":"96778f7d823daef4c612d60aa5bf2312","text":" CloudWatch Detailed Monitoring","correct":true},{"id":"af64135daff929ae7e26207cfae5e24a","text":"CloudWatch Standard Monitoring","correct":false},{"id":"60b018772cea138af5a8c452ed694734","text":"AWS Artifact","correct":false}]},{"id":"48613ba4-57e3-45db-8f05-7f933ca75c8d","domain":"security-comp","question":"Security Token Service (STS) allows for the creation of temporary token credentials. STS can work with users from what sources?","explanation":"The AWS Security Token Service (STS) is a web service that enables you to request temporary, limited-privilege credentials for AWS Identity and Access Management (IAM) users or for users that you authenticate (federated users). ","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"ec3222de3069bf4526f19703213ed211","text":"Only IAM users that have administrator privileges can access a generated security token","correct":false},{"id":"6f0a2b742bca843f3f7166f9ec5b1eeb","text":"Any configured IAM users or supported federated identity users can gain a generated security token","correct":true},{"id":"eefdebb91d87138fe3b156d1b5ad571d","text":"Only federated identity users can gain a generated security token","correct":false},{"id":"78526e12a19b987737f48b26e84171b1","text":"Any user that has an IAM user account for my account can gain a generated security token","correct":false}]},{"id":"9a336e95-d0f5-4b79-904b-f0618496cc2f","domain":"networking","question":"You have created a new VPC with the CIDR block of 10.0.0.0/16. You create 2 subnets: 10.0.1.0/24 and 10.0.2.0/24. 10.0.1.0 will be a public subnet and 10.0.2.0 will be a private subnet. You deploy a NAT gateway with the name i-7c1507ab into 10.0.1.0 and assign it a public IP address. You now need to update your route table to complete the setup. Which of the following is the correct route table listing?","explanation":"Destination: 0.0.0.0/0 Target:i-7c1507ab is correct.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#WorkWithRouteTables","title":"Working With route Tables"}],"answers":[{"id":"c4362c9a78985f2334fe591db6c45c50","text":"Destination: 10.0.0.0/16 Target:i-7c1507ab","correct":false},{"id":"5b62777103d2e471ec99428f0453f132","text":"Destination: 0.0.0.0/0 Target:i-7c1507ab","correct":true},{"id":"7540f0e829de47c0b695dae438a647d0","text":"Destination: 10.0.2.0/24 Target:i-7c1507ab","correct":false},{"id":"eee0734b451befed6d35d25ecd8b7e00","text":"Destination:10.0.1.0/16 Target:i-7c1507ab","correct":false}]},{"id":"83ef4c6f-4ebd-4ab1-b964-42345661b16e","domain":"security-comp","question":"As a Sysops Administrator for your company, you are the point of contact for a third-party auditor who is examining your AWS environment. The auditor requires a view of all the resources in your AWS account and the relationship between each resource to see the overall impact of any resource configuration change. How would you provide this information?","explanation":"When you use multiple AWS resources that depend on one another, a change in the configuration of one resource might have unintended consequences on related resources. With AWS Config, you can view how the resource you intend to modify is related to other resources and assess the impact of your change. Amazon Neptune is a graph database but is not the appropriate use case. Amazon Inspector runs security assessements on EC2 instance, not your AWS environment. CloudTrail log history only shows API calls and not the relationships between resources.","links":[{"url":"https://docs.aws.amazon.com/en_pv/config/latest/developerguide/WhatIsConfig.html","title":"What is AWS Config?"}],"answers":[{"id":"f6417679ee015e02f36ea3663d5a6300","text":"Export log data from CloudTrail event history. Parse the data to only include relevant AWS resources.","correct":false},{"id":"2b4d2e523329145cc3674082eaec8d38","text":"Retrieve configurations of one or more resources that exist in your account using AWS Config and view the relationships between resources.","correct":true},{"id":"2609fd7b786b580dd1a731400e416bc4","text":"Run an Amazon Inspector assessment that will produce a detailed list of security findings around configuration changes within your environment.","correct":false},{"id":"e249cf2d1b853d8faf906785117f8a16","text":"Deploy an Amazon Neptune database that is optimized for storing and querying relationships such as network security. Create an IAM role for the auditor for read-only access to your Neptune database.","correct":false}]},{"id":"988e212c-6400-4c9d-8e9b-25ce5413256b","domain":"dep-prov","question":"If you use an IAM user to copy an instance-store-backed AMI, the user must have which of the following Amazon S3 permissions?","explanation":"If you use an IAM user to copy an instance-store-backed AMI, the user must have the following Amazon S3 permissions: s3:CreateBucket, S3:GetObject, S3:PutObject, s3:GetBucketAcl, s3:ListAllMyBuckets and s3:PutObjectAcl.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/creating-an-ami-instance-store.html","title":"Creating an Instance Store-Backed Linux AMI"}],"answers":[{"id":"d0e4bee632dc55607e492853b76d8194","text":"s3:CreateBucket","correct":true},{"id":"53cfd5032381d05f65cbc6d64e0004f5","text":"s3:GetObject","correct":true},{"id":"28e5f48e9f12d4928897b706c15e527a","text":"s3:RestoreObject","correct":false},{"id":"7002b8d843e69183ff3fcc03410db0ad","text":"s3:GetObjectAcl","correct":false},{"id":"8e0864f8129f5d2b658668b9103e83a5","text":"s3:PutObject","correct":true},{"id":"3d48378493503b3c7c04da8400942853","text":"s3:DeleteBucket","correct":false}]},{"id":"27109f2b-2906-43cb-90b4-3e2bcfad7ab8","domain":"high-avail","question":"You are a consultant working for a global company. They are hosting their companies CRM web application on-premise across servers in three different countries. Amazon Route 53 is being used as their DNS Provider. When the servers in one of the countries goes down, traffic starts to drop instead of being redirected to the two working sites. Corporate policies prohibit client data being stored or transferred through a Public Cloud Provider. What would the simplest solution be to their issue?","explanation":"Multivalue Answer Routing will perform simple health checks on IP addresses before sending traffic to them. This has advantages over a simple routing, where an outage of one of the IP Addresses would result in failures to connect. Corporate policies prohibit in this scenario the storage or transfer of client data from the CRM through a Public Cloud Provider. This effectively rules out the migration to EC2, or the use of CloudFront as a CDN. Transferring DNS to an on-premise service may allow for more flexibility and abilities to write special health checks, but it would certainly not be the most simple option","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Amazon Route 53 Routing Policies"}],"answers":[{"id":"1ed8875652253a24ebf466592454a1be","text":"Use a Multivalue Answer Routing Policy on their Route 53, including the Health Checks to detect outages","correct":true},{"id":"abb8f1f2096c4f271cf6c11ab4be0ab4","text":"Implement CloudFront as a CDN for their website, ensuring global fault tolerance","correct":false},{"id":"bad6a2c2cd6a244c640ffb67243421bd","text":"Migrate the servers to EC2 in three different regions to prevent outages in local datacentres","correct":false},{"id":"dcfd51b6eec1175ce379fb23d19ec48f","text":"Transfer their DNS Zone to on-premise DNS servers to allow administrators more power to respond to outages","correct":false}]},{"id":"16482bd7-28fc-4d2d-8d24-37ad0a771da2","domain":"data-man","question":"You have been hired by an airline who has just had a MAJOR security breach exposing the full text of their customers and their credit card details. The company has fired most of their IT security team over the breach and it is your job to make immediate changes to prevent this from happening in the future. Your company has their production application on AWS and uses the following services – EC2 with EBS, RDS, EFS and S3. You need to apply encryption at rest to all 4 services ASAP. Which service can you apply encryption to immediately, without a data migration?","explanation":"Only S3 allows you to enable encryption after the bucket or object has been created and without requiring a migration. All the other services need encryption to be enabled at creation time, so you will need to create a new encrypted EBS, EFS or RDS resource and then migrate to it.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/default-bucket-encryption.html","title":"S3 Encryption"}],"answers":[{"id":"f332127ba5ee3389e4c5cff45ac9a518","text":"EFS","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"248c1b0bcb74394beb4a08030c4a6847","text":"EBS","correct":false}]}]}}}}
