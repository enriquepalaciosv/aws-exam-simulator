{"data":{"createNewExamAttempt":{"attempt":{"id":"29a50324-33f1-4c04-b66b-6151fa57d7a8"},"exam":{"id":"adc90ded-09b2-47dd-bdeb-7545e7cbabb4","title":"AWS Certified Developer - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"af4efcf0-4c08-4c5c-ade1-6e8196c9f0b7","domain":"deployment","question":"Your application needs to process large numbers of job requests and you need to ensure that they are processed in order, and that each request is processed only once. How would you deploy SQS to achieve this end?","explanation":"FIFO queues offer FIFO (First-In-First-Out) delivery and exactly-once processing: The order in which messages are sent and received is strictly preserved and a message is delivered once and remains available until a consumer processes and deletes it; duplicates are not introduced into the queue.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html","title":"SQS FIFO Queues"}],"answers":[{"id":"bbd8881e023d2e48310f360e90cc7582","text":"Convert your standard queue to a FIFO queue by renaming your standard queue with the .fifo suffix.","correct":false},{"id":"78f49aed62525e2d821207ac91af1b24","text":"Use the SetOrder attribute ensure sequential job processing.","correct":false},{"id":"31ea3ce575bc576b9ed1b36ce7cccbbc","text":"Configure FIFO delivery in a standard SQS queue.","correct":false},{"id":"54bf18f30fcf900dcdce5a9bcd553058","text":"Use an SQS FIFO queue to process the jobs.","correct":true}]},{"id":"daa8b2ee-b810-4e35-947d-9ad26196189d","domain":"mon-trb","question":"You can use X-Ray with applications running on which platforms? ","explanation":"X-Ray works with Lambda, EC2, API Gateway, Elastic Beanstalk and ECS","links":[{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":false},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"c8f63ecaff5e983a2441126a241c4cfa","text":"ECS","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":true}]},{"id":"87896ba2-d675-4fce-97b9-f144f05d42f1","domain":"security","question":"You are building an S3 hosted website and your website is accessing javascript and image files located in another S3 bucket. How can you enable this? ","explanation":"Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html","title":"Cross-Origin Resource Sharing (CORS)"}],"answers":[{"id":"0e0c1a7e0b6fe582226b82afc8eec89b","text":"S3 bucket policies","correct":false},{"id":"39e38061c46bfab6a44c6c8b5482763f","text":"Cross Origin Resource Sharing (CORS)","correct":true},{"id":"bef5f130edd0f036b2ca659d3295d5c7","text":"IAM roles","correct":false},{"id":"be48e3ddc7b57744c693982774a47dad","text":"S3 ACLs","correct":false}]},{"id":"15a0fdc7-3a7a-42b2-a937-ccfda81d4261","domain":"mon-trb","question":"You have developed a CloudFormation stack in the AWS Management Console. You have a few small number of CloudFormation stacks saved in the Region in which you are operating in. When you launch your stack that contains many EC2 resources, you receive the error Status=start_failed. How would you troubleshoot this issue?","explanation":"Verify that you didn't reach a resource limit. For example, the default number Amazon EC2 instances that you can launch is 20. If you try to create more Amazon EC2 instances than your account limit, the instance creation fails and you receive the error Status=start_failed. Also, during an update, if a resource is replaced, AWS CloudFormation creates new resource before it deletes the old one. This replacement might put your account over the resource limit, which would cause your update to fail. You can delete excess resources or request a limit increase. Saving the template in the CLI or waiting a few minutes will have no impact. The default limit for CloudFormation stacks is 200 and the question explicitly states that there are only a very small number of existing stacks.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/troubleshooting.html","title":"Troubleshooting AWS CloudFormation"}],"answers":[{"id":"57b1bceff40ae164e764946db0128ea0","text":"Save the template via the AWS CLI.","correct":false},{"id":"3e994bcee300070c97a3c141bc9967bd","text":"Use the Support Center in the AWS Management Console to request an increase in the number of EC2 instances.","correct":true},{"id":"2e0c1157e1b5a9bc0a985d53a1a60aa6","text":"Wait a few minutes before saving the template and retry the process.","correct":false},{"id":"dae0c844938d270767115f5f50079227","text":"Use the Support Center in the AWS Management Console to request an increase in the number of CloudFormation stacks.","correct":false}]},{"id":"b668531f-edd2-43f5-bf40-b7e68dad0d08","domain":"development","question":"A developer is working on a new green field project within an organization. The developer has been asked to recommend what technology could be used if the project is to be deployed with Elastic Beanstalk.\n\nWhich of the following platforms could the developer recommend for the project to meet its requirements?","explanation":"Elastic Beanstalk currently supports Docker, Ruby, and Go (amongst others). It does not support Perl or Swift.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html","title":"Elastic Beanstalk Supported Platforms"}],"answers":[{"id":"9916d1fc59fe22cc046a2fe1615bc764","text":"Ruby","correct":true},{"id":"5f075ae3e1f9d0382bb8c4632991f96f","text":"Go","correct":true},{"id":"ae832e9b5bda2699db45f3fa6aa8c556","text":"Swift","correct":false},{"id":"c5fd214cdd0d2b3b4272e73b022ba5c2","text":"Docker","correct":true},{"id":"0114ad06d728f1834e36fe1a39574ef4","text":"Perl","correct":false}]},{"id":"779acf8c-3df3-43fe-9714-3ebaf8e40ef2","domain":"refactoring","question":"You are working for an investment bank and have been asked to help the application support team with their annual Disaster Recovery testing. The main production PostgreSQL database is hosted in RDS Multi-AZ deployment, with multiple applications running on a combination of EC2 and Lambda. You have been asked to help the team to demonstrate the impact that a failed Availability Zone will have on the database. Which of the following do you suggest?","explanation":"If the Amazon RDS instance is configured for Multi-AZ, you can perform the reboot with a failover. An Amazon RDS event is created when the reboot is completed. If your DB instance is a Multi-AZ deployment, you can force a failover from one Availability Zone (AZ) to another when you reboot. When you force a failover of your DB instance, Amazon RDS automatically switches to a standby replica in another Availability Zone, and updates the DNS record for the DB instance to point to the standby DB instance. As a result, you need to clean up and re-establish any existing connections to your DB instance. Rebooting with failover is beneficial when you want to simulate a failure of a DB instance for testing, or restore operations to the original AZ after a failover occurs.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RebootInstance.html","title":"RDS - Rebooting a DB Instance"}],"answers":[{"id":"222811da7a574ef8ec4e058ece75fe23","text":"Simulate an AZ failure by deleting the primary RDS instance","correct":false},{"id":"1db313c348c46e6cefc8bf25ce3e0d15","text":"Simulate an AZ failure by moving your RDS instance to a different subnet","correct":false},{"id":"4496cfe7afc55864d488f038430be2b5","text":"Simulate an AZ failure by disconnecting your RDS instance from the network","correct":false},{"id":"e8d6fb964d48234750126a73a5fa41f4","text":"Simulate an AZ failure by performing a reboot with forced failover on the RDS instance","correct":true},{"id":"428c5da3acc9c6986847b2511e6129f5","text":"Simulate an AZ failure by rebooting the underlying EC2 instance which is running the database","correct":false}]},{"id":"6f11e8ea-c824-427c-9cf9-7bebec4fe4b6","domain":"development","question":"Where should the appspec.yml be stored?","explanation":"The AppSpec file (appspec.yml) must always be in the root or your application source directory otherwise the deployment will not work. The .ebextensions folder is used to set custom environment variables in Elastic Beanstalk, not CodeDeploy.","links":[{"url":"https://docs.aws.amazon.com/codedeploy/latest/userguide/reference-appspec-file.html","title":"CodeDeploy AppSpec File"}],"answers":[{"id":"b007c30133faeba98cd0fbcedbf4fa6c","text":"In the root of your application source directory","correct":true},{"id":"57f3232fcb44408176cbdb5c8b7e4b06","text":"In /opt","correct":false},{"id":"8ee84dac450c4097f3cce035b8ede57d","text":"In the config directory in your application source directory","correct":false},{"id":"0a2d3304fa88233c14e8c9ebffba0882","text":"In the .ebextentions folder","correct":false}]},{"id":"dc3e7895-b954-4fa8-8d4f-faffeca401d2","domain":"security","question":"Which of the following methods will allow you to *securely* upload/download your data to the S3 service? Pick all that apply.","explanation":"You can securely upload/download your data to Amazon S3 via SSL endpoints using the HTTPS protocol.","links":[{"url":"https://aws.amazon.com/s3/faqs/#security","title":"S3 Security"}],"answers":[{"id":"d7ad40729fa333427d4d8c3032d43fdf","text":"SSL endpoints using HTTP protocol","correct":false},{"id":"1019a747b087f11f97ef6a2bf46a1978","text":"HTTP endpoints using HTTPS protocol","correct":true},{"id":"2b716d646634dd42d3d1ab628b210081","text":"SSL endpoints using the HTTPS protocol","correct":true},{"id":"937a8b8e84ad5481f1983a1842154e18","text":"HTTP endpoints using HTTP protocol","correct":false}]},{"id":"3a11539f-9ee0-4b96-a649-ec7635e18dc8","domain":"deployment","question":"What is the size of one unit of read capacity?","explanation":"A read capacity unit is 4KB in size.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html","title":"Throughput Capacity for Reads and Writes"}],"answers":[{"id":"35ef8d3515745f7c6916d7644fb5d6e5","text":"4 KB","correct":true},{"id":"d54d09275c9dfc95026a3a52d2f66173","text":"3 KB","correct":false},{"id":"bf361755334066f22d019854dd2be686","text":"1 KB","correct":false},{"id":"e7363d80bd01165d7bb0c75f5add39c0","text":"5 KB","correct":false}]},{"id":"81a4f6d3-34ae-4753-8498-823bede20afe","domain":"deployment","question":"Your team is considering deploying an application on AWS Elastic Beanstalk. Your manager needs to know what infrastructure requirements are needed for the team, specifically in regards to maintenance, patching, and managing security. How would you explain what AWS is responsible for and what the team is responsible for to your manager?","explanation":"AWS and its customers share responsibility for achieving a high level of software component security and compliance. This shared model reduces customers' operational burden. AWS Elastic Beanstalk helps you perform your side of the shared responsibility model by providing a managed update feature. This feature automatically applies patches and minor updates for an Elastic Beanstalk supported platform version. Elastic Beanstalk publishes its platform support policy and retirement schedule for the coming 12 months. You (the customer) are responsible for the security of your application, your data, and any components that your application requires and that you downloaded. Be sure to review the Shared Responsibility Model in the URL provided.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/platforms-shared-responsibility.html","title":"Shared Responsibility Model for Elastic Beanstalk Platform Maintenance"}],"answers":[{"id":"7086eb1de01b03376ee097977ba7cd94","text":"You are responsible for runtime, application server, and web server components if you opt into Elastic Beanstalk managed updates.","correct":false},{"id":"9d22ad24853ac3a47fe7c0e7eb2585e3","text":"You are responsible for the security of your application, your data, and any components that your application requires and that you downloaded.","correct":true},{"id":"8fc7a262705a2a78a08dbc0ea667db64","text":"You are responsible for publishing Elastic Beanstalk's platform support policy and retirement schedule.","correct":false},{"id":"9fafdcf1a8a7c82b9e94d6080c00a245","text":"AWS is responsible for patches, minor, and major updates of operating system on its supported platform versions.","correct":true},{"id":"f1e49a967c2ae8dc1525d208a8170996","text":"AWS is responsible for the security of your application, your data, and any components that your application requires and that you downloaded.","correct":false}]},{"id":"55fbda31-57ba-4009-a6da-09f690b40351","domain":"security","question":"You are developing an application which will use Cognito to allow authenticated Facebook users to sign-in and use your application. You would like to use Cognito to handle temporary access allowing authenticated users to access product and transaction data that your application stores in S3 and DynamoDB. Which is the best approach?","explanation":"Cognito is the recommended approach for user sign-up and sign-in for mobile applications which allow access to users with Facebook, Google or Amazon.com credentials. Identity pools enable you to grant your users temporary access to AWS services. User pools are user directories that provide sign-up and sign-in options for your app users.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/what-is-amazon-cognito.html","title":"What Is Cognito?"}],"answers":[{"id":"67a47bfe3685e0b65597b1bb14c5426f","text":"Configure an IAM User Group to provide temporary AWS credentials to your users to allow temporary access to AWS resources","correct":false},{"id":"6e4d8be48c9bbd213381e12f94eaa9a7","text":"Configure a SAML 2 Federation to provide temporary AWS credentials to your users to allow temporary access to AWS resources","correct":false},{"id":"e83779413869ed1569c2eb035ca21ef9","text":"Configure an Identity Pool to provide temporary AWS credentials to your users to allow temporary access to AWS resources","correct":true},{"id":"edac71e5f6a783c051f80c7369a90c0d","text":"Configure a User Pool to provide temporary AWS credentials to your users to allow temporary access to AWS resources","correct":false}]},{"id":"6db2c293-ed5d-41ff-84fb-803e2970a0f9","domain":"development","question":"A developer is working on a new application which will use DynamoDB. One of the DynamoDB tables that the developer must create requires an index sort key. When creating this DynamoDB table, the developer must select an Attribute Type for the sort key.\n\nWhich of the following DynamoDB data types can the developer select to use for their index sort key?","explanation":"Both partition and sort keys attributes must be defined as type string, number, or binary.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.NamingRulesDataTypes.html#HowItWorks.DataTypes","title":"DynamoDB Data Types"}],"answers":[{"id":"27118326006d3829667a400ad23d5d98","text":"String","correct":true},{"id":"4ee29ca12c7d126654bd0e5275de6135","text":"List","correct":false},{"id":"b2ee912b91d69b435159c7c3f6df7f5f","text":"Number","correct":true},{"id":"6ce976e8f061b2b5cfe4d0c50c3405dd","text":"Binary","correct":true},{"id":"27226c864bac7454a8504f8edb15d95b","text":"Boolean","correct":false},{"id":"46f3ea056caa3126b91f3f70beea068c","text":"Map","correct":false}]},{"id":"88bcdf37-e9ac-4a5a-9561-a0b40b3d5942","domain":"deployment","question":"You have deployed your application on EC2 using Elastic Beanstalk. You would like to configure your application to send data to X-Ray. Where should you install the X-Ray daemon?","explanation":"To relay trace data from your application to AWS X-Ray, you can run the X-Ray daemon on your Elastic Beanstalk environment's Amazon EC2 instances. Elastic Beanstalk platforms provide a configuration option that you can set to run the daemon automatically. You can enable the daemon in a configuration file in your source code or by choosing an option in the Elastic Beanstalk console. When you enable the configuration option, the daemon is installed on the instance and runs as a service.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-beanstalk.html","title":"Running the X-Ray daemon on AWS Elastic Beanstalk"}],"answers":[{"id":"2e3b28f6b658014b7006069d657a21b0","text":"Manually provision a new EC2 instance and install the X-Ray daemon on the new instance","correct":false},{"id":"815e2ca172c43e652a7d680047998174","text":"Install the X-Ray daemon on a Docker container running on your EC2 instance","correct":false},{"id":"b869cc613e5695b1535e3509f2226824","text":"Install the X-Ray daemon on the EC2 instances inside your Elastic Beanstalk environment.","correct":true},{"id":"020611c7739a39c03183a066978fdad7","text":"Install the X-Ray daemon on the EC2 instances located in your own data center","correct":false}]},{"id":"952d36e5-535a-4b3c-a107-e834a2126477","domain":"development","question":"You have developed a web application running on a number of EC2 instances running Tomcat, you are using an S3 bucket to store product data, with customer transaction data held in an RDS database. You anticipate that the number of connections into your website will grow considerably over the next year and you want to configure a scalable place to store session state data so that multiple web servers can share the session state. Which of the following are suitable options for this application?","explanation":"DynamoDB and ElastiCache are both great options for storing session data. Both are scalable and resilient. RDS is more suited to relational data, whereas DynamoDB is far more flexible and better suited to storing session state data. Storing the data on the EC2 instances is not scalable or resilient. Lambda cannot store session state.","links":[{"url":"http://docs.amazonaws.cn/sdk-for-java/v1/developer-guide/java-dg-tomcat-session-manager.html","title":"Storing Web Server Session State in DynamoDB"},{"url":"https://aws.amazon.com/caching/session-management/","title":"Session management in AWS"}],"answers":[{"id":"be80d5651d3ee2a3c4e8736eb5082177","text":"Store session state locally on each EC2 instance","correct":false},{"id":"bc7071d9896321da24f137567ef7e97c","text":"Store the session state data in a DynamoDB table","correct":true},{"id":"690b4209ea43175d9fb511ffba4d6e52","text":"Store the session state data inside a Lambda function","correct":false},{"id":"ba003a66972966fcb9cc5503341c8a59","text":"Use ElastiCache to store session state","correct":true},{"id":"87bdddfb8d5f7cc0273d9b48a667d260","text":"Store the data in the same RDS database used for customer transactions","correct":false}]},{"id":"8caa9788-5c49-413f-b0c0-6f515af3fe5f","domain":"security","question":"An organization has mandated that all files stored in their newly created S3 bucket, 'top-secret-documents', must be encrypted using a Customer Master Key stored in KMS.\n\nWhat is the best way to enforce this requirement?","explanation":"To ensure objects are stored using a specific type of server-side encryption, you must use a bucket policy. In this case, the bucket policy must ensure the encryption type matches SSE-KMS.\n\nSetting a default encryption type on the bucket is not sufficient, as the default only applies to uploaded objects that do not specify any encryption type. For example, if the default encryption is set to AWS-KMS, but an object is uploaded with the header `x-amz-server-side-encryption: AES256`, the resulting object is encrypted using SSE-S3, not SSE-KMS.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting S3 Data Using Server-Side Encryption"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html","title":"Example bucket policy for enforcing SSE"}],"answers":[{"id":"62e28c6b06e8b3895db973aa3d03c4fd","text":"Add a bucket policy that denies PUT operations that don't contain the HTTP header `x-amz-server-side-encryption: AES256`","correct":false},{"id":"7910fc40ce77db47b28825a906611f8d","text":"Enable S3 Default encryption and select AWS-KMS","correct":false},{"id":"21b68cac2d99a4c11c51d224971ee62f","text":"Add a bucket policy that denies PUT operations that don't contain the HTTP header `x-amz-server-side-encryption: aws:kms`","correct":true},{"id":"8be8b17570d837c0301070a5b8fde1cb","text":"Add a bucket policy that denies PUT operations that don't contain the HTTP header `x-amz-server-side-encryption: SSE:C`","correct":false}]},{"id":"8e61dab4-571e-4a97-a6a7-bcbfddddd867","domain":"deployment","question":"You are using CloudFront to serve static website content to users based in multiple locations across the USA, Africa, India and the Middle East. You recently made some significant updates to the website, but users are complaining that they can only see the original content. What can you do you make sure the latest version of the website is being served by CloudFront?","explanation":"If you need to remove a file from CloudFront edge caches before it expires, you can do one of the following: Invalidate the file from edge caches. The next time a viewer requests the file, CloudFront returns to the origin to fetch the latest version of the file. Use file versioning to serve a different version of the file that has a different name.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Invalidation.html","title":"Invalidating Files in CloudFront"}],"answers":[{"id":"1215948dd7c3245305713d0ec57cae6f","text":"Update the file in the original location and reset the cache timestamp","correct":false},{"id":"cf938fcfef89105b2dc2d97975c87b22","text":"Wait for the cache to expire","correct":false},{"id":"78eef0aaf2d58aea70bfd13a7d03df31","text":"Invalidate the file from the CloudFront edge cache","correct":true},{"id":"6d72e9895d437372eba948f57e50610f","text":"Delete the file from the original location and replace it with a new version","correct":false}]},{"id":"004b0e0e-f5a4-4354-b130-46786f367c11","domain":"security","question":"A developer is running an application on an Amazon EC2 instance that requires access to an Amazon S3 bucket. An administrator creates a role that includes policies that grant read permissions to the bucket and that allow the developer to launch the role with an Amazon EC2 instance. The instance is launched with the created role attached. What additional step is required for the application running on the instance to access the objects in the bucket?","explanation":"Applications that run on an Amazon EC2 instance and that need access to AWS resources such as Amazon S3 buckets or an Amazon DynamoDB table must have security credentials in order to make programmatic requests to AWS. In this case, no other steps are necessary since the application running on the instance will have the necessary permissions by assuming the role attached to the EC2 instance. Since the developer is not using the bucket (the application on the instance is) granting access to the developer will have no impact. There is no need to share credentials with the bucket policy.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"d57505894b0e8e826335fc1b6ca1f88c","text":"No other steps are necessary. The application running on the instance will be able to access the bucket.","correct":true},{"id":"1bc25b995801c49945fc1175ebfaf95d","text":"The administrator must grant the developer permissions to access the bucket.","correct":false},{"id":"ff86c6c144ca49f130e8a6024c26d48c","text":"Create an IAM policy that allows the developer permissions to access the bucket. Attach the policy to the developer's IAM User.","correct":false},{"id":"723ec04523ad8f60803dd2ae402f886f","text":"The developer must share his/her credentials with the bucket policy.","correct":false}]},{"id":"4becf869-2fee-4023-80b0-0cb3a21c2651","domain":"development","question":"You are using CodeBuild to build the source code for your new application and would like to reference a large number of environment variables in buildspec.yml. However when you try to run the build you see an error telling you that the parameters you have specified have exceeded the number of characters allowed by the buildspec file. You need to find an alternative way to store these parameters, which of the following options would you recommend?","explanation":"Use Amazon Systems Manager Parameter Store to store large environment variables and then retrieve them from your buildspec file. Amazon EC2 Systems Manager Parameter Store can store an individual environment variable (name and value added together) that is a combined 4,096 characters or less.","links":[{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/troubleshooting.html","title":"Troubleshooting CodeBuild"},{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html","title":"Build Specification Reference for CodeBuild"}],"answers":[{"id":"fdc76a3ff4a2b80aefd90a5dd389f44c","text":"Store the variables as dependencies within the application code","correct":false},{"id":"18f72b8f598e9cc0d20295158be172dd","text":"Store the variables as key value pairs in DynamoDB","correct":false},{"id":"31a2f312e14f62be70158dff280e56cb","text":"Store the variables as key value pairs in S3","correct":false},{"id":"913d4a9f910c7f6b836d623b39131480","text":"Use Systems Manager Parameter Store","correct":true}]},{"id":"9554e10d-8fab-4545-b3ea-a756133ffab3","domain":"refactoring","question":"You need to retrieve some data from your DynamoDB table, which of the following methods would consume the least provisioned Capacity Units?","explanation":"A Query is generally more efficient than a Scan operation. Eventual consistency reads use up fewer Read Capacity Units than strongly consistent reads","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Query Vs Scan"},{"url":"https://aws.amazon.com/dynamodb/pricing/provisioned/","title":"Provisioned Capacity"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","title":"DynamoDB Read Consistency "}],"answers":[{"id":"ac9570514b07db98ad6cc89ea1cc8741","text":"Query with strong consistency","correct":false},{"id":"5d682b15ed6ff4d0b5100242fa11d4ea","text":"Scan with eventual consistency","correct":false},{"id":"d87fc0cde8df11c904ff6fe25cac6bfc","text":"Query with eventual consistency","correct":true},{"id":"8747d18821697e99310487487007af03","text":"Scan with strong consistency","correct":false}]},{"id":"b41da940-4b4e-11ea-b77f-2e728ce88125","domain":"mon-trb","question":"You created a CloudFormation template that launched a web application in us-west-1. However, you are experiencing a problem creating a development stack in us-east-1 to serve clients in another geographical location. What should you do to solve the problem?","explanation":"An Amazon Machine Image, or AMI, is used to launch an EC2 instance in a specified region. So, to use it in another region, you will have to copy it to the region of your choice. Recreating the resources is unnecessary since you only need to copy the AMI. And the IAM role is irrelevant to the question, since IAM roles are valid across the entire AWS account.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"e3bebd36eb37842d75a71b0a69c37abe","text":"Copy the AMI in the template from us-west-1 to us-east-1.","correct":true},{"id":"e72b5dc8983df71bdc1fa0c5b4985e4f","text":"Copy the AMI in the template from us-east-1 to us-west-1.","correct":false},{"id":"6971fa728cde2ee82b21faac08aeb60a","text":"Copy your IAM role to us-east-1 region so that you have permissions to deploy CloudFormation stacks in that region.","correct":false},{"id":"b5a9be3c7b03258224fb637458459b99","text":"Recreate the AWS resources used for the application in us-west-1.","correct":false}]},{"id":"71b8b773-eed1-4335-9631-5bfe132f16c7","domain":"development","question":"You are the development lead on a large project to launch a new e-commerce website specialising in fishing supplies. Your developers are located in India, USA and the Middle East. You need to find a source code repository that everyone can use, and that will allow developers to continue to work on their code even when they are not connected to the internet. Which of the following would you suggest to the team?","explanation":"CodeCommit is based on Git, which is a distributed version control system, meaning there is no single, central place where everything is stored. In a distributed system, there are multiple backups in the event that you need one. This approach also means that you can work offline and commit your changes when you are ready.","links":[{"url":"https://aws.amazon.com/devops/source-control/git/","title":"Source Control In AWS"}],"answers":[{"id":"c3a56d6c63ca88e19d3e6afc5b896c46","text":"Use CodeBuild in offline mode to manage your source code","correct":false},{"id":"94efdca7e5940d3078c950c64e833082","text":"Use CodeCommit to manage your source code","correct":true},{"id":"4e1b47d595e44072d3890d332ead7f86","text":"Run an instance of Git in a docker container on AWS ECS","correct":false},{"id":"c2a2ffe5e9352016e58fe01b3c304de3","text":"Install Git on 2 EC2 instances in an auto-scaling group","correct":false}]},{"id":"3a01c37a-6939-444b-89b0-f73b1f232601","domain":"deployment","question":"You are developing a social media messaging and photo-sharing application which consists of a web front end, with persistent data stored in S3 and RDS. Which of the following instance pricing models should you choose to make running this application as cost-effective as possible?","explanation":"Reserved instances provide a significant discount compared to running instances On-Demand. You can take advantage of Spot Instances to run and scale applications such as stateless web services, image rendering, big data analytics, and massively parallel computations. Dedicated Instances are Amazon EC2 instances that run in a VPC on hardware that is dedicated to a single customer.","links":[{"url":"https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/when-to-use-spot-instances.html","title":"When To Use Spot Instances"},{"url":"https://aws.amazon.com/ec2/pricing/reserved-instances/","title":"When To Use Reserved Instances"},{"url":"https://aws.amazon.com/ec2/pricing/dedicated-instances/","title":"When To Use Dedicated Instances"},{"url":"https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/when-to-use-spot-instances.html","title":"Cost Optimization White Paper"}],"answers":[{"id":"a057af2fca16fcc4c6997976ea994e95","text":"Use Spot instances for the web servers","correct":true},{"id":"86ed636cf8296c0bedacc99ec10c39f0","text":"Use dedicated instances for the database servers","correct":false},{"id":"7e5d7958c67ef51985894e5f8b2a25a8","text":"Use Spot instances for the database","correct":false},{"id":"60e31915c1c4910787bf03781555aa97","text":"Use reserved instances for the database","correct":true},{"id":"1b65fa924bf38ff7e68d41f3495434bd","text":"Use reserved instances for the web servers","correct":false},{"id":"04be777131f511081730fe2b34662123","text":"Use dedicated instances for the web servers","correct":false}]},{"id":"777f1a0d-0acd-4907-be1f-ceb4266d3170","domain":"development","question":"You are developing a Lambda function which takes an average of 20 seconds to execute. During performance testing, you are trying to simulate peak loads, however soon after the testing begins, you notice that requests are failing with a throttling error. What could be the problem?","explanation":"When requests come in faster than your function can scale, or when your function is at maximum concurrency, additional requests fail with a throttling error (429 status code).","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/limits.html","title":"Lambda Limits"},{"url":"https://aws.amazon.com/about-aws/whats-new/2017/05/aws-lambda-raises-default-concurrent-execution-limit/","title":"Default Concurrent Execution Limit"}],"answers":[{"id":"e7f379a6b188c5064bd7c1bf17994433","text":"You haven't allocated enough memory to your function","correct":false},{"id":"f33d22d5ee65a1e9f86c1631c889d199","text":"The Lambda function is taking too long to execute","correct":false},{"id":"396cb0f44930bc3d21771b4f8c6e7afd","text":"You have reached the limit of concurrent executions for Lambda","correct":true},{"id":"5f877189f6b1d52e35220d6fac989254","text":"Your application does not have permission to invoke the Lambda function","correct":false},{"id":"67713e6254fbdabc3504f77f455cf500","text":"The deployment package is too large","correct":false}]},{"id":"54fce7fa-7d85-4dde-92e6-4e6d1e12327c","domain":"deployment","question":"You have developed an application to run on Amazon EC2. Users have increased and you've found latency issues for users from various geographic locations. You decide to create a CloudFormation template of the application's environment in order to streamline application launch in other AWS Regions to improve performance for users. When creating the CloudFormation template, what is one thing you have to ensure for the resources to launch successfully?","explanation":"AWS CloudFormation templates that declare an Amazon Elastic Compute Cloud (Amazon EC2) instance must also specify an Amazon Machine Image (AMI) ID, which includes an operating system and other software and configuration information used to launch the instance. The correct AMI ID depends on the instance type and region in which you're launching your stack. And IDs can change regularly, such as when an AMI is updated with software updates. AMIs are stored in a region and cannot be accessed in other regions. To use the AMI in another region, you must copy it to that region. IAM roles are valid across the entire account. AWS CloudFormation StackSets let you provision a common set of AWS resources across multiple accounts and regions with a single CloudFormation template. Tags are not a universal namespace and are used as metadata or labels for your resources.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/walkthrough-custom-resources-lambda-lookup-amiids.html","title":"Walkthrough: Looking Up Amazon Machine Image IDs"}],"answers":[{"id":"e2c092a149099f0d0ae393acb19afd6d","text":"This is not possible. CloudFormation templates can be launched only in a single region.","correct":false},{"id":"fbbfa698853564b32d5e961010c48e36","text":"Ensure the AMIs referenced in the template correspond to the AMI IDs in the desired Region.","correct":true},{"id":"5b8b4dc7a6004401e2e0fb8002dfd3c7","text":"Ensure the tags of the resources are not the same in the new Region as they are a universal namespace.","correct":false},{"id":"c2a7b7d4dab7e7ef0dc554e6054d7f77","text":"Create and validate the right IAM roles in the template in the desired Region.","correct":false}]},{"id":"55ffe5c3-b16f-42d6-9b3e-5f4d77890f49","domain":"mon-trb","question":"You are troubleshooting a major incident which has resulted in data loss in your application. Your manager asks if you can provide a time-ordered sequence of any modifications which happened to the items in your DynamoDB table over the past 24 hours so that you can work out what happened. Which service could you use to most effectively provide this?","explanation":"DynamoDB Streams captures a time-ordered sequence of item-level modifications in a DynamoDB table and durably stores the information for up to 24 hours.","links":[{"url":"https://aws.amazon.com/blogs/database/dynamodb-streams-use-cases-and-design-patterns/","title":"DynamoDB Streams Use Cases"}],"answers":[{"id":"48d30a1b2a41bc37892197dc4df30262","text":"Kinesis Streams","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"1f60690ba7c488a02416a7bf195f900b","text":"DynamoDB Streams","correct":true}]},{"id":"d36289fe-be3b-4a73-8cc2-c216cfd47b05","domain":"security","question":"You're part of a developer team which is building an application that requires access to S3. Everyone on your team requires the same IAM permissions. As your team grows, how would you manage IAM policies and access to the right AWS resources in the most efficient manner?","explanation":"IAM groups are collections of IAM users in one AWS account. You can create IAM groups on a functional, organizational, or geographic basis, or by project, or on any other basis where IAM users need to access similar AWS resources to do their jobs. You can provide each IAM group with permissions to access AWS resources by assigning one or more IAM policies. All policies assigned to an IAM group are inherited by the IAM users who are members of the group. Creating IAM Users for each team member is not the most efficient manner; IAM Groups is more efficient. You cannot log into the AWS Management Console using an IAM role, nor can you do the same with Amazon Cognito. Amazon Cognito is best suited for mobile applications.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_","title":"AWS Security Best Practices"}],"answers":[{"id":"a834e2bd501ea84ca860e5213b4290ea","text":"Create one IAM role with the necessary permissions. Have all team members log into the AWS Management Console using that role. Rotate the password regularly.","correct":false},{"id":"d81d323b3e2be35dfba6061c653ce5d1","text":"Create an Amazon Cognito user pool for each user and a corresponding S3 bucket. Grant S3 bucket GET requests for each bucket to each Cognito user. Require users to log into the Console using their Cognito credentials.","correct":false},{"id":"7c9871a327396074304930d0dbe0fcee","text":"Create IAM Users for each team member. Attach an IAM policy to each user. Edit the IAM policy for each user adhering to the Principle of Least Privilege. Create new IAM policies for new team members as appropriate.","correct":false},{"id":"9ef5172ef2f91f7f79640375254443b1","text":"Create an IAM Group called 'Developers'. Attach an IAM policy to the group with the appropriate permissions. Associate your IAM user and your team members' users to the Group. Add new team members to the group as appropriate.","correct":true}]},{"id":"22556a45-7db0-48f9-85cf-654ac74d729f","domain":"security","question":"When using the AWS REST API to upload an object to S3, which of the following request headers will ensure that your data must be encrypted using SSE?","explanation":"To request server-side encryption using the object creation REST APIs, provide the x-amz-server-side-encryption request header.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html","title":"Protecting Data Using Server-Side Encryption"}],"answers":[{"id":"6d1f5944b9a6aada7e00dc385d5373bd","text":"x-s3-server-side-encryption","correct":false},{"id":"f041d978ebb9256a023c1f9d263316ac","text":"amz-s3-server-side-encryption","correct":false},{"id":"6d38512683c3cf8052e7e47d9d12a9f6","text":"x-amz-server-side-encryption","correct":true},{"id":"63e1961675193e5c234f582f08632a28","text":"s3-amz-server-side-encryption","correct":false}]},{"id":"eebfef11-98bd-48f5-9775-b70b3600480a","domain":"development","question":"You are working on updates to your .NET application which has been deployed using Elastic Beanstalk. Your environment consists of 4 EC2 instances, as well as a number of different Lambda functions and DynamoDB tables. The application requires at least 2 instances to cope with the average workload and a minimum of 3 instances to cope with peak-time traffic. The Project Manager has asked you to roll out the updates as quickly as possible. Which of the following deployment strategies do you recommend?","explanation":"An all-at-once deployment deploys to all instances simultaneously which will put all of your web servers out of action at once. Rolling with additional batch launches an extra batch of instances before starting the deployment, to maintain full capacity. However, full capacity is not required in this scenario. Immutable deployments perform an immutable update to launch a full set of new instances running the new version of the application in a separate Auto Scaling group, alongside the instances running the old version; this is not required in this scenario. You can use a rolling update with a batch size of 25%, to ensure that 75% of your servers remain available at any time.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","title":"Elastic Beanstalk Deployment Options"}],"answers":[{"id":"11efd9ae6f76e706e3f1b34d97584ebc","text":"Immutable","correct":false},{"id":"f4920797afb92022a9c6608efcd86317","text":"Rolling","correct":true},{"id":"ff2713a6181db42fded101c670bbd0dd","text":"Rolling with additional batch","correct":false},{"id":"d5b066eef81dedf1d0352f27d2128586","text":"All at once","correct":false}]},{"id":"6641f65a-c837-49a2-bbeb-11af158d44e0","domain":"mon-trb","question":"What is the maximum execution duration for a Lambda request?","explanation":"As of Oct 2018 the maximum execution duration has been increased from 300 seconds to 900 seconds (15 minutes)","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/limits.html","title":"Lambda Limits"},{"url":"https://aws.amazon.com/about-aws/whats-new/2018/10/aws-lambda-supports-functions-that-can-run-up-to-15-minutes/","title":"Update notice- Oct 2018"}],"answers":[{"id":"533f546e5ddb63fb2c810f7cca06678f","text":"300 seconds","correct":false},{"id":"a51534ea662db3ce23238035e25859e2","text":"900 seconds","correct":true},{"id":"4234838a99b7912e550babb083c205c4","text":"60 seconds","correct":false},{"id":"8d15ed7d27d83ed6229a66b1f44b7696","text":"3 minutes","correct":false},{"id":"7ed53d277129b356be62369ec930e3b8","text":"500 seconds","correct":false}]},{"id":"4b9c267c-f41d-4325-919e-7863e0abb6f3","domain":"development","question":"A three-tier web application is deployed using CloudFormation template. How can the CloudFormation developer ensure that the database resource is saved for backup purposes upon stack deletion?","explanation":"The DeletionPolicy attribute can be used to preserve a specific resource when its stack is deleted. The DeletionPolicy Retain option can be used to ensure AWS CloudFormation keeps the resource without deleting the resource.  The Stack Termination Protection feature enables protection against accidental deletion of an entire stack, not preservation of a specific resource. Similarly, the 'cloudformation:DeleteStack' Action applies to entire stack(s).","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html","title":"DeletionPolicy Attribute"}],"answers":[{"id":"558cc27970e2b64a29bdc85f381b8cb9","text":"Set the DeletionPolicy to Retain in the CloudFormation template.","correct":true},{"id":"6983aeb4c0d42bb293c8ec93966aedbb","text":"Set the DeletionProtection to True in the CloudFormation template.","correct":false},{"id":"8093dacb1a766d0f91fa60e48baa87ed","text":"Set Stack Termination Protection to Enable.","correct":false},{"id":"eee064b70f79422e8511f18b251253ef","text":"Create IAM Policy with Effect of Deny for 'cloudformation:DeleteStack' Action.","correct":false}]},{"id":"33d838eb-6e2a-499f-b1a0-0d385c20732a","domain":"deployment","question":"You have deployed an application using Elastic Beanstalk and your code is running in a Docker container. What is the process for upgrading this application?","explanation":"When you use the Elastic Beanstalk console to deploy a new application or an application version, you'll need to upload a source bundle. Your source bundle must consist of a single ZIP file or WAR file which does not exceed 512 MB. By using Docker with Elastic Beanstalk, you have an infrastructure that automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html","title":"Create an Application Source Bundle"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html","title":"Deploying Elastic Beanstalk Applications from Docker Containers"}],"answers":[{"id":"50ca13bdc867153ec83d6d066d4950b3","text":"Use CodeBuild to deploy the new code to the docker container","correct":false},{"id":"9142b51f935ad294eb31a909cbe9336e","text":"Upload a zip file containing the new version of your code using the \"Upload and Deploy\" button in the ElasticBeanstalk console","correct":true},{"id":"c9bd7c34b6482e6240a3a8a6404e5d09","text":"Upload your code to Elastic Container Registry and select the \"Deploy Now\" option in Elastic Container Service console","correct":false},{"id":"f65c3a605a6af1f8f362fab1debc50b2","text":"Upload your code to CodeCommit and select the \"Deploy Now\" option in Elastic Container Service console","correct":false}]},{"id":"f26b6227-d443-4a48-9a39-d52161ec3ef5","domain":"security","question":"What is the name of the service that allows users to use their social media account to gain temporary access to the AWS platform?","explanation":"Web Identity Federation is the services which allows users to authenticate with web Identity Providers like Facebook, Google and Amazon receive an authentication token and then exchange that token for temporary security credentials in AWS.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html","title":"Web Identity Federation"}],"answers":[{"id":"fba87e436c5368fd112fc79eddacea80","text":"Active Directory Authentication Services","correct":false},{"id":"9cc6ff53d9bbecc10bacb7866e5e957d","text":"Web Confederation Services","correct":false},{"id":"91c75725a837ff613915a3cf3f8208e1","text":"Web Identity Federation","correct":true},{"id":"876393862947dc478af3ab7b02c30ba9","text":"Facebook Sign In Service","correct":false}]},{"id":"1a6ef8eb-4675-4004-ab47-3f8682a6e038","domain":"security","question":"Your EC2 instance needs to access files located in an S3 bucket, what is the best way to enable access?","explanation":"Using an IAM role associated with the EC2 instance is the recommended way, storing credentials locally is not recommended.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html","title":"IAM Roles"}],"answers":[{"id":"f47981b92302bc40c2c9dc5f0ec40a23","text":"Create an IAM role with read access to S3 and assign the role to the EC2 instance","correct":true},{"id":"6642e43e9a2808c204a04b7c07a1f5ac","text":"Create a new IAM user and grant read access to S3. Store the user's credentials locally on the EC2 instance and configure your application to supply the credentials with each API request","correct":false},{"id":"7e00e264a60465681fb267faf13307e9","text":"Configure a bucket policy which grants read access based on the EC2 instance name","correct":false},{"id":"246491a279b8f11f71b3c083962c0e75","text":"Create a new IAM role and grant read access to S3. Store the role's credentials locally on the EC2 instance and configure your application to supply the credentials with each API request","correct":false}]},{"id":"a45d7c37-eb4b-4a39-9fb2-d5298cb40491","domain":"security","question":"You work for a large I.T. recruitment company that are launching a mobile application which will allow job seekers to apply for jobs online and attach their résumé to their application. Users will be able to log in to their account using Facebook and the application stores their contact and profile details in a DynamoDB table. Which of the following approaches would you recommend for enabling the users to gain access to view and update their data?","explanation":"With Web Identity Federation, you don't need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well-known external identity provider (IdP), such as Login with Amazon, Facebook, Google. For most Web Identity Federation scenarios, we recommend that you use Amazon Cognito because it acts as an identity broker and does much of the federation work for you.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html","title":"Web Identity Federation"}],"answers":[{"id":"f11ad00f139ee7fd7ecde821e3769c1a","text":"Configure cross-account access between the mobile app and DynamoDB ","correct":false},{"id":"3b5209dda18fcdea46a196b06d17c586","text":"Configure Web Identity Federation with Cognito","correct":true},{"id":"e0bc3be9eb85e3ef437aac25d15f5be4","text":"Allow customers to embed user credentials in settings of the mobile app","correct":false},{"id":"ff1fd8b56d2c836edd2795619fa9b681","text":"Configure Web Identity Federation with ADFS","correct":false}]},{"id":"545a364d-6872-4c56-aa7c-135a89d39133","domain":"mon-trb","question":"What does the error \"ProvisionedThroughputExceededException\" mean in DynamoDB?","explanation":"You exceeded your maximum allowed provisioned throughput for a table or for one or more global secondary indexes.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html","title":"Error Handling in DynamoDB"}],"answers":[{"id":"f64333b18f5422f67a98047421afcd5b","text":"There is no such error message. The correct error message would be \"ProvisionedThroughputFailureException\".","correct":false},{"id":"0e3a814eaadffaf2ce9fbd6c2c8ecaeb","text":"The DynamoDB table has exceeded the allocated space.","correct":false},{"id":"da824a20e75733561947108177c08dcb","text":"You exceeded your maximum allowed provisioned throughput for a table or for one or more global secondary indexes.","correct":true},{"id":"79851cf660541b5d451c8213382b5e0c","text":"The DynamoDB table is unavailable.","correct":false}]},{"id":"064a1ca2-3ce2-483d-9e44-f0381416aa53","domain":"development","question":"You are developing a CloudFormation template and need to retrieve a string value containing the DNS name of the load balancer from an earlier section of the template. How would to refer to this string value in the most efficient and automated fashion?","explanation":"The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. This is the best choice per documentation and eliminates the need to hardcode values to be able to automate future renditions of the template rather than having to manually change every hard-coded value. The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. The intrinsic function Fn::FindInMap returns the value corresponding to keys in a two-level map that is declared in the Mappings section.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getatt.html","title":"Fn::GetAtt"}],"answers":[{"id":"f9121262138f8b6c85cca08c00b4b4f5","text":"Use the condition function Fn::GetAtt to return the value of the attribute","correct":true},{"id":"a458b06d7d68a0755776d692742aebe5","text":"Hardcode the string value by checking the DNS name number ELBs in the Console and insert the value in the template.","correct":false},{"id":"d07c84be22b2e436b377f48b647e144a","text":"Use the condition function Fn::FindInMap to return the value corresponding to the key.","correct":false},{"id":"597e06174b5664dffc6d5fa8752fc74b","text":"Use the condition function Fn::Select to return the value of the string.","correct":false}]},{"id":"1710c298-c975-4762-8948-da98b2900d8a","domain":"development","question":"You are developing a web application which has been deployed using Lambda. Today you updated the code and uploaded the new version of your code to the Lambda console. Your test team have begun testing but have reported today that the application seems to still be using the original code. What could be the reason for this?","explanation":"The problem is that the application is referencing the function using an alias pointing to a previous version of the code. When you use versioning in AWS Lambda, you can publish one or more versions of your function. So that you can use different variations of your Lambda function in your development workflow, such as development, beta, and production. Lambda also supports creating aliases for each of your Lambda function versions. Conceptually, an AWS Lambda alias is a pointer to a specific Lambda function version. You can update aliases to point to different versions of functions.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda Function Versioning and Aliases"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/how-to-manage-versioning.html","title":"Lambda Versioning"}],"answers":[{"id":"b099c8a69bf8eac2d39f02ac07d53702","text":"Your application is referencing the function using an alias which points to a previous version of the code","correct":true},{"id":"ce472c670d174e72811d57156684bb1e","text":"You forgot to publish the version","correct":false},{"id":"2fcd244fd0d8e7833b6bf94d70f01295","text":"Your application is referencing the function using an unqualified ARN","correct":false},{"id":"b67108883bf2590e9f79b9ab834a84cd","text":"Your application is referencing the function using $LATEST","correct":false},{"id":"078229fa3cd7070c357a105fd9f1584d","text":"Your application is referencing the function using a qualified ARN","correct":false}]},{"id":"16387bfd-386c-4d6e-a808-8f42694fb73d","domain":"deployment","question":"Your application is using Kinesis to ingest click-stream data relating to your products from a variety of social media sites. Your company has been trending this quarter because a high profile movie star has recently signed a contract to endorse your products. As a result, the amount of data flowing through Kinesis has increased, causing you to increase the number of shards in your stream from 4 to 6. The application consuming the data runs on a single EC2 instance in us-east-1a with a second instance in us-east-1b which is used as a cold standby in case the primary instance fails. How many consumer instances will you now need in total to cope with the increased number of shards?","explanation":"Re-sharding enables you to increase or decrease the number of shards in a stream in order to adapt to changes in the rate of data flowing through the stream. You should ensure that the number of instances does not exceed the number of shards (except for failure standby purposes). Each shard is processed by exactly one KCL worker and has exactly one corresponding record processor, so you never need multiple instances to process one shard. However, one worker can process any number of shards, so it's fine if the number of shards exceeds the number of instances. When re-sharding increases the number of shards in the stream, the corresponding increase in the number of record processors increases the load on the EC2 instances that are hosting them. If the instances are part of an Auto Scaling group, and the load increases sufficiently, the Auto Scaling group adds more instances to handle the increased load.","links":[{"url":"https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html","title":"Kinesis Data Streams Terminology"},{"url":"https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html","title":"Resharding, Scaling, and Parallel Processing"}],"answers":[{"id":"834a08c5c4b013c0a9e06105fc8c873a","text":"6 instances in us-east-1a and 6 instances in us-east-1b","correct":false},{"id":"35e98ea97449addda5a6f1eecf072e4a","text":"6 instances in us-east-1a and 1 instance in us-east-1b","correct":false},{"id":"df38b78549933ce6cdce41ce65a061ba","text":"1 instance in us-east-1a and 1 instance in us-east-1b","correct":true},{"id":"205a5d33fbfbd8a66d4bbd686e7455b9","text":"3 instances in us-east-1a and 3 instances in us-east-1b","correct":false}]},{"id":"56a3a6cc-4c72-4b6c-a06c-4c310d107296","domain":"development","question":"An application successfully updates an existing object in S3. When checking the file contents, the developer does not see the updated file contents. What is the cause of this issue?","explanation":"Amazon S3 offers eventual consistency for overwrite PUTS and DELETES in all Regions. Amazon S3 provides high availability and high durability by replicating bucket objects across multiple availability zones and servers. This means that any updates to objects must replicate across all servers storing the data. This can take some time. Therefore, any updates to existing objects (using POST or DELETE), will take some time to be propagated across all of S3, and hence are eventually consistent.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Introduction to Amazon S3"}],"answers":[{"id":"4756256f32016be9d23caa16a75bb9c5","text":"HTTP 200 response code was not received.","correct":false},{"id":"47ad6c66cb5b231f66170a797fbb7782","text":"Overwrite PUTS in S3 have eventual consistency.","correct":true},{"id":"a693ecd0f4b5da724ee692d2059fc4c3","text":"S3 bucket policy permissions were not correct.","correct":false},{"id":"57d934f14c5f166d5f0604507d795cc0","text":"S3 Bucket Versioning was not enabled.","correct":false}]},{"id":"8b887631-86bd-436d-adee-4e2ba3b02111","domain":"security","question":"You have an application running on multiple EC2 instances, however every time an instance fails, your users complain that they lose their session. What can you do to prevent this from happening?","explanation":"There are various ways to manage user sessions including storing those sessions locally to the node responding to the HTTP request or designating a layer in your architecture which can store those sessions in a scalable and robust manner. Common approaches used include utilizing Sticky sessions or using a Distributed Cache for your session management. In order to address scalability and to provide a shared data storage for sessions that can be accessed from any individual web server, you can abstract the HTTP sessions from the web servers themselves. A common solution for this is to leverage an In-Memory Key/Value store such as ElastiCache.","links":[{"url":"https://aws.amazon.com/caching/session-management/","title":"Session management in AWS"}],"answers":[{"id":"b193b1caff1bda86125cc326ca1058ac","text":"Store session state on a dedicated EC2 instance","correct":false},{"id":"76fc6bddee6b0f8d088ea5cbe4e57160","text":"Store session state in S3","correct":false},{"id":"ef4fd36fa55c3c499f3fffa82a0c95e8","text":"Store session state in on the Elastic Load Balancer","correct":false},{"id":"89230492f141a4f85234c624287bb96a","text":"Store session state in ElastiCache","correct":true},{"id":"b225818943ba4680b8e7dc9d9c376359","text":"Store session state in RDS","correct":false}]},{"id":"a94b2c88-352b-4c39-83fc-7edfa8190fca","domain":"development","question":"Your application communicates using messages in an SQS queue. You have noticed recently that you are seeing a large number of empty responses where no messages exist in the queue. You want to make sure that your application is responsive as possible, but the cost of the solution is also a concern. What can you do to ensure your application is both cost-effective and responsive?","explanation":"In almost all cases, Amazon SQS long polling is preferable to short polling. Long-polling requests let your queue consumers receive messages as soon as they arrive in your queue while reducing the number of empty ReceiveMessageResponse instances returned. In general, you should use maximum 20 seconds for a long-poll timeout. Because higher long-poll timeout values reduce the number of empty ReceiveMessageResponse instances returned, try to set your long-poll timeout as high as possible.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"SQS FAQs"}],"answers":[{"id":"b2ccbf04a8f468dbcaad76b35f8f076b","text":"Configure multiple queues","correct":false},{"id":"cef7badd821b93647928923359f863e4","text":"Use a FIFO queue","correct":false},{"id":"66a35e1198bcce83d8654873aab562c6","text":"Configure multiple queues with short polling","correct":false},{"id":"f11916957f37c9cd171f126572d34864","text":"Use short polling","correct":false},{"id":"2247660601daf03d12f2fb4a1fccbf55","text":"Use long polling","correct":true}]},{"id":"46c2faa3-c022-4c5e-bb6b-fe84f70b3dc4","domain":"deployment","question":"Which of the following AWS services enables you to capture a time-ordered sequence of any modifications which happened to the items in your DynamoDB table over the past 24 hours?","explanation":"DynamoDB Streams captures a time-ordered sequence of item-level modifications in a DynamoDB table and durably stores the information for up to 24 hours.","links":[{"url":"https://aws.amazon.com/blogs/database/dynamodb-streams-use-cases-and-design-patterns/","title":"DynamoDB Streams Use Cases"}],"answers":[{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"52d5592ad24a2cda379ce38e9c218d65","text":"DynamoDB TTL","correct":false},{"id":"1f60690ba7c488a02416a7bf195f900b","text":"DynamoDB Streams","correct":true},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false}]},{"id":"f89a5f8e-ae8f-4ee6-842e-02f3101c7c60","domain":"development","question":"An application uses DynamoDB table as its backend data store. Each item has size of 10KB.  The application needs to perform 100 strongly consistent read operations per second, and 50 write operations per second.  What is the provisioned RCU value required to meet these requirements?","explanation":"1 RCU is equivalent to one strongly consistent read per second of an item up to 4KB in size.  Thus, to calculate the required RCU in this scenario we need to: 1) Round up the item size to the nearest 4KB (12KB). 2) Divide by 4KB to calculate number of strongly consistent read units (12/4 = 3). 3) Multiple by operations per second to get the total RCU required (3*100 = 300 RCU).","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.ProvisionedThroughput.Manual","title":"Provisioned Mode"}],"answers":[{"id":"a9b7ba70783b617e9998dc4dd82eb3c5","text":"1000","correct":false},{"id":"cee631121c2ec9232f3a2f028ad5c89b","text":"500","correct":false},{"id":"7ef605fc8dba5425d6965fbd4c8fbe1f","text":"150","correct":false},{"id":"94f6d7e04a4d452035300f18b984988c","text":"300","correct":true}]},{"id":"f956f10b-d615-4d75-a2a4-dd978268221b","domain":"deployment","question":"You are a developer running an application on AWS Elastic Beanstalk. You are implementing an application update and need to use a deployment policy. The requirements are to maintain full capacity, deploy five instances at once for the new version, and to terminate instances running the old version once the new instances are running successfully. How would you implement this deployment policy?","explanation":"To maintain full capacity during deployments, you can configure your environment to launch a new batch of instances before taking any instances out of service. This option is known as a rolling deployment with an additional batch. When the deployment completes, Elastic Beanstalk terminates the additional batch of instances. All at Once deployment takes the instances in your environment out of service for a short time. Rolling deployment also takes a batch of servers out of service while deploying the new version in batches. Blue/Green deployments are for cases when you want to have two versions live simultaneously and be able to swap between the two versions.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.rolling-version-deploy.html","title":"Deployment Policies and Settings"}],"answers":[{"id":"e693d0e841ddc0314ab81115baff0563","text":"Set the deployment policy as Rolling with Additional Batch. Set the batch size type as Fixed, and the batch size as 5.","correct":true},{"id":"ee833ae676b93a46ca5aafc9ce391102","text":"Set the deployment policy as Rolling. Set the batch size as 5.","correct":false},{"id":"da598c0ec61581331132eb0291fa30cd","text":"Set the deployment policy as Blue/Green. Set the timeout as 900, and the batch size as 5.","correct":false},{"id":"4a909b7335924524609c65e522fe581a","text":"Set the deployment policy as All at Once. Set the batch size type as Fixed, and the batch size as 5.","correct":false}]},{"id":"847e9972-b2da-4c6c-b5b5-74fde22cf193","domain":"refactoring","question":"Your application is storing a lot of data in an S3 bucket called mybucket and is routinely exceeding 100 requests per second using a mix of GET, PUT and DELETE operations. Which of the following naming strategies will ensure low latency performance with S3?","explanation":"Prior to July 2018, AWS recommendation was to use random keyname prefixes to ensure objects were stored on separate partitions in order to give the best performance for mixed workloads. Since July 2017 this is no longer necessary, however we expect the use of random key names to still be tested in the exam so it is still important to be aware of this approach.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","title":"Updated guidance on S3 performance - for reference"}],"answers":[{"id":"e327db1b1bbc74ad0be34391c8c54367","text":"mybucket/8761-2018-02-07-12-00-00/cust26347456/file1.txt","correct":true},{"id":"214a113d4fbf2063b6cbae4047f7e027","text":"mybucket/2018-02-07-12-00-00/cust26347456/8761file1.txt","correct":false},{"id":"a4df002d6a19b2b0edf9097af5315fce","text":"mybucket/customers/cust26347456/file1.txt","correct":false},{"id":"015205126ff1a0346b8753dbe82a2306","text":"mybucket/2018-02-07-12-00-00/cust26347456/file1.txt","correct":false}]},{"id":"e516825d-bec2-463c-9a64-63be7bc91509","domain":"refactoring","question":"You are developing a serverless application which runs on Lambda, DynamoDB and API Gateway. The application needs to support an average of 5,000 requests per second. During testing, the Test Team want to test for peaks of 2.5 x the average load (12,500 requests per second). Shortly after testing begins, your application crashes with API Gateway generating a 429 error code. What could be the reason for this?","explanation":"By default, API Gateway limits the steady-state request rate to 10,000 requests per second. The 429 error means that the application is generating too many requests and is being throttled.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html","title":"API Request Throttling"}],"answers":[{"id":"c44bbd8c68bc540a9f4ec1eb6aef1f14","text":"Your Lambda function has run out of memory, you need to increase CPU capacity in order to increase memory capacity","correct":false},{"id":"71cfc755a5cb85f74a6c94a83c5a102b","text":"Your Lambda function has run out of CPU, you need to increase the memory allocation in order to increase CPU capacity","correct":false},{"id":"e33a82eb6c47467dbddcc3cebfdd8dae","text":"Your tests have caused the application to hit the default limit of 10,000 requests per second for Lambda","correct":false},{"id":"998c50932ec426f49890c7568b789ab0","text":"Your tests have caused the application to hit the default limit of 10,000 requests per second for API Gateway","correct":true}]},{"id":"5cf3b6d4-9a0e-4602-8dab-26e687207049","domain":"development","question":"Which of the following platforms are supported in ElasticBeanstalk?","explanation":"Elastic beanstalk supports common platforms like including Tomcat, Passenger, Puma and Docker","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html","title":"Elastic Beanstalk Supported Platforms"}],"answers":[{"id":"8f72e28063c30c7468fb6af4653f4f9c","text":"Tomcat","correct":true},{"id":"7345f7045e4668138112c100f25517a4","text":"JBoss","correct":false},{"id":"c5fd214cdd0d2b3b4272e73b022ba5c2","text":"Docker","correct":true},{"id":"bf2528a296adb62d041a7519aa77f248","text":"Passenger","correct":true}]},{"id":"86b9ada2-ae5a-450b-8a69-88ffc0c65ee6","domain":"mon-trb","question":"A recent increase in the amount of users of an application hosted on an EC2 instance that you manage has caused the instances OS to run out of CPU resources and crash. The crash caused several users' unsaved data to be lost and your supervisor wants to know how this problem can be avoided in the future. Which of the following would you NOT recommend?","explanation":"Frequent snapshots are not recommended, as they can result in performance degradation. Additionally, these snapshots will not capture users' unsaved data that lives in the instance's memory.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"EBS Snapshots"}],"answers":[{"id":"e990838c77c787b8156a1101cebec36e","text":"Take frequent snapshots of the EBS volume during business hours to ensure users' data is backed up.","correct":true},{"id":"641a29c3ebde27a5fa880ae928ae6462","text":"Rewrite the application so that users' unsaved data is frequently written to disk.","correct":false},{"id":"65d5964c0293f901c37f0a8b00d46369","text":"Create an auto-scaling group to add more servers when demand is high.","correct":false},{"id":"02f0b48391d2df79b37ab3fe6fed3bbe","text":"Take a snapshot of the EBS volume and re-deploy as a larger instance type.","correct":false}]},{"id":"c73f812b-373b-4429-9a32-a3d71186c137","domain":"deployment","question":"Your application needs 100 strongly consistent reads on items that are 9KB in size every second. How many units of read capacity units should you provision?","explanation":"9KB rounds up to 12KB. 12KB/4KB=3 strongly consistent read capacity units each. 3*100=300 strongly consistent read capacity units.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html","title":"Throughput Capacity for Reads and Writes"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","title":"DDB - Read Consistency"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CapacityUnitCalculations.html","title":"Calculating CU"}],"answers":[{"id":"7ef605fc8dba5425d6965fbd4c8fbe1f","text":"150","correct":false},{"id":"94f6d7e04a4d452035300f18b984988c","text":"300","correct":true},{"id":"3644a684f98ea8fe223c713b77189a77","text":"200","correct":false},{"id":"9de6d14fff9806d4bcd1ef555be766cd","text":"350","correct":false}]},{"id":"60de4860-8791-4fd6-b3af-364209ceb5ab","domain":"mon-trb","question":"You are working on an application for an online training company which stores product data in DynamoDB. This week, the company is running a big promotion on a few courses and this is bringing lots of new traffic to your website, causing an increased number of queries to the database.  Database queries are now running much slower than usual and the Operations Team are concerned that the DynamoDB table is being throttled. Which of the following approaches would you recommend to improve read performance?","explanation":"Using DAX is the recommended approach to reducing response times for read-intensive applications, applications which read a small number of items frequently and also applications which perform repeated reads against a large set of data. Read Replicas are not a feature of DynamoDB. Configuring the application to use scans instead is not an efficient solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DAX.html","title":"DynamoDB DAX"}],"answers":[{"id":"1fdd30d4d2259438830cf9536f3da218","text":"Configure a DAX cluster and point the DynamoDB API calls at the DAX cluster","correct":true},{"id":"7d691dd8fcbce5a87b1211b09b47541a","text":"Add a Read Replica and point the DynamoDB API calls at the Read Replica","correct":false},{"id":"df31657d8e3247caf5b704d87a7fced3","text":"Redesign your table to use a more distinct partition key to enable the I/O load to be more evenly distributed across partitions","correct":false},{"id":"c9e5713b3f811b188f8770ffd016beaf","text":"Configure the application to use scans rather than queries and run multiple scans in parallel","correct":false}]},{"id":"72b0a4e6-82a6-4355-aa09-cf28563f00ed","domain":"development","question":"You are developing an online gaming application which needs to synchronize user profile data, preferences and game state across multiple mobile devices. Which of the following Cognito features enables you to do this?","explanation":"Amazon Cognito Sync is an AWS service and client library that enable cross-device syncing of application-related user data. You can use it to synchronize user profile data across mobile devices and web applications. The client libraries cache data locally so your app can read and write data regardless of device connectivity status. When the device is online, you can synchronize data, and if you set up push sync, notify other devices immediately that an update is available.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-sync.html","title":"Amazon Cognito Sync"},{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-cognito-sync.html","title":"Getting Started with Amazon Cognito Sync"}],"answers":[{"id":"0b422b4e655adc456bd9363c2dba938a","text":"Cognito Events","correct":true},{"id":"9a09b38e27134b81a45f7f2ed3939edc","text":"Cognito User Pools","correct":false},{"id":"67cb5d76e7fadc7e245c0cce89ad6dbf","text":"Cognito Sync","correct":true},{"id":"31aa670fdceaaf4289c74a1425e69d5b","text":"Cognito Streams","correct":false}]},{"id":"68ab8138-66fb-43fd-b5cc-c639875461b3","domain":"development","question":"You are developing an application in API Gateway, and need to categorize your APIs based on their status as: sandbox, test, or prod. You want to use a name-value pair system to label and manage your APIs. What feature of API Gateway would you use to accomplish this task?","explanation":"Stage variables are name-value pairs that you can define as configuration attributes associated with a deployment stage of a REST API. They act like environment variables and can be used in your API setup and mapping templates. With deployment stages in API Gateway, you can manage multiple release stages for each API, such as: alpha, beta, and production. Using stage variables you can configure an API deployment stage to interact with different backend endpoints. Environment variables apply to AWS Lambda. Canary release is a software development strategy in which a new version of an API (as well as other software) is deployed as a canary release for testing purposes, and the base version remains deployed as a production release for normal operations on the same stage. (This would be appropriate when your application is live and you'd want to reduce the risk inherent in a new software version release.) A tag is a metadata label that you assign or that AWS assigns to an AWS resource and would not impact the functionality of your APIs.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/stage-variables.html","title":"Set up Stage Variables for a REST API Deployment"}],"answers":[{"id":"728a86cd5cbdede9b11bece5753de3c0","text":"Use tags based on stages. The tag can be set directly on the stage of the API.","correct":false},{"id":"55420a5f29f3d3c0d5ebbdca81d18b74","text":"Use stage variables based on the API deployment stage to interact with different backend endpoints.","correct":true},{"id":"9c758b8244c31cda3eb63d52672989a0","text":"Use the API Gateway console to create a canary release deployment.","correct":false},{"id":"05e2467d5ea65bd259b0e9dd64cfe2f3","text":"Use environment variables based on the API deployment stage to interact with different backend endpoints.","correct":false}]},{"id":"36bd2e7a-adf7-4dae-ad6f-5e04d3ca873e","domain":"security","question":"You work for a large government agency which is conducting research for a top secret defense project. You are using SQS to handle messaging between components of a large, distributed application. You need to ensure that confidential data relating to your research is encrypted by the messaging system, which of the following services can you use to centrally manage your encryption keys?","explanation":"You can use a CMK to encrypt and decrypt up to 4 KB (4096 bytes) of data. Typically, you use CMKs to generate, encrypt, and decrypt the data keys that you use outside of AWS KMS to encrypt your data. This strategy is known as envelope encryption. CMKs are created in AWS KMS and never leave AWS KMS un-encrypted. To use or manage your CMK, you access them through AWS KMS.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys","title":"KMS Concepts"}],"answers":[{"id":"ea52c36203c5f99c3ce2442d531b1a22","text":"SSL","correct":false},{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":false},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"4a4df63c87b4f42081b846d9b9189984","text":"KMS","correct":true},{"id":"fa9c36d7e57eae51ce84cfd30a7346a3","text":"Systems Manager Parameter Store","correct":false}]},{"id":"9548796c-789c-42ea-9e90-3da3a9252c1b","domain":"security","question":"Your Security team have recently reviewed the security standards across your entire AWS environment. They have identified that a number of EC2 instances in your development environment have read and write access to an S3 bucket containing highly confidential production data. You have been asked to help investigate and suggest a way to remedy this. Which of the following can you use to find out what is going on so that you can suggest a solution?","explanation":"With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies attached to IAM users, groups, or roles in your AWS account. You can test which actions are allowed or denied by the selected policies for specific resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html","title":"Testing IAM Policies with the IAM Policy Simulator"}],"answers":[{"id":"17d9101067c49b2ec4b35087e24ce8eb","text":"Use the IAM Policy Simulator to identify which role or policy is granting access","correct":true},{"id":"58f20da8b31f9e9da2e5a374608338ef","text":"Use the CLI or console to check the public access permissions of the S3 bucket","correct":false},{"id":"5bc514eb754ea13140481ed2afc68d45","text":"Use the VPC flow logs to identify which EC2 instances are attempting to access the bucket","correct":false},{"id":"aac02aded2357ef60d7cc0b8f32df947","text":"Use CloudTrail and Athena to identify which role or policy is granting access","correct":false}]},{"id":"2689a73b-04ed-4719-9cdf-49c4ffe3eb17","domain":"deployment","question":"A developer is deploying a new application to ECS. The application requires permissions to send messages to an SQS queue. \n\nWhich role should the developer apply the policy to so that the application can access the SQS queue?","explanation":"The policy must be attached to the ECS Task's execution role to allow the application running in the container access SQS.","links":[{"url":"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html","title":"Amazon ECS Task Execution IAM Role"}],"answers":[{"id":"29aefbd6a89941ca26d2ef879d25237c","text":"The execution role attached to the ECS Task.","correct":true},{"id":"d89a15f255b7e5a2b6cfe8aa7d628173","text":"The execution role attached to the ECS Cluster.","correct":false},{"id":"2413a4993d7f9395b5ddf84bc7b51b62","text":"The execution role attached to the ECS Container.","correct":false},{"id":"2d64ba22b9f8e2998aed499099374359","text":"The execution role attached to the ECS Service.","correct":false}]},{"id":"1c37eac2-4401-11ea-b77f-2e728ce88125","domain":"security","question":"Which of the following protocols are used to set up secure connections to AWS CodeCommit repositories?","explanation":"AWS allows you to use either the HTTPS or the SSH protocol to connect to CodeCommit repositories. There’s no option to select HTTP or RDP connections.","links":[{"url":"https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up.html","title":"Setting Up for AWS CodeCommit"}],"answers":[{"id":"293c9ea246ff9985dc6f62a650f78986","text":"HTTP","correct":false},{"id":"765553e6c7ac8592c389acb9878a050a","text":"SSH","correct":true},{"id":"a66d0b3ece299ba53eafac86750cfb4a","text":"RDP","correct":false},{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":true}]},{"id":"52d02968-6d43-434e-8d41-eaa3d8e69b68","domain":"mon-trb","question":"You are trying to diagnose a performance problem with your serverless application, which uses Lambda, API Gateway, S3 and DynamoDB. Your DynamoDB table is performing well and you suspect that your Lambda function is taking too long to execute. Which of the following could you use to investigate the source of the issue?","explanation":"AWS X-Ray can be used to display a histogram showing the latency of your Lambda function. Latency is the amount of time between when a request starts and when it completes. API Gateway Integration Latency in the time between when API Gateway relays a request to the backend and when it receives a response from the backend. API Gateway Latency is the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Lambda Invocations Sum measures the number of times a function is invoked in response to an event or invocation API call.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html","title":"API Gateway CloudWatch Metrics"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-metrics.html","title":"Lambda CloudWatch Metrics"},{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"},{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-histograms.html","title":"Using Latency Histograms in the AWS X-Ray Console"}],"answers":[{"id":"a8d172dc1d7797b755f243837a74be36","text":"API Gateway Latency metric in CloudWatch","correct":false},{"id":"c464cce256f4ab986973ddae5e8fdf34","text":"Lambda Invocations Sum metric in CloudWatch","correct":false},{"id":"90099b94810e3f14b68c4739eb4c456c","text":"API Gateway Integration Latency metric in CloudWatch","correct":true},{"id":"3dc993924bceb799c7009d281aa91408","text":"AWS X-Ray","correct":true}]},{"id":"86524d3b-b3e8-46ca-97a2-e12d4edfabed","domain":"development","question":"Which of the following best describes Amazon ECS?","explanation":"ECS stands for Elastic Container Service: It manages running containers on your EC2 instances. It does not act as a scheduler and it is neither serverless nor software that you manage.","links":[{"url":"http://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html","title":"About Amazon ECS"}],"answers":[{"id":"d3958d5a87a697631979b920c68a9ae2","text":"The Elastic Container Service is a service that manages running Docker containers on a group of your EC2 instances.","correct":true},{"id":"a966ed9a7fc5f750acbbef6754f3ad57","text":"The Elastic Container Scheduler is a serverless system to manage running many Docker containers in a flexible and cost-effective way.","correct":false},{"id":"8180f2f15ee5ff1c554855a0352e23bf","text":"The Elastic Container Scheduler is software that you can run and manage to orchestrate many running Docker containers.","correct":false},{"id":"f0fbcb4f668b638f39ce41a6972d9a94","text":"The Elastic Container Service is software that you can run and manage to orchestrate many running Docker containers.","correct":false}]},{"id":"45bb762d-32a6-4fc7-a9e3-1377f0161979","domain":"security","question":"Which of the following activities are the responsibility of the customer?","explanation":"Security and Compliance is a shared responsibility between AWS and the customer. The customer assumes responsibility and management of the guest operating system (including updates and security patches), other associated application software as well as the configuration of the AWS-provided security group firewall. AWS is responsible for protecting the infrastructure that runs all of the services offered in the AWS Cloud. This infrastructure is composed of the hardware, software, networking, and facilities that run AWS Cloud services.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"AWS Shared Responsibility Model"}],"answers":[{"id":"a66d0f8d16b1d93bbe53e387d4b62b37","text":"Controls around who can physically access the data center","correct":false},{"id":"a505eb81276d69b88b77d5b605ad4a9a","text":"Safe disposal of storage devices","correct":false},{"id":"2b169fd2a3342cf14cd9fdfca94943c5","text":"Security Group configuration settings","correct":true},{"id":"e64e7c083b43e01c37b09547a9d7fa31","text":"Management of user credentials","correct":true},{"id":"24950338a19d0ddaa9b785b69709702f","text":"Encryption of sensitive data","correct":true}]},{"id":"870dde60-9a99-4f30-8d55-38e1210b0d43","domain":"security","question":"You are trying to use CodeDeploy to deploy the latest version of your application which is stored in S3. You are trying to deploy the code to a new EC2 instance for the very first time. However the deployment keeps failing with an IAM_ROLE_PERMISSIONS error. Other team members have been able to successfully run the deployment to other EC2 instances and you suspect that your instance may not have permission to access the code in the S3 bucket. Which of the following can you use to test whether the instance role allows your EC2 instance to get the code from S3?","explanation":"With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies attached to IAM users, groups, or roles in your AWS account. You can test which actions are allowed or denied by the selected policies for specific resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html","title":"Testing IAM Policies with the IAM Policy Simulator"}],"answers":[{"id":"b165b6ec45a2a25d8d218f6f03383a30","text":"Use the console to check the public access permission on the S3 bucket and enable it if is set to false","correct":false},{"id":"45e2014a81f5345a25e46e1cadc42450","text":"Use the IAM Policy Simulator test whether the instance role allows access","correct":true},{"id":"062324ad112d3df43caf83238dda051b","text":"Check the IAM logs to see whether the instance role allows access","correct":false},{"id":"5895d9b1a65074025b856fa95f5df0a5","text":"Use Trusted Advisor to check whether the instance role allows access","correct":false}]},{"id":"86c22858-5cf0-4a67-b1c5-54d1de3ca2da","domain":"refactoring","question":"You store a new object in Amazon S3 and receive a confirmation that it has been successfully stored. You then immediately make another API call attempting to read this object. Will you be able to read this object immediately?","explanation":"Amazon S3 buckets in all Regions provide read-after-write consistency for PUTS of new objects and eventual consistency for overwrite PUTS and DELETES.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel","title":"Amazon S3 Data Consistency Model"}],"answers":[{"id":"8596049a57e596b85941153836ade663","text":"Yes, unless you exceed API call limits.","correct":false},{"id":"9093951ee8a45059ab694f2f97f8d00a","text":"Yes. S3 has read-after-write consistency, which means you will have access to the object immediately.","correct":true},{"id":"07fc991ba9f0a91e26627f8af0c332ac","text":"No. S3 imposes a one second delay on all reads.","correct":false},{"id":"3ac4811c4441245d5a9b35dec13054fd","text":"It depends, because S3 objects are not available until they have replicated to another region. This replication can take up to several seconds.","correct":false}]},{"id":"03ea5729-a486-470f-8cf7-a006c62c2045","domain":"deployment","question":"You have been asked to run your in-house application code using Lambda. Which of the following services could you use to deploy your code?","explanation":"You cannot deploy code using CodeCommit or CodeBuild. All of the other services can be used to deploy code in a Serverless environment","links":[{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/deploying-aws-lambda-functions-using-aws-cloudformation-the-portable-way/","title":"Deploying Lambda Functions Using CloudFormation"},{"url":"https://aws.amazon.com/blogs/compute/implementing-safe-aws-lambda-deployments-with-aws-codedeploy/","title":"Deploying Lambda Functions Using CodeDeploy"},{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"AWS SAM"}],"answers":[{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"2565605f16beacf2f11c0ac6e7510e80","text":"AWS Serverless Application Model","correct":true},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":true},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"56c20df941e069e1a35a1871f662298a","text":"CodeCommit","correct":false}]},{"id":"32c62228-3eab-45da-8f39-58fad0f1b614","domain":"refactoring","question":"You are building an application that requires an Auto Scaling group in order to scale in and out based on demand. You have the proper IAM permissions to create an Auto Scaling group, and also to create EC2 resources for the instances. What additional requirements are necessary for you to move forward?","explanation":"When you create an Auto Scaling group, you must specify the necessary information to configure the Amazon EC2 instances, the subnets for the instances, and the initial number of instances. Before you can create an Auto Scaling group using a launch template, you must create a launch template that includes the parameters required to launch an EC2 instance, such as the Amazon Machine Image (AMI) ID and an instance type. Key pairs and instance roles are optional configuration settings when creating the launch template. You do not have to create a security group beforehand as AWS will provide a default security group. Lifecycle hooks enable you to perform custom actions by pausing instances as an Auto Scaling group launches or terminates them. These are optional configurations that can be attached to an Auto Scaling policy.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-launch-template.html","title":"Creating an Auto Scaling Group Using a Launch Template"}],"answers":[{"id":"751a4eab03ae6623d345ab81ca8518ff","text":"Create a launch template with the required Amazon Machine Image (AMI) content.","correct":true},{"id":"f5818eb3488ca8de4b28fd00844c91ab","text":"Specify a lifecycle hook to perform actions as the Auto Scaling group launches or terminates instances.","correct":false},{"id":"3f28a4f490092b9940ca1ee7b2395d69","text":"Create a launch template with the key pair and instance role template contents.","correct":false},{"id":"abc589d96f375d4ec6b80da2495c01f3","text":"Create a security group first and select the appropriate security group under network settings.","correct":false}]},{"id":"d91b5d09-a238-441f-b247-d81789372ec1","domain":"development","question":"GetItem operation is used to read data from a DynamoDB table. What strategy can be used to reduce the size of the read operations and increase read efficiency?","explanation":"Projection Expressions are a DynamoDB feature used to limit the attributes returned by the GetItem operation. Thus, this can be used to reduce the size of the payload returned by a read operation. Parallel Scans allows multi-threaded applications to perform DynamoDB Scan operations quicker. It cannot be used with GetItem operations to make them more efficient. Pagination allows developer to perform a Scan operation on a table and divide the result set into multiple pages. It cannot be used to make GetItem operations more efficient. Filter expression can be used with Scan operations to filter the results returned by the scan operation. It is not a GetItem operation feature.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ProjectionExpressions.html","title":"Projection Expressions"}],"answers":[{"id":"ba803153fcb13208c9f26c6ae0dedef6","text":"Use Filter Expression.","correct":false},{"id":"30eb0435ad1702227f2d730850a75e93","text":"Use Pagination.","correct":false},{"id":"5081ca486a2f5aed471c714c6d81489f","text":"Use Parallel Scan.","correct":false},{"id":"e37aefa5950be4eef211c98b18690f64","text":"Use Projection Expression.","correct":true}]},{"id":"c1362509-8ba6-4411-80d7-a3dfff7b1c29","domain":"mon-trb","question":"As you retrieve information from DynamoDB, you receive a ProvisionedThroughputExceededException error. Further investigation shows that you're not exceeding your table's read capacity throughput. What is causing this error?","explanation":"DynamoDB distributes capacity evenly across all available partitions. If a given partition is consuming more than its share of throughput, this error will be raised.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html","title":"ProvisionedThroughputExceededException"}],"answers":[{"id":"d1b67149a21e4fba2199fd83ca4b3a86","text":"You are exceeding an individual partition's throughput capacity, even if you're not exceeding the overall table throughput capacity.","correct":true},{"id":"7bee1d9584711c70ca477468c92d24d4","text":"AWS metrics do not run in real time. This error will disappear.","correct":false},{"id":"2151c5ca19006af967ad87fd46b71782","text":"You have too many sort keys on your table.","correct":false},{"id":"d133230e1647cdbd9c08bcbe4c2148eb","text":"The table is warming up and this process consumes throughput.","correct":false}]}]}}}}
