{"data":{"createNewExamAttempt":{"attempt":{"id":"3658d041-4a65-4785-ae1f-58d22298f3ec"},"exam":{"id":"f3dffe0b-b4a2-4be5-a2c8-27f9b6c357a8","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"eba390fe-7699-47c0-b51f-f38cbc948112","domain":"CostOptimized","question":"What is the 'first-byte' latency when retrieving data from Glacier?","explanation":"You should expect data retrieval latency of 3-5 hours when retrieving data from Glacier.","links":[{"url":"https://aws.amazon.com/glacier/faqs/#dataretrievalpolicies","title":"Glacier Data Retrieval Policies"}],"answers":[{"id":"72ab9d0304d3e84c6aa2dd15eda282f2","text":"1 hour","correct":false},{"id":"99d888e6893ac480abd21ecb8a18e060","text":"3-5 hours","correct":true},{"id":"6619a70f8ab8877e4131643fb8ded723","text":"2 hours","correct":false},{"id":"b86a4270946442f3b17bd51e3aa226ce","text":"> 5 hours","correct":false}]},{"id":"63ff2802-fc45-48b3-87db-08fc452b9597","domain":"Performant","question":"Your project manager (PM) tasked you with launching two Amazon EC2 instances for an issue-tracking application. One of them will serve as the proxy server, which will act as an intermediary for requests by users seeking access to the application installed on the other EC2 instance. The PM expects the instance for the proxy server to be a balance of compute, memory, and network resources, with low-to-moderate network performance. Which of the following instance types would be appropriate to use?","explanation":"c5.large and r5.xlarge do not provide a balance of compute, memory, and network resources, since the former is a compute-optimized instance type and the latter is memory-optimized. That leaves t2.2xlarge and t2.medium. t2.medium does specifically fulfill the low-to-moderate network performance range that the PM requested. However, since t2.2xlarge offers moderate network performance, in addition to twice the number of vCPUs and four times the RAM, you can choose this instance type instead to avoid having to scale vertically in the future if you believe you need greater capability. Ultimately, either t2.2xlarge or t2.medium would do.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"Amazon EC2 Instance Types"},{"url":"https://d1.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf","title":"Architecting for the Cloud"}],"answers":[{"id":"d6c756c3ad88241444ff9f5d58543014","text":"c5.large","correct":false},{"id":"e1369dc9aee5f7165363f55d10884546","text":"r5.xlarge","correct":false},{"id":"c7ea994d704bd3dd12d0c3ff5ef94f9b","text":"t2.medium","correct":true},{"id":"12ad1d1ee6b663a9a67f50e3cfbd9673","text":"t2.2xlarge","correct":true}]},{"id":"66262de0-506e-4e56-901b-e49a60aa0c6d","domain":"ResilientDesign","question":"You are testing an application that uses EC2 instances to poll an SQS queue. At this stage of testing, you have verified that the EC2 instances can retrieve messages from the queue, but your coworkers are complaining about not being able to manually retrieve any messages from the queue from their on-premises workstations. What is the most likely source of this problem?","explanation":"Short polling may fail to retrieve messages sometimes, but if no messages can be retrieved after multiple attempts, permissions are the more likely cause.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-authentication-and-access-control.html","title":"Authentication and Access Control for Amazon SQS"}],"answers":[{"id":"6536a818dab64143ae0178e357e5e841","text":"Your coworkers do not have permission to access the SQS queue.","correct":true},{"id":"d16cb376900ea9c06c68759d668824d1","text":"It's not possible to poll an SQS queue manually.","correct":false},{"id":"574a8d560b8f2dd210703546008b8c64","text":"SQS queues accept traffic only from within AWS.","correct":false},{"id":"38672a9de56ddbc170a51a046d074146","text":"Short polling is occasionally leaving messages behind.","correct":false}]},{"id":"2a66405e-baf4-44b2-9f82-1473bc4fac96","domain":"SecureSolutions","question":"You've been tasked with migrating an on-premise application architecture to AWS. During the design process, you give consideration to current on-premise security and identify the security attributes you are responsible for on AWS. Which of the following does AWS provide for you as part of the shared responsibility model?","explanation":"Understanding the AWS Shared Responsibility Model will help you answer quite a few exam questions by recognizing false answers very quickly.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"The Shared Responsibility Model"}],"answers":[{"id":"ec260804fcc18ef10e22772f4401253d","text":"Physical network infrastructure","correct":true},{"id":"dd4ec43803918fe3ee9d6c3e8482c1df","text":"User access to the AWS environment","correct":false},{"id":"6de1fb3029549fbd94d79415e8036810","text":"Instance security","correct":false},{"id":"9f437974a72e2dafff526fad12c4c925","text":"Virtualization Infrastructure","correct":true}]},{"id":"54f49b19-525b-42bc-956a-c02a709ea575","domain":"Performant","question":"A political consulting group wants to monitor Twitter tweets from all candidates in an election to assess campaign statements and positions on current issues. They'll implement calls to the Twitter API from a Python script on an EC2 instance to get the tweets, and they'll use Amazon QuickSight to visualize the data. They anticipate that as the election approaches, tweet volume will increase dramatically. Which architecture will provide the scalability they need in the most cost effective way?","explanation":"Using Kinesis Streams to batch the tweets for the Lambda consumer function helps orchestrate the process of invoking Comprehend on a specific set of tweets. If the data is written directly to S3 via Kinesis Firehose PutRecord calls without some batching of the tweets, Comprehend will scan the same data multiple times. Comprehend currently does not support DynamoDB as a data source. Comprehend is a natural language processing service and doesn't require the data to be pre-formatted.","links":[{"url":"https://aws.amazon.com/kinesis/","title":"Amazon Kinesis"},{"url":"https://aws.amazon.com/comprehend/","title":"Amazon Comprehend"},{"url":"https://github.com/aws-samples/lambda-refarch-streamprocessing","title":"Serverless Reference Architecture: Real-time Stream Processing"}],"answers":[{"id":"60a15003c784ca46eb2291738f62038a","text":"Have the Python script write the tweets to an Amazon Kinesis Streams stream. Configure a Lambda function as the consumer of the stream. Have the Lambda function write the data to Amazon DynamoDB. Invoke Amazon Comprehend from the Lambda function to assess sentiment in the tweets and write the results back to DynamoDB","correct":false},{"id":"2447562bf64c3157516a40a083254449","text":"Have the Python script write the tweets to an Amazon Kinesis Firehose stream with PutRecord API calls. Configure the stream to write the data to Amazon S3. Trigger a Lambda function to invoke Amazon Comprehend to assess sentiment in the tweets and write the results back to S3","correct":false},{"id":"29db045869ea4a45b00a8df4819dc756","text":"Have the Python script write the tweets to an Amazon Kinesis Streams stream. Configure a Lambda function as the consumer of the stream which receives tweets in batches. Have the Lambda function write the data to Amazon S3. Have the Lambda function also invoke Amazon Comprehend to assess sentiment in the batch and write the results back to S3","correct":true},{"id":"4e077d33575cabb8babd3a56c3f77d32","text":"Have the Python script write the tweets to an Amazon Kinesis Firehose stream with PutRecordBatch API calls. Configure the stream to write the data to Amazon S3. Trigger a Lambda function to put the data into a standard format, and then invoke Amazon Comprehend to assess sentiment in the tweets. Write the results back to S3","correct":false}]},{"id":"ac8f79d2-72d6-4dcb-84c7-2ec0b61e48ca","domain":"Performant","question":"Power plant technicians at an electrical utility need to monitor equipment heat readings in real-time on their mobile devices. They would like to be able to see changing temperature values without refreshing the device's screen. Temperature sensors have already been installed on the equipment, and they've connected the sensors to AWS IoT Core. A mobile app has been developed in React Native to receive the temperature updates. An additional twenty percent more equipment will be installed at the plant over the next year. Which architecture will provide the most scalable solution for the utility?","explanation":"An AWS AppSync GraphQL update mutation will update a sensor's record in DynamoDB and broadcast updated data to mobile device clients. A Lambda function can initiate a connection to an AppSync GraphQL API endpoint. Each component of this architecture is a managed service that will scale with the power plant's growth plans. AWS Mobile Hub is used for building mobile applications, not for broadcasting messages to mobile devices. DynamoDB and Mobile Hub are not valid consumers of a Kinesis Data Streams stream. Amazon Pinpoint is used to send personalized communications, not forward data updates to mobile devices.","links":[{"url":"https://aws.amazon.com/appsync/","title":"AWS AppSync"},{"url":"https://aws.amazon.com/blogs/mobile/iot-with-aws-appsync/","title":"Monitoring IoT devices in real time with AWS AppSync"}],"answers":[{"id":"436ea268a30690aa25516a2df81f12f6","text":"Create an AWS IoT rule to forward messages to an Amazon Simple Queue Service queue. Have an EC2 instance read the queue and write the messages to DynamoDB, and forward the data to Amazon Pinpoint to broadcast the changed data to mobile device users.","correct":false},{"id":"fe256ea9199399aa63a19f558746acda","text":"Implement an AWS IoT rule to forward messages to a Lambda function. Have the Lambda function execute an AWS AppSync GraphQL mutation to write updates to Amazon DynamoDB and broadcast changed data to mobile device users.","correct":true},{"id":"0fea673c8089e1f7d3a591bdaa3af824","text":"Configure an AWS IoT rule to forward messages to a Lambda function. Have the Lambda function write the messages to DynamoDB, and to AWS Mobile Hub, which broadcasts the changed data to mobile device users.","correct":false},{"id":"f3d62c495d620412d9f919ff6f58fafc","text":"Have an AWS IoT rule forward messages to an Amazon Kinesis Data Streams stream. Create one consumer of the stream to be Amazon DynamoDB. Create a second consumer of the stream to be AWS Mobile Hub, which broadcasts the changed data to mobile device users.","correct":false}]},{"id":"596626b1-f08c-4afb-a723-39c8abf31af5","domain":"ResilientDesign","question":"An EC2 instance retrieves a message from an SQS queue, begins processing the message, then crashes. What happens to the message?","explanation":"When the message visibility timeout expires, the message becomes available for processing by other EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html","title":"SQS Visibility Timeout"}],"answers":[{"id":"b7b87efcf5ef61b425d9a60bc33efe62","text":"When the message visibility timeout expires, the message becomes available for processing by other EC2 instances.","correct":true},{"id":"82e027481e331aba93999ce96b1af424","text":"To prevent corruption, the message is deleted.","correct":false},{"id":"77d789cecbe676c6c677cc6cd389b99a","text":"When the message timeout expires, the message is duplicated, the original message is archived, and the duplicate becomes available for processing.","correct":false},{"id":"d69db62ea1f468c166c785ced48037ba","text":"It remains in the queue in a locked state until the EC2 instance comes back online.","correct":false}]},{"id":"2d66a68a-db0b-46af-93f2-8fbb712d7f8d","domain":"ResilientDesign","question":"Which of the following are the application integration services enable communication between decoupled components in order to build a scalable and more resilient solution?","explanation":"Amazon SQS, Amazon MQ and Amazon App Sync are AWS application integration services. Application integration services enable communication between decoupled components within micro-services, distributed systems, and serverless applications so you can easily build scalable and more resilient solutions. Amazon DataSync is AWS Migration and Transfer service and is not an integration service. AWS SES is a cloud-based email sending service designed for customer engagement.","links":[{"url":"https://aws.amazon.com/products/application-integration/?nc2=h_m1","title":"AWS Application Integration Services"}],"answers":[{"id":"71f398f7b21d60364b4a577a13a1271f","text":"Amazon Data Sync","correct":false},{"id":"b65c2d4cd3e247c1554f92a08e6ea48b","text":"Amazon App Sync","correct":true},{"id":"335523617c1b39d5772d3e75b7da2014","text":"AWS Simple Email Service (SES)","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true},{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":true}]},{"id":"aaff9d18-ee89-4f46-8b06-36cacf10c72d","domain":"SecureSolutions","question":"A regional telecommunications company requires that applications be isolated from each other on their AWS cloud network in order to minimize the impact of a security issue in any one of the applications. The applications must be able to exchange data with each other, and they need to be able to communicate with two company-owned data centers. Which architecture will accomplish these requirements in the most secure and operationally efficient way?","explanation":"Direct Connect offers greater security than a VPN because it doesn’t involve an Internet connection. Creating separate VPCs provides greater isolation and greater operational efficiency because Network ACL firewall rules don’t need to be maintained every time the characteristics of application-to-application communication change.","links":[{"url":"https://aws.amazon.com/answers/networking/aws-single-region-multi-vpc-connectivity/","title":"Single Region Multi-VPC Connectivity"}],"answers":[{"id":"d8d115b0f357da698c35adf6751c3468","text":"Place each application in separate subnets in a single VPC and lock down Network ACL rules on each subnet. Use IPSec VPNs from this same VPC to the company-owned data centers","correct":false},{"id":"a89251b806fbe05bdcf7d40074d812cc","text":"Place each application in separate subnets in a single VPC and lock down Network ACL rules on each subnet. Use Direct Connect from this same VPC to the company-owned data centers","correct":false},{"id":"ddad117753774711835e99bfacdb8c83","text":"Create individual VPCs for each application with peering connections between them. Create a shared VPC with Direct Connect to the company-owned data centers","correct":true},{"id":"03f6fa016703ef26250435d21e5558d8","text":"Create individual VPCs for each application with peering connections between them. Create a shared VPC with IPSec VPNs to the company-owned data centers","correct":false}]},{"id":"cbcc2938-15ec-4a2f-bb94-1fefe41f3efe","domain":"Performant","question":"You have an RDS database that has high performance OLTP workloads. Which storage medium would be best to accommodate these requirements?","explanation":"Amazon RDS Provisioned IOPS (SSD) Storage would be the most suitable.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS","title":"RDS Provisioned IOPS for OLTP Workloads"}],"answers":[{"id":"4d548ff7278077c929b63c67f768cc97","text":"Amazon RDS Provisioned IOPS (SSD) Storage","correct":true},{"id":"a257df0abf37db5da9b921f8222eab2a","text":"Amazon RDS General Purpose (SSD) Storage","correct":false},{"id":"e774a96af9adfaa2402148c9828271e7","text":"Amazon RDS Magnetic Storage","correct":false},{"id":"0db6de47eed9671e44098c2117fe8916","text":"Amazon RDS Cold Storage","correct":false}]},{"id":"adbe2585-a484-493a-bec9-ed54d0ff4672","domain":"SecureSolutions","question":"You have a website that contains public content and member-only content. These are being served from 2 different auto-scaling EC2 instance groups, one for members and one for non-members. Once a member logs in, they are re-directed to a \"members.myawesomesite.com\" URL. You would like to put a single load balancer in front of both groups to direct users as appropriate - how would you design this?","explanation":"Both the network load balancer and classic load balancer do not support layer-7, and therefore cannot help route based on the hostname. Although having 2 load balancers and using R53 would work, the scenario asks for 1 if possible - and this is possible using an application load balancer as these operate at Level 7","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/","title":"Elastic Load Balancing features"}],"answers":[{"id":"8ab4d2b861c5ab884c9ef4cbdebe221a","text":"It is not possible to have multiple auto-scaling groups attached to one load balancer, so 2 load balancers will we required, then use R53 to point to the appropriate load balancer based on URL.","correct":false},{"id":"bae789245cb0d3f5b010dd39d2af14bb","text":"Use a classic load balancer with URL based routing configured","correct":false},{"id":"f3551559eb91b2d8b762d7c8fd38a725","text":"Use a network load balancer with domain-based routing enabled","correct":false},{"id":"18e6dd30c5604d6a1b97f7f9fd9b21f3","text":"Use an application load balancer with host-based routing configured","correct":true}]},{"id":"42cc5ed7-0d57-429c-973a-79cb287f6a1e","domain":"Performant","question":"You have an extremely high performance compute application that you need to deploy to AWS. You will need extremely low-latency network performance to allow node-to-node communication between your EC2 instances. You will also need a minimum network speed of 10 Gbps in order for your application to work. How should you deploy your instances?","explanation":"Amazon EC2 cluster placement group functionality allows users to group Cluster Compute Instances in clusters – allowing applications to get the low-latency network performance necessary for tightly-coupled node-to-node communication typical of many HPC applications.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"About Placement Groups"}],"answers":[{"id":"414edd18dd54c2a37e611231a1476dc1","text":"By using CloudFront to cache static assets so as to increase performance","correct":false},{"id":"02aadc5ab6e7cd4f88243caf5bf9fe9b","text":"Using a private VPC","correct":false},{"id":"49b8db049be133de9f86118999a12827","text":"By creating a cluster placement group","correct":true},{"id":"0994949ea896595c07d97ddc73598ca5","text":"By deploying in multiple availability zones","correct":false}]},{"id":"db72323e-0c43-4542-9f6b-cd6136b5dcd8","domain":"ResilientDesign","question":"You have a production website for a car insurance company running on AWS. One of the important KPI’s for the company is the number of users on the website at any given time and you have been asked to track this. The website runs on a fleet of EC2 instances behind an application load balancer. What is the simplest way to track this metric.","explanation":"Be clear in yor own mind about the difference between CloudWatch & CloudTrail. An ELB is a service, you cannot install anything onto an ELB.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-cloudwatch-metrics.html","title":"CloudWatch Metrics for your ALB"}],"answers":[{"id":"0ea85fc826488c41b0f86072ac7fd0ad","text":"Install the CloudTrail agent on the Application Load Balancer. In CloudTrail look for the “ActiveConnectionCount” metric.","correct":false},{"id":"1056f30813bb025d216b87a2fdd790d9","text":"Enable CloudTrail in the region that your ALB is in. Using CloudTrail metrics look for the “ActiveConnectionCount” metric.","correct":false},{"id":"98c71b3c230ff081ea967bf92fad4707","text":"In CloudWatch metrics look for the “ActiveConnectionCount”","correct":true},{"id":"dd97365a376f41ec276427520159fbd4","text":"Install the CloudWatch agent on the Application Load Balancer. After the agent is installed, look for the “ActiveConnectionCount” in CloudWatch.","correct":false}]},{"id":"f1bfb201-fad6-40da-be6b-b33d27d1f838","domain":"CostOptimized","question":"You work for a genetics company that has extremely large datasets stored in S3. You need to minimize storage costs without introducing unnecessary risk or delay.  Mandated restore times depend on the age of the data. Data 30-59 days old must be available immediately without delay, and data more than 60 days old must be available within 12 hours. Which of the following options below should you consider?","explanation":"You should use S3 - IA for the data that needs to be accessed immediately, and you should use Glacier for the data that must be recovered within 12 hours. RRS and 1Zone-IA would not be suitable solution for irreplaceable data or data that required immediate access (each introduces reduced Durability or Availability), and CloudFront is a CDN service, not a storage solution.","links":[{"url":"https://aws.amazon.com/s3/faqs/#sia","title":"S3 - Infrequent Access"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html","title":"Comparing the Amazon S3 Storage Classes"},{"url":"https://aws.amazon.com/s3/faqs/#glacier","title":"About Glacier"}],"answers":[{"id":"e9a5105fa288ef2b71c037e42d665d91","text":"S3 - OneZone-IA","correct":false},{"id":"4340570ba672bfa48cd45e3f026c01d1","text":"S3 - IA","correct":true},{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":true},{"id":"31e831ec49678aed7f467f791d1f8704","text":"S3 - RRS","correct":false}]},{"id":"7ff46f0c-2e05-11ea-8a91-2e728ce88125","domain":"Performant","question":"You wish to exclusively use AWS services to buy a domain name and create a static website. Which of the following combinations will enable you to do so?","explanation":"You use Route 53 to register your domain and configure it so that Internet traffic is routed to your designated target. The target can be Amazon S3, where you can create a bucket, upload the HTML file that will function as the static website, configure the permissions for everyone to see the content, and configure the bucket for website hosting. Route 53 is missing from the other three choices; this omission makes these responses wrong.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html#root-domain-walkthrough-update-ns-record","title":"Setting Up a Static Website Using a Custom Domain"}],"answers":[{"id":"a119836cf024ddc24285f609454cf7bf","text":"Amazon Route 53 and Simple Storage Service (S3)","correct":true},{"id":"28968cd50e98048b344f0d7bd4fd54e6","text":"Amazon Virtual Private Cloud (VPC) and Relational Database Service (RDS)","correct":false},{"id":"8399383b83ea44cd15f0f7f7f8d1fe6b","text":"Amazon API Gateway and Elastic Compute Cloud (EC2)","correct":false},{"id":"c3794257c21696f8d06348f26e2b81a9","text":"Amazon Lambda and Elastic File Service (EFS)","correct":false}]},{"id":"9ac6fef3-785c-4655-a261-4e04f106fd58","domain":"ResilientDesign","question":"Your application has a global user base, and in order to improve user experience you have deployed an instance in both the us-east-1 and eu-central-1 regions. Which routing policy would you use to ensure users get the best experience possible?","explanation":"Latency Based routing will use data on the latency between the users' location and the location of your services in AWS to return the address which has the lowest latency for the user that will result in an improved user experience. Although Geolocation or Geoproximity could be used to route users to instances closest to them, latency will change over time with changes to network connectivity and routing over the internet, and the closest location may not be the one with least latency. Weighted routing will not help in this scenario.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"cd88dcd797ede7375ca4f73d841fb6ca","text":"Geolocation Routing","correct":false},{"id":"bd2b592da6667c27766101b6983ce1ad","text":"Geoproximity Routing","correct":false},{"id":"77e6d59cd5033b8199d2472da9ed05c9","text":"Weighted Routing","correct":false},{"id":"2698e08f63eed21d0ba0f3889c42f1cf","text":"Latency-based Routing","correct":true}]},{"id":"2aad5b9a-23aa-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"As a Solutions Architect helping to develop and add an unabated stream of web applications, you worry that the company’s cloud architecture is increasingly getting more complicated, making it difficult to track the applications’ performance. Which AWS service checks how applications are performing and helps to identify and resolve issues?","explanation":"AWS Trusted Advisor is for optimizing the cloud environment and does not specifically address applications. Although AWS CloudWatch monitors applications and can direct you to issues with them, it does not fix errors. And Amazon Inspector is a security assessor, not an application performance tracker. Only AWS X-Ray helps to optimize the performance of applications by identifying and fixing their issues.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html","title":"What is AWS X-Ray?"}],"answers":[{"id":"543096643aa6d28d9fac278e9257783d","text":"Amazon Inspector","correct":false},{"id":"3dc993924bceb799c7009d281aa91408","text":"AWS X-Ray","correct":true},{"id":"5714e9332e476d05d9a1763a1b10be50","text":"AWS CloudWatch","correct":false},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":false}]},{"id":"18f5f9ac-72ae-44e6-a607-875acd4b7508","domain":"CostOptimized","question":"Your company is moving their entire 20 TB data warehouse to the cloud. With your current bandwidth, it would take 2 months to transfer the data. Which service would you use to quickly get your data into AWS?","explanation":"At that amount of data and those bandwidth restrictions, Snowball would be the most expedient choice.","links":[{"url":"https://aws.amazon.com/snowball/faqs/#when-to-use","title":"When to Use Snowball"}],"answers":[{"id":"25e163616bb5cc20c769ad3e8b7a0703","text":"Multipart Upload","correct":false},{"id":"cdd0d04de2b79c78e792aec6263d2d3d","text":"DirectConnect","correct":false},{"id":"a8e1dc43989241e706e31c52d23be15c","text":"S3 with Transfer Acceleration","correct":false},{"id":"c0429b6a658dd488f7262d983c7e02bb","text":"Snowball","correct":true}]},{"id":"69e2d5c3-0b46-43b6-b5d5-cf1021256e41","domain":"SecureSolutions","question":"Meridian Media Services is migrating their customer facing online applications to AWS. They've experienced revenue impacting DDoS attacks in the past and would like to mitigate that risk going forward. They have both in-house developed and COTS applications that will run on EC2. CloudFront will be used for content delivery. Which security services should they implement to reduce the risk of DDoS interruptions?","explanation":"AWS Shield is a managed DDoS protection service that safeguards applications running on AWS. AWS Shield Standard provides comprehensive availability protection for CloudFront and Route 53, and AWS Shield Advanced gives higher levels of protection for EC2, ELB, and other AWS services.","links":[{"url":"https://aws.amazon.com/shield/","title":"AWS Shield"}],"answers":[{"id":"e34a57da0c06cbb3d1f5743459c20306","text":"Use the standard version of Amazon GuardDuty at no fee to protect CloudFront. Implement Amazon GuardDuty Advanced for a fee to protect the EC2 instances.","correct":false},{"id":"62879f82a5496e13612fab26735c4e32","text":"Rely on the standard version of AWS Shield to protect both CloudFront and the EC2 instances as they are both included at no fee.","correct":false},{"id":"10bfd36d94ade6e61b462d7c05c3065a","text":"Apply the standard version of Amazon GuardDuty to protect both CloudFront and the EC2 instances as they are both included for a small fee.","correct":false},{"id":"4506e0fedb041a54663245c51aa25e81","text":"Leverage the standard version of AWS Shield at no fee to protect CloudFront. Deploy AWS Shield Advanced for a fee to protect the EC2 instances.","correct":true}]},{"id":"491201a9-371b-4123-ae89-1419f3804be4","domain":"ResilientDesign","question":"You work for a large insurance company that has issued 10,000 insurance policies. These policies are stored as PDFs. You need these policies to be highly available, and company policy says that the data must be able to survive the simultaneous loss of two facilities. What storage solution should you use?","explanation":"Your best solution would be to use S3, which redundantly stores multiple copies of your data in multiple facilities and on multiple devices within each facility.","links":[{"url":"https://aws.amazon.com/s3/faqs/#Where_is_my_data_stored","title":"S3 - Storage Across Multiple Facilities"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"248c1b0bcb74394beb4a08030c4a6847","text":"EBS","correct":false},{"id":"1975c42630e9441aaabe6b700afc92d5","text":"A single EC2 instance with an EBS volume provisioned as a secondary volume.","correct":false}]},{"id":"85006d63-82b7-45dc-88c6-0baddad33725","domain":"ResilientDesign","question":"Which of the following is true with regards to a private IP address of an EC2 instance?","explanation":"Multiple IP addresses (IPv4 or IPv6) can be specified for an Instance depending upon Instance Types. Multiple IP addresses can be assigned and unassigned to network interfaces attached to running or stopped instances. An instance receives a static private IPv4 address from the address range within a VPC. Private IP address remains associated with the Network Interface when the instance is stopped and restarted, and is released when the instance is terminated. A secondary private IPv4 address can be assigned to any network interface. The network interface need not be attached to the instance. A secondary private IPv4 address that is assigned to a network interface can be reassigned to another one if you explicitly allow it. Although the primary network interface cannot be detached from an instance, the secondary private IPv4 address of the primary network interface can be reassigned to another network interface.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/MultipleIP.html","title":"Instance IP Addressing"}],"answers":[{"id":"9846d1971f5a7fb2fea9fcc99d4cc93d","text":"Private IP address remains associated with the Network Interface when the instance is restarted, and is released when the instance is stopped or terminated","correct":false},{"id":"08ce21259a0fb5332a9f8cf840942c51","text":"Private IP address remains associated with the Network Interface when the instance is stopped and restarted, and is released when the instance is terminated","correct":true},{"id":"c8eaf93ec90c897e9475642c70e3e7d2","text":"A secondary private IPv4 address cannot be detached or reassigned from the primary network interface to another network interface","correct":false},{"id":"8b90202f343b063cae25d7b89efaa9b1","text":"A secondary private IPv4 address can be reassigned from the primary network interface to another network interface","correct":true}]},{"id":"6853a0e8-ce9d-4d37-a7af-b235c0d5fc05","domain":"SecureSolutions","question":"To establish a successful site-to-site VPN connection from your on-premise network to an AWS Virtual Private Cloud, which of the following must be configured?","explanation":"You must have a VPC with Hardware VPN Access, an on-premise Customer Gateway, and a Virtual Private Gateway to make the VPN connection work.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/NetworkAdminGuide/Introduction.html#Summary","title":"Setting Up a VPN Connection"}],"answers":[{"id":"e04ddd768294b403207504bfa9eb006c","text":"A private subnet in your VPC","correct":false},{"id":"d776301586e8b5388ed61cd90c180467","text":"A NAT instance","correct":false},{"id":"ade419f8f6139a9769e4b0131d39f641","text":"A Virtual Private Gateway","correct":true},{"id":"de8b5ba929b3369272eb1146eb6f3f64","text":"A VPC with Hardware VPN Access","correct":true},{"id":"3d989f6e836bff71e5a2d4a288d70000","text":"An on-premise Customer Gateway","correct":true}]},{"id":"47e2a7bb-8eb1-401d-b350-543af2df7025","domain":"Performant","question":"A company is designing a log event processing application that must process 1000 events per second. Maintaining event ordering is also a requirement. Which service should they use for this messaging platform?","explanation":"Amazon SQS FIFO queues support processing of messages in first-in-first-out order. However, the service has a limit of 300 messages per second. Therefore, it does not meet the 1000 events per second requirement. Kinesis Data Streams support in-order event processing per shard. Each shard supports up to 1000 events per second. Hence, this is the correct option. Amazon MQ is a managed message broker service meant as a migration replacement for Apache ActiveMQ. Therefore, it is not an optimal solution when designing a new AWS cloud native application. SNS is a service for sending notifications and is not a suitable option in this scenario.","links":[{"url":"https://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html","title":"Kinesis Data Streams Limits"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html","title":"Amazon SQS FIFO (First-In-First-Out) Queues"}],"answers":[{"id":"7a16a49dc1812ae9bd4736a497c23736","text":"SQS FIFO Queues","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":false},{"id":"656ce3a05cc3f15979b05086924e3ffc","text":"Kinesis Data Streams","correct":true},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":false}]},{"id":"9e8fac4c-6095-468a-bc93-9a274047c7ad","domain":"SecureSolutions","question":"Your mobile app needs to have images uploaded to S3. You want to bypass the existing web server for the uploads to avoid increasing load on the server. How can this be accomplished?","explanation":"All objects and buckets by default are private. The pre-signed URLs are useful if you want your user/customer to be able to upload a specific object to your bucket, but you don't require them to have AWS security credentials or permissions.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/PresignedUrlUploadObject.html","title":"Uploading Objects Using Pre-signed URLs"}],"answers":[{"id":"1768d724dcf884a855c2889522437fa6","text":"Use Pre-Signed URLs to upload the images.","correct":true},{"id":"83e87dae98de34e44fb616d962301f0d","text":"Create a second S3 bucket and use Lambda to sync the files to the primary bucket.","correct":false},{"id":"5f088b72412d6935807479e2840f0b16","text":"Use ECS Containers to upload the images.","correct":false},{"id":"8bf8469577529a39055c2f1b9a301286","text":"Upload the images to SQS and then push them to the S3 bucket.","correct":false}]},{"id":"fedb7a40-0fc4-11ea-8d71-362b9e155667","domain":"Performant","question":"A company needs to collect, store and analyze data, from various data sources, to calculate the net profit from sales of its bags, socks, shoes, and underwear brands in the United States, England, France, and South Africa during the first quarter of the year. Which of the following AWS services is most suitable for this application?","explanation":"Amazon Redshift is designed for companies like this one to pull very large and complex data sets and analyze them to make critical business decisions. Unlike Redshift, neither the Aurora RDS database engine nor DynamoDB are suitable for data warehousing, and S3 is simply for storing objects.","links":[{"url":"https://aws.amazon.com/redshift/","title":"Amazon Redshift"}],"answers":[{"id":"f7415e33f972c03abd4f3fed36748f7a","text":"Amazon Redshift","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"69670a9d53817d1ec89e685997343ce2","text":"Amazon Aurora","correct":false},{"id":"270fcb785810d0206945029bb05f4e97","text":"Amazon S3","correct":false}]},{"id":"b21cf2a7-0cf1-47d4-a0c2-60403bb9cf37","domain":"CostOptimized","question":"To stay within the AWS Free Tier using Amazon EC2 for the first 12 months of having an AWS account, which of the following instance types should you use?","explanation":"One of the EC2 requirements for staying within the AWS Free Tier is using EC2 micro instances only. That makes t2.micro and t3.micro the correct responses.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc","title":"AWS Free Tier"}],"answers":[{"id":"1d4f2c610dbeb44e7ba09fed19564c76","text":"t2.micro","correct":true},{"id":"affa6cb0576af5aa6e603780fe7b203c","text":"t3a.small","correct":false},{"id":"7d3869f3c790e32d408d21d331095b0b","text":"t3.micro","correct":true},{"id":"ab61127647912c159c3fc08e9a102efc","text":"t2.small","correct":false}]},{"id":"24f26b84-497a-4a07-a40f-1f636c0aa7da","domain":"Performant","question":"You have designed an application that stores large videos in S3. These videos are usually larger than 100Mb in size. You need to maximize upload performance. Which of the following will achieve this end.","explanation":"Multipart Upload is recommended for files greater than 100 Mb, and is required for files 5 GB or larger. S3 Transfer Acceleration is especially useful in cases where your bucket resides in a Region other than the one in which the file transfer was originated.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2016/04/transfer-files-into-amazon-s3-up-to-300-percent-faster/","title":"Transfer Acceleration"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html","title":"Multipart Upload Overview"}],"answers":[{"id":"27cbe99b103845434c5d99034be17b10","text":"Utilize S3 Transfer Acceleration.","correct":true},{"id":"34188758a0d842537d7d14f43c94c315","text":"Design the application to use multipart upload, so that the file is split in to multiple parts which are then uploaded simultaneously.","correct":true},{"id":"137ef2be67b8313e80b25b2c3ea64ec0","text":"Implement a third party CDN solution.","correct":false},{"id":"c1b6778485fc5a390b6a08f16f22afec","text":"Require the users to use Direct Connect in order to use to application so as to maximize the upload bandwidth.","correct":false}]},{"id":"5b52d388-382c-4f3c-9d9d-0e15d2c4dccd","domain":"CostOptimized","question":"You have a static HTML website that requires inexpensive, highly available hosting solution that scales automatically to meet traffic demands. Which AWS service would best suit this requirement?","explanation":"S3 Static Website Hosting offers the best solution here: it is highly-available, scales automatically, and is cost-effective.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Static Website Hosting"}],"answers":[{"id":"b812d3912dbd32666e0d2865e0ee9d19","text":"EC2 with CloudFront","correct":false},{"id":"b0bca3ada773197571a3697e029cdfc4","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 1 instance","correct":false},{"id":"7e247cebfa4700e9281d3e30ac07ac70","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 2 instances","correct":false},{"id":"a98f92c3d9a3073bdf1d35f748a53342","text":"S3 - Static Website Hosting","correct":true}]},{"id":"1ad4b101-8078-4f3c-86bf-2f865ee09a54","domain":"CostOptimized","question":"A government agency has a regulatory mandate that all archived data must be preserved exclusively in a non-rewriteable and non-erasable format. What solution satisfies this requirement in the most cost-effective way?","explanation":"Amazon S3 versioning does not protect object versions from being deleted and is therefore an incorrect solution. Amazon S3 bucket policies do not satisfy the requirement and is not the correct solution. Amazon S3 bucket policies can be changed, thus removing protection on the objects. Implementing Amazon S3 Object Locks is incorrect because it is not the most cost-effective solution. The question specifically asks about archived data. Storing archived data in Amazon S3 Glacier is more cost-effective than Amazon S3. Amazon S3 Glacier is the most cost-effective storage solution for archive data. Amazon S3 Glacier Vault Lock can be used to implement a 'Write-Once-Read-Many' archive storage solution.","links":[{"url":"https://docs.aws.amazon.com/amazonglacier/latest/dev/vault-lock.html","title":"Amazon S3 Glacier Vault Lock"},{"url":"https://aws.amazon.com/blogs/aws/glacier-vault-lock/","title":"Create Write-Once-Read-Many Archive Storage with Amazon Glacier"}],"answers":[{"id":"6a730079c6c38844cd80386edd5634f3","text":"Enable Amazon S3 Versioning.","correct":false},{"id":"1430bbbd409858a9a820458c0f311d39","text":"Enable Amazon S3 Object Lock.","correct":false},{"id":"554acd3f3712f630497b0180dbb5124c","text":"Implement Amazon S3 Glacier Vault Lock.","correct":true},{"id":"c367faed034f6f722c499e129d8ca5dd","text":"Implement Amazon S3 Bucket Policy with deny statements for object delete operations.","correct":false}]},{"id":"86d024c1-7027-401d-a4d2-5457b7f976a0","domain":"CostOptimized","question":"Your site uses machine learning algorithms to modify user-uploaded images in interesting ways, generating new images in under a second as a result. Both the original user image and the generated images are currently stored in S3 - but your site is currently growing with 50Gb of new content added per day, driving up your storage costs. Recent usage statistics have shown that both user uploaded and generated images are heavily accessed in the first 21 days after upload or creation, after which access sharply drops off. After 120 days they are never accessed again. You want to keep the good buzz you site has going and want to ensure that images are there when users need them, but at the same time you want to reduce storage costs to keep you site profitable. Which of the below is the best trade-off of the two?","explanation":"With a complex scenario like this, it's a good a to break it down into components. In the first 21 days, due to the high usage of the images any storage that includes retrieval costs will not be suitable - ruling out any IA storage. After 21 days as usage drops off significantly IA becomes a viable option. Taking it a step further - as your site is generating the images based on the user uploaded image, generated images are easily replaceable if lost, as long as you have the user image. This means that a reduced redundancy storage option is valid for generated images - S3-1Z-IA. Anything older than 120 days can be deleted as it is no longer needed.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"afcd1b04e8899f07bdff4b5a7b6df83d","text":"Store all images on S3. After 21 days move them both user uploaded and generated images to S3-IA with a lifecycle policy, then after 120 days move them to Glacier for archival purposes","correct":false},{"id":"b3f69f81f2babbf2f17f845d1fcd4109","text":"Store all images on S3 in the first 21 days. After 21 days, move user images to S3-IA and generated images to S3-1Z-IA. Delete all content older than 120 days via lifecycle policy","correct":true},{"id":"eccefc577b666cc3968032eb19067e5b","text":"Store all images on S3 in the first 21 days. After 21 days move them both to S3-IA with a lifecycle policy. Create Lambda function that runs daily that deletes anything older than 120 days","correct":false},{"id":"bcfb0baa0a994f7d1fc253718a0eb14a","text":"Store all images on S3-IA in the first 21 days. After 21 days move both user uploaded and generated images to S3-1Z-IA with a lifecycle policy, then after 120 days move them to Glacier for archival purposes","correct":false}]},{"id":"bafcc6eb-1121-46e6-80cb-f9ce6b37f305","domain":"Performant","question":"You audit an S3 bucket in the GUI and find that it contains hundreds of objects of 0 bytes.  Why might you observe this ?","explanation":"An empty file (often, a file that has been 'touched') is allowed.  The most likely reason to have many of these is a process that generates the file record but never populates it.  The CLI aws ls command can also be used to get a report, but it has no significant benefit over the GUI unless you are programmatically analyzing the result. There are many policy options for S3, but that is not one of them.","links":[{"url":"https://aws.amazon.com/s3/faqs/","title":"How Much Data Can I Store?"},{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/list_amazons3.html","title":"Policy Actions, Resources, and Condition Keys for Amazon S3"}],"answers":[{"id":"d16296fd4b954befa4fef43973b7773d","text":"Display of the files size is controlled by a Policy action.  Update your User Policy to be able to see the values.","correct":false},{"id":"685b105c7f2ee5f6a8b1165bf496a6a3","text":"The GUI is slow to update and is incorrectly reporting the capacity.  Press the refresh option. ","correct":false},{"id":"2f4bb0e1ab87ff7ea6d26a4e653b9a03","text":"You may have a process that creates files but crashes before anything is written to it.","correct":true},{"id":"b12cc3acbe044245f7f7c062b8d628d6","text":"CLI  s3api list-objects to do this reporting as it is much more up-to-date.","correct":false}]},{"id":"4529a700-0c98-4d1e-a64a-fe1543c8bcdd","domain":"SecureSolutions","question":"You have a 3-tier application that you want to deploy into AWS - this application is accessed by users around the world over the Internet.  The design calls for an Application Load Balancer, EC2 Instances for the application software and another set of EC2 Instances to run the custom relational database system for the application. Also, periodically you want the instances to be able to download updates from the internet, via an already-deployed NAT gateway & Internet Gateway in the public subnet. Which of the below deployments would you recommend, keeping in mind that you want to keep costs and complexity to a minimum? ","explanation":"Placing the ALB in a private subnet would generally make it inaccessible to users outside your organization, so these two options can be discounted. Of the remaining two options, although both could work in theory, one has you deploying the application servers into the same public subnet as the ALB - this would mean having to attach a public IP to them in order to allow them to download updates, or using some custom routing at the OS which increases complexity. The recommended architecture is to deploy the ALB into the public subnet, and the application & database tiers into different private subnets.","links":[],"answers":[{"id":"918887f1baa6a0485499321635ed99c9","text":"Place the ALB in a public subnet inside the VPC. Deploy the application EC2 instances into the same public subnet, and the EC2 instances required for the database into a private subnet","correct":false},{"id":"187ce2fdaf78304235d6899a3a1049e7","text":"Place the ALB in a private subnet inside the VPC. Deploy the application EC2 instances into a different private subnet, and the EC2 instances required for the database into a the same subnet as the application instances","correct":false},{"id":"f8d132549046a020830a21bd5dad78ee","text":"Place the ALB in a public subnet inside the VPC. Deploy the application EC2 instances into a private subnet, and the EC2 instances required for the database into a different private subnet","correct":true},{"id":"afa56b5db37a4928a03e39cab6650e6e","text":"Place the ALB in a private subnet inside the VPC. Deploy the application EC2 instances into the same private subnet, and the EC2 instances required for the database into a different private subnet","correct":false}]},{"id":"737e3562-19f3-11ea-978f-2e728ce88125","domain":"Performant","question":"Which of the following AWS services enables on-premises applications to use AWS Cloud storage?","explanation":"Although all four responses are similar in that they are AWS storage services, it is Storage Gateway that enables on-premises applications to use cloud-based storage. EFS is for simple, scalable file storage, EBS serves as a virtual disk for virtual servers launched with EC2, and S3 is for object-based storage.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html","title":"What Is AWS Storage Gateway?"}],"answers":[{"id":"d2a6652ddeb631da029d1f2806e11fdc","text":"Amazon Elastic File System (EFS)","correct":false},{"id":"9155453f43b8a6472df0b8ffa5b5a028","text":"Amazon Elastic Block Storage (EBS)","correct":false},{"id":"5ba49687f2f5ade4cd1c756a7e9024e3","text":"AWS Storage Gateway","correct":true},{"id":"df346128c45efa43efc29607224fc716","text":"Amazon Simple Storage Service (S3)","correct":false}]},{"id":"d5e8caaa-e2d5-4d00-b9bc-53efee2b366f","domain":"Performant","question":"You have a production work load on AWS consisting of a Web Tier, Application Tier and Database Tier. Your web application starts to slow down under heavy use and can even become unresponsive. You investigate the issue and discover the issues are with the PostgreSQL RDS. What two steps could you do to improve performance?","explanation":"This is a classic scale-up or scale-out question. upgrading the disk is a scale-up solution, and adding read-replicas is a scale-out solution. Multi-AZ is possible, but will not help with performance, only resiliency.  RDS autoscaling is available only with Aurora","links":[{"url":"https://aws.amazon.com/blogs/database/scaling-your-amazon-rds-instance-vertically-and-horizontally/","title":"Scaling Your Amazon RDS Instance Vertically and Horizontally"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Integrating.AutoScaling.html","title":"Aurora Auto Scaling"}],"answers":[{"id":"eda178658eacb51c3dcfd2f1f9e2c4c5","text":"Add multi-AZ to the RDS cluster and direct all read traffic to the secondary instance.","correct":false},{"id":"ad6b88231cab9ea7642a5c16ce20722e","text":"Upgrade the storage type from General Purpose SSD to Provisioned IOPS SSD.","correct":true},{"id":"4b8062204769a36aff6ebc2fb3ffb313","text":" Turn on RDS Autoscaling and scale when CPU Utilization reaches 90% for 5 minutes.","correct":false},{"id":"bd7d139b54a720f913080f4bec971220","text":"Provision 3 Read Replicas and direct all read traffic to these new instances.","correct":true}]},{"id":"10118f04-2d87-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You wish to delete an EC2 instance that you no longer use. However, you realize that you can’t do so. Which of the following actions in the EC2 dashboard will you need to execute to enable the deletion?","explanation":"If you can’t delete the instance, click the 'Change Termination Protection' to disable termination protection, which prevents anyone from unintentionally deleting it. Once Termination Deletion is disabled, you can delete the instance. 'Attach to Auto Scaling Group' enables automatic scaling for your EC2 instance, and 'Get System Log' pulls up the history of actions in the instance; both have nothing to do with its termination. 'Change Shutdown Behavior' is for determining whether the EC2 instance is terminated or stopped when the shutdown command is used from within the instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/terminating-instances.html","title":"Terminate Your Instance – Amazon Elastic Compute Cloud"}],"answers":[{"id":"5d4bd148bcf891ce27ceffce5be92781","text":"Get System Log","correct":false},{"id":"91a6832787d50d959e40e389e5ac6b7e","text":"Change Shutdown Behavior","correct":false},{"id":"d1168fface65b719f1378443cee9d883","text":"Attach to Auto Scaling Group","correct":false},{"id":"e815242d6e8235575d2814adbe2439dc","text":"Change Termination Protection","correct":true}]},{"id":"b3e0d6fc-310d-4245-b634-5783129ea33a","domain":"Performant","question":"Your large scientific organization needs to use a fleet of EC2 instances to perform high-performance, CPU-intensive calculations. Your boss asks you to choose an instance type that would best suit the needs of your organization. Which of the following instance types should you recommend?","explanation":"C-class instances are recommended for high-performance front-end fleets, web servers, batch processing, distributed analytics, high performance science and engineering applications, ad serving, MMO gaming, and video-encoding. The best answer would be to use a C4 instance.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types - Compute Optimized"}],"answers":[{"id":"c4d62b6dcca08e5caf06c01889282859","text":"D2","correct":false},{"id":"b713e6323a68d3ddabf4855826c50148","text":"C4","correct":true},{"id":"f1c6eb6f4e48eb34ab40b2987d4976a8","text":"M3","correct":false},{"id":"5c108ce0fe89d0632cfce75f650b36c2","text":"R3","correct":false}]},{"id":"89d134f1-d269-43a5-b281-7103503d6fda","domain":"ResilientDesign","question":"You have been creating a number of EBS volumes for your EC2 instances. Your company has asked that you to ensure these EBS volumes are available in the event of a disaster. What can be done to help accomplish this?","explanation":"You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots. Snapshots are constrained to the Region in which they were created. To share a snapshot with another Region, copy the snapshot to that Region.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"Amazon EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modifying-snapshot-permissions.html","title":"Sharing an Amazon EBS Snapshot"}],"answers":[{"id":"2a6b8582b314574632c267c828b5b80b","text":"Ensure Snapshots are made available in another region.","correct":false},{"id":"d74765a9c34b22db50cadcb7e20ce91c","text":"Create Snapshots of the EBS volumes.","correct":true},{"id":"c7b84d21fb27659b1379dae03375ac7c","text":"Ensure Snapshots are made available in another Availability Zone.","correct":false},{"id":"d14f5bb7ac86c400a8c1a96b61346194","text":"Configure Amazon Storage Gateway with the source being the EBS volumes, then store the backups on premise.","correct":false}]},{"id":"1024766e-2157-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"When setting up the properties of an S3 bucket, which of the following options should you select to track storage cost?","explanation":"You need to label your S3 buckets with tags to track their storage costs. AWS will use the tags to organize costs in a cost allocation report. Object-level logging is for using AWS CloudTrail to record object-level API activity, server access logging is for logging requests for access to the bucket, and versioning is for keeping all versions of an object in the same bucket - not for tracking costs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/CostAllocTagging.html","title":"Using Cost Allocation S3 Bucket Tags"}],"answers":[{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":true},{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":false},{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false},{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":false}]},{"id":"c6a3e070-265a-11ea-978f-2e728ce88125","domain":"Performant","question":"An SEO company collects data based on disparate search engine optimization metrics and stores it in a DynamoDB database. The company wants to create an extra copy of the database tables as a form of disaster recovery. Which of the following AWS services can do that?","explanation":"True to its naming, AWS Backup is the service that you can use to back up the DynamoDB database tables. It also works for RDS databases.","links":[{"url":"https://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html","title":"What Is AWS Backup?"}],"answers":[{"id":"ce1a41ee0352cee512475ef6a6233963","text":"Amazon Elastic Compute Cloud (EC2)","correct":false},{"id":"df346128c45efa43efc29607224fc716","text":"Amazon Simple Storage Service (S3)","correct":false},{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":false},{"id":"ce52d2cff6e50f2e74505e0c70d072b3","text":"AWS Backup","correct":true}]},{"id":"cbd65c24-5330-4cbe-aadc-f65637bed971","domain":"CostOptimized","question":"Your SQL server requires a specific type of collation and some unique third party tools installed on it. You will need access to the underlying operating system for management and monitoring of these third party tools. However, you'd like to keep the overall amount of management to a minimum. Which AWS service would best suit your needs?","explanation":"With all services you are trading control of underlying processes for cost saving and ease of management.  In the case of RDS, AWS has exclusive control of the DB engine and underlying processes.  If you need to have access to these, building a bespoke DB server on an EC2 instance is the correct technical choice.","links":[{"url":"https://aws.amazon.com/sql/","title":"SQL Server on AWS"}],"answers":[{"id":"8f23d472ee9e39b19dec8c94f59f497b","text":"ElasticCache","correct":false},{"id":"8d8f3d54a16acc76a831ced6958141b9","text":"SQL server installed on EC2 with EBS","correct":true},{"id":"0ccd2cb2fe485108788ab60e8dbdfb4e","text":"RDS with SQL Server","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false}]},{"id":"86bc5815-e2a2-435d-b36a-de0291f03384","domain":"ResilientDesign","question":"A company disaster recovery policy requires that all RDS backups are retained in a secondary AWS region. What is the optimal solution to meet this requirement?","explanation":"RDS automated backups store backup data in the same region as the RDS instance. It is not possible to configure RDS automated backups to store data in a different region. The correct solution to meet the requirement is to copy RDS snapshots to the secondary region. It is not possible to copy RDS DB snapshots to an S3 bucket. Although it is possible to configure an RDS read-replica with automated backups in the secondary region, this is not an optimal solution as it involves additional costs associated with the running RDS instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html","title":"Working With Backups"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html","title":"Creating a DB Snapshot"}],"answers":[{"id":"bc87f2bd894c0887220a36be79571629","text":"Create an RDS DB snapshot. Copy the RDS DB snapshot to the secondary region.","correct":true},{"id":"1575bfe0f50108d320a7b04107a11d21","text":"Configure an RDS automated backups target region to the secondary region.","correct":false},{"id":"0ffef8639c8e9a75fa845bb6e9e6488b","text":"Configure RDS Read-Replica instance in the secondary region. Enable RDS automated backups on the read-replica instance.","correct":false},{"id":"6cb16d4a90eb4167d69dad6d62a4afa0","text":"Create an RDS DB snapshot. Copy the RDS DB snapshot to an S3 bucket. Enable Cross-Region replication on the S3 bucket.","correct":false}]},{"id":"6f99dc29-9e5a-4d5c-9152-c4e9d5e2325c","domain":"SecureSolutions","question":"When making use of EC2 instances on Dedicated Hosting, which of the following modes are you able to transition between by stopping the instance and starting it again?","explanation":"The tenancy of an instance can only be change between variants of 'dedicated' tenancy hosting. It cannot be changed from or to default tenancy hosting.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-instance.html","title":"About Dedicated Instances and Tenancy"}],"answers":[{"id":"04459d2ad5ea321a35a184d5db44d7ec","text":"Dedicated & Host","correct":true},{"id":"aa095ba3b4f590c56ebe3dd7632cf1d4","text":"Host & Default","correct":false},{"id":"d15424a6445328926f6ca57c29e143ca","text":"Host & Dedicated","correct":true},{"id":"d31d964b101ff444e700016740c91a5e","text":"Default & Dedicated","correct":false}]},{"id":"72e1713a-1087-4cd7-b969-6409a9d8ba8c","domain":"SecureSolutions","question":"Your CEO is still concerned about the durability and availability of company data stored in S3 after reading up on regions and availability zones. From the following, select all valid statements about this.","explanation":"All of the storage classes except for ONEZONE_IA are designed to be resilient to simultaneous complete data loss in a single Availability Zone and partial loss in another Availability Zone.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html","title":"Storage Classes"},{"url":"https://aws.amazon.com/s3/faqs/","title":"Amazon S3 Frequently Asked Questions"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-regions-availability-zones","title":"Region and Availability Zone Concepts"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/DataDurability.html","title":"Protecting Data in Amazon S3"}],"answers":[{"id":"32671011fa3b643c410faafe42ef8c38","text":"All of the storage classes except for ONEZONE_IA are designed to be resilient to simultaneous complete data loss in two Availability Zones.","correct":false},{"id":"b00c4e1c861e0343d7cf6808e7423eb0","text":"Objects are redundantly stored on multiple devices across multiple facilities in an Amazon S3 region.","correct":true},{"id":"1f85ee498591a1d4ab81999909893dc1","text":"The Amazon S3 One Zone-IA storage class replicates data within a single AZ. AWS recommends using this storage class for object replicas when setting cross-region replication.","correct":true},{"id":"89ccc0729546b39c6ed1166522cf7f28","text":"Availability Zones in the same region are connected to each other with fast, private fiber-optic networking. S3 operates in a minimum of three AZs within each region, each separated by miles to protect against local events like fires, floods, etc. This remains true in Regions where fewer than three AZs are publicly available.","correct":true}]},{"id":"7dd78d8f-4ef3-4d55-941a-c6e865c5ab7c","domain":"Performant","question":"Using the AWS Server Migration Service, what's the maximum number of volumes that can be attached to a VMs during a SMS migration job?","explanation":"At this writing, a VM can only have 22 virtual volumes during the SMS replication job.","links":[{"url":"https://aws.amazon.com/server-migration-service/faqs/","title":"AWS Server Migration Service - FAQ"},{"url":"https://docs.aws.amazon.com/server-migration-service/latest/userguide/prereqs.html","title":"AWS Server Migration Service - limits"}],"answers":[{"id":"0cae09dcea866a75f21e4e0d07a2ebc5","text":"only limited by the OS","correct":false},{"id":"6364d3f0f495b6ab9dcf8d3b5c6e0b01","text":"32","correct":false},{"id":"b6d767d2f8ed5d21a44b0e5886680cb9","text":"22","correct":true},{"id":"c74d97b01eae257e44aa9d5bade97baf","text":"16","correct":false}]},{"id":"2403cf92-cd58-4ade-8a82-52be2b2a6b5b","domain":"SecureSolutions","question":"Your Security team is concerned about a recent spate of large-scale DDoS attacks on other providers in your industry. You have a number of internet-exposed services in your business, and any potential outage has significant financial impact. The security team wants to be informed of any attack as it happens, and would like some assistance from AWS to help mitigate an attack should one happen. You currently have WAF deployed, and an Enterprise support agreement in place, but which of the below extra steps would you recommend","explanation":"AWS Shield Standard does not include notification of any attacks detected, therefore can be eliminated straight away. Although WAF can be used during a DDoS attack to help mitigate the attack with custom block rules, there are no in-built DDoS protections with WAF as these are provided by Shield. AWS has a dedicated DDoS Response Team (DRT) to assist during any DDoS attacks - however in order to access them, you need to be on an Enterprise or Business support agreement, and relevant to this scenario, have purchased Shield Advanced. This combined with the alerting of attacks that is available with Shield Advanced make purchasing Shield Advanced the most appropriate choice. ","links":[{"url":"https://aws.amazon.com/shield/getting-started/","title":"Getting Started with AWS Shield"},{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-overview.html#ddos-drt","title":"How AWS Shield Works"}],"answers":[{"id":"b8ede9969b12d6122fcef9029ff00b52","text":"By default all AWS services are automatically protected against DDoS attacks by AWS Shield - nothing extra needs to be done. During an attack lodge a support request using your Enterprise support agreement for assistance","correct":false},{"id":"b41f4d516374b164d0a2c054a39dfe3f","text":"Enable rate limiting on your load balancers, and during an attack lodge a support request using your Enterprise support agreement for assistance","correct":false},{"id":"191789dacb98c2ed977f4a62437a00af","text":"Enable the inbuilt AWS WAF DDoS protections, use SNS to notify when an attack is detected. During an attack lodge a support request using your Enterprise support agreement for assistance","correct":false},{"id":"6afd0c59a36c013760fbb187d8bbb415","text":"Purchase AWS Shield Advanced, and during an attack lodge a support request asking for assistance from AWS","correct":true}]},{"id":"e44a6772-240a-4c67-af0a-1119285833f9","domain":"ResilientDesign","question":"The large manufacturing company you work for is interested in moving their production estate to AWS. They run a Joomla store which utilizes MySQL on the back end. Currently, they also use clustered MySQL databases in an active/passive configuration at a single site. In moving to AWS, they want an active/passive configuration across 2 geographically distinct locations, with automatic failover between the two. As their solutions architect, which of the following RDS options should you recommend?","explanation":"To automatically failover from one geographic location to another you should use Multi-AZ for RDS.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/#Failover_conditions","title":"RDS Failover Conditions"}],"answers":[{"id":"c1d3dc1d00857a4c8a41667c4089187c","text":"RDS Read Replicas","correct":false},{"id":"b1e142eeffe2e60520001a47e8ea488d","text":"RDS with Cross Region Failover","correct":false},{"id":"57513d6064870e41de997c1e161825c7","text":"RDS Multi-AZ","correct":true},{"id":"955edcbe47cfada50233bc45752305b7","text":"RDS with Cross Region Replication","correct":false}]},{"id":"aad18b7b-a805-45b3-9b77-66eecf097e97","domain":"CostOptimized","question":"Your AWS environment contains several on-demand, EBS-backed EC2 instances dedicated to a project that has just been canceled. Your supervisor does not want to incur charges for these on-demand instances, but also does not want to lose the data just yet because there is a chance the project may be revived in the next few days. What should you do to minimize charges for these instances in the meantime?","explanation":"Stopping an EBS-backed on-demand instance will stop the charges and preserve the data.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html","title":"Stopping and Starting Your Instances"}],"answers":[{"id":"ad806d84c4f630fa88693a83dc990289","text":"Take snapshots of the EBS volumes and sell the instances on the In-Demand Instance Marketplace.","correct":false},{"id":"3e9091dfa36a1ab60c68658d5b630b61","text":"Terminate the instances.","correct":false},{"id":"bcf45b66b85859c34f9a1bc2e2e3d537","text":"Explain your situation to AWS Support and ask them to hold your instances for you.","correct":false},{"id":"1c1cacea035822ccf211f7f588b085fe","text":"Stop the instances as soon as possible.","correct":true}]},{"id":"bb6edecf-874f-4cc4-b25c-8de7fd0ce77a","domain":"SecureSolutions","question":"Which types of server-side encryption are available for S3??","explanation":"You can choose to encrypt data using SSE-S3, SSE-C, SSE-KMS, or a client library such as the Amazon S3 Encryption Client. All four enable you to store sensitive data encrypted at rest in Amazon S3.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingEncryption.html","title":"Protecting Data Using Encryption"}],"answers":[{"id":"bfc99aa741651a4def65ccb3d9f47505","text":"Client Side Encryption Using Amazon Provided Keys (CSE-AWS)","correct":false},{"id":"ff68c66786ecdb191ab814051921f833","text":"Server Side Encryption Using S3 (SSE-S3)","correct":true},{"id":"22f1418d9d1d58eb0b2d21aa4217bd2e","text":"Server Side Encryption with Customer-Provided Keys (SSE-C)","correct":true},{"id":"3bc510112120bf0cb211bd503eb58c46","text":"Server Side Encryption Using KMS (SSE-KMS)","correct":true}]},{"id":"4884c069-b179-4be0-ba18-d5fbfdd15e99","domain":"CostOptimized","question":"Your fleet of EC2 instances is running 100% of the time, and there is no reason to believe that the demand will decrease. What pricing model might you use to reduce costs?","explanation":"Reserved Instances provide you with a significant discount (up to 75%) compared to On-Demand instance pricing. You have the flexibility to change families, OS types, and tenancies while benefiting from Reserved Instance pricing when you use Convertible Reserved Instances.  To maintain a fleet of Spot instances you would need to be bidding fairly high, so it is likely the RIs will give you a better price point. But you would need to check.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","title":"About Reserved Instances"}],"answers":[{"id":"026db7f2265667575c05772f32778b8a","text":"Spot Instances","correct":false},{"id":"29068f6044e3fedf44165e646a2d2bb1","text":"Reserved Instances","correct":true},{"id":"d1328967694907a29a579faae6055cae","text":"Special Instances","correct":false},{"id":"02982929de0aab45a9fe119838ad82e6","text":"On-Demand Instances","correct":false}]},{"id":"2bf99c9d-4fc2-409d-b791-c6c4a0768549","domain":"Performant","question":"Which of the following are true about Amazon S3 - OneZone-IA?","explanation":"S3 - OneZone-IA enables customers to reduce their costs by storing non-critical, reproducible data at lower levels of availability than Amazon S3’s standard storage.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/?nc=sn&loc=3","title":"S3 - Storage Classes Overview"}],"answers":[{"id":"ddd83209deb4bf5fdc24d22fb5e12c3c","text":"S3 - OneZone-IA is most often used with objects that are easy to re-create.","correct":true},{"id":"d1a5624e6fbe325e3889a95a62c96184","text":"S3 - OneZone-IA is designed for 99.90% availability.","correct":false},{"id":"80e69120164bdeae440ac4a4af1b973d","text":"S3 - OneZone-IA is designed for 99.99% durability","correct":false},{"id":"dc2b74cf19d83fee510b2c972d70db9a","text":"S3 - OneZone-IA is designed for 99.999999999% durability.","correct":true},{"id":"d18f42bdcdbac2b13beeadb7f15654a6","text":"S3 - OneZone-IA is designed for 99.50% availability.","correct":true}]},{"id":"4527c4d5-21af-43d6-bb31-827ec2b91ebf","domain":"Performant","question":"What is the minimum size of an General Purpose SSD EBS Volume?","explanation":"SSD volumes must be between 1 GiB - 16 TiB.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html","title":"EBS Volume Types"}],"answers":[{"id":"208b4367cf771ded0e29ff6f9282442e","text":"1GB","correct":false},{"id":"2820ea55c8d1ec2fa9dfcf1495076480","text":"1GiB","correct":true},{"id":"785dfc0dff56385171bea51ba18b6a95","text":"1MB","correct":false},{"id":"8b3e84771bc65950c3e79446c2e72978","text":"1byte","correct":false}]},{"id":"74895349-5083-446e-a106-a0af4f0853d0","domain":"ResilientDesign","question":"If an instance belonging to an Elastic Load Balancer fails its health check, what will the ELB do?","explanation":"The ELB will de-register the instance and stop sending traffic to it.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-healthchecks.html","title":"Health Checks for ELB"}],"answers":[{"id":"c1438fa7ade98c37b521fe125b63ce1d","text":"The ELB will de-register the instance and stop sending traffic to it.","correct":true},{"id":"3f06dfecb47dd344952d684143ff06e9","text":"The ELB will launch a new instance.","correct":false},{"id":"21558324d05b7fbd37d11ddd53c8964e","text":"Unfortunately, the ELB will continue to send the unhealthy instance traffic until the instance is terminated.","correct":false},{"id":"072b06f88cd7172f5098893f72f0011e","text":"ELB will tell Auto Scaling to launch a new instance.","correct":false}]},{"id":"b66725f5-c28a-40e3-a66f-ab440f24f05d","domain":"SecureSolutions","question":"You work for a construction company that has their production environment in AWS. The production environment consists of 3 identical web servers that are launched from a standard Amazon Linux AMI using Auto Scaling. The web servers are launched in to the same public subnet and belong to the same security group. They also sit behind the same ELB. You decide to do some testing: you launch a 4th EC2 instance into the same subnet and same security group. Annoyingly, your 4th instance does not appear to have internet connectivity. What could be the cause of this?","explanation":"Of these choices, the absence of the Elastic IP is the only one that could prevent internet access.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Internet_Gateway.html","title":"Enabling Internet Access"}],"answers":[{"id":"dbfb29d2865a1da80068dc82bdf11f7f","text":"You have not configured a NAT in the public subnet.","correct":false},{"id":"1b5e2f314ee9201857bbf929863476b9","text":"You have not configured a routable IP address in the host OS of the fourth instance.","correct":false},{"id":"3645b812b5554461edf969a5a7b19083","text":"You need to update your route table so as to provide a route out for this instance.","correct":false},{"id":"3de8a51a1f321c3839a3ac9442da1f72","text":"You have not assigned an elastic IP address to this instance.","correct":true}]},{"id":"43fc6fe5-d8d0-493d-9ea4-2e93a60b689a","domain":"ResilientDesign","question":"You want to create a video stream and then send the video to it using your smartphone. In addition, you want to retain the data of this stream for 24 hours. Which of the following configurations will accomplish this?","explanation":"To stream video from your smartphone, you have to use an Amazon Kinesis video stream. At the 'Create video stream' page, you can either set a retention period for the stream with the default configuration, which is 1 day, or specify the 24-hour period with the custom configuration by choosing the '1 day(s)' option. Kinesis Firehose is for preparing and loading real-time data streams into data stores and analytics tools so is not the correct service.","links":[{"url":"https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/what-is-kinesis-video.html","title":"What Is Amazon Kinesis Video Streams?"}],"answers":[{"id":"f0c3c1c8c93c553a2affbb5b0691b601","text":"Amazon Kinesis video stream with a custom retention period of 1 day","correct":true},{"id":"a055b51b6508d9a53621f3c603ba9fac","text":"Amazon Kinesis Firehose stream with a custom retention period of 1 day","correct":false},{"id":"10fd0db073392ab026dfbeeede3d6f46","text":"Amazon Kinesis Firehose stream with a default retention period","correct":false},{"id":"7ecb10d64a1f75dcef24251af655a2b2","text":"Amazon Kinesis video stream with a default retention period","correct":true}]},{"id":"ac606721-1133-4438-8a6f-ec7bc24443ed","domain":"SecureSolutions","question":"Your organization has a custom VPC, but you've just discovered that one of your developers has created an RDS instance in the default VPC (in violation of company policy.) You need to re-create this RDS instance inside your custom VPC with as little effort as possible. What should you do?","explanation":"The easiest way would be to take a snapshot of the DB Instance in the Default VPC and restore it to your custom VPC by specifying the DB Subnet Group you want to use.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RestoreFromSnapshot.html","title":"Restoring (or moving) From a Snapshot"}],"answers":[{"id":"c04f8f858073c4a62ff00a4eff9386dc","text":"Use AWS Database Migration Service.","correct":false},{"id":"7a4d78c86de0e51b5dbc37976fdf85cb","text":"Use the RDS Import/Export Wizard to Migrate the RDS instance across to the custom VPC.","correct":false},{"id":"4997ddcea578c38851dfd6681dc85500","text":"Take a snapshot of your DB Instance in the default VPC and restore it to VPC by specifying the DB Subnet Group you want to use in your custom VPC.","correct":true},{"id":"71ae0650c202e7da315185fadebdec02","text":"Use the command 'aws rds mv dbname < VPC'.","correct":false}]},{"id":"07689304-6bbb-46ce-ba91-08edaeee087a","domain":"ResilientDesign","question":"You are creating an RDS database for your production environment and it needs to be highly available and continue to function in the event of an outage to the Primary database. Which of the following options will best meet this requirement?","explanation":"Multi-AZ deployment involves the creation of a standby replica in a different Availability Zone (AZ) from the primary database. A standby replica cannot serve read traffic, it is used to synchronously replicate data from the primary database. AZs are isolated from one another to prevent failure from spreading to them all. So, if the location of the primary database has issues, Amazon RDS automatically fails over to the standby replica. Read replicas are used to scale out to cater for high volumes of read requests - not automated failover. Multi-region deployment is not a valid RDS option and Cross-region deployments enable support for scaling of Read replicas and can be used for cross-region DR, but don't support the automatic failover due to a Primary DB outage.","links":[{"url":" https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Concepts.RegionsAndAvailabilityZones.html","title":"Choosing the Regions and Availability Zones"}],"answers":[{"id":"b75ef1477da122d3b8733ab5da141356","text":"Read replicas","correct":false},{"id":"9256e377c39a64274bd60ff4916a4cb9","text":"Multi-AZ deployment","correct":true},{"id":"794e9156bdd31164380a7005f8599e08","text":"Cross-region deployment","correct":false},{"id":"a9fa9ab64858fe533c9b65e9b8ba2fb9","text":"Multi-region deployment","correct":false}]},{"id":"62d8dc77-c233-45c2-a957-5d33339eab6e","domain":"Performant","question":"When reviewing Auto Scaling events, it is noticed that an application is scaling up and down multiple times per hour. What design change could you make to optimize cost while preserving elasticity?","explanation":"Modifying your scaling threshold is preferable to altering your number of instances manually.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/as-instance-termination.html","title":"Auto-scaling Thresholds"}],"answers":[{"id":"e8210fd4c78d4a3776a601bbefdec9e3","text":"Change the Launch Configuration to use a larger instance type.","correct":false},{"id":"7ef405f3ad8fb6e5ab62fdb296690514","text":"Change the scale-down CloudWatch metric to a higher threshold.","correct":true},{"id":"375c182a3d055fd5c0423b9ae48f006a","text":"Add a Provisioned IOPS volume to the instance.","correct":false},{"id":"efe86514d63b2cddf4fff0701f7625e8","text":"Increase the number of instances in the Auto Scaling group.","correct":false}]},{"id":"89f330aa-397e-49a6-99c1-59a911318d03","domain":"SecureSolutions","question":"To protect S3 data from accidental overwrites and deletes, which of the following should you do first?","explanation":"The first thing you should do is enable versioning.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html","title":"S3 Object Versioning"}],"answers":[{"id":"253efe32850426ce32c509612536c798","text":"Enable versioning on the bucket.","correct":true},{"id":"f85fb671c749e7fcc0f440124d0879d7","text":"Access S3 only from signed URLs.","correct":false},{"id":"d5ea3592264e2a8848ca043466fd5c46","text":"Allow only MFA access","correct":false},{"id":"9fb0a6abf0e1bda745fab85832252ee0","text":"Use a bucket policy to disable deletes from S3","correct":false}]},{"id":"40bd28c9-dee5-42d8-bc1b-1822db4e5243","domain":"ResilientDesign","question":"An enterprise has a large customer base and sends marketing emails (such as special offers and discounts), transactional orders (such as order confirmations) and correspondence emails (such as newsletters) to all customers. They engaged you to set up an email platform that provides an easy and cost-effective way to send and receive emails using their own email address and domains, and also wanted to set email auto-responders and email unsubscribe systems. Which AWS service below best matches the requirement?","explanation":"Amazon Simple Email Service (Amazon SES) is a highly scalable and cost-effective service for sending and receiving email. Amazon SES eliminates the complexity and expense of building an in-house email solution or licensing, installing, and operating a third-party email solution. Amazon WorkMail is a suite of office tools which help manage daily email workflow. With WorkMail, it is not possible to send transaction email or email newsletters. Amazon WorkMail uses Amazon SES to send and receive mail.","links":[{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/sending-email.html","title":"Setting up Simple Email Service"}],"answers":[{"id":"f25bb6e1bd825ac7b88a0340c5d8f4ec","text":"Amazon WorkMail","correct":false},{"id":"09e915452f715da52789fa62d9dd5291","text":"Amazon Simple Email Service","correct":true},{"id":"ca50f9e142e8d3e5e8fa73cf07d1a437","text":"Amazon Integrated Email solution","correct":false},{"id":"224510290621b43664ba1741744d7c57","text":"Amazon Active Directory Email Service","correct":false}]},{"id":"107a46c0-b5bb-4a4e-8e9e-064fb934147b","domain":"ResilientDesign","question":"You've been tasked with the creation of a highly-available, decoupled web application. Which of the following will not aid in that effort?","explanation":"The creation of IAM credentials does not aid this effort.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"SQS FAQs"}],"answers":[{"id":"c26840e8046d6e7ceba0501533c4a4d0","text":"An Elastic Load Balancer that sends web traffic to instances with the least latency.","correct":false},{"id":"0aa788c33829b966b170f6bdc4b12af9","text":"An AutoScaling group that ensures a self-healing application.","correct":false},{"id":"2b55480a5d566fb3ed3a9e515e9aa355","text":"An SQS queue that allows secondary EC2 instances to process jobs dropped by the primary instance.","correct":false},{"id":"73612f52f6119b29ce40ab23feacefb9","text":"IAM credentials on the primary EC2 instance that allow it to modify the SQS queue.","correct":true}]},{"id":"922ca882-d73b-4685-acf4-7c0827021c2b","domain":"ResilientDesign","question":"The customer service organization at your company just told you that a client purchase from your website was processed twice. Your order process involves EC2 instances processing messages from an SQS queue. What changes might you make to ensure this does not happen again?","explanation":"An SWF workflow ensures that actions are executed only once.","links":[{"url":"https://aws.amazon.com/documentation/swf/","title":"SWF Documentation"}],"answers":[{"id":"ae73003f30fc75b349d6c7e1407060ca","text":"Switch to long-polling.","correct":false},{"id":"da3af33124cb0627efe41ca5c7617ddf","text":"Increase the visibility timeout on the SQS queue.","correct":false},{"id":"24e1d12f9d1b3de53719bbd5341fbdf1","text":"Rewrite the order-processing workflow to use SWF, rather than SQS.","correct":true},{"id":"bacf185330f80f745f66f02bab85053a","text":"Manually delete the order after processing.","correct":false}]},{"id":"7ad502a4-1c97-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"A Fortune 500 company is currently migrating to AWS. The organization has determined that it needs an AWS Support plan that can mitigate failure or disruption of processes essential to its operation. Which of the following plans is most suitable for this purpose?","explanation":"Basic Support is included with each AWS account, so that automatically rules it out as the correct answer. Based on the description of the company’s needs and size, Enterprise Support is strongly recommended. This plan is ideally designed for organizations that have business or mission-critical workloads in AWS. Developer is geared towards those who experiment or test in AWS, and Business is ideal for production workloads. Neither of them is as robust as the Enterprise offering.","links":[{"url":"https://aws.amazon.com/premiumsupport/plans/","title":"Compare AWS Support Plans"}],"answers":[{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":false},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false}]},{"id":"6686ab14-14fd-11ea-8d71-362b9e155667","domain":"ResilientDesign","question":"You want a storage solution to store all e-commerce sales numbers processed on a daily basis. Notably, this solution must be designed in a way that protects against accidental deletion of data. Which of the following actions will satisfy your requirements?","explanation":"Enabling versioning will mean that if someone accidentally deletes an object, S3 would insert a delete marker to make that the current object version. In addition, you can always restore the previous object version if needed. Although storing data in three S3 buckets gives you an extra layer of protection, users can still delete the objects in both buckets. With a new EBS snapshot, the changes made since the last one are lost. And Redshift is the least likely response, since it is used for data warehousing rather than simple straightforward storage.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"Using Versioning"}],"answers":[{"id":"be181d98494c2caf02d54e25874885ac","text":"Store the sales numbers in a Redshift cluster.","correct":false},{"id":"a402eb2caf5dae12b4abc6d85c669024","text":"Store the sales numbers in an S3 bucket and enable versioning.","correct":true},{"id":"2a3b97d09893c4810970c8557d4e9933","text":"Store the sales numbers in an EBS volume and create snapshots at the end of each day.","correct":false},{"id":"7b87e237a929b789241cfd271cfbf5eb","text":"Store the sales numbers in three S3 buckets and in different AWS Regions.","correct":false}]},{"id":"75003c2a-e25e-46f8-a370-1c731b9ae191","domain":"CostOptimized","question":"You are speaking with a former colleague who asks you about cloud migrations. The place she is working for runs a large fleet of on-premise Microsoft servers and they are concerned about licensing costs. Which of the following statements is invalid?","explanation":"If you are bringing your own licenses into EC2 Dedicated Hosts or EC2 Dedicated Instances then Software Assurance is not required subject to Microsoft’s terms.","links":[{"url":"https://aws.amazon.com/blogs/compute/byol-and-oversubscription/","title":"BYOL and Oversubscription"},{"url":"https://aws.amazon.com/windows/faq/","title":"Amazon Web Services and Microsoft FAQ"},{"url":"https://aws.amazon.com/windows/resources/licensing/","title":"Microsoft Licensing on AWS"},{"url":"https://aws.amazon.com/about-aws/whats-new/2019/02/introducing-five-new-amazon-ec2-bare-metal-instances/","title":"Introducing Five New Amazon EC2 Bare Metal Instances"}],"answers":[{"id":"deb9a6947ea19d1368fde55946d0486a","text":"License Mobility allows customers to move eligible Microsoft software to third-party cloud providers such as AWS for use on EC2 instances with default tenancy.","correct":false},{"id":"efe6cc699df1fc725b09b77fbc5d5485","text":"If I bring my own licenses into EC2 Dedicated Hosts or EC2 Dedicated Instances, then - subject to Microsoft’s terms - Software Assurance is required.","correct":true},{"id":"d541aa9437c3dc1d5de97d24c01bfddd","text":"AWS License Manager includes features to help your organization manage licenses across AWS and on-premises. With AWS License Manager, you can define licensing rules, track license usage, and enforce controls on license use to reduce the risk of license overages. You can also set usage limits to control licensing costs. There is no additional charge for AWS License Manager.","correct":false},{"id":"5151b957b59a818ead21a6e5e6a9a611","text":"EC2 Bare Metal instances give the customer full control of the configuration of instances just as they have on-premise: The customer has the ability to install a hypervisor directly on the hardware and therefore define and configure their own instance configurations of RAM, disk and vCPU which can minimize additional licensing costs.","correct":false}]},{"id":"390ab5d8-2fc2-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"As a Cloud Solutions Architect, you have been tasked to set up an enterprise-class database with six-way replication across three Availability Zones. This measure is proposed to strengthen the database’s fault tolerance to disk failures. Which of the following engines will enable you to do that?","explanation":"Aurora is the database engine that provides six-way replication of each database volume across three Availability Zones. The other responses are just like Aurora in that they are relational database engines that offer Multi-AZ deployments. However, Oracle, MariaDB, and MySQL do not have this specific ability.","links":[{"url":"https://aws.amazon.com/rds/aurora/faqs/","title":"Amazon Aurora FAQs"}],"answers":[{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"7f9733e208088b1ce6df3d4be1765396","text":"MariaDB","correct":false},{"id":"30162ed78b6c10f731411f2fc440c24f","text":"Oracle","correct":false},{"id":"69670a9d53817d1ec89e685997343ce2","text":"Amazon Aurora","correct":true}]}]}}}}
