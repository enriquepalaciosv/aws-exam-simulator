{"data":{"createNewExamAttempt":{"attempt":{"id":"36417050-646a-424f-bf8c-b7825c296ae5"},"exam":{"id":"233c5f46-1a34-4f20-8f38-07faa52a67cd","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"ca86c215-dab3-4d06-bdec-131d5e1dc80d","domain":"SecureSolutions","question":"Your company runs a website that is presenting content that is stored in a back-end Aurora cluster. Content that makes up this website is created and managed from a handful of EC2 instances in your VPC, and this content is then accessed by a different set of EC2 instances acting as web servers in a public subnet. How would you configure the public-facing web servers to access the database, while minimising any security risks and operational overheads?","explanation":"As the public facing web servers are only presenting or reading data from the database, it makes sense from a security perspective to limit them to only being able to do so. The mechanism for doing this in Aurora is to use the Reader Endpoint - this method of accessing the database is limited to read-only operations, and will not allow any writes to the database. Although the Cluster Endpoint would also work, as it allows writes is is less secure for this scenario. Custom Endpoints will add unneeded complexity.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html","title":"Aurora Endpoints Overview"}],"answers":[{"id":"d7bcd2460b48eb366dee56e7e9523d20","text":"Use a Custom Endpoint, and configure it so writes are not allowed","correct":false},{"id":"15db1b612e8a6459801e52752ac7396d","text":"Use the Reader Endpoint for the Aurora Cluster","correct":true},{"id":"72c05b4624c78b852781cc573e7e26b9","text":"Use a Custom Endpoint, and configure it so that only the public EC2 instances can access it","correct":false},{"id":"478e18c3e9df393337232e395752b36c","text":"Use the Cluster Endpoint for the Aurora Cluster","correct":false}]},{"id":"c9673900-1c6a-4815-993d-f79e63fe5eae","domain":"ResilientDesign","question":"You are investigating a performance issue on a MYSQL RDS database and discover that there is only a single DB instance in a Single Availability zone for this database. This goes against your organisation's availability requirements, which specify that the application must remain available during AZ outages without interruption. This needs to be addressed, along with the performance issue. How would you go about resolving this, while keeping cost to a minimum?","explanation":"When in a Multi-AZ configuration, the secondary database instance is not \"active\" and cannot be read from or written to by clients. This rules out using the secondary instance to address the performance issue. Putting a read replica in a different AZ can help with redundancy, however the read replica will need to be promoted manually in case of a disaster, resulting downtime while this takes place. As this scenario requires that there is no interruption to service in case of a AZ outage, any answer using the Read Replica for availability can be discounted. This leaves using a Multi-AZ configuration with a Read Replica as the only valid option.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"Amazon RDS Multi-AZ Deployments"},{"url":"https://aws.amazon.com/blogs/aws/amazon-rds-for-mysql-promote-read-replica/","title":"Amazon RDS for MySQL – Promote Read Replica"}],"answers":[{"id":"ebda44f0999233da222783fb1a8079dc","text":"Deploy a Read Replica for the database into a different AZ. This will address the performance issue, and can be used in case of a AZ outage","correct":false},{"id":"43a8b1df93731fc791a9c59882df77b7","text":"Modify the database to be Multi-AZ to address the availability requirement. This will also address the performance issue as there will now be 2 instances for reads and writes.","correct":false},{"id":"92df2c8707d1018172156f0e95fd5b26","text":"Deploy a Read Replica for the database into a different AZ to address the availability requirement. Create another read replica in primary zone to improve performance.","correct":false},{"id":"9a2f983568edc620fc3719d40f9ea028","text":"Modify the database to be Multi-AZ to address the availability requirement, and deploy a read replica to improve performance","correct":true}]},{"id":"00350e3e-1c42-4f88-9a7f-da5a13c3beee","domain":"ResilientDesign","question":"You've been tasked with replicating your production VPC in another region for disaster recovery purposes. Part of your environment relies on EC2 instances with pre-configured software. What steps would you take to configure the instances in another region?","explanation":"The AMIs must be copied to the new Region prior to deployment.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/copy-ami-region/","title":"Cross Region EC2 AMI Copy"}],"answers":[{"id":"9d549a4d4d39135fb60e16e3239b85c3","text":"Write the IAM permissions for the new Region to use the AMIs from the original Region.","correct":false},{"id":"4bb6756625fe14c21f17ff3bc0e4a53f","text":"Create AMIs of the instances and copy them to the new Region for deployment.","correct":true},{"id":"965dceca3b86aea95ef5de037128780c","text":"None of these.","correct":false},{"id":"5523070f6b789b40c425d4c3776182fc","text":"Create AMIs of the instances and deploy them in the new Region","correct":false}]},{"id":"6a9be830-9658-4f9f-a5ea-518038423adb","domain":"ResilientDesign","question":"You're running an application that needs to be highly available in eu-west-1. In order for this application to function correctly,  9 related EC2 instances must running at all times. Which of the following deployments provides the ability to meet the requirements should an AZ go down and is the most cost optimized solution?","explanation":"Should an AZ go down, only the answers of 5,5,5 or 6,6,6 or 9,9,0 would meet the requirement of having 9 EC2 instances up, with the most cost optimized being the answer with 15 total EC2 instances.","links":[{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Cost-Optimization-Pillar.pdf","title":"Cost Optimization Pillar - AWS Well-Architected Framework"},{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Reliability-Pillar.pdf","title":"Reliability Pillar - AWS Well-Architected Framework"}],"answers":[{"id":"23ed0726519369cf6068f29abb57e8e7","text":"3 EC2 instances in eu-west-1a, 3 EC2 instances in eu-west-1b, and 3 EC2 instances in eu-west-1c.","correct":false},{"id":"6d68ff6a6b53ca045964ee07faeeab96","text":"5 EC2 instances in eu-west-1a, 5 EC2 instances in eu-west-1b, and 5 EC2 instances in eu-west-1c.","correct":true},{"id":"3c730af5a3243511e706f8068c1afc8c","text":"6 EC2 instances in eu-west-1a, 6 EC2 instances in eu-west-1b, and 6 EC2 instances in eu-west-1c.","correct":false},{"id":"640aac80e904b262d7fadd12c44a5802","text":"9 EC2 instances in eu-west-1a, 9 EC2 instances in eu-west-1b, and no EC2 instances in eu-west-1c.","correct":false}]},{"id":"f26af436-9d46-43c4-bc90-7102c73af3c5","domain":"SecureSolutions","question":"You are creating a new website where users will be able to login using their facebook, google and amazon.com credentials. You need to deploy this website as quickly as possible and you are looking for an AWS service that will enable you to deploy the authentication quickly. Which AWS service should you use?","explanation":"Cognito is a service that can authenticate users via federated Identity Providers, and assign them manage access to AWS resources based on your policies.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/external-identity-providers.html","title":"Identity Pools (Federated Identities)"}],"answers":[{"id":"e402520d8999ab859a1625c0012ecb4a","text":"Identity Access Management with Open Connect","correct":false},{"id":"8a1c4d12f4eb4126267c40d270d264c4","text":"IAM with Microsoft Active Directory Authentication","correct":false},{"id":"5de42305de3cd44564a54719deb43a37","text":"Amazon Authentication Zero","correct":false},{"id":"a095c741ced0e0849b29ce2600af29b0","text":"Cognito with Identity Pools (Federated Identities) External Identity Providers","correct":true}]},{"id":"bee3fc3a-4738-4c3f-b6ad-e6f25e600772","domain":"Performant","question":"Which of the following are types of virtualization available on AWS?","explanation":"The two different types of virtualization available are Hardware Virtual Machine (HVM) & Paravirtual Machine (PVM)","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#instance-virtualization-type","title":"EC2 Virtualization Types"}],"answers":[{"id":"fc9184bf07a56c1342576d092d7cdf15","text":"Physical Virtual Machine (PVM)","correct":false},{"id":"5136698bc5a65f152fe16da0719dd612","text":"Paravirtual Machine (PV)","correct":true},{"id":"e526c533a9df6aff264b1313a0908f9d","text":"Cloud Virtual Machine (CVM)","correct":false},{"id":"4b796a884a8b85e9857127deafecc5e7","text":"Hardware Virtual Machine (HVM)","correct":true}]},{"id":"bdfff765-ad59-45a9-9e3c-605a3d2ad9d7","domain":"ResilientDesign","question":"You have been asked to set up an EFS storage solution for a project team.  Which of the following tasks do you need to complete ?","explanation":"It is necessary to set up the bi-directional network permissions, normally with Security Groups. You will connect the EFS Target to your EC2 instance with a 'mount' statement. You do not need to stipulate the size or format the volume. AWS provide a nominally unlimited file system ready for you to use.  As normal under the shared security model AWS will ensure that the EFS system is secure, but you are responsible for the access control security inside the EFS file space provided to you.","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html","title":"EFS - How It Works"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/limits.html","title":"EFS limits"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/security-considerations.html","title":"EFS Security"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/accessing-fs-create-security-groups.html","title":"EFS Security Groups"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/wt1-getting-started.html","title":"Mounting and EFS target"}],"answers":[{"id":"7f41c759c946659e0ef49f87f6684503","text":"Set Linux file system permissions on the presented EFS volume using 'chmod' and 'chown'.","correct":true},{"id":"30f2e62c04d187f6e6f58e730e462680","text":"Configure a Security Group to allow admin traffic on port 22 to connect to the EFS system.","correct":false},{"id":"8388b16ddec8dec25d6caba4dbe7f8cb","text":"specify and provision disk capacity on the EFS system using 'fdisk' and 'mkfs -t xfs'.","correct":false},{"id":"417164507c199eb8b0fb1daa3bae285c","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EFS target","correct":true},{"id":"9a0eabcd19e62a99932848808a473c0f","text":"mount EFS vol to your EC2 instance using 'mount -t nfs -o xxxx '.","correct":true},{"id":"9bc552892ca2c2c5be9e7c352fc0cdc8","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EC2 server.","correct":true}]},{"id":"a2470754-2333-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"As a monitoring and security measure, you want to create an alarm to trigger when there is a failed attempt to log into the company’s AWS account. Which of the following services will enable you to do that?","explanation":"CloudWatch enables you to set an alarm for any event deemed notable. In this situation, you want to be alerted of any possible unauthorized attempts to access your company’s cloud infrastructure. CloudTrail is used to capture all API actions within your environment (audit), IAM is used to manage users and control what actions can be taken against resources, and Systems Manager is used to centrally manage your data and services.","links":[{"url":"https://aws.amazon.com/cloudwatch/","title":"Amazon CloudWatch"}],"answers":[{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":true},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":false},{"id":"113b1ad9ce6cdc3a37ad8475bc9bb2b2","text":"AWS Systems Manager","correct":false},{"id":"a86087964fb00f6ae81475d2c8c3c40c","text":"AWS Identity and Access Management (IAM)","correct":false}]},{"id":"75344f68-2344-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"You have a one private subnet and one public subnet in your VPC. Each subnet has a running EC2 instance. While the EC2 instance in the public subnet can connect to the Internet for software updates, the one in the private subnet can’t. However, you do not want to make the subnet public. Which one of the following actions will enable the instance in the private subnet communicate with the Internet without making it public?","explanation":"To enable the EC2 instance in the private subnet to connect to the Internet, you will need to create a network address translation (NAT) gateway in the public subnet. After that, update the route table associated with the private subnet to point Internet-bound traffic to the NAT gateway in the public subnet. Notably, the EC2 instance in the private subnet will initiate connection with the Internet for software updates; the NAT gateway prevents the Internet from initiating the connection. There’s already an Internet gateway attached to the VPC, which is why the public subnet can connect to the Internet; so, Response A is the wrong answer. While you can edit the route table to direct inbound traffic to both subnets, that would actually make the private subnet open to the public; Response C is therefore wrong. Response D is incorrect because simply dissociating the private subnet from its security group does not address connection to the Internet without making it public at all.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","title":"NAT Gateways"}],"answers":[{"id":"91e914033f772bc8acbe12e9ff2e40e8","text":"Dissociate the private subnet from its security group.","correct":false},{"id":"eb2c20b6f1eb2c553287e7d2515a5332","text":"Attach an Internet gateway to your VPC.","correct":false},{"id":"3b587d826f93d38e7db2ae83adc14468","text":"Create a NAT gateway in the public subnet.","correct":true},{"id":"1d03ba7c79604f909a119d3cd37780d1","text":"Edit the route table to direct inbound traffic to both public and private subnets.","correct":false}]},{"id":"0fa75b94-0aac-40ea-b312-cd38e8015b3c","domain":"SecureSolutions","question":"You need to add a route to your routing table that will allow connections to the internet from your subnet. Which of the following routes should you add?","explanation":"When setting a Custom Route Table, the destination should be 0.0.0.0/0, and the target should be the Internet gateway.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#CustomRouteTables","title":"Custom Route Tables"}],"answers":[{"id":"0bd386dbb40d5a1d0a565535fd77209e","text":"Destination: 0.0.0.0/33 --> Target: your virtual private gateway","correct":false},{"id":"899b7e9080653ebca0ce71d40bec7471","text":"Destination: 0.0.0.0/0 --> Target: 0.0.0.0/24","correct":false},{"id":"c60df6d18e83ca3ad6180d0c6cbb3859","text":"Destination: 192.168.1.258/0 --> Target: your Internet gateway","correct":false},{"id":"a09fb8c63b2f9ad6d6cc5d6fa022a702","text":"Destination: 0.0.0.0/0 --> Target: your Internet gateway","correct":true}]},{"id":"b1f70ce6-0e60-408d-b911-395f6238f5e7","domain":"CostOptimized","question":"Your legal team has just identified a significant confidentiality breach in your web site and you have instructions to take all content down immediately. which of the following statements are correct.","explanation":"While the first 1000 invalidation paths per month are free, additional invalidation paths are charged for per request.  There is a limit of 3000 concurrent individual invalidation, however you can stage them or combine then with wildcard path invalidations.  It takes time for the invalidation instruction to circulate and pull down content from all edge locations.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Invalidation.html","title":"CloudFront Invalidation"},{"url":"https://aws.amazon.com/blogs/aws/simplified-multiple-object-invalidation-for-amazon-cloudfront/","title":"Multiple Object Invalidation for CloudFront"}],"answers":[{"id":"e21d19a175e9c402d4ce86ca522c4514","text":"Invalidation requests can be cancelled if you issue the cancellation instruction in time.","correct":false},{"id":"3e5e72b6232c6205e16547a888294e05","text":"Only under certain circumstances will CloudFront invalidations be charged to your account.","correct":true},{"id":"ad95f0498b65e02aed5aa16a59b6c2a6","text":"You cannot invalidate more that 3000 files in CloudFront at a time.","correct":false},{"id":"27cf368fc73e24fe8c1fa2823bd75179","text":"Invalidation are effective immediately on request.","correct":false},{"id":"74d845824030304a665a29b3d252dcb6","text":"Versioning object names can be used in place of invalidation if you set it up ahead of time.","correct":true}]},{"id":"cc769fff-7738-4265-93c0-a92d5c113bcd","domain":"ResilientDesign","question":"You are a solutions architect working for a company that conducts surveys on specific industries. Each industry that you survey has its own EC2 fleet, separate from those of other industries. Company policy dictates that you should keep costs to a minimum, using only 1 load balancer, if possible. What type of load balancer should you use to suit this requirement?","explanation":"You need an application-aware load balancer, so your best option would be to use an Application Load Balancer.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html","title":"Application Load Balancer - Overview"}],"answers":[{"id":"6bee0fa60aa90f436c7e97e3621b8e15","text":"Elastic Load Balancer with IDS","correct":false},{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":true},{"id":"d7d91b002fbcf2615a58bba06d7028eb","text":"Elastic Load Balancer with IPS","correct":false},{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false}]},{"id":"95ab1573-ff07-4e33-a7f9-2847945bda35","domain":"SecureSolutions","question":"Your company requires that all the data on your EBS-backed volumes for your EC2 instances be encrypted. How would you achieve this?","explanation":"Encryption is supported by all EBS volume types. You can expect the same IOPS performance on encrypted volumes as on unencrypted volumes, with a minimal effect on latency. You can access encrypted volumes the same way that you access unencrypted volumes. Encryption and decryption are handled transparently, and they require no additional action from you or your applications.You can configure your AWS account to enforce the encryption of the new EBS volumes and snapshot copies that you create. For example, Amazon EBS encrypts the EBS volumes created when you launch an instance and the snapshots that you copy from an unencrypted snapshot.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html","title":"EBS Encryption"},{"url":"https://aws.amazon.com/blogs/aws/new-encrypted-ebs-boot-volumes/","title":"EBS Encryption Boot Volumes"}],"answers":[{"id":"8266443c60747acae9efd389e34e7e70","text":"AWS allows you to encrypt an EBS volume at the time of creation.","correct":true},{"id":"f49d586546b0e4a094812ec3492c6940","text":"You can configure encryption via KMS passthrough","correct":false},{"id":"9e54463e6b60221114b73938f3d298f1","text":"Encryption is totally handled at the OS layer.","correct":false},{"id":"8c8e380abba308fa34145575f2e6f910","text":"You can toggle on EBS encryption post creation.","correct":false}]},{"id":"4487121d-7fa3-446f-a535-c39966b96711","domain":"Performant","question":"Your CFO is after a ballpark estimate for the new customer-facing loyalty portal that you are currently designing and plan to host on AWS. She is particularly interested in all ongoing data transfer storage costs and wants to check her understanding of S3 pricing with you. Select all of her correct statements.","explanation":"Data transferred into S3 is generally free of $/GB charges. However the PUT, POST, GET, HEAD, etc transactions to process the data do carry a small cost per 1000 transactions. The data transfer OUT from Amazon S3 normally attracts a $/GB cost, except transfers to CloudFront is currently free.","links":[{"url":"https://aws.amazon.com/s3/pricing/","title":"Amazon S3 Pricing - Data Transfer pricing"}],"answers":[{"id":"6b21114362384aeb45a60d9135079fc7","text":"Transferring up to one GB of data per month out of S3 to end customers over the public internet is free.","correct":true},{"id":"d99ef1167cb494249040f92e1ee9b1b3","text":"Transfers between S3 buckets or from Amazon S3 to EC2 within the same AWS Region are free.","correct":true},{"id":"d77d1f7ba424ba16fe5c346b0251d6d3","text":"All S3 costs are based on the volume of data regardless of how it is handled.","correct":false},{"id":"95a0cb345bc0de8f225b2df1abf31406","text":"The total costs for data transfer out from S3 to CloudFront depend on the monthly volume of data, i.e a tiered pricing applies: The more data goes out, the more you save.","correct":false},{"id":"ed2d90d0da43d174ddaeb31b9c583017","text":"Data transfer into S3 from the Internet doesn't incur any costs","correct":true}]},{"id":"ea0ef349-4945-4bb8-a709-085950970f39","domain":"ResilientDesign","question":"Which of the following may happen when an EC2 instance with an associated Elastic IP is stopped and restarted?","explanation":"When such an instance is stopped and restarted, the instance will restart on a different physical host, and all instance-store data will be lost.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html#instance_stop","title":"Stopping and Restarting an EC2 Instance"}],"answers":[{"id":"3584e4a5f01330d2d34eb6ca5e70ff4d","text":"All data on instance-store devices will be lost.","correct":true},{"id":"e42e1eb5fb9c32ffa31fcc6728348082","text":"The underlying host for the instance may be changed.","correct":true},{"id":"586e97fed0c75137b72fad2a3489cf02","text":"The Elastic Network Interface will be detached.","correct":false},{"id":"65558bb868b9f8837c9add499fa4468c","text":"The Elastic IP will be disassociated from the instance.","correct":false}]},{"id":"d5462fb3-227a-4285-8a77-8672c8558693","domain":"CostOptimized","question":"Your AWS environment in us-east-1 contains several EC2 instances with associated RIs dedicated to a project that has just been canceled. You need to recoup the cost of these reserved instances, and you need to preserve the data for future use. What can you do to minimize charges for these instances?","explanation":"You should preserve the data by taking snapshots of the EBS volumes backing your instances and sell the RIs on the Reserved Instance Marketplace.  Remember the Reserved Instances is both a Capacity reserve, and a Billing discount.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"About EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html","title":"Selling on the Reserved Instance Marketplace"}],"answers":[{"id":"8cf9e85628c02261b9bbc22141dba658","text":"Stop the instances and retain them for future use.","correct":false},{"id":"9dda53fcc86762b17e493dad51eb121a","text":"Take snapshots of the EBS volumes and terminate the instances.","correct":true},{"id":"79ac46c5a0e1356d35f90962f478b6cb","text":"Sell the unused reservations on the AWS Reserved Instance Marketplace.","correct":true},{"id":"8a56365b62c17d312312ea07efd07dc1","text":"Contact AWS and ask them to release you from your Reserved Instance purchase.","correct":false}]},{"id":"f1bfb201-fad6-40da-be6b-b33d27d1f838","domain":"CostOptimized","question":"You work for a genetics company that has extremely large datasets stored in S3. You need to minimize storage costs without introducing unnecessary risk or delay.  Mandated restore times depend on the age of the data. Data 30-59 days old must be available immediately without delay, and data more than 60 days old must be available within 12 hours. Which of the following options below should you consider?","explanation":"You should use S3 - IA for the data that needs to be accessed immediately, and you should use Glacier for the data that must be recovered within 12 hours. RRS and 1Zone-IA would not be suitable solution for irreplaceable data or data that required immediate access (each introduces reduced Durability or Availability), and CloudFront is a CDN service, not a storage solution.","links":[{"url":"https://aws.amazon.com/s3/faqs/#sia","title":"S3 - Infrequent Access"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html","title":"Comparing the Amazon S3 Storage Classes"},{"url":"https://aws.amazon.com/s3/faqs/#glacier","title":"About Glacier"}],"answers":[{"id":"31e831ec49678aed7f467f791d1f8704","text":"S3 - RRS","correct":false},{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"4340570ba672bfa48cd45e3f026c01d1","text":"S3 - IA","correct":true},{"id":"e9a5105fa288ef2b71c037e42d665d91","text":"S3 - OneZone-IA","correct":false},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":true}]},{"id":"c4ce254d-d835-4beb-b096-153d84bada07","domain":"SecureSolutions","question":"Which of the following services allows you to access the service's underlying operating system?","explanation":"Access to the underlying operating system is granted for Elastic Map Reduce and Elastic Beanstalk. The others are managed services.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html","title":"About Elastic Beanstalk"},{"url":"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html","title":"About EMR"}],"answers":[{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"8d4c0b2cef256d21ab680366c8b1c6bf","text":"EMR","correct":true}]},{"id":"43bbab14-2b64-442d-98c0-632324c887f8","domain":"CostOptimized","question":"Your company has been running its core application on a fleet of r4.xlarge EC2 instances for a year.  You are confident that you understand the application steady-state performance and now you have been asked to purchase Reserved Instances (RIs) for a further 2 years to cover the existing EC2 instances, with the option of moving to other Memory or Compute optimised instance families when they are introduced. Which of the following options meet the above criteria whilst offering the greatest flexibility and maintaining the best value for money.","explanation":"When answering this question, it's important to exclude those options which are not relevant, first.  The question states that the RI should allow for moving between instance families and this immediately rules out Standard and Scheduled RIs as only Convertible RIs can do this.  Of the 2 Convertible RI options, the first can be ruled out as it suggests selling unused RI capacity on the Reserved Instance Marketplace, but this is not available for Convertible RIs and therefore that only leaves one answer as being correct.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/reserved-instances-types.html","title":"Types of Reserved Instances (Offering Classes)"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","title":"Reserved Instances"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html","title":"Scheduled Reserved Instances"}],"answers":[{"id":"b46dcc09115bb8c1683455addbc4fa46","text":"Purchase a 1 year Convertible RI for each EC2 instance, for 2 consecutive years running","correct":true},{"id":"41620e7974f0d2cca7f57d1972e30387","text":"Purchase a Convertible RI for 3 years, then sell the unused RI on the Reserved Instance Marketplace","correct":false},{"id":"188dc576a2e69c4182330092ab7f3786","text":"Purchase a Scheduled RI for 3 years, then sell the unused RI on the Reserved Instance Marketplace","correct":false},{"id":"89987ea3ddc88d352336561f25d83387","text":"Purchase a 1 year Standard Zonal RI for 3 years, then sell the unused RI on the Reserved Instance Marketplace","correct":false}]},{"id":"f464468f-7851-4684-a8a1-ece519bc244c","domain":"Performant","question":"An online music catalog application will use Amazon DynamoDB as it's database. Catalog entries will consist of information about individual song titles. Users will query songs primarily by artist. They'll also have the ability to retrieve a list of songs by genre, and from a specific decade within each genre. How should the music catalog table be structured in order to provide the best performance for these queries?","explanation":"Since users will be given the ability to query songs primarily by artist, the DynamoDB table's Primary Key should be set up with artist as the Partition Key and song title as the Sort Key. To provide the additional capability to query by genre, and to retrieve a list of songs according to decade within genre, a Global Secondary Index with genre as the Partition Key and decade as the Sort Key will give the best query performance. An artist Partition Key in the Primary Key without a song title Sort Key will place song titles randomly on the partition, resulting in poorer query performance. Same thing with a Global Secondary Index on genre without a decade Sort Key. Local Secondary Indexes must have the same Partition Key as the Primary Key. If artist doesn't exist as the Partition Key in the Primary Key or a Secondary Index, the query on artist will be performed as a full scan rather than a direct read.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html","title":"DynamoDB Core Components"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SecondaryIndexes.html","title":"Improving Data Access with Secondary Indexes"}],"answers":[{"id":"a3a841e8ef9cd63612e0a1dce7979275","text":"Create a Primary Key with artist as the Partition Key. Create a Global Secondary Index with genre as the Partition Key. Create a Local Secondary Index with decade as the Partition Key.","correct":false},{"id":"7ffad0b101f65b02826d61402fa11b74","text":"Create a Primary Key with artist as the Partition Key and song title as the Sort Key. Create a Global Secondary Index with genre as the Partition Key and decade as the Sort Key.","correct":true},{"id":"eb1a3f607b1bbeb89019415956a59252","text":"Create a Primary Key with song title as the Partition Key. Create a Local Secondary Index with artist as the Partition Key. Create a Local Secondary Index with genre as the Partition Key and decade as the Sort Key.","correct":false},{"id":"5304348a393031193fcd240783476b14","text":"Create a Primary Key with song title as the Partition Key and artist as the Sort Key. Create a Global Secondary Index with genre as the Partition Key. Create a Local Secondary Index with decade as the Sort Key.","correct":false}]},{"id":"8c7d8c0b-3c91-4d63-9adb-87636a5b8306","domain":"Performant","question":"You are managing a website hosted in an AWS EC2 instance. The logs are stored in Amazon S3. Which of the following is a serverless interactive query service that can be used for analyzing data in S3 to troubleshoot performance issues?","explanation":"Query services like Amazon Athena, data warehouses like Amazon Redshift, and sophisticated data processing frameworks like Amazon EMR, all address different needs and use cases. Amazon Redshift provides the fastest query performance for enterprise reporting and business intelligence workloads, particularly those involving extremely complex SQL with multiple joins and sub-queries. Amazon EMR makes it simple and cost-effective to run highly distributed processing frameworks such as Hadoop, Spark, and Presto when compared to on-premise deployments. Amazon EMR is flexible and can run custom applications and code, and define specific compute, memory, storage, and application parameters to optimize analytics requirements. Amazon Athena provides the easiest way to run ad-hoc queries for data in S3 without the need to setup or manage any servers.","links":[{"url":"https://docs.aws.amazon.com/athena/latest/ug/when-should-i-use-ate.html","title":"Instant Data Analytics Service"}],"answers":[{"id":"cc5cafce27b070d7c2d800486d23fda0","text":"Amazon RedShift","correct":false},{"id":"6d54c710d35b106057d416187bc27ac9","text":"Amazon Glue","correct":false},{"id":"13f4833f14110af4cb2943f6ee04ec0c","text":"Amazon Athena","correct":true},{"id":"469d12a9b614674fd9a6d9168d1494ec","text":"Amazon EMR","correct":false}]},{"id":"57fa9bae-f7f1-403e-9f2e-a4fed8194a26","domain":"Performant","question":"What is the maximum size of a general-purpose SSD EBS volume?","explanation":"The maximum size of a general-purpose SSD EBS volume is 16 TiB.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html","title":"EBS Volume Types"}],"answers":[{"id":"d54709907386131ba964655bbc9648fb","text":"16TiB","correct":true},{"id":"2dc6494faaf47acd40a479d5e8f22eeb","text":"2TB","correct":false},{"id":"00670b1d97c6a389b23ec0c46c497322","text":"4GB","correct":false},{"id":"69f53017d7fcd22c16c654c107c078c5","text":"2TiB","correct":false}]},{"id":"c487c002-443f-4d86-bdde-a915adb7924d","domain":"ResilientDesign","question":"You have chosen to use S3 - OneZone-IA with your cloud application. Which limitations have you considered in doing so?","explanation":"In exchange for a significant cost savings, 1Zone-IA has the same Durability as S3, but a lower Availability SLA.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/?nc=sn&loc=3","title":"S3 Storage Classes"}],"answers":[{"id":"3ffe3458e13ccc426e49a1893b78a3f3","text":"1Zone-IA has a 3 - 5 hour data recovery windows.","correct":false},{"id":"e0a1c69e07da2a370da0dedf28084491","text":"1Zone-IA offers only 99.50% durability. Therefore you have to design your application to re-create any objects that may be lost.","correct":false},{"id":"4068f35933f215b2818a03234567736a","text":"1Zone-IA requires supplementary Access Control Lists.","correct":false},{"id":"a86f1cf2d99a9643587b837f464b5ef8","text":"1Zone-IA offers only 99.50% availability. Therefore you have to design your application to re-create any objects that may be temporally unavailable.","correct":true},{"id":"bcddbe2d89ec46d45172296d890040c3","text":"1Zone-IA is available only in the US-STANDARD region.","correct":false}]},{"id":"a5e7d141-7d5e-4a87-a7e1-552203993c3e","domain":"SecureSolutions","question":"Your data warehousing company has a number of different RDS instances. You have a medium size instance with automated backups switched on and a retention period of 1 week. One of your staff carelessly deletes this database. Which of the following apply.","explanation":"Under normal circumstances, all automatic backups of an RDS instance are deleted upon termination. However, it is possible to  can create a final DB Snapshot upon deletion. If you do, you can use this DB Snapshot to restore the deleted DB Instance at a later date. Amazon RDS retains this final user-created DB Snapshot along with all other manually created DB Snapshots after the DB Instance is deleted.You can now retain Amazon RDS automated backups (system snapshots and transaction logs) when you delete a database instance. This allows you to restore a deleted database instance to a specified point in time within the backup retention period even after it has been deleted, protecting you against accidental deletion of data.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_DeleteInstance.html","title":"Deleting a DB Instance"},{"url":"https://aws.amazon.com/about-aws/whats-new/2018/11/amazon-rds-automated-backups-can-now-be-retained/","title":"Amazon RDS Automated Backups Can Now Be Retained After Database Deletion"}],"answers":[{"id":"ee57cc2e6614ff0630f78349f8c1188d","text":"If the option is not enabled to retain them, the automatic backups are deleted when the instance is deleted.","correct":true},{"id":"e380a1c948f0262ff32fbc83f5ca8020","text":"A final snapshot will be created upon deletion automatically.","correct":false},{"id":"a3f7b42bb25bb66def213ba0f0db182c","text":"The automated backups will be retained for 2 weeks and then deleted after the 2 weeks has expired.","correct":false},{"id":"201a44f070a04c2e9099ed1fdca9a346","text":"A final snapshot MAY have been created when the instance was deleted, depending on whether the 'SkipFinalSnapshot' parameter was set to 'False.'","correct":true}]},{"id":"3f41cb1e-265b-11ea-978f-2e728ce88125","domain":"Performant","question":"You are setting up the properties of an S3 bucket created for storing monthly pie charts. You want to use a template that will serve as the pie chart for the month of January, and for making alterations corresponding with subsequent months. All charts will be stored in the same bucket. Which of the following options should you select to allow that to happen?","explanation":"Enabling the Versioning feature will enable you to keep multiple versions of the pie chart in the S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/enable-versioning.html","title":"Enable Versioning"}],"answers":[{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false},{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":true},{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":false},{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":false}]},{"id":"5d18ab25-729c-46ea-aa11-66386391c0cd","domain":"SecureSolutions","question":"One of your junior developers needs access to an Elastic Load Balancer in your custom VPC. This is the first and only time he will need access to AWS services. Which of the following choices is the most secure way to grant this access?","explanation":"It's always best practice to grant users access via IAM roles and groups. In this case, there's no sense in adding him to a group that may have more permissions than he requires to do his job. Add an individual user with the minimum permissions required.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html","title":"Creating an IAM User"}],"answers":[{"id":"5b7444663d6c0d306878b7c2959e8297","text":"Create a new IAM user with only the required credentials.","correct":true},{"id":"80e0b9e929eb83fd3841f5b6395082f3","text":"Let them log in with Admin credentials and change the Admin password when he is finished.","correct":false},{"id":"625d4a006020f25fe043418f2e83fab2","text":"Add that developer to a Group with the requisite access.","correct":false},{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false}]},{"id":"d0946223-5972-4d84-b34d-e2529e3fc7e1","domain":"Performant","question":"You have a set of read only data on an EBS st1 volume which needs to be referenced by all the EC2 instances in an autoscaling groups.  Which of these are valid options ?","explanation":"Not all types of EBS volumes can be mounted to more than one instance at a time.  However Snapshots can be used to create copies. The better option would probably be EFS.  Storing the data set on S3 would also work, however the CLI script offered is not valid as the source and destination are reversed.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html#EBSFeatures","title":"EBS Volumes: Data Availability"},{"url":"https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html","title":"AWS S3 CLI cp"},{"url":"https://aws.amazon.com/blogs/aws/new-multi-attach-for-provisioned-iops-io1-amazon-ebs-volumes/","title":"Multi-Attach for Amazon EBS Volumes"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-restoring-volume.html","title":"Restore and mount a snapshot"}],"answers":[{"id":"db01b924625278a0a9fe4b1627595467","text":"Create a copy of the data set in an S3 bucket from time to time. Then use the script 'aws S3 cp <LocalPath> <S3Uri> --recursive' to copy the files onto the EC2 instances as they are brought on-line by autoscaling.","correct":false},{"id":"0f813c39a0b5e5a3c85eb5f9c6fa147f","text":"Create the a Snapshot of the Master copy at regular intervals.  Then restore and mount the latest snapshot to the EC2 instances as they are brought on-line by autoscaling.","correct":true},{"id":"07edfbbebc085c363f396930d13af41c","text":"Mount the EBS volume to all the EC2 instances using 'Multi-Attach for EBS'.","correct":false},{"id":"2868667ad6244fef7d80dcf63a2ecf56","text":"Create an EFS volume and migrate the data to the EFS instance.  Then mount the EFS volume to the EC2 instances as they are brought on-line by autoscaling.","correct":true}]},{"id":"30e234fe-027c-4ba0-b92a-717833173b25","domain":"CostOptimized","question":"The pharmaceutical company you work for has an aggressive schedule to bring a number of new products to market. You’d like to provide a library of metabolism assessment functions to application developers across the various teams so that each one doesn’t have to write their own. Which AWS compute solution will be the most cost-effective to host this library?","explanation":"A microservices architecture provides the most cost-effective environment for a library of code, and the serverless nature of AWS Lambda allows you to do that with zero administration. You could host your microservices on Elastic Container Service, but the serverless nature of Lambda makes it more cost-effective. EC2 Spot and Reserved Instances provide lower cost options to EC2 On-Demand, but not lower than Lambda executions.","links":[{"url":"https://aws.amazon.com/lambda/","title":"AWS Lambda"}],"answers":[{"id":"8a869b4068c02de382b5cb07d67b4479","text":"Amazon EC2 Spot Instances","correct":false},{"id":"2f9fc8b2a7a4c8ac66ec03afff926e96","text":"Amazon EC2 Reserved Instances","correct":false},{"id":"dee7ff8f7b10b9d388c7c561e9413b0d","text":"AWS Lambda","correct":true},{"id":"0383d27e1438422d247bbe8ffedfe1d4","text":"Amazon Elastic Container Service","correct":false}]},{"id":"b00e560b-da74-4cef-b912-1d07988a194c","domain":"SecureSolutions","question":"You are working for a security-conscious organisation that is about to deploy their first application in the cloud. This web-based application will need a load balancer in front of it, and due to the nature of the security posture of the organisation will need to be always available on the same (static) IP Address. Which load balancer configuration will deliver this outcome?","explanation":" By default, any Application Load Balancer’s IP may change over time due to changes in AWS’s infrastructure. It is recommended to always use DNS to find the public IP. For this reason, an ALB alone is not suitable in this scenario. An NLB’s IP address on the other hand will not change and is, therefore, a better choice to meet this specific requirement. “UseEIP” is not a valid setting in either Load Balancer","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/ ","title":"Load Balancing Features"}],"answers":[{"id":"9748a65c4342eda59ebc9f04fd3220a3","text":"A Network Load Balancer, with \"UseEIP\" set to \"true\" and an EIP assigned","correct":false},{"id":"be79367cfc0bad72327a2f169c4b8f27","text":"None - all load balancer IP will change over time - DNS needs to be used to find the IP","correct":false},{"id":"a765e07af33c3005e4acc0c84fe05ff7","text":"A Network Load Balancer in a public subnet","correct":true},{"id":"17d1a0fb988c07422d8eaa6cc012a5b9","text":"An Application Load Balancer, with \"UseEIP\" set to \"true\" and an EIP assigned","correct":false},{"id":"48e19fbb51f1039e8d6e263d970a5652","text":"An Application Load Balancer in a public subnet","correct":false}]},{"id":"8ce0cff9-4e62-41cb-8edd-a45f0b2a2bd3","domain":"Performant","question":"You have a application that is running in an EC2 instance that performs some heavy processing on sales data stored in S3. This sales data is first loaded into memory and numerous operations are performed on it before it is written back to S3. During the processing phase, a large amount of temporary data is created which is not needed once processing completes. This data needs to be stored on as low-latency storage as possible - which of the below storage types should you use?","explanation":"Although all 4 options would work, Instance Store has the lowest latency as it is located on the same physical infrastructure as the EC2 instance. As data permanency is not required, Instance Store is the best choice.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","title":"AWS Instance Store"}],"answers":[{"id":"43fd7af2adc3101adebb61366bf16df2","text":"Provisioned IOPS SSD","correct":false},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":false},{"id":"41c96096fbbf551daa42cd6455c15603","text":"Instance Store","correct":true},{"id":"248c1b0bcb74394beb4a08030c4a6847","text":"EBS","correct":false}]},{"id":"ed2dd1db-a1de-42d4-87ea-eaef11c67022","domain":"SecureSolutions","question":"An insurance provider will be migrating all of their applications to AWS. The production environment will reside in a single VPC for web tier, app tier, data tier, and control plane resources. Many of the transactional applications make heavy use of Amazon DynamoDB. New data classification mandates have been issued to ensure that information with different access requirements is segregated. Which networking architecture will provide the most secure data classification solution for the DynamoDB information?","explanation":"You can achieve DynamoDB network separation using VPC endpoints and VPC endpoint policies. A different VPC endpoint in each subnet with the appropriate endpoint policy will provide a networking architecture for data classification. Amazon Macie works with data in S3 buckets, not DynamoDB. DynamoDB subnet groups are used by DynamoDB Accelerator, not for assigning different Network ACLs. DynamoDB supports only identity-based policies, not resource-based policies.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints-access.html","title":"Controlling Access to Services with VPC Endpoints"},{"url":"https://aws.amazon.com/blogs/database/applying-best-practices-for-securing-sensitive-data-in-amazon-dynamodb/","title":"Applying best practices for securing sensitive data in Amazon DynamoDB"}],"answers":[{"id":"846e9db2b878c7df6d978322e6c35f35","text":"Create a single public subnet for web tier resources and a single private subnet for control plane, app tier, and data tier resources. Assign DynamoDB resource-based policies to manage permissions for different classifications of DynamoDB users.","correct":false},{"id":"6e93732fa397458f99a27e5fd55a0179","text":"Create a single public subnet for web tier resources and a single private subnet for control plane, app tier, and data tier resources. Deploy Amazon Macie to identify DynamoDB data classification categories and alert when unauthorized access occurs.","correct":false},{"id":"b7a32175fc364d3fe098613b996f3091","text":"Create separate subnets for control plane, web tier, app tier, and data tier resources. Configure DynamoDB VPC endpoints in each subnet. Assign an appropriate endpoint policy to each one.","correct":true},{"id":"bece04126871a6e709b69ecdfdee8e46","text":"Create separate subnets for control plane, web tier, app tier, and data tier resources. Assign a Network ACL to each subnet according to data classification requirements. Add each subnet to the DynamoDB subnet group.","correct":false}]},{"id":"1131af07-2a70-4e76-9964-1c8c8ff48627","domain":"ResilientDesign","question":"You've been tasked with setting up an S3 solution to store large amounts of critical data. With high availability and fault-tolerance in mind, what further safeguards should you implement to protect your data in the event that an entire AZ became unusable?","explanation":"S3 is designed to be regionally redundant through replication between data centres (for most classes). The exception is the  S3-OneZone-IA class which is NOT replicated and therefore would be at risk if a whole AZ became unavailable.","links":[{"url":"https://aws.amazon.com/s3/","title":"About S3"},{"url":"https://aws.amazon.com/s3/storage-classes/","title":"About S3 , S3 One Zone-IA"}],"answers":[{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"20de218abe483588a9454b83bc8ef9ac","text":"Use One Zone-IA class to take advantage of it's unique replication configuration.","correct":false},{"id":"77dabb1c3a140e4601e6911ff822ebd3","text":"Deploy a gateway-stored AWS Storage Gateway.","correct":false},{"id":"01126a45eebb74981a7a80fc3dabf48d","text":"Use lifecycle policies to copy the data to Glacier.","correct":false},{"id":"222cdf6bec04850773a7236508610daf","text":"Nothing if you use the correct storage class.","correct":true}]},{"id":"5fac4bb4-d450-440d-bc31-62fd409b5bee","domain":"ResilientDesign","question":"A company has an LNMP (Linux, Nginx, MySQL, PHP) stack application deployed to AWS. The availability requirements for their backend database specify automatic failover in case of disaster recovery. What is the optimal solution that meets this requirement?","explanation":"Since the scenario calls for MySQL, we must choose a relational database for the backend database. This means that DynamoDB is not a correct option. With RDS Multi-AZ deployment, a primary DB instance is automatically and synchronously replicated to a secondary RDS instance in a different availability zone (AZ). In case of a disaster causing primary instance failure, RDS performs automatic failover to the secondary standby RDS instance. During the failover, the database endpoint remains the same. RDS Read-Replica provide secondary RDS instances that are asynchronous replicated from the primary. RDS read-replicas have different endpoints and do not provide automatic failover. Additionally, they only provide read (not write) operations. It is possible to use Route53 with Health-check and DNS failover configurations to route traffic to multiple RDS instances. However, this solution does not provide automatic data synchronization between instances.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"High Availability (Multi-AZ) for Amazon RDS"}],"answers":[{"id":"f38116f4410ef57b5ffc6e17d11b1721","text":"RDS with Multi-AZ deployment.","correct":true},{"id":"9e445d25eaf3cc7b2f2412dbf19e6e4b","text":"RDS with Read-Replica deployment.","correct":false},{"id":"8a8d90b530fbd9c90820ca63425401b5","text":"Deploy multiple RDS instances. Use Route53 with Health-Check and DNS failover configured.","correct":false},{"id":"23f694af0e449b15b6fb26401d12eb0e","text":"DynamoDB with Global Tables deployment.","correct":false}]},{"id":"ab704d26-226d-4951-b238-549daba176a5","domain":"ResilientDesign","question":"What is the durability of S3 - IA?","explanation":"S3 Standard - IA is designed for the same 99.999999999% durability as S3 Standard and Amazon Glacier.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#Infrequent_Access","title":"S3 Infrequent Access"}],"answers":[{"id":"19fb9916968211db983d13bffe0cc6af","text":"99.99%","correct":false},{"id":"78262a35fc5fdefbb7740ac7102b8cc4","text":"99.999999999%","correct":true},{"id":"ebb51b0b7e8f1fcf89ef483709bd61c6","text":"99.9%","correct":false},{"id":"91009c0d8d2ec85d07a48cb81bfcfb0d","text":"99%","correct":false}]},{"id":"54f49b19-525b-42bc-956a-c02a709ea575","domain":"Performant","question":"A political consulting group wants to monitor Twitter tweets from all candidates in an election to assess campaign statements and positions on current issues. They'll implement calls to the Twitter API from a Python script on an EC2 instance to get the tweets, and they'll use Amazon QuickSight to visualize the data. They anticipate that as the election approaches, tweet volume will increase dramatically. Which architecture will provide the scalability they need in the most cost effective way?","explanation":"Using Kinesis Streams to batch the tweets for the Lambda consumer function helps orchestrate the process of invoking Comprehend on a specific set of tweets. If the data is written directly to S3 via Kinesis Firehose PutRecord calls without some batching of the tweets, Comprehend will scan the same data multiple times. Comprehend currently does not support DynamoDB as a data source. Comprehend is a natural language processing service and doesn't require the data to be pre-formatted.","links":[{"url":"https://aws.amazon.com/kinesis/","title":"Amazon Kinesis"},{"url":"https://aws.amazon.com/comprehend/","title":"Amazon Comprehend"},{"url":"https://github.com/aws-samples/lambda-refarch-streamprocessing","title":"Serverless Reference Architecture: Real-time Stream Processing"}],"answers":[{"id":"29db045869ea4a45b00a8df4819dc756","text":"Have the Python script write the tweets to an Amazon Kinesis Streams stream. Configure a Lambda function as the consumer of the stream which receives tweets in batches. Have the Lambda function write the data to Amazon S3. Have the Lambda function also invoke Amazon Comprehend to assess sentiment in the batch and write the results back to S3","correct":true},{"id":"4e077d33575cabb8babd3a56c3f77d32","text":"Have the Python script write the tweets to an Amazon Kinesis Firehose stream with PutRecordBatch API calls. Configure the stream to write the data to Amazon S3. Trigger a Lambda function to put the data into a standard format, and then invoke Amazon Comprehend to assess sentiment in the tweets. Write the results back to S3","correct":false},{"id":"2447562bf64c3157516a40a083254449","text":"Have the Python script write the tweets to an Amazon Kinesis Firehose stream with PutRecord API calls. Configure the stream to write the data to Amazon S3. Trigger a Lambda function to invoke Amazon Comprehend to assess sentiment in the tweets and write the results back to S3","correct":false},{"id":"60a15003c784ca46eb2291738f62038a","text":"Have the Python script write the tweets to an Amazon Kinesis Streams stream. Configure a Lambda function as the consumer of the stream. Have the Lambda function write the data to Amazon DynamoDB. Invoke Amazon Comprehend from the Lambda function to assess sentiment in the tweets and write the results back to DynamoDB","correct":false}]},{"id":"2bf99c9d-4fc2-409d-b791-c6c4a0768549","domain":"Performant","question":"Which of the following are true about Amazon S3 - OneZone-IA?","explanation":"S3 - OneZone-IA enables customers to reduce their costs by storing non-critical, reproducible data at lower levels of availability than Amazon S3’s standard storage.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/?nc=sn&loc=3","title":"S3 - Storage Classes Overview"}],"answers":[{"id":"d1a5624e6fbe325e3889a95a62c96184","text":"S3 - OneZone-IA is designed for 99.90% availability.","correct":false},{"id":"d18f42bdcdbac2b13beeadb7f15654a6","text":"S3 - OneZone-IA is designed for 99.50% availability.","correct":true},{"id":"dc2b74cf19d83fee510b2c972d70db9a","text":"S3 - OneZone-IA is designed for 99.999999999% durability.","correct":true},{"id":"80e69120164bdeae440ac4a4af1b973d","text":"S3 - OneZone-IA is designed for 99.99% durability","correct":false},{"id":"ddd83209deb4bf5fdc24d22fb5e12c3c","text":"S3 - OneZone-IA is most often used with objects that are easy to re-create.","correct":true}]},{"id":"b21cf2a7-0cf1-47d4-a0c2-60403bb9cf37","domain":"CostOptimized","question":"To stay within the AWS Free Tier using Amazon EC2 for the first 12 months of having an AWS account, which of the following instance types should you use?","explanation":"One of the EC2 requirements for staying within the AWS Free Tier is using EC2 micro instances only. That makes t2.micro and t3.micro the correct responses.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc","title":"AWS Free Tier"}],"answers":[{"id":"1d4f2c610dbeb44e7ba09fed19564c76","text":"t2.micro","correct":true},{"id":"7d3869f3c790e32d408d21d331095b0b","text":"t3.micro","correct":true},{"id":"ab61127647912c159c3fc08e9a102efc","text":"t2.small","correct":false},{"id":"affa6cb0576af5aa6e603780fe7b203c","text":"t3a.small","correct":false}]},{"id":"43fc6fe5-d8d0-493d-9ea4-2e93a60b689a","domain":"ResilientDesign","question":"You want to create a video stream and then send the video to it using your smartphone. In addition, you want to retain the data of this stream for 24 hours. Which of the following configurations will accomplish this?","explanation":"To stream video from your smartphone, you have to use an Amazon Kinesis video stream. At the 'Create video stream' page, you can either set a retention period for the stream with the default configuration, which is 1 day, or specify the 24-hour period with the custom configuration by choosing the '1 day(s)' option. Kinesis Firehose is for preparing and loading real-time data streams into data stores and analytics tools so is not the correct service.","links":[{"url":"https://docs.aws.amazon.com/kinesisvideostreams/latest/dg/what-is-kinesis-video.html","title":"What Is Amazon Kinesis Video Streams?"}],"answers":[{"id":"7ecb10d64a1f75dcef24251af655a2b2","text":"Amazon Kinesis video stream with a default retention period","correct":true},{"id":"f0c3c1c8c93c553a2affbb5b0691b601","text":"Amazon Kinesis video stream with a custom retention period of 1 day","correct":true},{"id":"10fd0db073392ab026dfbeeede3d6f46","text":"Amazon Kinesis Firehose stream with a default retention period","correct":false},{"id":"a055b51b6508d9a53621f3c603ba9fac","text":"Amazon Kinesis Firehose stream with a custom retention period of 1 day","correct":false}]},{"id":"f1715a54-ef4a-4912-9093-e8e36698b0c9","domain":"CostOptimized","question":"Your company needs to run several monthly workloads that will each take several hours to complete. Although critical, these workloads can be stopped and restarted without adversely affecting the outcome of the job. Which pricing model would you use to deliver the most economical solution?","explanation":"Spot instances are a cost-effective choice if you can be flexible about when your applications run and if your applications can be interrupted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html","title":"About Spot Instances"}],"answers":[{"id":"de53d38fe38e0fce729f15c292a59891","text":"Free-Tier Instances","correct":false},{"id":"c658c72ec41cc513ad91a3f3e6d2c060","text":"On-demand Instances","correct":false},{"id":"026db7f2265667575c05772f32778b8a","text":"Spot Instances","correct":true},{"id":"29068f6044e3fedf44165e646a2d2bb1","text":"Reserved Instances","correct":false}]},{"id":"291ca555-1236-404c-a465-fa9fa118364b","domain":"ResilientDesign","question":"You're running an application that needs to be highly available in eu-west-1. In order for this application to function correctly,  10 related EC2 instances must running at all times. Which of the following deployments provides the ability to meet the requirements should an AZ go down?","explanation":"Should an AZ go down, only the answers of 5,5,5 or 10,0,10 EC2 instances are correct because if you take out one of those AZs, you would still have 10 EC2 instances running. Of course 10,10,10 will be more expensive, butit is still a valid answer.","links":[{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Reliability-Pillar.pdf","title":"Reliability Pillar - AWS Well-Architected Framework"}],"answers":[{"id":"6d68ff6a6b53ca045964ee07faeeab96","text":"5 EC2 instances in eu-west-1a, 5 EC2 instances in eu-west-1b, and 5 EC2 instances in eu-west-1c.","correct":true},{"id":"c77fd5803949296fc9e47e645230c402","text":"4 EC2 instances in eu-west-1a, 4 EC2 instances in eu-west-1b, and 2 EC2 instances in eu-west-1c.","correct":false},{"id":"611169e594d21e09c256b0c24733c751","text":"10 EC2 instances in eu-west-1a, 0 EC2 instances in eu-west-1b, and 10 EC2 instances in eu-west-1c.","correct":true},{"id":"23ed0726519369cf6068f29abb57e8e7","text":"3 EC2 instances in eu-west-1a, 3 EC2 instances in eu-west-1b, and 3 EC2 instances in eu-west-1c.","correct":false}]},{"id":"c232c020-d1d3-4b31-91c9-e8906b3fe973","domain":"Performant","question":"A business productivity service would like to add an online chat platform to their offerings. Their customer base is made up primarily of large multi-national corporations. These corporations will need to be able to include users in multiple countries in real-time chats. Static content for the application will reside on Amazon S3 and chat orchestration will be hosted on Amazon EC2 with Elastic Block Store volumes. Which architecture will provide the best performance efficiency for the chat platform?","explanation":"CloudFront supports WebSockets to establish persistent connections, which provide lower latency for real-time communications. Origin behaviors specify which origin satisfies which type of content request (ex. all .jpg files), not which origin servers to use. Route 53 is not needed, because requests for CloudFront content are automatically routed to the edge location with the lowest latency. Using ElastiCache to cache at the storage level may result in some efficiency, but leveraging CloudFront's Edge locations at the network level will provide the greatest performance gains.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-working-with.websockets.html","title":"Using WebSocket with CloudFront Distributions"}],"answers":[{"id":"49d904e69d2f386dc05917de19119370","text":"Use a Route 53 latency routing policy to send traffic to the lowest latency CloudFront Edge location","correct":false},{"id":"06a06760d361cbafcca4c47d8ab93c8e","text":"Have clients use HTTP upgrade semantics to establish WebSockets connections with CloudFront distributions","correct":true},{"id":"00539fd580f87a3d665dfe784d08d459","text":"Create a CloudFront distribution with origin behaviors that point to chat servers in the regions where the clients reside","correct":false},{"id":"3cdc4a0838e007f3a5500a2b555b9a73","text":"Leverage ElastiCache to manage in-progress chat conversations in-memory, and write conversation history to EBS volumes later","correct":false}]},{"id":"c55f22ae-80d0-4959-b174-d829799c0ebe","domain":"SecureSolutions","question":"An AWS VPC allows you to:","explanation":"With a VPC, you can connect your cloud resources to your own IPSec VPN connections.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html","title":"AWS Managed VPN Connections"}],"answers":[{"id":"80b64cf6fc3a37e7c804ff0db69f8916","text":"Provision unlimited S3 resources.","correct":false},{"id":"f7ddabca6bedcc81b8b193a009967f58","text":"Connect your cloud resources to your own IPSec VPN connections.","correct":true},{"id":"b6d6372266b9d9c86bea479d7e2ed72f","text":"Forget about security: AWS does it all for you.","correct":false},{"id":"965dceca3b86aea95ef5de037128780c","text":"None of these.","correct":false}]},{"id":"424b1344-ed2d-45df-8705-ccc54d235d1e","domain":"ResilientDesign","question":"You've been storing social media post information about your company's products for a little over two years. Most of the information is frequently used by the marketing department. The raw posts and some metadata are stored in an Amazon Aurora database. One day, the query application begins returning error messages. Marketing department users tell you they need the application available immediately for work on a campaign that's launching next week. Upon investigation you find that database storage has grown to the 64 TB limit for Aurora. What will be the most expeditious way to solve this issue?","explanation":"You can use AWS Database Migration Service (DMS) to migrate data from Aurora to S3 in CSV format, which can then be queried by Amazon Athena if needed. Creating a case with AWS Support won't resolve this issue since the Aurora storage limit is not an adjustable quota. Using the Aurora Global Database feature will not increase the maximum storage limit for a single database. While an EMR cluster may be a better solution for this use case, there is not time to perform such a migration in the time frame required by the marketing department","links":[{"url":"https://aws.amazon.com/rds/aurora/","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/dms/","title":"Amazon Database Migration Service"},{"url":"https://aws.amazon.com/blogs/database/archiving-data-from-relational-databases-to-amazon-glacier-via-aws-dms/","title":"How to archive data from relational databases to Amazon Glacier using AWS DMS"}],"answers":[{"id":"e9351ebb109e6e0e2d29eaa03a931116","text":"Open a case with the AWS Support Center to increase the Aurora database's storage quota","correct":false},{"id":"40f74ae9c39738abdadc3558462e1b39","text":"Turn on the Aurora Global Database feature and distribute part of the data to another AWS Region","correct":false},{"id":"deb5ee8cd76c99a18d1c712fa2fe45a5","text":"Migrate the database to an Amazon EMR cluster and use data mining tools for analyses going forward","correct":false},{"id":"98787ed0461b156ab50abac0b75e22c4","text":"Use AWS Database Migration Service to move the least accessed data to Amazon S3","correct":true}]},{"id":"40c8ad54-f968-412c-a7e0-9732db1d93ae","domain":"Performant","question":"You have a small database workload with infrequent I/O. Which storage medium would the most cost-effective way to meet these requirements?","explanation":" The question is specific that you are evaluating for RDS. Cold Storage is not a valid option for RDS. of the three valid types for RDS, Magnetic is still the cheapest","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","title":"RDS Storage Types"},{"url":"https://aws.amazon.com/rds/pricing/","title":"RDS pricing"},{"url":"http://calculator.s3.amazonaws.com/index.html#s=RDS","title":"AWS pricing calculator"}],"answers":[{"id":"4d548ff7278077c929b63c67f768cc97","text":"Amazon RDS Provisioned IOPS (SSD) Storage","correct":false},{"id":"a257df0abf37db5da9b921f8222eab2a","text":"Amazon RDS General Purpose (SSD) Storage","correct":false},{"id":"e774a96af9adfaa2402148c9828271e7","text":"Amazon RDS Magnetic Storage","correct":true},{"id":"0db6de47eed9671e44098c2117fe8916","text":"Amazon RDS Cold Storage","correct":false}]},{"id":"89d134f1-d269-43a5-b281-7103503d6fda","domain":"ResilientDesign","question":"You have been creating a number of EBS volumes for your EC2 instances. Your company has asked that you to ensure these EBS volumes are available in the event of a disaster. What can be done to help accomplish this?","explanation":"You can back up the data on your Amazon EBS volumes to Amazon S3 by taking point-in-time snapshots. Snapshots are constrained to the Region in which they were created. To share a snapshot with another Region, copy the snapshot to that Region.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"Amazon EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modifying-snapshot-permissions.html","title":"Sharing an Amazon EBS Snapshot"}],"answers":[{"id":"c7b84d21fb27659b1379dae03375ac7c","text":"Ensure Snapshots are made available in another Availability Zone.","correct":false},{"id":"2a6b8582b314574632c267c828b5b80b","text":"Ensure Snapshots are made available in another region.","correct":false},{"id":"d74765a9c34b22db50cadcb7e20ce91c","text":"Create Snapshots of the EBS volumes.","correct":true},{"id":"d14f5bb7ac86c400a8c1a96b61346194","text":"Configure Amazon Storage Gateway with the source being the EBS volumes, then store the backups on premise.","correct":false}]},{"id":"2d66f5e8-54d1-4364-af7a-52ebcffda715","domain":"Performant","question":"A startup clothing retailer has begun designing their online ordering application. The user interface will require presentation of four different screens to complete an order (product selection, shopping cart, payment, order confirmation). Orders can contain multiple line items. The application backend will need to scale seamlessly for seasonal spikes in demand. Which architecture will provide the most elastic and highest performing solution?","explanation":"Deploying individual Lambda functions with different order processing capabilities provides scalability and performance at an atomic function level. A deployment package that includes all of the order processing logic will take longer to cold-start. DynamoDB will provide faster overall performance for interim order data than RDS. Storing all interim order data in browser cookies is not feasible, especially if the order contains multiple line items","links":[{"url":"https://aws.amazon.com/serverless/build-a-web-app/","title":"Serverless Web Application"}],"answers":[{"id":"9585d6076d65862d61c9bec06c0d9ef5","text":"Store all interim order information in browser cookies and submit it to a single EC2 instance at the end of the ordering process. Implement Auto Scaling to handle the fluctuations in demand","correct":false},{"id":"bc1e03e1b048963acfa7d91267d73450","text":"Deploy a different Lambda function to process each step of the ordering process. Submit interim order information to the backend after each ordering step and store it in Amazon DynamoDB. Index the data with a transaction ID cookie stored in the browser","correct":true},{"id":"6e475a25a83c4ef5618fd3979e83b690","text":"Use a single Lambda function with the capability to process all the steps of the ordering process. Submit interim order information to the backend after each ordering step and store it in an Amazon RDS database. Keep track of order state in a database table","correct":false},{"id":"ba250a1b654920d1974ffae0ae713e76","text":"Deploy EC2 instances, each with the capability to process all the steps of the ordering process. Submit interim order information to the backend after each ordering step and store it on EBS volumes for persistence. Implement Auto Scaling to handle the fluctuations in demand","correct":false}]},{"id":"33481ccb-46de-434a-ad35-cfcd2b9a960f","domain":"SecureSolutions","question":"Which of the following AWS services can you use to protect data within your VPC?","explanation":"For data protection, AWS recommends tools like IAM, CloudTrail, and Macie. IAM is for safeguarding account credentials and granting users only the necessary permissions to perform their job duties. CloudTrail is for tracking user activity and API usage. And Macie is an advanced security service that uses machine learning to automatically discover, classify, and protect data. CloudFront is the only odd one out; it is AWS’s content delivery service, rather than a security or management and governance tool.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/data-protection.html","title":"Data Protection in Amazon Virtual Private Cloud"}],"answers":[{"id":"dfdfd742376f1e718ab36a8a1ee9143e","text":"Amazon CloudFront","correct":false},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":true},{"id":"a86087964fb00f6ae81475d2c8c3c40c","text":"AWS Identity and Access Management (IAM)","correct":true},{"id":"1f7efb5a61d1162575c83917dd086ad7","text":"Amazon Macie","correct":true}]},{"id":"18196faa-35f6-4a0b-b91b-c62326bbd9bf","domain":"CostOptimized","question":"A team is designing the architecture for a new application with full CI/CD testing.  They want to implement feature branch testing based on pull requests to master.  A Pull Request should cause a full deployment to be run on that feature branch being pulled so that a tester can run through functional tests.  What would you recommend the team does to automate this process at the lowest cost?","explanation":"CloudFormation allows AWS to automatically deploy the infrastructure required to deploy the application for testing.  The infrastructure code can be stored alongside application code to allow the application to be deployed in a fully-isolated infrastructure which can be destroyed once integration testing is complete.  CloudWatch Events (and not CloudTrail) enables pull request events to trigger a deployment.  Finally Amazon EC2 Spot Fleet allow us to deploy a set of EC2 instances at the lowest cost. Reserved Instances are better-suited to pre-purchasing compute capacity which you will use for a fixed period of time - it is not cost-effective to pre-purchase EC2 capacity just to perform integration testing.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html","title":"How Spot Fleet Works"},{"url":"https://ec2spotworkshops.com/amazon-ec2-spot-cicd-workshop.html","title":"CI/CD and Test Workloads with EC2 Spot Instances"}],"answers":[{"id":"e4f3730b2899903ad8a6c27eb2693ff2","text":"Configure CloudWatch Events to trigger a deployment based on pull requests","correct":true},{"id":"9d9cce9ec8f58e568222274098cf9b08","text":"Use Amazon EC2 Reserved Instance and Amazon CloudFormation to deploy a testing environment at lowest cost","correct":false},{"id":"cb82b20f57a6882ec563593d14dfb01b","text":"Configure AWS CloudTrail to log pull request events and trigger a deployment","correct":false},{"id":"254cbe0fa6a5e0b25dd7841402f05e7e","text":"Use Amazon EC2 Spot Fleet and Amazon CloudFormation to deploy an integration testing environment at lowest cost","correct":true}]},{"id":"7bcf3cb7-6154-4148-96ca-7e9ff7c16f27","domain":"ResilientDesign","question":"Your company is a heavy user of CloudFormation to deploy standard websites using WordPress for Media, PR and Marketing clients. As your company grows you are repeating the same load balancer configuration for most of your stacks. Currently you are manually copying and pasting the same configurations from one template to another. You want to reduce the administrative overhead in deploying CloudFormation templates. What options are there to achieve this?","explanation":"Breaking large complex builds into sections gives you the advantage of being able to reuse common templates patterns with a known and proven configuration, plus being able to share responsibility to SME for their portion of the architecture.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html","title":"CloudFormation - Nested Stacks"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks.html","title":"CloudFormation - Stacks Updates"}],"answers":[{"id":"8511646bc9edf9631791dd72182f9c76","text":"Use AWS lambda to automatically deploy the load balancer once your CloudFormation Template has finished provisioning.","correct":false},{"id":"57bd133b2237789f413b1486e2bac4a5","text":"Create an Elastic Beanstalk Deployment stack.","correct":false},{"id":"d605a2578632e3bf9fe88e8b645c335f","text":"Reference the template as part of a nested stack.","correct":true},{"id":"b8291da95d71714b3f5314572a6d5e47","text":"Create a dedicated template for the load balancer.","correct":true}]},{"id":"1ea8aa1e-9454-49b0-b4e2-379eadf674e0","domain":"CostOptimized","question":"You are an employee at a communications firm that is in the process of migrating its data to Amazon S3. The data will be stored in buckets and is sent to customers to do as they see fit. However, certain data is frequently changed when customers request revisions, while the rest of the data is rarely changed. You must be able to immediately access certain data while minimizing costs. Which S3 storage class should you choose?","explanation":"While S3 Glacier is a low-cost storage class, it is for data archiving and thus not ideal for frequent access or changes to data. And S3 One Zone-Infrequent Access is also low-cost, but it does not address the frequently changed data. Although S3 Standard is a suitable choice, since it addresses frequent access, it is not the least expensive choice for the less frequently accessed data. If it was hard to determine which data is frequently changed and which isn’t, S3 Standard might have been the most cost-effective choice. But in this case, S3 Intelligent Tiering is. Intelligent Tiering stores data in two access tiers: one tier is optimized for frequently accessed data while the other is a lower-cost tier for infrequent access.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false},{"id":"5605213ade8877d8d601580dbd0a8aa2","text":"S3 One Zone-Infrequent Access","correct":false},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":true}]},{"id":"952a1ff3-9e44-4ea3-99ba-886bca88a621","domain":"SecureSolutions","question":"You plan to consolidate the two AWS accounts that you currently have so that you can protect them and their resources centrally against common web exploits and attacks. Which of the following combinations of AWS services can do that for you?","explanation":"You need AWS Organizations for consolidating your accounts, so this automatically rules out WAF and Shield as the right answer. While WAF protects your resources against web exploits and AWS Shield protects them against web attacks, neither tool is a centralizing protection service. Rather, it is Firewall Manager that will simplify your WAF and AWS Shield tasks by providing a single point of control. Notably, your AWS accounts being in an organization is one of the prerequisites for using Firewall Manager.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/fms-chapter.html","title":"AWS Firewall Manager"}],"answers":[{"id":"8421d513e178656de832265230613532","text":"AWS Web Application Firewall (WAF) and AWS Shield","correct":false},{"id":"32a8ea3869fee49bca61f4cabbfac398","text":"AWS Organizations and AWS WAF","correct":false},{"id":"cf658332aeff3680485add6485a734ac","text":"AWS Organizations and AWS Firewall Manager","correct":true},{"id":"886aafc053322ceac05e481b60abf924","text":"AWS Organizations and AWS Shield","correct":false}]},{"id":"e44a6772-240a-4c67-af0a-1119285833f9","domain":"ResilientDesign","question":"The large manufacturing company you work for is interested in moving their production estate to AWS. They run a Joomla store which utilizes MySQL on the back end. Currently, they also use clustered MySQL databases in an active/passive configuration at a single site. In moving to AWS, they want an active/passive configuration across 2 geographically distinct locations, with automatic failover between the two. As their solutions architect, which of the following RDS options should you recommend?","explanation":"To automatically failover from one geographic location to another you should use Multi-AZ for RDS.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/#Failover_conditions","title":"RDS Failover Conditions"}],"answers":[{"id":"955edcbe47cfada50233bc45752305b7","text":"RDS with Cross Region Replication","correct":false},{"id":"57513d6064870e41de997c1e161825c7","text":"RDS Multi-AZ","correct":true},{"id":"c1d3dc1d00857a4c8a41667c4089187c","text":"RDS Read Replicas","correct":false},{"id":"b1e142eeffe2e60520001a47e8ea488d","text":"RDS with Cross Region Failover","correct":false}]},{"id":"9fc041cf-1305-46e0-9851-bbf11b320f3c","domain":"Performant","question":"You need to develop an infrastructure that can be replicated and deployed in another AWS Region in a matter of minutes. Which AWS service might you use to build a reproducible, version-controlled infrastructure?","explanation":"AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"About CloudFormation"}],"answers":[{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"c0f075697e6a50da6356e4718f5a1de0","text":"CloudWatch Template","correct":false},{"id":"d8d0959d6dfc410044ed02441ee86c96","text":"EC2 AMIs with EBS snapshots","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false}]},{"id":"eba390fe-7699-47c0-b51f-f38cbc948112","domain":"CostOptimized","question":"What is the 'first-byte' latency when retrieving data from Glacier?","explanation":"You should expect data retrieval latency of 3-5 hours when retrieving data from Glacier.","links":[{"url":"https://aws.amazon.com/glacier/faqs/#dataretrievalpolicies","title":"Glacier Data Retrieval Policies"}],"answers":[{"id":"99d888e6893ac480abd21ecb8a18e060","text":"3-5 hours","correct":true},{"id":"b86a4270946442f3b17bd51e3aa226ce","text":"> 5 hours","correct":false},{"id":"72ab9d0304d3e84c6aa2dd15eda282f2","text":"1 hour","correct":false},{"id":"6619a70f8ab8877e4131643fb8ded723","text":"2 hours","correct":false}]},{"id":"15c91139-c33f-4583-8864-dba8207c73a0","domain":"Performant","question":"Your organisation is running a business critical application with a backend MySQL DB that has been experiencing performance issues due to an increase in customers hitting the website. Management are concerned that the existing solution will not handle the anticipated customer growth over the next 12 months and any outages could lead to a loss in potential revenue.\\n You’ve been asked to develop a suitable AWS cloud based solution that will best meet the requirements of the organisation and require minimal operational overhead. Which AWS DB service will be most suitable for your organisation?","explanation":"Aurora natively maintains 2 copies of your data in each availability zone (3 AZs x 2 = 6 copies) within a region providing the highly available solution needed for this scenario. It also supports storage autoscaling and CPU and Memory scaling. Aurora also provides up to 5 times improved performance over a traditional DB installation.  MySQL and PostgreSQL support multi-AZ deployments and read replicas, but this requires additional configuration. CPU, memory and storage scaling is not automated and requires additional configuration and design consideration. Redshift does not support Multi-AZ deployments.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/","title":"Amazon Aurora FAQs"}],"answers":[{"id":"f52a9d91766886fb3a524dd06d1581cb","text":"Redshift","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":true},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false}]},{"id":"181cab5b-23af-4947-8821-51ed16f55a7d","domain":"ResilientDesign","question":"A large jewelry distributor has installed their new inventory application in a development environment on AWS. After completing their testing, they're ready to deploy the application into its production environment. They've been using VPN connections for the development phase, but they need to upgrade to a higher resiliency network connection scheme to communicate back and forth from other on-premises business applications that are mirrored across two data centers. Testing results indicate that some transactions may require more than a 1.25 Gbps connection to ensure a quality customer experience. Which network architecture will provide the appropriate resiliency for this inventory application?","explanation":"For critical production workloads like an inventory application that require high resiliency, it is recommended to have one connection at multiple locations. Such a topology ensures resilience to connectivity failure due to a fiber cut or a device failure as well as a complete location failure. Use of a Direct Connect Gateway will provide access to any AWS Region from any Direct Connect location. Installing separate connections terminating on separate devices in more than one location gives another layer of resiliency, but that configuration, along with its added costs, is not necessary for this use case. Creating separate connections to only a single Direct Connect location from a single data center does not mitigate the risk of full facility outages. AWS doesn't recommend using a VPN as a backup for connections that require speeds greater than 1 Gbps.","links":[{"url":"https://aws.amazon.com/directconnect/","title":"AWS Direct Connect"},{"url":"https://aws.amazon.com/directconnect/resiliency-recommendation/","title":"AWS Direct Connect Resiliency Recommendations"}],"answers":[{"id":"508aa0084ed6faa994e17273231899f1","text":"Create an AWS Direct Connect connection from one data center to an AWS Direct Connect location. Install another AWS Direct Connect connection from the other data center to a different AWS Direct Connect location.","correct":true},{"id":"6dd9941a3ca38128754b0fb66f8642cb","text":"Install two AWS Direct Connect connections to an AWS Direct Connect location from two different network devices in one data center. Create another two AWS Direct Connect connections to a different AWS Direct Connect location from two different network devices in the other data center.","correct":false},{"id":"a4c6c0827f35637ae33dfd03b1b3e0f6","text":"Configure two AWS Direct Connect connections to an AWS Direct Connect location from two different network devices in one data center.","correct":false},{"id":"8a967bd089e29673bac3c13fd00105ca","text":"Implement an AWS Direct Connect connection from one data center to an AWS Direct Connect location. Establish a VPN connection from the other data center as a backup.","correct":false}]},{"id":"22b1c6a0-1e15-4a38-8a17-4a90fa381ffa","domain":"ResilientDesign","question":"Your business is evaluating several database technologies from AWS - one of the major requirements is the ability to withstand an Availability Zone outage within a single database cluster. Which of the following AWS Database services does NOT meet this requirement?","explanation":"A RedShift DB cluster can only be deployed in a single AZ. All other RDS Databases: MS SQL, PostgreSQL, MySQL, Oracle and MariaDB natively support Multi-AZ deployments. Although Redshift can be architected in a way that has Availability Zone level redundancy, this requires the use of multiple RedShift clusters, and manually setting up DB to DB replication across AZ’s, and therefore does not satisfy the requirement.","links":[{"url":"https://aws.amazon.com/redshift/faqs/","title":"Amazon Redshift FAQs"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"Amazon Relational Database Service"}],"answers":[{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"35f802e4a5e1cbdf3f99a71a86ae3153","text":"RedShift","correct":true},{"id":"d2727816fa1087ddac7dff69e35c5536","text":"MS SQL","correct":false}]},{"id":"c4f7d0f0-4b57-41b4-a5b1-109004f29af1","domain":"Performant","question":"A CRM application runs in your data center and you have disaster recovery instances running in the AWS cloud. The on-premises CRM application requires low-latency access to all of the storage, as the entire dataset is accessed frequently. Which architecture will provide the highest performance efficiency for your business?","explanation":"Storage Gateway Volume Gateway in the stored volume configuration keeps the entire dataset on-premises and asynchronously backs up point-in-time snapshots to Amazon S3. This provides low-latency access to the entire dataset on-premises. The snapshots can be recovered to EC2 instances. Storage Gateway Volume Gateway in cached mode keeps frequently accessed data on-premises, so it would perform many S3 reads to access the entire dataset. Using an on-premises backup solution or a Storage Gateway file gateway would require the EC2 instances to use different storage access techniques than the on-premises environment.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html","title":"What Is AWS Storage Gateway"}],"answers":[{"id":"2913578801d8d764ddbef31fe86af4b2","text":"Deploy a Storage Gateway file gateway as a network file share","correct":false},{"id":"27f55f1ffd3c7df753670476a47be8d9","text":"Use your on-premises backup solution to move the data to S3 each night for use by the EC2 instances in a disaster scenario","correct":false},{"id":"86480a8866121094f21ba24ad4a8c13c","text":"Implement a Storage Gateway Volume Gateway in cached mode and perform snapshots","correct":false},{"id":"6c5b3c0e5b4db806f92ab9d4ab500667","text":"Implement a Storage Gateway Volume Gateway in stored mode and perform snapshots","correct":true}]},{"id":"191d9026-c3aa-48b5-ad59-cd1bd9f73477","domain":"SecureSolutions","question":"A developer accidentally deleted a couple of PostgreSQL database tables in the staging environment. Since you are using AWS RDS, you are planning to restore it using the most recent backup of the database. Select the invalid statement.","explanation":"If the backup requires more time than allotted to the backup window, the backup continues after the window ends, until it finishes.","links":[{"url":"https://aws.amazon.com/rds/faqs/","title":"Amazon RDS FAQs"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html","title":"Working With Backups"},{"url":"https://aws.amazon.com/rds/details/backup/","title":"Amazon RDS Backup and Restore"}],"answers":[{"id":"cd946430c17b33996859165657c3ed9b","text":"Automated backups occur daily during the preferred backup window. If the backup requires more time than allotted to the backup window, the backup stops and you will be notified.","correct":true},{"id":"a5f8467765f659b47dccd4fc5d99b456","text":"Amazon RDS provides two different methods for backing up and restoring your DB instance(s) - automated backups and database snapshots. DB Snapshots are user-initiated and enable you to back up your DB instance in a known state as frequently as you wish, and then restore to that specific state at any time.","correct":false},{"id":"68b8201b4e2afe07df1390ada0799ec1","text":"Your Amazon RDS backup storage for each region is composed of the automated backups and manual DB snapshots for that region. Your backup storage is equivalent to the sum of the database storage for all instances in that region.","correct":false},{"id":"86d5948791418a3dacfaccf67623885c","text":"You can set the backup retention period to between 0 and 35 days. Setting the backup retention period to 0 disables automated backups. The default backup retention period is seven days if you create the DB instance using the console.","correct":false}]},{"id":"955a81c8-335f-4c4c-9841-5092fb517bba","domain":"ResilientDesign","question":"A team is migrating a three-tier web application to AWS.  Currently the application runs from a single server which stores session information about user transactions.  As part of migration the team wants to take advantage of the High Availability that AWS provides by deploying on to simple low specification ec2 instances across multiple Availability Zones.  The team is aware that the application might provide an inconsistent experience if users are load-balanced between servers storing different state information.  Which options may allow you to move the application into AWS with minimal additional delay?","explanation":"The best answer here is to use sticky sessions on the ELB. This will route requests from a user to the same server every time, ensuring their session details are preserved.  Route 53 weighted or multi-value routing will not ensure routing to the same server each time. It is possible to share certain types of EBS volumes across ec2 instances, however they cannot be across AZs, and the EBS types would not fall into the description 'simple low specification'.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-target-groups.html#sticky-sessions","title":"Sticky Sessions"},{"url":"https://aws.amazon.com/blogs/aws/new-multi-attach-for-provisioned-iops-io1-amazon-ebs-volumes/","title":"Multi-Attach for Amazon EBS Volumes"}],"answers":[{"id":"f6d1002ac85996490667b2b8fee9586d","text":"Deploy the application to two EC2 instances with shared EBS storage to share the session details between instances","correct":false},{"id":"f159b6f5434eb8067673b979c8b8bea6","text":"Deploy the application to two EC2 instances and enable sticky sessions on the Elastic Load Balancer","correct":true},{"id":"6f54375e0f74acb0a1a330c3bc2ec01a","text":"Deploy the application to two EC2 instances and use Route 53 to perform weighted routing of users to the same server each time","correct":false},{"id":"5617928a445d24401162686f8b7c099d","text":"Deploy the application to two EC2 instances and use Route 53 multi-value routing to send users to the same server each time","correct":false}]},{"id":"e74fe976-5239-428f-a289-a171092a22e5","domain":"CostOptimized","question":"The volume of transactions coming into your online trading application fluctuates each day depending on market events. Log analyses indicate that on the heaviest volume days, compute demand comes in triple that of the average volume days. These heavy volume days occur about 15 days per year. You also have some workloads that need to process before close of business to provide input to daily reporting functions. How would you structure your mix of EC2 General Purpose Linux instances to obtain the highest cost efficiency?","explanation":"The most cost effective pricing for EC2 General Purpose Linux instances will usually involve a mix of pricing models. In this scenario, since the number of heavy volume days is limited, using a combination of reserved instances sized for the average volume days, on-demand instances to handle transaction volume increases on the heavy volume days, and spot instances to handle workloads that just need to complete by a certain time is the best option.  Spot instances for reporting workloads will cost less than using reserved instances and capacity doesn't need to be guaranteed. 3-year reserved instances are more cost-effective than one-year-term reserved instances. Over-provisioning for all but the 15 heavy volume days each year by using RI to cover heaviest load leaves a lot of underutilised capacity.","links":[{"url":"https://aws.amazon.com/ec2/pricing/","title":"Amazon EC2 Pricing"}],"answers":[{"id":"03f9a4a0692a0ea73ab4d51403b45abb","text":"1-Year Term Standard Reserved Instances for 100% of the average and heavy volume days, and Spot Instances to handle the reporting workloads","correct":false},{"id":"b9561b6540a0f9ae99dee0f11fb11d69","text":"3-Year Term Standard Reserved Instances for 100% of the average volume days, On-Demand instances to handle the spikes from the heavy volume days, and Spot Instances to handle the reporting workloads","correct":true},{"id":"e4422c9ca1969401387bc4262b9cc0a7","text":"3-Year Term Standard Reserved Instances for 100% of the average volume days and the reporting workloads, On-Demand instances to handle the spikes from the heavy volume days","correct":false},{"id":"e1376165009a434d36a5271305c1773a","text":"3-Year Term Standard Reserved Instances for 100% of the average and heavy volume days, and the reporting workloads","correct":false}]},{"id":"3a6323db-58c8-4ddf-a758-288887c972ed","domain":"CostOptimized","question":"You are a small business startup and wanted to host a website for your business. You purchased a Reserved EC2 instance with all upfront payment with one year commitment. Because of difficulties, the website hosting is given to a third party provider to host the website. As the reserved EC2 instance is not required anymore, what are the options available?","explanation":"Reserved instances provide significant savings on Amazon EC2 costs compared to on-demand instance pricing. Reserved instances are not physical instances, but rather a billing discount applied to the use of on-demand instances in AWS account. The Reserved instance applies to a single instance type, platform, scope, and tenancy over a term. Reserved instances once purchased cannot be cancelled. But the unused reserved instances can be sold in the Reserved Instance Marketplace if the eligibility criteria are met. The Reserved Instance Marketplace is a platform that supports the sale of third-party and AWS customers' unused Standard Reserved Instances, which vary in term lengths and pricing options.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html","title":"Reserved Instance Marketplace"}],"answers":[{"id":"cd9f297f2ab1b919d62d05c2aaa09984","text":"The reserved instance can be transferred to another account owned by your friend for a cheaper rate.","correct":false},{"id":"df56e478b94b7cf467346bbdd6b7fb2b","text":"Terminate the EC2 instance so that there will not be any running cost. Submit a request to AWS to refund the cost for remaining tenure.","correct":false},{"id":"fe819908a4d33b8ae37ab227c535e0f7","text":"The reserved instance purchase can be cancelled so that AWS will refund the EC2 instance cost for the remaining tenure.","correct":false},{"id":"86529fdb220411c4056281091b93c2eb","text":"Reserved instance purchases cannot be cancelled. But if the business need changes, these reserved instances may be sold in the Reserved Instance Marketplace.","correct":true}]},{"id":"62ce46dc-9858-4179-b84a-49f85cddb413","domain":"Performant","question":"You maintain an application which needs to store files in a file system which has the ability to be mounted on various Linux EC2 Instances. Which of the following would be an ideal storage solution?","explanation":"Amazon EFS provides scalable file storage for use with Amazon EC2. You can create an EFS file system and configure your instances to mount the file system. You can use an EFS file system as a common data source for workloads and applications running on multiple instances.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEFS.html","title":"Amazon Elastic Files System (Amazon EFS)"}],"answers":[{"id":"270fcb785810d0206945029bb05f4e97","text":"Amazon S3","correct":false},{"id":"f7b96044a16becafecad63df1725e9c8","text":"Amazon EFS","correct":true},{"id":"516729a7c0562425406a22cfe6a2c163","text":"Amazon EBS","correct":false},{"id":"a0d5b037004b9bef739343edbcb14326","text":"Amazon EC2 Instance store","correct":false}]},{"id":"dbb146aa-ae1d-411e-82be-4777bd07c916","domain":"Performant","question":"A financial market dashboard needs to update asset values almost instantaneously for customers across the United States. Updates will be written to the primary application instance which resides in the AWS us-east-1 region. Which database architecture will provide the best performance for consumers of the dashboard's information?","explanation":"With Aurora MySQL you can configure cross-region Aurora Replicas using logical replication to up to five secondary AWS regions. Aurora PostgreSQL currently does not support cross-region replicas. Aurora Replica physical replication can only replicate to one secondary region. Using Aurora over RDS provides multiple read replicas in the deployment region and other benefits automatically without having to configure them.","links":[{"url":"https://aws.amazon.com/rds/aurora/?nc=sn&loc=0","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/?nc=sn&loc=6","title":"Amazon Aurora FAQs - High Availability and Replication"}],"answers":[{"id":"91857d4bed60ff0818ab1d95e0314b9c","text":"Deploy Amazon Aurora MySQL with Aurora Replicas using cross-region logical replication. Create the replicas in the AWS us-east-2 and us-west-2 regions.","correct":true},{"id":"f95722da1c54e4a7b38d775dec9d3952","text":"Implement Amazon Aurora MySQL with Aurora Replicas using cross-region physical replication. Create the replicas in the AWS us-east-2 and us-west-2 regions.","correct":false},{"id":"a3f216bc2a3134a725e71894673ef3cd","text":"Deploy Amazon Aurora PostgreSQL with Aurora Replicas using cross-region logical replication. Create the replicas in the AWS us-east-2 and us-west-1 regions.","correct":false},{"id":"31441ec91d70f043876be523dca440b3","text":"Use Amazon RDS PostgreSQL with read replicas. Create the replicas in the AWS us-east-1, us-east-2, and us-west-2 regions.","correct":false}]},{"id":"22315d49-9040-4de7-ae4f-ead04e5b4966","domain":"CostOptimized","question":"An application that performs statistical analysis on weather data receives files once a week. It assimilates the data in these files with previously collected data via its algorithms, and publishes a report at the end of each month. At unspecified times during the week, interim results need to be made available to meteorologists within minutes. Which architecture will meet the data availability requirements for the solution at the least cost, and with the simplest application code?","explanation":"Hibernating an EC2 instance provides a warm-start capability. When an EC2 instance is hibernated, RAM contents are saved to the EBS root volume. RAM contents are reloaded when the instance is restarted. AWS doesn't charge for the time that an instance is in the hibernated state. Storing data in Amazon DynamoDB costs more than EBS. EMR clusters cost more than EC2 instances. Stopping an EC2 instance clears RAM and requires the application to reload the data from a storage source when the instance is restarted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html","title":"Hibernate Your Instance"}],"answers":[{"id":"e45f5352867fe69bdbc5efaad38e34b2","text":"Process the data on a transient EMR cluster and store temporary results in S3","correct":false},{"id":"1270950fb1ac5049d96bd1c8633745fe","text":"Process the data on EC2 and stop the instance until new data files arrive or an interim results request is made","correct":false},{"id":"79010e5d6c3a7a1b4739890ce79939bd","text":"Process the data on EC2 and store temporary results in Amazon DynamoDB","correct":false},{"id":"591c99dbc7dc2331d09abbc9ee1fb721","text":"Process the data on EC2 and hibernate the instance until new data files arrive or an interim results request is made","correct":true}]}]}}}}
