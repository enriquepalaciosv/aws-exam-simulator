{"data":{"createNewExamAttempt":{"attempt":{"id":"03390be3-aa78-499e-99bf-2c05b9976af4"},"exam":{"id":"c73a95e8-10fc-4816-bca5-cbe93084f2da","title":"AWS Certified Developer - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"8e61dab4-571e-4a97-a6a7-bcbfddddd867","domain":"deployment","question":"You are using CloudFront to serve static website content to users based in multiple locations across the USA, Africa, India and the Middle East. You recently made some significant updates to the website, but users are complaining that they can only see the original content. What can you do you make sure the latest version of the website is being served by CloudFront?","explanation":"If you need to remove a file from CloudFront edge caches before it expires, you can do one of the following: Invalidate the file from edge caches. The next time a viewer requests the file, CloudFront returns to the origin to fetch the latest version of the file. Use file versioning to serve a different version of the file that has a different name.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Invalidation.html","title":"Invalidating Files in CloudFront"}],"answers":[{"id":"cf938fcfef89105b2dc2d97975c87b22","text":"Wait for the cache to expire","correct":false},{"id":"78eef0aaf2d58aea70bfd13a7d03df31","text":"Invalidate the file from the CloudFront edge cache","correct":true},{"id":"6d72e9895d437372eba948f57e50610f","text":"Delete the file from the original location and replace it with a new version","correct":false},{"id":"1215948dd7c3245305713d0ec57cae6f","text":"Update the file in the original location and reset the cache timestamp","correct":false}]},{"id":"c73f812b-373b-4429-9a32-a3d71186c137","domain":"deployment","question":"Your application needs 100 strongly consistent reads on items that are 9KB in size every second. How many units of read capacity units should you provision?","explanation":"9KB rounds up to 12KB. 12KB/4KB=3 strongly consistent read capacity units each. 3*100=300 strongly consistent read capacity units.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ProvisionedThroughput.html","title":"Throughput Capacity for Reads and Writes"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","title":"DDB - Read Consistency"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/CapacityUnitCalculations.html","title":"Calculating CU"}],"answers":[{"id":"94f6d7e04a4d452035300f18b984988c","text":"300","correct":true},{"id":"3644a684f98ea8fe223c713b77189a77","text":"200","correct":false},{"id":"7ef605fc8dba5425d6965fbd4c8fbe1f","text":"150","correct":false},{"id":"9de6d14fff9806d4bcd1ef555be766cd","text":"350","correct":false}]},{"id":"6a5ea0b3-2527-4c20-9410-d8807d16fcd3","domain":"security","question":"An organization is hosting their static website on S3, using a custom domain name. Users have started reporting that their web browsers' are alerting them to the fact that the organization's website is \"Not Secure\" because it is not served via a secure HTTPS connection.\n\nWhat is the easiest way to start serving the website via HTTPS?","explanation":"S3 buckets do not directly support HTTPS with a custom domain name. The simplest solution is to create a CloudFront distribution and set its origin to the S3 bucket. CloudFront allows you to specify a custom domain name, and supports managed certificates via Amazon Certificate Manager.\n\nEnabling AES-256 Default Encryption on the S3 bucket only affects the object at rest.\n\nApplication Load Balancers do support SSL termination but do not support S3 as a target.\n\nAWS Shield relates to Distributed Denial of Service protection, not encryption over the wire.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-requests-s3/","title":"Use CloudFront to serve HTTPS requests for Amazon S3"}],"answers":[{"id":"d76d398f54d04a531867ae84eda26050","text":"Add an Application Load Balancer in front of the S3 bucket and enable SSL termination.","correct":false},{"id":"6d63f6dae98a20c7db6446021c83e7f5","text":"Enable AWS Shield on the S3 bucket. Browsers automatically detect that Shield is enabled and report that the website is secure.","correct":false},{"id":"674d0590e06799926f232e63b73894a8","text":"Add a CloudFront distribution in front of the S3 static website, which supports HTTPS with a custom domain name.","correct":true},{"id":"27631f4c194c5ea5116e308788e945f2","text":"Enable AES-256 Default Encryption on the S3 bucket, which ensures all content is delivered via HTTPS.","correct":false}]},{"id":"868cb94f-ce60-4590-bfd2-60e8295cc413","domain":"security","question":"You are developing a online-banking website which will be accessed by a global customer base. You are planning to use CloudFront to ensure users experience good performance regardless of their location. The Security Architect working on the project asks you to ensure that all requests to CloudFront are encrypted using HTTPS. How can you configure this?","explanation":"Viewer Protocol Policy defines the protocols which can be used to access CloudFront content","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.html","title":"Requiring HTTPS for Communication Between Viewers and CloudFront"}],"answers":[{"id":"052066815497ced9f9852e55d66c6782","text":"Set the Request Protocol Policy to redirect HTTP to HTTPS","correct":false},{"id":"c40022183e6d5dd97e4c778332064ed2","text":"Set the Viewer Protocol Policy to redirect HTTP to HTTPS","correct":true},{"id":"ae41866f6b2df14a344847e9629076db","text":"Set the User Protocol Policy to redirect HTTP to HTTPS","correct":false},{"id":"659099387a57b1f316abf3c6afac459d","text":"Set the Session Protocol Policy to redirect HTTP to HTTPS","correct":false}]},{"id":"ea9dc476-332a-424f-a806-8a535a8b516e","domain":"deployment","question":"You want to quickly deploy and manage an application in the AWS Cloud without having to learn about the infrastructure that runs the application. Elastic Beanstalk is the first service that comes to mind. You have written you application with C#. How would you launch your application on Elastic Beanstalk in the most efficient manner?","explanation":"AWS Elastic Beanstalk supports custom platforms which lets you develop an entire new platform from scratch, customizing the operating system, additional software, and scripts that Elastic Beanstalk runs on platform instances. This flexibility enables you to build a platform for an application that uses a language or other infrastructure software, for which Elastic Beanstalk doesn't provide a managed platform. In addition, with custom platforms you use an automated, scripted way to create and maintain your customization, whereas with custom images you make the changes manually over a running instance. Rewriting your application would not be the most efficient way if you can create your own platform. Launching an EC2 instance would still require you to manage your own infrastructure. OpsWorks manages infrastructure deployment by organizing applications into layers to provision EC2 instances and resources for an application.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/custom-platforms.html","title":"Elastic Beanstalk Custom Platforms"}],"answers":[{"id":"5d283fee57c43b00226df6388edd5bb7","text":"Use EC2 instance. Launch the application on an EC2 instance and use CloudFormation to automate infrastructure provisioning.","correct":false},{"id":"a55638d3d79efef4debfe4f43fcf4c40","text":"Rewrite your application in Python as C# is not a supported programming language.","correct":false},{"id":"0993d2ef16ec086413357c635d131d1c","text":"Create your own Elastic Beanstalk platform using Packer. Use this platform for your application.","correct":true},{"id":"15978d42b93994c5fa1bdaaa66df8564","text":"Use AWS OpWorks instead to launch your application that will help automate deployment and configurations for your application.","correct":false}]},{"id":"9382a270-2c44-45b2-95f3-79d0cf319120","domain":"mon-trb","question":"A developer has been tasked with enabling Access Logs on the Application Load Balancer that sits in-front of their web services. As part of this task, they must configure a location to which the logs are delivered.\n\nTo what AWS service can Access Logs from an Application Load Balancer be delivered?","explanation":"S3 is the only service supported by AWS for receiving ALB access logs.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html","title":"Application Load Balancer Access Logs"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false},{"id":"594025cae6dfa6b9073dc25de93ddb56","text":"Kinesis","correct":false}]},{"id":"1afa6661-6523-49f7-912c-46b740714117","domain":"deployment","question":"You are deploying a number of Lambda functions using CloudFormation. Which section of the CloudFormation template should you use to define your Lambda resources?","explanation":"Use the Resources section of the CloudFormation template to define the resources you are going to deploy, e.g. EC2 instances, S3 buckets, IAM roles, Lambda functions etc.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"},{"url":"https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-lambda-state-machine-cloudformation.html#lambda-state-machine-cfn-step-2","title":"Example CloudFormation Template"}],"answers":[{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false}]},{"id":"f0a4c3a7-cde4-426a-80bf-645a82fa8b0e","domain":"deployment","question":"You are developing an online auction application which uses SQS to exchange messages between application components. Some of the messages are between 1GB and 2GB in size. What is the AWS recommended way of managing large messages in SQS?","explanation":"You can use Amazon S3 and the Amazon SQS Extended Client Library for Java to manage Amazon SQS messages. This is especially useful for storing and consuming messages up to 2 GB in size. Unless your application requires repeatedly creating queues and leaving them inactive or storing large amounts of data in your queue, consider using Amazon S3 for storing your data. You can use the Amazon SQS Extended Client Library for Java to manage Amazon SQS messages using Amazon S3. However, you can't do this using the AWS CLI, the Amazon SQS console, the Amazon SQS HTTP API, or any of the AWS SDKs—except for the SDK for Java.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"bfbc5038d999f6f0ab92b309e50255df","text":"Store the messages in SQS","correct":false},{"id":"eb81c01f6b821dc9333c84f06831acac","text":"Use the SQS API to manage SQS messages","correct":false},{"id":"03106345f4886f6b4b406f2769d6384f","text":"Use the Amazon SQS Extended Client Library for Java to manage SQS messages","correct":true},{"id":"36d3451512daf210b2d21dcbb244f4e3","text":"Store the messages using DynamoDB","correct":false},{"id":"331185071d9d6e99abcc36e4f3f31f92","text":"Use the AWS Java SDK to manage SQS messages","correct":false},{"id":"b6227350f95f0bdacaf98a814df335a6","text":"Store the messages using S3","correct":true},{"id":"8f3287e8c8645a8ce6387775506f8bf3","text":"Use the SQS CLI to manage SQS messages","correct":false}]},{"id":"c90384c4-a4e3-44cd-909d-9c75fd296455","domain":"security","question":"You are running an application on an EC2 instance. The application needs to be able to access an S3 bucket to read and write data. Which of the following is the best approach to enabling the EC2 instance to access your bucket?","explanation":"Storing credentials in EC2, in the code or in databases is not recommended. Using an IAM role with the requisite permissions and associating that with your EC2 instance is the recommended approach.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html","title":"Using an IAM Role To Allow EC2 Access To S3"}],"answers":[{"id":"cae4292072ddb87ec39678934d1edc5d","text":"Use an IAM role with permissions to read and write to the bucket","correct":true},{"id":"9a58eab1d5aec409abbb6212545b5d45","text":"Store AWS credentials within the application code","correct":false},{"id":"2e9ca3aed8c9e4854687f9556f8e5b1a","text":"Store AWS credentials locally on the EC2 instance","correct":false},{"id":"53f6cd0aebbfa4fcbc2c8102ece8c9d8","text":"Store an access key and secret access key in a DynamoDB table","correct":false}]},{"id":"4b9c267c-f41d-4325-919e-7863e0abb6f3","domain":"development","question":"A three-tier web application is deployed using CloudFormation template. How can the CloudFormation developer ensure that the database resource is saved for backup purposes upon stack deletion?","explanation":"The DeletionPolicy attribute can be used to preserve a specific resource when its stack is deleted. The DeletionPolicy Retain option can be used to ensure AWS CloudFormation keeps the resource without deleting the resource.  The Stack Termination Protection feature enables protection against accidental deletion of an entire stack, not preservation of a specific resource. Similarly, the 'cloudformation:DeleteStack' Action applies to entire stack(s).","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html","title":"DeletionPolicy Attribute"}],"answers":[{"id":"558cc27970e2b64a29bdc85f381b8cb9","text":"Set the DeletionPolicy to Retain in the CloudFormation template.","correct":true},{"id":"6983aeb4c0d42bb293c8ec93966aedbb","text":"Set the DeletionProtection to True in the CloudFormation template.","correct":false},{"id":"eee064b70f79422e8511f18b251253ef","text":"Create IAM Policy with Effect of Deny for 'cloudformation:DeleteStack' Action.","correct":false},{"id":"8093dacb1a766d0f91fa60e48baa87ed","text":"Set Stack Termination Protection to Enable.","correct":false}]},{"id":"5820892f-2759-4cd8-be11-8b2dbcc5d1b5","domain":"development","question":"Your Lambda function requires a few libraries which are not available as standard in the Lambda runtime environment. Which of the following is a recommended way to make the libraries available to your function?","explanation":"A deployment package is a ZIP archive that contains your function code and dependencies. You need to create a deployment package if you use the Lambda API to manage functions, or if you need to include libraries and dependencies other than the AWS SDK. You can upload the package directly to Lambda, or you can use an Amazon S3 bucket, and then upload it to Lambda. If the deployment package is larger than 50 MB, you must use Amazon S3.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html","title":"AWS Lambda Deployment Package"}],"answers":[{"id":"d43e57bd5184ca5787e6827646b30fa5","text":"Create a handler function downloads the libraries you need","correct":false},{"id":"c5aba36fa7ce91daccd7cb3a4e3cf9a1","text":"Add the dependencies to S3 and create an environment variable to reference them","correct":false},{"id":"24030d747fefc92f6c68f2934974ba96","text":"Upload the deployment package to Lambda","correct":true},{"id":"f21d58a10f3609c9feab39647fa533cf","text":"Store the deployment package in an S3 bucket and then upload it to Lambda","correct":true},{"id":"585237ca133be02e26db990e229ab6f4","text":"Create a custom runtime which includes the libraries you need","correct":false},{"id":"a74c95d1ac4aa0e191861afb10c345d4","text":"Create a deployment package containing your function code and libraries","correct":true}]},{"id":"1ff687ab-5cc2-477e-a5d6-2b7341f37562","domain":"refactoring","question":"You are developing a serverless application and you need somewhere to persist user state data. Which if the following would you recommend?","explanation":"Out of the possible answers, DynamoDB is the only solution that can be used to save state. Lambda by itself does not persist data, API gateway is used to expose APIs to make them available to your users and the Serverless Application Model (SAM) is a framework to build serverless applications.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"What is SAM?"},{"url":"https://aws.amazon.com/lambda/","title":"What is Lambda?"},{"url":"https://aws.amazon.com/api-gateway/","title":"What is API Gateway?"},{"url":"https://aws.amazon.com/serverless/","title":"Serverless"}],"answers":[{"id":"2ef9dd82927a3196ca2df3fc0cdf2e0b","text":"API Gateway","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"9c6ff7999454bedded4c4a17f7a61b99","text":"Serverless Application Model","correct":false},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false}]},{"id":"3eb49e2e-25b6-4fe6-8bbe-e3ccedcd1efd","domain":"security","question":"A developer is looking to implement a load balancing solution for web-based service oriented application deployed in AWS EC2. The solution must support path based routing and all communication to the users must be encrypted. What is the most performant method to achieve these requirement?","explanation":"The application requirement states support for path based routing. This means that we must use an Application Load Balancer as Network Load Balancer does not have this feature. It is best practice to deploy the SSL certificates on the Load Balancer. This implements SSL termination on the load balancer and off-loads this task from the application, thus reducing the load on EC2 instances. Additionally, it removes the requirement of distributing the certificate to all target EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html","title":"Create an HTTPS Listener for Your Application Load Balancer"}],"answers":[{"id":"b97b895cbdc513c48c5bfb7564a38aa7","text":"Use Network Load Balancer. Deploy SSL certificates on the EC2 instances.","correct":false},{"id":"a5a020608230cb06058ddd6291c7886a","text":"Use Application Load Balancer. Deploy SSL certificates on the EC2 instances.","correct":false},{"id":"7ebcbebf7f00c8f17f377813b31cc76e","text":"Use Network Load Balancer. Deploy SSL certificates on the Network Load Balancer.","correct":false},{"id":"206131d0e41aa9e13214ac701d6f08e2","text":"Use Application Load Balancer. Deploy SSL certificate on the Application Load Balancer.","correct":true}]},{"id":"2692273f-3f45-48a9-8db1-bd08542db08c","domain":"security","question":"You need to allow another AWS account access to resources in your AWS account, what is the recommended mechanism to configure this?","explanation":"Roles are the primary way to grant cross-account access.  With IAM roles, you can grant third parties access to your AWS resources without sharing your AWS security credentials. Instead, the third party can access your AWS resources by assuming a role that you create in your AWS account.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_terms-and-concepts.html","title":"IAM Roles and Cross Account Access"},{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_third-party.html","title":"Providing Access to AWS Accounts Owned by Third Parties"}],"answers":[{"id":"bf90de82812c0e6a3c80cf9c3579975d","text":"Use Cognito to allow the third party to sign-up as a guest user to get temporary access to your account","correct":false},{"id":"573753accb681d032a85cdc6773bf08e","text":"Configure Web Identity Federation to allow them to log in to your account","correct":false},{"id":"b2cc52fe397cf7827353562b7ca92e91","text":"Configure cross account access by creating a role in your account which has permission to access only the resources they need. Allow the third party account to assume the role based on their account ID and unique external ID","correct":true},{"id":"353c57d4949d688d413dfe136b6a3e2b","text":"Provide AWS credentials to the third party so that they can log into your account and access the resources they need","correct":false}]},{"id":"71b8b773-eed1-4335-9631-5bfe132f16c7","domain":"development","question":"You are the development lead on a large project to launch a new e-commerce website specialising in fishing supplies. Your developers are located in India, USA and the Middle East. You need to find a source code repository that everyone can use, and that will allow developers to continue to work on their code even when they are not connected to the internet. Which of the following would you suggest to the team?","explanation":"CodeCommit is based on Git, which is a distributed version control system, meaning there is no single, central place where everything is stored. In a distributed system, there are multiple backups in the event that you need one. This approach also means that you can work offline and commit your changes when you are ready.","links":[{"url":"https://aws.amazon.com/devops/source-control/git/","title":"Source Control In AWS"}],"answers":[{"id":"4e1b47d595e44072d3890d332ead7f86","text":"Run an instance of Git in a docker container on AWS ECS","correct":false},{"id":"c2a2ffe5e9352016e58fe01b3c304de3","text":"Install Git on 2 EC2 instances in an auto-scaling group","correct":false},{"id":"94efdca7e5940d3078c950c64e833082","text":"Use CodeCommit to manage your source code","correct":true},{"id":"c3a56d6c63ca88e19d3e6afc5b896c46","text":"Use CodeBuild in offline mode to manage your source code","correct":false}]},{"id":"b170b108-ed74-40ba-a811-383fa049982d","domain":"mon-trb","question":"You receive a \"timed out\" error message when running a command using the AWS CLI. What could be a possible reason for this?","explanation":"If you see issues when running list commands on a large number of resources, the default page size of 1000 might be too high. This can cause calls to AWS services to exceed the maximum allowed time and generate a \"timed out\" error. You can use the --page-size option to specify that the AWS CLI request a smaller number of items from each call to the AWS service. The CLI still retrieves the full list, but performs a larger number of service API calls in the background and retrieves a smaller number of items with each call. This gives the individual calls a better chance of succeeding without a timeout. Changing the page size doesn't affect the output; it affects only the number of API calls that need to be made to generate the output.","links":[{"url":"https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-pagination.html","title":"AWS CLI Pagination"}],"answers":[{"id":"693a2ee98a96c9712d1720d141c29c5b","text":"You have run a command which is trying to return a large number of items and has exceeded the maximum allowed time to return results","correct":true},{"id":"afdc0b8222f758f2d5101f7516eac7b5","text":"Your network connection is too slow","correct":false},{"id":"9a732fb1da270d734f8c6fd13ec818f7","text":"The AWS service that you are trying to call is taking too long to respond","correct":false},{"id":"6671b1dd34271b2e7f713a895d4dc800","text":"The AWS service that you are trying to call is unreachable","correct":false}]},{"id":"6593608d-3801-4b5d-8947-89efa395825a","domain":"refactoring","question":"You need to monitor application-specific events every 10 seconds. How can you configure this?","explanation":"You need to configure a custom metric to handle application specific events and if you want to monitor at 10 second intervals, you need to use high-resolution metrics. Detailed monitoring reports metrics at 1 minute intervals.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html","title":"CloudWatch Custom Metrics"}],"answers":[{"id":"886f04b8880657a2d07a12c6355639a7","text":"Configure the application to send notifications using SNS every 10 seconds","correct":false},{"id":"da902bf148db5983868bf3383162183a","text":"Select high-resolution metrics in CloudWatch","correct":false},{"id":"8625460160031630c52a466b7a91f16b","text":"configure a high-resolution custom metric in CloudWatch","correct":true},{"id":"f3e15ffbefd8415dda26321a2912dca1","text":"Select detailed monitoring in CloudWatch","correct":false}]},{"id":"3a01c37a-6939-444b-89b0-f73b1f232601","domain":"deployment","question":"You are developing a social media messaging and photo-sharing application which consists of a web front end, with persistent data stored in S3 and RDS. Which of the following instance pricing models should you choose to make running this application as cost-effective as possible?","explanation":"Reserved instances provide a significant discount compared to running instances On-Demand. You can take advantage of Spot Instances to run and scale applications such as stateless web services, image rendering, big data analytics, and massively parallel computations. Dedicated Instances are Amazon EC2 instances that run in a VPC on hardware that is dedicated to a single customer.","links":[{"url":"https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/when-to-use-spot-instances.html","title":"When To Use Spot Instances"},{"url":"https://aws.amazon.com/ec2/pricing/reserved-instances/","title":"When To Use Reserved Instances"},{"url":"https://aws.amazon.com/ec2/pricing/dedicated-instances/","title":"When To Use Dedicated Instances"},{"url":"https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/when-to-use-spot-instances.html","title":"Cost Optimization White Paper"}],"answers":[{"id":"04be777131f511081730fe2b34662123","text":"Use dedicated instances for the web servers","correct":false},{"id":"60e31915c1c4910787bf03781555aa97","text":"Use reserved instances for the database","correct":true},{"id":"a057af2fca16fcc4c6997976ea994e95","text":"Use Spot instances for the web servers","correct":true},{"id":"86ed636cf8296c0bedacc99ec10c39f0","text":"Use dedicated instances for the database servers","correct":false},{"id":"1b65fa924bf38ff7e68d41f3495434bd","text":"Use reserved instances for the web servers","correct":false},{"id":"7e5d7958c67ef51985894e5f8b2a25a8","text":"Use Spot instances for the database","correct":false}]},{"id":"42ff013e-95f1-4ead-958d-26a843b0b207","domain":"mon-trb","question":"Your security team have brought in an external auditor to review the security standards across your AWS account. They have identified that your development team have elevated privileges across a number of services, which according to company policy, they should not have access to. You have been asked to help work out which of the IAM policies are granting too much access to the team. Which of the following can you use to find out which policies are granting too many privileges?","explanation":"With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies attached to IAM users, groups, or roles in your AWS account. You can test which actions are allowed or denied by the selected policies for specific resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html","title":"Testing IAM Policies with the IAM Policy Simulator"}],"answers":[{"id":"0863526e514d88cd2d00b39f8dda0920","text":"X-Ray","correct":false},{"id":"b6632fa69795d5fabc908fe75210b177","text":"IAM Policy Simulator","correct":true},{"id":"fa535ffb25e1fd20341652f9be21e06e","text":"Config","correct":false},{"id":"df8a1f2103a58209a3008c02a93162b5","text":"Cognito","correct":false}]},{"id":"a0b993eb-5210-4269-b055-8cb0f8ee0192","domain":"security","question":"Your mobile application needs to read data from DynamoDB. What is the best way to give mobile devices permissions to read from DynamoDB?","explanation":"Web identity federation removes the need for creating individual IAM users. Instead, users can sign in to an identity provider and then obtain temporary security credentials from the AWS Security Token Service.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WIF.html","title":"Using Web Identity Federation"}],"answers":[{"id":"9fb0f3fc8b9734347e97c0b47d69bbba","text":"Create an IAM role that can be assumed by an app that allows federated users.","correct":true},{"id":"baa876447171bf9fb69ccfb1811d73e1","text":"Issue an access key and secret access key to each user.","correct":false},{"id":"85b1805591d84001d38b3d9942fee4fe","text":"Connect your application to an EC2 instance with permission to read from DynamoDB.","correct":false},{"id":"8b6a4ec1dbecce8cd70cbe48c62b5c6c","text":"Create an IAM role for your users.","correct":false}]},{"id":"15a0fdc7-3a7a-42b2-a937-ccfda81d4261","domain":"mon-trb","question":"You have developed a CloudFormation stack in the AWS Management Console. You have a few small number of CloudFormation stacks saved in the Region in which you are operating in. When you launch your stack that contains many EC2 resources, you receive the error Status=start_failed. How would you troubleshoot this issue?","explanation":"Verify that you didn't reach a resource limit. For example, the default number Amazon EC2 instances that you can launch is 20. If you try to create more Amazon EC2 instances than your account limit, the instance creation fails and you receive the error Status=start_failed. Also, during an update, if a resource is replaced, AWS CloudFormation creates new resource before it deletes the old one. This replacement might put your account over the resource limit, which would cause your update to fail. You can delete excess resources or request a limit increase. Saving the template in the CLI or waiting a few minutes will have no impact. The default limit for CloudFormation stacks is 200 and the question explicitly states that there are only a very small number of existing stacks.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/troubleshooting.html","title":"Troubleshooting AWS CloudFormation"}],"answers":[{"id":"2e0c1157e1b5a9bc0a985d53a1a60aa6","text":"Wait a few minutes before saving the template and retry the process.","correct":false},{"id":"dae0c844938d270767115f5f50079227","text":"Use the Support Center in the AWS Management Console to request an increase in the number of CloudFormation stacks.","correct":false},{"id":"3e994bcee300070c97a3c141bc9967bd","text":"Use the Support Center in the AWS Management Console to request an increase in the number of EC2 instances.","correct":true},{"id":"57b1bceff40ae164e764946db0128ea0","text":"Save the template via the AWS CLI.","correct":false}]},{"id":"b5ddd11e-a955-43ce-bc64-c067631c90ab","domain":"development","question":"A Developer is implementing an application that must allow users to subscribe to e-mail notifications. Which AWS service is the best option for implementing this functionality?","explanation":"Amazon Simple Notification Service (Amazon SNS) is a web service that coordinates and manages the delivery or sending of messages to subscribing endpoints or clients. In Amazon SNS, there are two types of clients: publishers and subscribers, which are also referred to as producers and consumers. Publishers communicate asynchronously with subscribers by producing and sending a message to a topic, which is a logical access point and communication channel. Subscribers (that is, web servers, email addresses, Amazon SQS queues, AWS Lambda functions) consume or receive the message or notification over one of the supported protocols (that is, Amazon SQS, HTTP/S, email, SMS, Lambda) when they are subscribed to the topic.","links":[{"url":"https://docs.aws.amazon.com/sns/latest/dg/welcome.html","title":"What is Amazon Simple Notification Service?"}],"answers":[{"id":"3dee8a3d0ac81b151d8a0fa87c673799","text":"WorkMail","correct":false},{"id":"8513f757701b24dbadad3df74e817df5","text":"SES","correct":false},{"id":"ef4ba2f338cdf4b615ed280ff0b2777d","text":"SQS","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":true}]},{"id":"d8b8e087-28cf-41f5-b882-7c4d8e237e4b","domain":"refactoring","question":"You are working on a project to migrate an on-premises website to AWS, your CTO has mandated that wherever possible, Serverless technologies should be used. Which of the following services would you consider for this project?","explanation":"S3, Lambda and DynamoDB are all serverless technologies that could be used to build a website. EC2 and RDS are not considered to be serverless because they are backed by a virtual server.","links":[{"url":"https://aws.amazon.com/serverless/","title":"What is Serverless?"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true}]},{"id":"1710c298-c975-4762-8948-da98b2900d8a","domain":"development","question":"You are developing a web application which has been deployed using Lambda. Today you updated the code and uploaded the new version of your code to the Lambda console. Your test team have begun testing but have reported today that the application seems to still be using the original code. What could be the reason for this?","explanation":"The problem is that the application is referencing the function using an alias pointing to a previous version of the code. When you use versioning in AWS Lambda, you can publish one or more versions of your function. So that you can use different variations of your Lambda function in your development workflow, such as development, beta, and production. Lambda also supports creating aliases for each of your Lambda function versions. Conceptually, an AWS Lambda alias is a pointer to a specific Lambda function version. You can update aliases to point to different versions of functions.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda Function Versioning and Aliases"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/how-to-manage-versioning.html","title":"Lambda Versioning"}],"answers":[{"id":"078229fa3cd7070c357a105fd9f1584d","text":"Your application is referencing the function using a qualified ARN","correct":false},{"id":"2fcd244fd0d8e7833b6bf94d70f01295","text":"Your application is referencing the function using an unqualified ARN","correct":false},{"id":"b099c8a69bf8eac2d39f02ac07d53702","text":"Your application is referencing the function using an alias which points to a previous version of the code","correct":true},{"id":"b67108883bf2590e9f79b9ab834a84cd","text":"Your application is referencing the function using $LATEST","correct":false},{"id":"ce472c670d174e72811d57156684bb1e","text":"You forgot to publish the version","correct":false}]},{"id":"c11f4354-0409-46a1-a058-1e377939c655","domain":"development","question":"You are in a development team working on a popular serverless web application which allows users to book late availability flights and hotels at a significant discount. You occasionally receive complaints that the website is running slowly. After some investigation, you notice that at the time of the complaints, DynamoDB reported a ProvisionedThroughputExceeded error. Which of the following approaches is a recommended way to handle this error?","explanation":"Increasing Lambda capacity will not fix the issue because the problem is with DynamoDB. As the error only appears occasionally, the first thing to do is to ensure that the application is using Exponential Backoff to improve flow control. Increasing the capacity on the DynamoDB table could be considered but only if the problem persists.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff","title":"DynamoDB Error Handling"}],"answers":[{"id":"e7668448048601413de55468a4091b5d","text":"Increase the RAM capacity of the Lambda function","correct":false},{"id":"528fd1044e587b850c48dc8d209cfe11","text":"Increase the read/write capacity of the DynamoDB table","correct":false},{"id":"7f6f787080ee787e0f7554f770e0c693","text":"Ensure your application is using Exponential Backoff","correct":true},{"id":"cbf47ddd16d15ef42c8c335fe895c69f","text":"Increase the CPU capacity of the Lambda function","correct":false}]},{"id":"1116e527-edc2-4085-83cb-c9e079216e32","domain":"deployment","question":"You receive the following response from STS, What is happening here? \r\r <AssumeRoleWithWebIdentityResult> \r\r <SubjectFromWebIdentityToken>amzn1.account.AF6RHO7KZU5XRVQJGXK6HB56KR2A</SubjectFromWebIdentityToken> \r\r <Audience>client.5498841531868486423.1548@apps.example.com</Audience> \r\r <AssumedRoleUser> \r\r <Arn>arn:aws:sts::123456789012:assumed-role/FederatedWebIdentityRole/app1</Arn> \r\r <AssumedRoleId>AROACLKWSDQRAOEXAMPLE:app1</AssumedRoleId> \r\r </AssumedRoleUser> \r\r <Credentials> \r\r <SessionToken>AQoDYXdzEE0a8ANXXXXXXXXNO1ewxE5TijQyp+IEXAMPLE</SessionToken> \r\r <SecretAccessKey>wJalrXUtnFEMI/K7MDENG/bPxRfiCYzEXAMPLEKEY</SecretAccessKey> \r\r <Expiration>2014-10-24T23:00:23Z</Expiration> \r\r <AccessKeyId>ASgeIAIOSFODNN7EXAMPLE</AccessKeyId> \r\r </Credentials> \r\r <Provider>www.amazon.com</Provider> \r\r </AssumeRoleWithWebIdentityResult> \r\r <ResponseMetadata> \r\r <RequestId>ad4156e9-bce1-11e2-82e6-6b6efEXAMPLE</RequestId> \r\r </ResponseMetadata> \r\r </AssumeRoleWithWebIdentityResponse>","explanation":"STS AssumeRoleWithWebIdentity returns a set of temporary security credentials for users who have been authenticated in a mobile or web application with a web identity provider. Example providers include Amazon Cognito, Login with Amazon, Facebook, Google, or any OpenID Connect-compatible identity provider. See the link below for an explanation of the sample response.","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithWebIdentity.html","title":"STS AssumeRoleWithWebIdentity - Sample Response"}],"answers":[{"id":"d3562fb1d308ca43930bef1cd0c73dae","text":"The web identity token that was passed could not be validated by AWS.","correct":false},{"id":"0bbbde1281c67ded59674ac672162af8","text":"STS is returning temporary security credentials to a user who has successfully authenticated with a web identity provider.","correct":true},{"id":"b5df8e29437333169d6d6dd6dfa9da80","text":"The user has requested permission to assume the following role: client.5498841531868486423.1548@apps.example.com","correct":true},{"id":"f8c4ec8e47f0236f83e5f637262e037e","text":"The user with the following ARN is given access to the application: arn:aws:sts::123456789012:assumed-role/FederatedWebIdentityRole/app1","correct":false},{"id":"2b7d1e4142953fa9b0c10630830050ba","text":"The user is allowed to assume the following role: arn:aws:sts::123456789012:assumed-role/FederatedWebIdentityRole/app1","correct":true}]},{"id":"7dbf3269-3e9f-46ed-b413-adf6ea40092f","domain":"development","question":"An organization wishes to use AWS SQS as a job queue. There is no requirement that jobs have to be processed in the order in which they are added to the queue; however, duplicate jobs must not appear in the queue.\n\nHow best can these requirements be implemented?","explanation":"SQS FIFO queues, while guaranteeing message delivery order, also support a Message Deduplication ID. This can be used to detect and ignore duplicate messages within a 5-minute deduplication interval. Standard SQS queues do not have this feature.\n\nUsing DynamoDB to track jobs could also meet the requirements, but would require the organization to manage the duplication detection process themselves; thus, it is not the best solution.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-additional-fifo-queue-identifiers.html","title":"Message Deduplication ID in Message Deduplication ID"}],"answers":[{"id":"fb60ef2b19fbf048dbfbd0391ae8f529","text":"Implement a standard SQS queue.","correct":false},{"id":"2115f8907c04dc2d23d61170928db50d","text":"Lock messages once they are added to the queue to prevent duplicates from being added.","correct":false},{"id":"c228a504700f07a4a3120f940bcae255","text":"Use DynamoDB to track what jobs are in the queue. Check DynamoDB before adding a new job to the queue to ensure it is not a duplicate.","correct":false},{"id":"40b0cd0f9be83c492848af27bb3a7a18","text":"Implement a FIFO SQS queue.","correct":true}]},{"id":"87fa94ce-da14-4dfe-95b7-2664251e3644","domain":"development","question":"What attribute should be set on a message when sent to a SQS queue that prevents the message from becoming visible to consumers of the queue for 300 seconds?","explanation":"DelaySeconds allows the delivery of a message to be delayed for between 0 (default) and 900 seconds before the message becomes visible to consumers of the queue for the first time.\n\nVisibilityTimeout controls the time a message is hidden from consumers *after* it has been consumed.\n\nMessageRetentionPeriod controls how long a message remains available in a queue before it is discarded.\n\nReceiveMessageWaitTimeSeconds controls polling wait time.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"Amazon SQS Delay Queues"}],"answers":[{"id":"7d24beb123793541bb62974b1d96000c","text":"ReceiveMessageWaitTimeSeconds","correct":false},{"id":"32a09171a5c0dc0e3d105afdc109127a","text":"VisibilityTimeout","correct":false},{"id":"4052d7654cde58db70c4c7bddc897056","text":"DelaySeconds","correct":true},{"id":"3ecef87637aa97f59f1688e608394dab","text":"MessageRetentionPeriod","correct":false}]},{"id":"235fa5cd-42b5-4017-af9a-e62d0503651a","domain":"security","question":"You are working on a Lambda function which needs to access data in RDS, which of the below are valid approaches for securely storing the encrypted database connection strings and other secrets which your function needs to use?","explanation":"Parameter Store provides secure storage for configuration data, connection strings, passwords and secrets management. None of the other options are secure.","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html","title":"AWS Systems Manager Parameter Store"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/tutorial-env_console.html","title":"Create a Lambda Function Using Environment Variables To Store Sensitive Information"}],"answers":[{"id":"913d4a9f910c7f6b836d623b39131480","text":"Use Systems Manager Parameter Store","correct":true},{"id":"ca7c47bd30833fb42e5bc78f6c7583be","text":"Use Lambda Environment Variables","correct":true},{"id":"f2523ec5429fa4e1be124d650a69a0f5","text":"Store the encrypted connection string and other secrets in S3","correct":false},{"id":"53708b71a9f9d0c3994b3bd1d470b254","text":"Use DynamoDB to store the encrypted connection string and secrets","correct":false}]},{"id":"86b9ada2-ae5a-450b-8a69-88ffc0c65ee6","domain":"mon-trb","question":"A recent increase in the amount of users of an application hosted on an EC2 instance that you manage has caused the instances OS to run out of CPU resources and crash. The crash caused several users' unsaved data to be lost and your supervisor wants to know how this problem can be avoided in the future. Which of the following would you NOT recommend?","explanation":"Frequent snapshots are not recommended, as they can result in performance degradation. Additionally, these snapshots will not capture users' unsaved data that lives in the instance's memory.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"EBS Snapshots"}],"answers":[{"id":"02f0b48391d2df79b37ab3fe6fed3bbe","text":"Take a snapshot of the EBS volume and re-deploy as a larger instance type.","correct":false},{"id":"641a29c3ebde27a5fa880ae928ae6462","text":"Rewrite the application so that users' unsaved data is frequently written to disk.","correct":false},{"id":"e990838c77c787b8156a1101cebec36e","text":"Take frequent snapshots of the EBS volume during business hours to ensure users' data is backed up.","correct":true},{"id":"65d5964c0293f901c37f0a8b00d46369","text":"Create an auto-scaling group to add more servers when demand is high.","correct":false}]},{"id":"7e589557-fe47-4b17-8c0a-f4afe1a9c764","domain":"mon-trb","question":"Your application servers are behind an Application Load Balancer with sticky sessions configured. However during busy times you are occasionally finding that one of your application servers is becoming overloaded. Which of the following options could help avoid this from happening?","explanation":"The use of Sticky Sessions means that requests which are part of the same session get routed to the same target, which may cause the host to become throttled. ElastiCache can be accessed by multiple servers, allowing the load to be distributed more evenly.","links":[{"url":"https://aws.amazon.com/caching/session-management/","title":"Session Management"}],"answers":[{"id":"b225818943ba4680b8e7dc9d9c376359","text":"Store session state in RDS","correct":false},{"id":"be8019a0436605aff98fc69abd0feeec","text":"Store session state locally on the EC2 instance","correct":false},{"id":"2aa6ae3b5971bedd1a05b4d5636afbac","text":"Store session state in an ElastiCache cluster","correct":true},{"id":"88efe13a943c7fa646b910592ecda2f9","text":"Store session state in memory","correct":false}]},{"id":"ed0618e6-a6db-4b7e-8564-384ae63b0e89","domain":"development","question":"You are working for a small but busy veterinary surgery and you need to design a new DynamoDB table to store information relating to customers, their pets, and any medications that are currently being prescribed. Which of the following attributes would be a good choice for a partition key, in order to achieve maximum provisioned throughput efficiency?","explanation":"When selecting a partition key, you want to distribute the workload evenly across as many partitions as you can, to maximize provisioned throughput of your DynamoDB table. The partition key determines which partition the record will be stored on. To achieve maximum provisioned throughput, choose a partition key with a unique attribute like Customer ID, Product ID, email address, phone number etc. A partition key design that does not distribute I/O requests evenly can create hot partitions which result in throttling and uses your provisioned I/O capacity inefficiently. Values such as Medication, Species and Registration date, are not unique and in some cases may have only a few possible values which could result in hot partitions and inefficient use of provisioned throughput.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-partition-key-uniform-load.html","title":"Designing Partition Keys to Distribute Your Workload Evenly"}],"answers":[{"id":"d37c2bf1bd3143847fca087b354f920e","text":"Customer ID","correct":true},{"id":"22ffd0379431f3b615eb8292f6c31d12","text":"Registration date","correct":false},{"id":"353bd6f65060d17097c3b03141e79cce","text":"Medication","correct":false},{"id":"e1520b5997a532c7889f6e8883920ab8","text":"Species","correct":false}]},{"id":"6d133985-53e5-48d7-a1e9-6db8bb940208","domain":"security","question":"You are working as a Developer for an online retailer. Your Security Architect has requested that any files stored in S3 must be encrypted. However some teams are continuing to upload their files without encrypting them. Which of the following will ensure that only encrypted data is uploaded?","explanation":"There are a few different ways to enforce encryption, however from the provided options, the use of a bucket policy to reject requests that do not include encryption in their header is the best answer","links":[{"url":"https://aws.amazon.com/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/","title":"How to Prevent Uploads of Un-encrypted Objects to Amazon S3"}],"answers":[{"id":"0f6a3c5c345549f63a0da92ac93e45cf","text":"Use a bucket policy that only allows PUT operations which include the x-amz-server-side-encryption parameter in the request header","correct":true},{"id":"e7d6b8da11c238d437edeadb18bf5493","text":"Create a bucket ACL that only allows PUT operations which include the x-amz-encryption parameter in request header","correct":false},{"id":"d61960e2fc2a82679514fe6f3401150f","text":"Select the Encrypted Files Only checkbox in the S3 Permissions tab in the AWS console","correct":false},{"id":"da402b6935d7bb0b6868419dc1fcf54f","text":"Tell all team members to include the x-amz-encryption parameter in request header","correct":false}]},{"id":"b6e02165-99c1-465f-b270-e95ed7b282c6","domain":"deployment","question":"Your distributed application sends and receives a number of large SQS messages, each of which can be up to 2GB in size. You are finding that the messages in one particular queue are getting processed a few seconds faster than expected which is causing problems in your application. The application architect has asked you to introduce a sleep period of 5 seconds which should apply to all the messages in the queue and you have also been asked to avoid storing large amounts of data in SQS. Which of the following changes do you recommend?","explanation":"Delay queues let you postpone the delivery of new messages to a queue for a number of seconds. If you create a delay queue, any messages that you send to the queue remain invisible to consumers for the duration of the delay period. You can use Amazon S3 and the Amazon SQS Extended Client Library for Java to manage Amazon SQS messages. This is especially useful for storing and consuming messages up to 2 GB in size. Unless your application requires repeatedly creating queues and leaving them inactive or storing large amounts of data in your queue, consider using Amazon S3 for storing your data.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"afb12b79c99a2eeace3a062cd3ad4cd6","text":"Use a FIFO queue to postpone the delivery of SQS messages by 5 seconds","correct":false},{"id":"1f11b5e76705a7428ff631dfaae81308","text":"Store the large messages on S3","correct":true},{"id":"64c850e3b6d5e1a54696ff59341cffc2","text":"Use an SQS delay queue to let you postpone the delivery of SQS messages by 5 seconds","correct":true},{"id":"a41630268ea2c21362c11173dd3e5ff1","text":"Store the large messages in DynamoDB","correct":false},{"id":"3b29dadac2fdd775f1294d12bdccec11","text":"Store the large messages in a separate queue","correct":false}]},{"id":"064a1ca2-3ce2-483d-9e44-f0381416aa53","domain":"development","question":"You are developing a CloudFormation template and need to retrieve a string value containing the DNS name of the load balancer from an earlier section of the template. How would to refer to this string value in the most efficient and automated fashion?","explanation":"The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. This is the best choice per documentation and eliminates the need to hardcode values to be able to automate future renditions of the template rather than having to manually change every hard-coded value. The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. The intrinsic function Fn::FindInMap returns the value corresponding to keys in a two-level map that is declared in the Mappings section.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getatt.html","title":"Fn::GetAtt"}],"answers":[{"id":"597e06174b5664dffc6d5fa8752fc74b","text":"Use the condition function Fn::Select to return the value of the string.","correct":false},{"id":"f9121262138f8b6c85cca08c00b4b4f5","text":"Use the condition function Fn::GetAtt to return the value of the attribute","correct":true},{"id":"a458b06d7d68a0755776d692742aebe5","text":"Hardcode the string value by checking the DNS name number ELBs in the Console and insert the value in the template.","correct":false},{"id":"d07c84be22b2e436b377f48b647e144a","text":"Use the condition function Fn::FindInMap to return the value corresponding to the key.","correct":false}]},{"id":"69332ca4-69c7-4b5c-b3fd-3dcc1b2154c6","domain":"security","question":"You would like to test the effect of a new IAM policy which you are planning to attach to a group of developers in your team. Which of the following can you use to check that the policy works as expected?","explanation":"With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies that are attached to IAM users, groups, or roles in your AWS account. You can test which actions are allowed or denied by the selected policies for specific resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html","title":"Testing IAM Policies with the IAM Policy Simulator"}],"answers":[{"id":"b6632fa69795d5fabc908fe75210b177","text":"IAM Policy Simulator","correct":true},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"543096643aa6d28d9fac278e9257783d","text":"Amazon Inspector","correct":false}]},{"id":"fcee1e83-0558-4267-ba27-58a978b7003c","domain":"deployment","question":"You are working on an application which is made up of a number of Lambda functions as well as API Gateway endpoints. Which of the following technologies would you use to build and deploy this application in AWS?","explanation":"CloudFormation and the AWS SAM CLI can be used to deploy serverless applications. Use the Transform section of the CloudFormation template to specify the serverless resources you would like to deploy. The other technologies cannot be used to deploy serverless applications. OpsWorks provides configuration management using managed instances of Puppet or Chef. Elastic Beanstalk is for deploying and scaling web applications on familiar servers such as Apache, Nginx, Passenger, and IIS. CodeBuild is an automated build system, and CodeDeploy deploys your built code to either EC2 or an on-premises server.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"What is the AWS Serverless Application Model?"},{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/appendix-appendix-sam-templates-and-cf-templates.html","title":"CloudFormation & the AWS Serverless Application Model"}],"answers":[{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":false},{"id":"c42aaccedc51aac929c8ae313066f320","text":"OpsWorks","correct":false},{"id":"4d926e7259ad82fea671d810b2211451","text":"AWS Serverless Application Model CLI","correct":true},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true}]},{"id":"daa8b2ee-b810-4e35-947d-9ad26196189d","domain":"mon-trb","question":"You can use X-Ray with applications running on which platforms? ","explanation":"X-Ray works with Lambda, EC2, API Gateway, Elastic Beanstalk and ECS","links":[{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"}],"answers":[{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":true},{"id":"c8f63ecaff5e983a2441126a241c4cfa","text":"ECS","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":false}]},{"id":"7bd7a103-821e-40af-9665-7695fac3de16","domain":"deployment","question":"AWS recommends that you use Multipart Upload for files larger than _____.","explanation":"","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html","title":"Uploading Objects Using Multipart Upload"}],"answers":[{"id":"208b4367cf771ded0e29ff6f9282442e","text":"1GB","correct":false},{"id":"0be25e5b91d25f9db3b4d3dcaf2cfd1f","text":"5GB","correct":false},{"id":"6df47862fbfbd67605dc294d3f41925a","text":"100MB","correct":true},{"id":"84fb7b98e6e50302bf6cc709c92a6192","text":"5TB","correct":false}]},{"id":"87896ba2-d675-4fce-97b9-f144f05d42f1","domain":"security","question":"You are building an S3 hosted website and your website is accessing javascript and image files located in another S3 bucket. How can you enable this? ","explanation":"Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html","title":"Cross-Origin Resource Sharing (CORS)"}],"answers":[{"id":"39e38061c46bfab6a44c6c8b5482763f","text":"Cross Origin Resource Sharing (CORS)","correct":true},{"id":"be48e3ddc7b57744c693982774a47dad","text":"S3 ACLs","correct":false},{"id":"bef5f130edd0f036b2ca659d3295d5c7","text":"IAM roles","correct":false},{"id":"0e0c1a7e0b6fe582226b82afc8eec89b","text":"S3 bucket policies","correct":false}]},{"id":"f8566b59-119b-4a20-9402-3f0b8ab8cf73","domain":"development","question":"You are developing a serverless retail application which includes a mobile app. All your product data is stored in DynamoDB, whilst the application itself runs on Lambda. The product catalogue is updated once every 6 months, to reflect seasonal stock and price updates. Each database read is 3KB in size and the application performs around 20 reads per second. Which of the following DynamoDB settings would you recommend?","explanation":"A read capacity unit represents one strongly consistent read per second, or two eventually consistent reads per second, for an item up to 4 KB in size. Eventually consistent reads provide greater throughput than strongly consistent. In this case the data changes infrequently, so eventually consistent is a good option.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ProvisionedThroughput.html#ProvisionedThroughput.CapacityUnits.Read","title":"DynamoDB Provisioned throughput"}],"answers":[{"id":"bfd40f3271d850d341d74d81e5e0208b","text":"Configure the table to use high performance reads","correct":false},{"id":"b35bcd1ffd25ca5d2feccdfaf102e6bf","text":"Configure the table with 20 read capacity units","correct":false},{"id":"d983271d85e1d9a838703052106e6190","text":"Use eventually consistent reads","correct":true},{"id":"1cff2c2aa83b7775e9cd6b16efc7c78a","text":"Use strongly consistent reads","correct":false},{"id":"e35b7f703854cc79bba03d472f38eaca","text":"Configure your application to use a query rather than a scan","correct":false},{"id":"744a67c638333d2ab1dc7063094dae67","text":"Configure the table with 10 read capacity units","correct":true}]},{"id":"efa5e898-d746-4a5f-b112-11861aa90108","domain":"deployment","question":"A developer is making changes to the CloudFormation template used to deploy an application. They would like to know if any existing resources will be deleted or replaced before applying the template updates. What service feature will enable this?","explanation":"CloudFormation Change sets enable the preview of proposed changes to a stack in order to assess the impact on running resources. This functionality allows the developer to check if any existing resources will be deleted or replaced upon application of the CloudFormation template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html","title":"Updating Stacks Using Change Sets"}],"answers":[{"id":"400f40520b42783d45e80c35c9b18641","text":"CloudFormation Registry","correct":false},{"id":"e340c6d6c2f5866020158726104d63d7","text":"CloudFormation Change Sets","correct":true},{"id":"b5b91cf0fb04ab0cccd3dc8d197bfdaf","text":"CloudFormation Rolling Updates","correct":false},{"id":"e3692dda22879fd00506eaa434a3913b","text":"CloudFormation StackSets","correct":false}]},{"id":"08e64f1f-bcb0-40f6-843c-3457d9588552","domain":"refactoring","question":"A mobile social network application uses AWS SQS to distribute user's friends' profile updates. As the application grows in popularity, the required updates are reaching the 256KB message limit of SQS. What is a suitable solution to this problem?","explanation":"Using compression to reduce the size of the message payload is a possible approach to solving this issue. However, this would only be a temporary solution. As the number of members increased, the payload size would increase and would start to exceed the SQS message limit again. A more flexible approach is to store the update data in S3. This ensures that the data is stored reliably without any concerns regarding the data size. The SQS message payload would then contain a reference to the S3 blob. If the application is written in Java, the AWS SDK for Java supports this functionality out of the box. SNS has the same message payload limit as SQS, so this is not a suitable option. AWS AppSync is a service for enabling development of GraphQL based applications.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"8face15b61dcc69017b29352cd7dc288","text":"Create an SNS Topic. Use SNS to send updates instead of SQS.","correct":false},{"id":"a2b93e7b257a6da054c32b0dd043384e","text":"Use compression to store the update data in a smaller SQS message.","correct":false},{"id":"0f7d51f145a99e3a18dbed75b79df613","text":"Store update data in S3 bucket. Send the reference to the S3 blob in the SQS message.","correct":true},{"id":"520228b4da343e55c373c25f4d422e6e","text":"Use AWS AppSync to synchronize data to mobile app.","correct":false}]},{"id":"45bb762d-32a6-4fc7-a9e3-1377f0161979","domain":"security","question":"Which of the following activities are the responsibility of the customer?","explanation":"Security and Compliance is a shared responsibility between AWS and the customer. The customer assumes responsibility and management of the guest operating system (including updates and security patches), other associated application software as well as the configuration of the AWS-provided security group firewall. AWS is responsible for protecting the infrastructure that runs all of the services offered in the AWS Cloud. This infrastructure is composed of the hardware, software, networking, and facilities that run AWS Cloud services.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"AWS Shared Responsibility Model"}],"answers":[{"id":"a505eb81276d69b88b77d5b605ad4a9a","text":"Safe disposal of storage devices","correct":false},{"id":"a66d0f8d16b1d93bbe53e387d4b62b37","text":"Controls around who can physically access the data center","correct":false},{"id":"24950338a19d0ddaa9b785b69709702f","text":"Encryption of sensitive data","correct":true},{"id":"e64e7c083b43e01c37b09547a9d7fa31","text":"Management of user credentials","correct":true},{"id":"2b169fd2a3342cf14cd9fdfca94943c5","text":"Security Group configuration settings","correct":true}]},{"id":"6cdfb12d-88c9-4182-8761-892327d0d6e1","domain":"security","question":"You are working on a mobile phone app for an online retailer which stores its customer data in DynamoDB. You would like to enable new users to sign-up using Facebook or Google credentials. What is the recommended approach?","explanation":"Using Cognito is the recommended approach to federating with Web ID Providers for mobile applications","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc_cognito.html","title":"Amazon Cognito for Mobile Apps"}],"answers":[{"id":"8a7c438e9d3be3a418abd985f62a5eba","text":"Embed encrypted AWS credentials into the application code, so that the application can access DynamoDB on the user's behalf","correct":false},{"id":"7afe23d8d3d95622b0bc6973be88c599","text":"Write your own custom code which allows the user to log in via a Web Identity Provider and receive an authentication token, then calls the AssumeRoleWithWebIdentity API and exchanges the authentication tokens for temporary access to DynamoDB","correct":false},{"id":"f6b8be7d8470d0f29d80578d719a209e","text":"Once the user has logged in to the Web Identity Provider, use Cognito to exchange the authentication tokens for temporary access to DynamoDB","correct":true},{"id":"f27fa20337c218b3cbc5c69c91585adf","text":"After the user has authenticated with Facebook, allow them to download encrypted AWS credentials to their device so that the mobile app can access DynamoDB","correct":false}]},{"id":"c1271c56-09c1-44e0-9e24-840abbf8ad96","domain":"development","question":"You are deploying a new version of your application using a CodeDeploy In-Place upgrade. At the end of the deployment you test the application and discover that something has gone wrong. You need to roll back your changes as quickly as possible. What do you do?","explanation":"With an In-Place upgrade you will need to redeploy the original version. Only a Blue / Green upgrade allows you to keep the original instances and roll back by routing all requests to the original instances","links":[{"url":"https://docs.aws.amazon.com/codedeploy/latest/userguide/deployments-rollback-and-redeploy.html#deployments-rollback-and-redeploy-manual-rollbacks","title":"CodeDeploy Rollback and Redeploy"}],"answers":[{"id":"f7d2972260a5229eaad04f071022e255","text":"Use the CodeDeploy roll back feature to seamlessly roll back to the previous version","correct":false},{"id":"d2949de6ed3d3a5197775436b9302635","text":"Point all incoming requests to your development environment while you fix the problem with the failed deployment","correct":false},{"id":"63d25b1e978fde1df3b91bb3d47c31a6","text":"Use CodeDeploy to redeploy the previous version of the application","correct":true},{"id":"079d9ac5765ea898c4d08a65d8e35c53","text":"Configure your load balancer to send all incoming requests to the original instances running the old version of the application","correct":false}]},{"id":"e475aa36-e8a9-4d0d-81db-abf30a055ef5","domain":"mon-trb","question":"How can you configure CodeBuild to notify the DevOps team of a failure in the build process?","explanation":"CodeBuild natively supports CloudWatch Events, SNS is a subscription based notification service which integrates with CloudWatch.","links":[{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/sample-build-notifications.html","title":"Build Notifications"}],"answers":[{"id":"4a31b4240a14801eefb085b05f7985a6","text":"Use CloudWatch Events and an SNS topic to notify subscribers of build events","correct":true},{"id":"1448724d0c2de970718ae2bfe3159256","text":"Use CloudWatch Events and SES notifications to send an email to the DevOps team","correct":false},{"id":"d6c5ab1abdce3cd74b1ebe325b88d27e","text":"Use the CodePipeline dashboard to view the CodeBuild events log","correct":false},{"id":"571ab39fe2270d1c1193587ccfd234f1","text":"Add the name of the email group to the notifications section of the CodeBuild console","correct":false}]},{"id":"4a098f64-6cd3-4da4-9c03-e7877d28fb80","domain":"security","question":"Your EC2 instance needs to access a number of files which have been encrypted using KMS. Which of the following must be configured in order for the EC2 instance to successfully read the files?","explanation":"Manage access to KMS keys using a key policy. In the key policy, you must specify the principal (the identity) that the permissions apply to. You can specify AWS accounts (root), IAM users, IAM roles, and some AWS services as principals in a key policy. You can use IAM policies in combination with key policies to control access to your customer master keys (CMKs) in AWS KMS.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/control-access.html","title":"KMS Developer Guide - Access Control"},{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/control-access-overview.html","title":"Managing Access to Your AWS KMS Resources"},{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/iam-policies.html","title":"Using IAM Policies with AWS KMS"}],"answers":[{"id":"d91e2a356c12a95b1768867410657bd4","text":"The Key Policy must allow the IAM user to use the CMK","correct":false},{"id":"17f84c2da6e5c820c31bc9bc9b8ba783","text":"The EC2 instance must have an instance role which has permission run the decrypt operation","correct":true},{"id":"070a7d0f2bcb70c9dc90f21deecf341a","text":"The Key Policy must allow the instance role to use the CMK","correct":true},{"id":"3cb9094c5f7738a8b51960d160e7e9fe","text":"The IAM user associated with the application must have a role which has permission run the decrypt operation","correct":false}]},{"id":"51d0eac3-d55e-4a50-aa5b-c133add86037","domain":"refactoring","question":"A content publishing organization runs its own platform, which uses DynamoDB as its data store. A bug report has come in from the content team. They say that when two editors are working on the same content they frequently overwrite each other's changes.\n\nWhat DynamoDB feature would prevent the most number of overwrite bug reports?","explanation":"Using a condition-expression we can perform a conditional update to an item. The condition must evaluate to true; otherwise, the update operation fails. We can use this feature to make sure the content of an article has not changed since it was last read, before we update it.\n\nacid-expression is incorrect because there is no such expression.\n\nDynamoDB TTL is incorrect because it is for deleting items from DynamoDB after a given duration, not creating a lock.\n\nCalling GetItem immediately before calling UpdateItem would help mitigate the issue, but still leaves a small race condition where condition-expression does not. It is, therefore, not the best solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ConditionExpressions.html","title":"Condition Expressions in DynamoDB"}],"answers":[{"id":"058706dd0f32f05aa73a515774a5dc2d","text":"Call GetItem immediately before calling UpdateItem to ensure the item has not changed.","correct":false},{"id":"b1d92ca8c7500f89cffdf0057251aec1","text":"Include a condition-expression in the UpdateItem command.","correct":true},{"id":"ddb55880d9b1b331207bcb38cebd6dbf","text":"Include an acid-expression in the UpdateItem command.","correct":false},{"id":"9d2d53ddaae2b905e48ea3705529a19c","text":"Apply a time-limited lock to the item while an author is editing it using a DynamoDB TTL.","correct":false}]},{"id":"32c62228-3eab-45da-8f39-58fad0f1b614","domain":"refactoring","question":"You are building an application that requires an Auto Scaling group in order to scale in and out based on demand. You have the proper IAM permissions to create an Auto Scaling group, and also to create EC2 resources for the instances. What additional requirements are necessary for you to move forward?","explanation":"When you create an Auto Scaling group, you must specify the necessary information to configure the Amazon EC2 instances, the subnets for the instances, and the initial number of instances. Before you can create an Auto Scaling group using a launch template, you must create a launch template that includes the parameters required to launch an EC2 instance, such as the Amazon Machine Image (AMI) ID and an instance type. Key pairs and instance roles are optional configuration settings when creating the launch template. You do not have to create a security group beforehand as AWS will provide a default security group. Lifecycle hooks enable you to perform custom actions by pausing instances as an Auto Scaling group launches or terminates them. These are optional configurations that can be attached to an Auto Scaling policy.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/create-asg-launch-template.html","title":"Creating an Auto Scaling Group Using a Launch Template"}],"answers":[{"id":"3f28a4f490092b9940ca1ee7b2395d69","text":"Create a launch template with the key pair and instance role template contents.","correct":false},{"id":"751a4eab03ae6623d345ab81ca8518ff","text":"Create a launch template with the required Amazon Machine Image (AMI) content.","correct":true},{"id":"f5818eb3488ca8de4b28fd00844c91ab","text":"Specify a lifecycle hook to perform actions as the Auto Scaling group launches or terminates instances.","correct":false},{"id":"abc589d96f375d4ec6b80da2495c01f3","text":"Create a security group first and select the appropriate security group under network settings.","correct":false}]},{"id":"0f02f4b2-9d11-4efb-b467-19bc558ef33d","domain":"security","question":"Your application on EC2 must write to an Aurora cluster to store user and purchasing data. Your CISO implements a new company-wide policy that requires all AWS credentials are encrypted and rotated monthly. How would you fulfill the new security policy with minimum administrative burden?","explanation":"AWS designed IAM roles so that your applications can securely make API requests from your instances, without requiring you to manage the security credentials that the applications use. IAM roles are based on temporary security tokens, so they are rotated automatically. Credentials embedded in source code cannot be rotated without it being an administrative burden, and is a bad practice. It’s impossible to retrieve credentials from an S3 bucket if you don’t already have credentials for that bucket. IAM users cannot be associated with resources, and Active Directory authorization will not grant access to AWS resources.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html","title":"IAM Roles for Amazon EC2"}],"answers":[{"id":"c3e276ad3302f173e7d92b40534f2074","text":"Allow the application to fetch the credentials from an S3 bucket with SSE-S3. Upload new credentials monthly.","correct":false},{"id":"fc14a6fe77ae1367c0f776ae96c7379c","text":"Attach an IAM role to the instance with proper credentials.","correct":true},{"id":"5fa27e0170ca1f467557d0d8db5502ff","text":"Encrypt the Aurora clusters' credentials using SHA-256 hash function in the application code, and schedule a CRON job to rotate monthly.","correct":false},{"id":"05a57da8fa8c802639a4f49ed0d59116","text":"Associate an IAM user with the application. Enroll that user with your Active Directory domain to use AD authorization.","correct":false}]},{"id":"616a7b1c-bc17-42a4-b361-74af9a86607f","domain":"development","question":"A financial services company is implementing a payments processing application utilizing DynamoDB tables for its data store. To process payments, the application needs to perform a write operation on a sequence of items, and roll back and reverse all operations in case of any one faulty operation.  What is the best method to accomplish this requirement?","explanation":"DynamoDB transactions feature provides ability to group multiple items into a single atomic transaction and perform all-or-nothing coordinated operations.  This can be done programmatically using the TransactWriteItems operation. The BatchWriteItem operation does not meet the question requirements as it does not guarantee that the actions will be performed on all items as a single atomic coordinated operation. It is possible that only some of the actions in the batch succeed while the others do not. Updating the payments application is not the ideal solution.  It requires application code change and tracking all connected operations and reversing them as required is not trivial to implement.  Using the native transaction ability provided by DynamoDB is a better option.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html","title":"Amazon DynamoDB Transactions: How It Works"}],"answers":[{"id":"cb748237c6e223d0f4506cff55c6b259","text":"Use the TransactWriteItems operation.","correct":true},{"id":"758e6d47da6512d38526cfcfa39bb5c1","text":"Update the application to manage and perform roll-back operations.","correct":false},{"id":"3b08e25699a7082805a9be123c9acbbb","text":"DynamoDB does not support atomic transactions.  Use relational database (such as RDS) that supports atomic transactions.","correct":false},{"id":"aa5647f8e2c8e7147097b79d2b2a5555","text":"Use the BatchWriteItem operation.","correct":false}]},{"id":"0471ebc4-d106-4e3d-a3d4-0f594589ad5f","domain":"deployment","question":"How long can a message be retained in an SQS Queue?","explanation":"Messages will be retained in queues for up to 14 days.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-how-it-works.html#sqs-basic-requirements","title":"SQS - Basic Prerequisites"}],"answers":[{"id":"947d8520f04473da621f2718138f3bc6","text":"30 days","correct":false},{"id":"cb8f14fd3a41cfe1236a3c6b90077ca0","text":"7 days","correct":false},{"id":"0e92d2ae86e7d3e8eece27b399af6ea3","text":"14 days","correct":true},{"id":"e3b481d5297f475abc283227bedbd9b9","text":"1 day","correct":false}]},{"id":"16387bfd-386c-4d6e-a808-8f42694fb73d","domain":"deployment","question":"Your application is using Kinesis to ingest click-stream data relating to your products from a variety of social media sites. Your company has been trending this quarter because a high profile movie star has recently signed a contract to endorse your products. As a result, the amount of data flowing through Kinesis has increased, causing you to increase the number of shards in your stream from 4 to 6. The application consuming the data runs on a single EC2 instance in us-east-1a with a second instance in us-east-1b which is used as a cold standby in case the primary instance fails. How many consumer instances will you now need in total to cope with the increased number of shards?","explanation":"Re-sharding enables you to increase or decrease the number of shards in a stream in order to adapt to changes in the rate of data flowing through the stream. You should ensure that the number of instances does not exceed the number of shards (except for failure standby purposes). Each shard is processed by exactly one KCL worker and has exactly one corresponding record processor, so you never need multiple instances to process one shard. However, one worker can process any number of shards, so it's fine if the number of shards exceeds the number of instances. When re-sharding increases the number of shards in the stream, the corresponding increase in the number of record processors increases the load on the EC2 instances that are hosting them. If the instances are part of an Auto Scaling group, and the load increases sufficiently, the Auto Scaling group adds more instances to handle the increased load.","links":[{"url":"https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html","title":"Kinesis Data Streams Terminology"},{"url":"https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html","title":"Resharding, Scaling, and Parallel Processing"}],"answers":[{"id":"df38b78549933ce6cdce41ce65a061ba","text":"1 instance in us-east-1a and 1 instance in us-east-1b","correct":true},{"id":"35e98ea97449addda5a6f1eecf072e4a","text":"6 instances in us-east-1a and 1 instance in us-east-1b","correct":false},{"id":"834a08c5c4b013c0a9e06105fc8c873a","text":"6 instances in us-east-1a and 6 instances in us-east-1b","correct":false},{"id":"205a5d33fbfbd8a66d4bbd686e7455b9","text":"3 instances in us-east-1a and 3 instances in us-east-1b","correct":false}]},{"id":"6969665b-60e1-4b4b-88db-b3a70e483f9a","domain":"security","question":"Which of the following does Cognito use to manage sign-up and sign-in functionality for mobile and web applications?","explanation":"Cognito User Pools are like a directory, allowing users sign-up and sign-in. Identity pools are used to grant temporary access to unauthenticated guests. IAM users are user account entities which allow you to interact with AWS resources. IAM groups are collections of IAM users and are used to specify permissions for multiple users.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools.html","title":"Cognito User Pools"}],"answers":[{"id":"a07a0085c7712cdcacc4b2cc1359a351","text":"Identity Pools","correct":false},{"id":"6b92da4fed3ac1c921485e4de62af19b","text":"IAM Users","correct":false},{"id":"cb40a6c9df6d32418e5f67e35ed37fd0","text":"User Pools","correct":true},{"id":"2a3ae7e866e21a59b0cdd627c7f7da55","text":"IAM Groups","correct":false}]},{"id":"5cf3b6d4-9a0e-4602-8dab-26e687207049","domain":"development","question":"Which of the following platforms are supported in ElasticBeanstalk?","explanation":"Elastic beanstalk supports common platforms like including Tomcat, Passenger, Puma and Docker","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/concepts.platforms.html","title":"Elastic Beanstalk Supported Platforms"}],"answers":[{"id":"8f72e28063c30c7468fb6af4653f4f9c","text":"Tomcat","correct":true},{"id":"bf2528a296adb62d041a7519aa77f248","text":"Passenger","correct":true},{"id":"7345f7045e4668138112c100f25517a4","text":"JBoss","correct":false},{"id":"c5fd214cdd0d2b3b4272e73b022ba5c2","text":"Docker","correct":true}]},{"id":"dc3e7895-b954-4fa8-8d4f-faffeca401d2","domain":"security","question":"Which of the following methods will allow you to *securely* upload/download your data to the S3 service? Pick all that apply.","explanation":"You can securely upload/download your data to Amazon S3 via SSL endpoints using the HTTPS protocol.","links":[{"url":"https://aws.amazon.com/s3/faqs/#security","title":"S3 Security"}],"answers":[{"id":"2b716d646634dd42d3d1ab628b210081","text":"SSL endpoints using the HTTPS protocol","correct":true},{"id":"1019a747b087f11f97ef6a2bf46a1978","text":"HTTP endpoints using HTTPS protocol","correct":true},{"id":"937a8b8e84ad5481f1983a1842154e18","text":"HTTP endpoints using HTTP protocol","correct":false},{"id":"d7ad40729fa333427d4d8c3032d43fdf","text":"SSL endpoints using HTTP protocol","correct":false}]},{"id":"9822dfa6-67ab-47c1-9ee6-16f567e8f9ae","domain":"development","question":"You have created a DynamoDB table for your application with one partition key and no local secondary index. The table will include the following attributes: \nAccountID (partition key)\nAccountName\nReportingPeriod\nTotalRevenue\n You have an application running on EC2 that displays revenue data as a dashboard for your sales organization. The dashboard requires a view of total revenue over multiple reporting periods by customer name as a readable format. What secondary index will you need to add to your table?","explanation":"The requirement is for a particular CustomerName as it would be difficult for a reader to identity customers by their ID. We need a Global Secondary Index for a different partition key because a local secondary index must be created at the time you create a table. To retrieve only the time of interest, the ReportingPeriod must be the sort key. Finally, projecting TotalRevenue into the index will provide the necessary data to fulfill the requirement.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SecondaryIndexes.html","title":"Improving Data Access with Secondary Indexes"}],"answers":[{"id":"ce82afc52e016682dd4eb59cdcc0d6dd","text":"Local secondary index with a partition key of ReportingPeriod and sort key of CustomerName; project the TotalRevenue attribute","correct":false},{"id":"c923b638655c852ecf536b4a089fc8b3","text":"Local secondary index with a partition key of CustomerName and sort key of ReportingPeriod; project the TotalRevenue attribute","correct":false},{"id":"54b2fc130eec92721970eedc9f515ad9","text":"Global secondary index with a partition key of ReportingPeriod and sort key of CustomerName; project the TotalRevenue attribute","correct":false},{"id":"5a18172e710f5f6e062e96ddfedb6f9b","text":"Global secondary index with a partition key of CustomerName and sort key of ReportingPeriod; project the TotalRevenue attribute","correct":true}]},{"id":"708176eb-71b7-4204-9c7b-3c264fe7b990","domain":"deployment","question":"You are using CloudFormation to build a number of different application environments to host development, test, UAT, pre-production and production stacks. Your application is comprised of web servers, load balancers, application servers and databases each web server, load balancer and database needs to be configured identically across all environments. How can you achieve this with CloudFormation?","explanation":"Nested stacks provide the ability to configure multiple elements within your environment while reducing duplication of code. As your infrastructure grows, common patterns can emerge in which you declare the same components in multiple templates. You can separate out these common components and create dedicated templates for them. Then use the resource in your template to reference other templates, creating nested stacks.","links":[{"url":"https://aws.amazon.com/blogs/devops/use-nested-stacks-to-create-reusable-templates-and-support-role-specialization/","title":"Nested Stacks To Create Reusable Templates"}],"answers":[{"id":"b37138310fd665c01b87b8a10b3bc912","text":"Use environment variables","correct":false},{"id":"7787568901c6933adbc971d946dc170a","text":"Copy and paste the configuration code that you want to re-use into the CloudFormation template for each environment","correct":false},{"id":"fc8b86a0172250c06d0b47ac00a9581d","text":"Use a CloudFormation Nested Stack","correct":true},{"id":"42b52ff9f79cc77411fd5fab9e6f2da7","text":"Use the Mappings section of the template to reference the code you want to re-use","correct":false}]},{"id":"0c35721a-5f70-44fa-b450-3a734cffe32d","domain":"development","question":"You are working on an application which runs inside a Docker container. All your images are stored in a repository named mydockerrepo AWS ECR. Which of the following commands could you use to pull the Docker image to your local workstation?","explanation":"If you would like to run a Docker image that is available in Amazon ECR, you can pull it to your local environment with the docker pull command.","links":[{"url":"https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-pull-ecr-image.html","title":"Pulling an Image From ECR To Your Local Machine"}],"answers":[{"id":"d2b7e2822cfd2c34e140e5a2b38a8844","text":"docker clone aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":false},{"id":"90dc63a057ad01f414275df9fe070ea1","text":"docker get aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":false},{"id":"2adf07d0af0f83b4c0e540b293950cae","text":"docker pull aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":true},{"id":"3de38211ddfad5912196a8d85b693d6b","text":"docker push aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":false}]},{"id":"33a233e7-f5ba-44d5-8c29-c72d59329262","domain":"development","question":"You are planning to write some Python code which will query a DynamoDB table and display the output on your website, which of the following tools can you use to start writing your code?","explanation":"AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser.","links":[{"url":"https://aws.amazon.com/cloud9/faqs/","title":"Cloud9 FAQs"}],"answers":[{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"fc8e90107dabb9a35c490b0d86adea06","text":"Cloud9","correct":true},{"id":"07929940c38c1e9e91ecf67c01ccfa73","text":"CodeDeploy","correct":false},{"id":"706f0c9ac9a93c06a6db5f8838d71b0c","text":"CodeStar","correct":false}]},{"id":"007a648d-faa9-4464-9816-0b646386047f","domain":"mon-trb","question":"A three-tier application consists of a presentation and application tier deployed on EC2 instances in a public VPC subnet, and a data tier hosted on an RDS databases in a private VPC subnet.  When attempting to establish a connection to the RDS database, the application times out.  What could be the source of this problem?","explanation":"A VPC Network Security Groups are a network security capability providing firewall functionality.  They control inbound and outbound traffic on EC2 or RDS instances. NSG rules applied on the RDS database must be configured to allow inbound traffic from the NSG on the EC2 instances on the database port. If the NSG's on the RDS database are not configured correctly, any connection attempting to access the RDS instance will time out as the database will be unreachable. If database credentials were incorrect, the application would not time out. A connection to the RDS instance would be established, an the database would return an error code.  The question specifically states that there is an issue establishing a connection. VPC peering is used to establish a secure connection between two VPC’s, and is not suitable in this scenario. Similarly, Internet Gateway is used in public subnets to route outbound traffic to the internet and is not relevant to the situation.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.RDSSecurityGroups.html","title":"Controlling Access with Security Groups"}],"answers":[{"id":"b7adf16356fbe2a22cd0c74e0b333b26","text":"Database NSG is not configured to allow traffic from EC2 instances.","correct":true},{"id":"caf6ad7f31cbd20a32d3eea156a6cffb","text":"The public subnet does not have Internet Gateway configured.","correct":false},{"id":"77a29c8aaf1cae7a01a6aa1960c59878","text":"Database credentials are incorrect.","correct":false},{"id":"2954caaf920be59b173a0e00624c47f0","text":"VPC Peering is not configured properly.","correct":false}]},{"id":"f70f0615-b415-485e-93d5-2286bc2c25cc","domain":"development","question":"What is the maximum size of an item in a DynamoDB table?","explanation":"The maximum item size in DynamoDB is 400 KB.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html","title":"Limits in Amazon DynamoDB"}],"answers":[{"id":"3c0512af07779a4b40b2b3d95dd1375b","text":"40 KB","correct":false},{"id":"5bdde53de5ac658c8aeeacac334b0152","text":"40 MB","correct":false},{"id":"1310fc461ca5af7082d588ba9c2a795b","text":"400 KB","correct":true},{"id":"462e2e8040f8c2b03228a91524dd8953","text":"400 MB","correct":false}]},{"id":"fef4400a-946f-4f47-8a06-1d8cac177396","domain":"mon-trb","question":"You are attempting to list the objects contained in an S3 bucket. The bucket contains over 3000 objects and the list-objects command times out and does not complete successfully, however when you run the same command on a different bucket, it works without errors. What could be the reason for this?","explanation":"If you see issues when running list commands on a large number of resources, the default page size of 1000 might be too high. This can cause calls to AWS services to exceed the maximum allowed time and generate a \"timed out\" error. You can use the --page-size option to specify that the AWS CLI request a smaller number of items from each call to the AWS service. The CLI still retrieves the full list, but performs a larger number of service API calls in the background and retrieves a smaller number of items with each call. This gives the individual calls a better chance of succeeding without a timeout. Changing the page size doesn't affect the output; it affects only the number of API calls that need to be made to generate the output.","links":[{"url":"https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-pagination.html","title":"AWS CLI Pagination"}],"answers":[{"id":"12b3ee65ff4239dcb2e54ada9d0307d5","text":"You are running the command on a bucket which contains a large number of resources, and the default page size might be need to be increased.","correct":false},{"id":"fe6ecb35fc38b38806053192af45aadd","text":"The command is generating too many API calls due to the large number of objects in the bucket.","correct":false},{"id":"c105a5c0f66ee44cff21cb53bd7ec1e5","text":"You are running the command on a bucket which contains a large number of resources, and the default page size might be too high.","correct":true},{"id":"abf2e493ee10caa92d340b7832cc908f","text":"You do not have the required permission to run the list-objects command on the bucket.","correct":false}]},{"id":"a94b2c88-352b-4c39-83fc-7edfa8190fca","domain":"development","question":"Your application communicates using messages in an SQS queue. You have noticed recently that you are seeing a large number of empty responses where no messages exist in the queue. You want to make sure that your application is responsive as possible, but the cost of the solution is also a concern. What can you do to ensure your application is both cost-effective and responsive?","explanation":"In almost all cases, Amazon SQS long polling is preferable to short polling. Long-polling requests let your queue consumers receive messages as soon as they arrive in your queue while reducing the number of empty ReceiveMessageResponse instances returned. In general, you should use maximum 20 seconds for a long-poll timeout. Because higher long-poll timeout values reduce the number of empty ReceiveMessageResponse instances returned, try to set your long-poll timeout as high as possible.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"SQS FAQs"}],"answers":[{"id":"f11916957f37c9cd171f126572d34864","text":"Use short polling","correct":false},{"id":"2247660601daf03d12f2fb4a1fccbf55","text":"Use long polling","correct":true},{"id":"b2ccbf04a8f468dbcaad76b35f8f076b","text":"Configure multiple queues","correct":false},{"id":"cef7badd821b93647928923359f863e4","text":"Use a FIFO queue","correct":false},{"id":"66a35e1198bcce83d8654873aab562c6","text":"Configure multiple queues with short polling","correct":false}]}]}}}}
