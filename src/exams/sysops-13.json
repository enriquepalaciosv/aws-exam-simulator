{"data":{"createNewExamAttempt":{"attempt":{"id":"0f831be6-5b32-44f9-ad43-a2c8d1fde4a0"},"exam":{"id":"112d542b-d05c-4232-bd0d-791e278b3412","title":"AWS Certified SysOps Administrator - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"739bcd50-ad59-4cbe-a911-17cff575b80d","domain":"security-comp","question":"You have been asked by your company's CISO to create and manage an S3 bucket with highly confidential company information. Only two business-critical individuals within the company should have read and write access to the bucket. All other personnel should not have access. How would you go about ensuring the security and confidentiality of the bucket in the most efficient manner?","explanation":"Bucket policies provide centralized access control to buckets and objects based on a variety of conditions, including Amazon S3 operations, requestors, resources, and aspects of the request (for example, IP address). The policies are expressed in the access policy language and enable centralized management of permissions. The permissions attached to a bucket apply to all of the objects in that bucket. AWS Config would only report on if buckets are in compliance to any rules set. An explicitly deny for all IAM users would work but it isn't the most efficient solution. Bucket access control lists apply to bucket objects, not the bucket itself.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Bucket Policies"}],"answers":[{"id":"ebf041183040a34a7220734ce5497478","text":"Create an IAM policy for all non-business-critical individuals that explicitly denies access to the bucket.","correct":false},{"id":"fdadf86a8030fc5cbfd2cdb0b16b95f6","text":"Create a bucket policy explicitly granting access to the two principals.","correct":true},{"id":"48f34a3e8e8a95fcbe3abee586e0f775","text":"Create a bucket access control list to explicitly grant access to the two individuals.","correct":false},{"id":"06899090182266f944ef7ff8a34750ed","text":"Create an AWS Config rule that denies access to the S3 bucket except for the business-critical users. Set an alarm whenever someone attempts to access the bucket.","correct":false}]},{"id":"2f757d58-833a-40ab-9eb6-2a981fb6b79f","domain":"security-comp","question":"Under the AWS shared responsibility model which of the following would be your responsibility as a customer?","explanation":"The shared Responsibility Model states that you are responsible for configuring the security of your EC2 instances, VPCs and S3 buckets as well as any guest Operating Systems, application and database security settings. AWS is responsible for patching RDS instances and software platforms provided by Elastic Beanstalk","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"b71690da3d36c4e2b8fe168de0e70b84","text":"PHP patching for applications using Elastic Beanstalk","correct":false},{"id":"fa7989aaf9918b210db642de0de21650","text":"OS level patching for EC2 instances","correct":true},{"id":"96785b9a477bb691ff03d686c919e1cf","text":"Antivirus for EC2 instances","correct":true},{"id":"e4e2b01049a70752d94080ef404f35cf","text":"OS level patching for RDS instances","correct":false},{"id":"ceb259f9a51f0549f076e847bf207781","text":"Application level patching for RDS","correct":false}]},{"id":"4e911348-5056-4ece-a91d-ce96b619578f","domain":"automation","question":"The DevOps team of an insurance company has been instructed to use CloudFormation to manage the different environments of the company. Due to the size of the templates prepared exceeding the limit, the CloudFormation service rejected the processing of the template. How can the DevOps team resolve this issue?","explanation":"Due to the size of the templates exceeding the limit, dividing the CloudFormation template into smaller subparts is the solution. With this in mind, CloudFormation nested stacks will yield to the same template behavior but will involve different files","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html","title":"Using CloudFormation Nested Stacks"}],"answers":[{"id":"e29c7f5b3439e3e8355a1e6bede51fa1","text":"Minify the CloudFormation template","correct":false},{"id":"f163f3aff96f7db10bfa4b93ed9a0a67","text":"Use CloudFormation wait handlers","correct":false},{"id":"1d75dba4b52318bdc075c815a7690e4c","text":"Use CloudFormation custom resources","correct":false},{"id":"d4838aa62aeb5717c4100906a75dea2d","text":"Use CloudFormation nested stacks","correct":true}]},{"id":"d584866c-4884-40ad-a263-94eaad98f894","domain":"mon-rep","question":"AWS Config is a managed service which is part of the AWS Management & Governance portfolio of services.  Which of the following options are functions of the AWS Config service?","explanation":"AWS Config is a service that provides access to resource configuration history, an inventory of resources and alerts on any configuration changes, however it doesn't log API calls as this is the function of CloudTrail.","links":[{"url":"https://aws.amazon.com/config/faq/","title":"AWS Config FAQs"}],"answers":[{"id":"46057f48c99511ac9dfb7fe92df1aefa","text":"Provides notification of configuration item changes","correct":true},{"id":"511bc797ffd63fd0702e8632fb5156db","text":"Provides a log of all configuration related API calls","correct":false},{"id":"b3a15d8a30c303c913c4b2976f61f5c7","text":"Provides an inventory of all AWS resources","correct":true},{"id":"77eef0aefcbae3f15cc5ce086d0bff63","text":"Provides access to resource configuration history","correct":true}]},{"id":"a8410bf2-3c51-49cc-8e44-ca3a1241eff2","domain":"dep-prov","question":"A developer has a monolithic Python application which is being migrated and refactored to use a microservice architecture. The developer has decided to use multiple AWS Lambda functions to run the Python code. During the preparation of the Lambda functions, the developer has noticed that the code requires several third party dependencies which are not part of the standard library. What needs to be done to ensure that the Lambda function code referencing the third party libraries can be executed properly?","explanation":"In order for a Lambda function to run scripts that involve third party libraries, a deployment package needs to be generated in a Lambda-like environment and uploaded to the Lambda or an S3 bucket. This is automatically done by tools like the SAM CLI. Third party libraries are not stored in EFS, ECR, or AppSync.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html","title":"Lambda Python - How to Create a Deployment Package"}],"answers":[{"id":"d3ae725bd59d297fd27e71f3db582c01","text":"Store the third party libraries in ECR and link the Lambda function to the ECR repo.","correct":false},{"id":"e45dd8b567270f7faf25f4111f41fa9e","text":"Generate a deployment package containing the code and the third party libraries.","correct":true},{"id":"b41396a5bc20297186c72b266cf8be9e","text":"Use AppSync to manage and store the third party libraries.","correct":false},{"id":"de93e97f2545dd02641eecd1a42fba8d","text":"Store the third party libraries in EFS and link the Lambda function to the EFS store.","correct":false}]},{"id":"557a8cbf-ffb7-492a-b24a-7662b95c6269","domain":"automation","question":"A startup is planning to migrate their existing on-premise application to AWS. The company is already using Chef as the configuration management tool to manage their on-premise application and is looking to continue using Chef to manage their AWS resources. In addition to this, the team is looking to use a managed service to reduce the overhead of managing its PostgreSQL databases. How can the team accomplish this?","explanation":"OpsWorks is a managed service for Chef and Puppet and can easily be used to deploy and manage resources utilizing the Chef recipes already prepared. CloudFormation uses AWS's own engine to process and convert JSON or YAML templates to AWS resources. For requirements involving Chef and Puppet, OpsWorks is the primary (and only) managed service. For managed database service requirements, Aurora, RDS, and DynamoDB can be used as the managed database.","links":[{"url":"https://aws.amazon.com/opsworks/","title":"OpsWorks"}],"answers":[{"id":"ce66fcb736d2db75172e1c56777a36e1","text":"Use CloudFormation for the configuration management requirements. Use Aurora for the database management requirements.","correct":false},{"id":"33b2bf9a830d2dddb0570706a774902f","text":"Use OpsWorks for the configuration management requirements. Use RDS for the database management requirements.","correct":true},{"id":"5b18a2364c2c69356af48e23e5347e81","text":"Use Elastic Beanstalk for the configuration management requirements. Use DynamoDB for the database management requirements.","correct":false},{"id":"378e25243c4a87f77553aed4ddbb2808","text":"Use ECS for the configuration management requirements. Use Athena for the database management requirements.","correct":false}]},{"id":"a9a1c52d-1ddd-4c03-bbdf-0f7088844afd","domain":"networking","question":"Which of the following features only relate to Spread Placement Groups?","explanation":"Spread placement groups have a specific limitation that you can only have a maximum of 7 running instances per Availability Zone and therefore this is the only correct option.  Deploying instances in a single Availability Zone is unique to Cluster Placement Groups only and therefore is not correct.  The remaining options are common to all placement group types and so are not specific to Spread Placement Groups.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"Placement Groups"}],"answers":[{"id":"62e7178075716f412e6f6cea59a301f5","text":"Instances must be deployed in a single Availability Zone","correct":false},{"id":"1d682b1a96356cb1692b672d49901726","text":"The name of your placement group must be unique within your AWS Account","correct":false},{"id":"fde221f3ce615a530b477c7f48067e81","text":"There is no charge for creating a placement group","correct":false},{"id":"fd53e2976a7600365c406c0580e67862","text":"The placement group can only have 7 running instances per Availability Zone","correct":true}]},{"id":"50aa4157-f34a-4783-a384-54a3d6a01a56","domain":"security-comp","question":"According to the AWS shared responsibility model for abstracted services such as Amazon S3 and Amazon DynamoDB, what is the customer responsible for? Choose two.","explanation":"For abstracted services, such as Amazon S3 and Amazon DynamoDB, AWS operates the infrastructure layer, the operating system, and platforms, and customers access the endpoints to store and retrieve data. Customers are responsible for managing their data and configuring the service to match their use case.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"ff0cec3b4483d0f78461e26f53e22b1e","text":"Provisioning the underlying infrastructure.","correct":false},{"id":"f085213d0eb85dba2852d4806d44c8d8","text":"Using IAM to apply the appropriate permissions.","correct":true},{"id":"45701a6f69581c386f76dc415b5f9c4e","text":"Managing the data (including encryption options).","correct":true},{"id":"c664130f5b6e5a24cd61a355e8b97540","text":"High availability of the endpoints","correct":false},{"id":"e027059be4bd1474a9b38c65eb31e483","text":"Operating system patches.","correct":false}]},{"id":"be30bba9-7133-43b6-b1b9-a21de73dbf17","domain":"dep-prov","question":"You have created a new Auto Scaling group and you discover that your instances are not launching in to it. Which of the following is not a reason that this might be happening?","explanation":"The instance type specified is not supported for Auto Scaling","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/ts-as-instancelaunchfailure.html#ts-as-instancelaunchfailure-6","title":"Troubleshooting Auto-Scaling"}],"answers":[{"id":"2094f86fb69fd7383b4a5b26e6fa5f65","text":"The associated Key Pair does not exist.","correct":false},{"id":"04c0d163b1711459d69938ad0495fba5","text":"The security group does not exist.","correct":false},{"id":"21ff5db3973f2b3f7cf4a218ae1bb59f","text":"The instance type specified is not supported for Auto Scaling.","correct":true},{"id":"6788d6762b58bb5d71fe6d713712ca09","text":"The requested configuration is currently not supported.","correct":false}]},{"id":"1023ad60-61cd-42e7-98d2-bd9496ccb28e","domain":"security-comp","question":"You work at a Fintech company in London who is applying for a banking license. As a part of the approval process a very intense IT audit must be preformed by an independent auditing team of security experts. They have asked for access to your AWS estate and you must give them this while upholding the principles of least privilege. Which three steps below should you do in order to give them access?","explanation":"You should create new IAM users and use IAM policies to grant least privilege access. The root account should not be used for this purpose and the AWS Organizations cannot be used in this way.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_controlling.html","title":"AWS Access Control"}],"answers":[{"id":"b3b5d90b9180a2e772a231c85ab0a265","text":" Create a new “Auditors” group in Identity Access Management","correct":true},{"id":"aaf6c02472ee97a85ab075ce4ed1e413","text":"Apply a read only policy to the “Auditors” group allowing them full read access to the account.","correct":true},{"id":"867ab998dd391e8deb1b8d04e9029143","text":"Create the user accounts for the auditors","correct":true},{"id":"44a45f2f464a54bb9a52b13fe123e2fe","text":"Using AWS Organizations, apply a read only policy to the “Auditors” account allowing them full read access to the account.","correct":false},{"id":"d170f56317e67ea38d7399042b56f3c0","text":"Create a new “Auditors” AWS account","correct":false},{"id":"cb171ef9ccff95de1be0cd5ad892d1ec","text":"Secure the root account with MFA","correct":false}]},{"id":"01c5ef85-f86c-4577-a360-c95f8b18f0b4","domain":"networking","question":"A company is using AWS CloudFormation to manage its infrastructure resources. The resources in the CloudFormation template include a web application EC2 instance in the public subnet, a database RDS instance and a background worker instance in the private subnet, and a NAT gateway in the private subnet. Upon launching the resources with CloudFormation, the background worker instance could not perform the required patching operations. How can the team resolve this issue?","explanation":"NAT gateways need to be in the public subnet in order for the resources in the private subnet to have internet connectivity. Usually, the default route for a private subnet points to the NAT gateway. If the NAT gateway is in a private subnet, then the traffic cannot reach the internet and the resources in the private subnet won't have internet connectivity.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html","title":"VPC - Scenario"}],"answers":[{"id":"020488512a65f6ba76a54fe218be0393","text":"Run the CloudFormation template in a private subnet.","correct":false},{"id":"85ed6715d192d5fa6f511643f57bbc3d","text":"Run the CloudFormation template in a public subnet.","correct":false},{"id":"eab056f2f227b9e8b14f19de962820d4","text":"Replace the NAT gateway with a NAT instance.","correct":false},{"id":"0dd5664349040ac37294cf1395f180f0","text":"Launch the NAT gateway in the public subnet.","correct":true}]},{"id":"17885db5-c61d-4edf-b0e3-e9d449d8e618","domain":"mon-rep","question":"Which of the following EC2 instance metrics are sent to Amazon CloudWatch by default? Select three.","explanation":"CPU utilization, disk I/O and network traffic are visible to the hypervisor running the instance and are sent to CloudWatch by default. For the others, you would need to install CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html","title":"Available CloudWatch Metrics for Your Instances"}],"answers":[{"id":"c4903df1e41e0ba0b4636e753d8c7661","text":"Disk read and write operations","correct":true},{"id":"ec1e54ae04652319df5c011f228c07ac","text":"Free disk space","correct":false},{"id":"b4e5bb2b6842990e919682b3d6d5726c","text":"Volume of incoming and outgoing network traffic","correct":true},{"id":"613b1188dd73dfdb768f39cfad3cc9a3","text":"Memory utilization","correct":false},{"id":"2105454033539f83d3b07265aac88d7a","text":"The amount of swap space currently in use","correct":false},{"id":"fb8326e1edbd06b1bf6ea0332e089055","text":"CPU utilization","correct":true}]},{"id":"7afdb34a-f5da-4e8f-ab9c-e059038d650e","domain":"networking","question":"You have just launched an EC2 instance in the public subnet of a newly-created VPC, but you forgot to assign a public IP address during creation. How might you make your instance reachable from the outside world?","explanation":"For an instance to be reachable from the internet, your VPC must have an Internet Gateway and your instance must have a Public or Elastic IP. Public IP addresses can be created only at the time of instance creation. You cannot \"go back\" and create one.  In order for a subnet to be described as a \"Public subnet\" it must already have a route to the Internet","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Internet_Gateway.html","title":"Internet Gateways"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html","title":"About Elastic IP Addresses"},{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html","title":"About Public subnet"}],"answers":[{"id":"e9ce11f00035e2973045eabe5deb1a36","text":"Create an Internet Gateway and associate it with the private IP address of your instance with it.","correct":false},{"id":"93d71e191e2b0ea46c66ef9f7de5f064","text":"Go back and create a Public IP address. Associate it with your Internet Gateway.","correct":false},{"id":"568466971ef09a401e2f77e242156994","text":"Create an Internet gateway and an Elastic IP address. Associate the Elastic IP with the EC2 instance.","correct":false},{"id":"0fa79a82264c55eff18e206e030f5c16","text":"Create an Elastic IP address for your instance. Associate the Elastic IP with the EC2 instance.","correct":true}]},{"id":"5b0a461a-8b87-4e0b-b090-bb310aa5888f","domain":"dep-prov","question":"You are a SysOps Engineer for a fancy umbrella manufacturer \"Raincloud Gurus\".  You have been asked to deploy a new EC2 instance in your VPC to act as a bastion host for access to their systems. When you try to launch the instance you receive the error InsufficientInstanceCapacity.  What is the cause of your error?","explanation":"You get the InsufficientInstanceCapacity error when you try to launch a new instance or restart a stopped instance.  If you receive this error it means that AWS does not currently have enough available On-Demand capacity to service your request.  Either wait some time for the capacity to be provisioned in your region/Availability zone or try a different instance type.  ","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html","title":"Troubleshooting EC2 Launch"}],"answers":[{"id":"68d9f0033f27b30099c86ea525509a2a","text":"You selected an EBS volume size that is too small for the AMI you are trying to deploy","correct":false},{"id":"f130e4749fd898444fc50993d748bfb8","text":"AWS does not currently have enough available On-Demand capacity to service your request","correct":true},{"id":"c6bcc41fea94bf39436d5eca43b66c34","text":"You forgot to raise EC2 instance service limits on your instance type","correct":false},{"id":"98b15ca0626988b3169c48a7a2053331","text":"The instance type you selected is not available in your region","correct":false}]},{"id":"a4edb410-e5e5-40b4-9335-1da82639c2e3","domain":"networking","question":"You work for an investment bank, supporting a mission critical stock market data processing application running on EC2 and consuming real-time data feeds from your on-premises systems. Your traders are complaining that the system is sometimes very slow to refresh the data and you suspect that this is due to fluctuations in available network bandwidth between AWS and your datacentre. What improvement can you suggest to give users a consistent experience and improve performance for users?","explanation":"AWS Direct Connect is a network service that provides an alternative to using the Internet to connect customer's on premise sites to AWS.","links":[{"url":"https://aws.amazon.com/directconnect/faqs/","title":"Direct Connect FAQs"}],"answers":[{"id":"35461a11ab55ba8f2b7eb1d3fcc15eff","text":"Scale out your application servers","correct":false},{"id":"3225172eff8d104a4744f0ee6f50d836","text":"Configure an additional Elastic IP for each of your application servers to increase the network bandwidth","correct":false},{"id":"a60c49fc87050d8b3c698515938d624b","text":"Configure S3 Transfer Acceleration to move the data into AWS much faster","correct":false},{"id":"5d5c067abd490006c21d11ff221c552a","text":"Configure a Direct Connect connection between your data center and AWS","correct":true}]},{"id":"5b71bc80-b7ef-4fde-86f0-1a73d1d63e4c","domain":"high-avail","question":"You are an AWS administrator and have set up an Elastic Load Balancer inside a VPC. The ELB spans several Availability Zones. The ELB sits in front of a web application running on Amazon EC2. You notice that incoming traffic is not being evenly distributed across the AZs. How would you solve this issue?","explanation":"Traffic not evenly distributed across the instances in multiple AZs means the traffic is going to only specific EC2 instances. This happens when either the instances which are not receiving the traffic are unhealthy, or the instances that are receiving the traffic are holding on to the session. Since there is no mention of unhealthy instances, disabling sticky sessions on the ELB is the best answer. Increasing the number of subnets and/or instances will not solve the problem as users will remain stuck to the original instance. Increasing the frequency of health checks will have no impact to force even distribution of traffic.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html","title":"Configure Sticky Sessions for Your Classic Load Balancer"}],"answers":[{"id":"d532ac3048a69a5902a79b51bc219bd3","text":"Increase the number of EC2 instances behind the ELB.","correct":false},{"id":"c0d9e44a3e92d6d91864058257e9922c","text":"Add additional subnets within your ELB and configure your ELB to span the new subnets.","correct":false},{"id":"b7116d2a43d8462c83e8b93fda085c71","text":"Disable sticky sessions on the ELB.","correct":true},{"id":"e23eea1cecbc63f7423de00e65f29614","text":"Increase the frequency of the health checks to the EC2 instances running your application.","correct":false}]},{"id":"217a427c-502e-401f-b0e1-9a1794748dd2","domain":"dep-prov","question":"You have designed your corporate AWS infrastructure so that all applications will reside in private subnets to reduce the chance of unauthorised attack from the Internet. However, you have been reminded that some people may need SSH access to these applications from the Internet, under certain circumstances.  You decide to install a Bastion Host in a public subnet to allow SSH access through to the applications for these people.  Which of the following options can be used to reduce the chance of the Bastion Host being compromised?","explanation":"Firstly, let us discount building from a Bastion AMI as this doesn't exist and we can also remove options that include logging, because although they are useful to find who attempted access, they don't reduce the chance of attack.  Implementing any or all of the remaining options will add to the \"strength in depth\" philosophy and could prevent the Bastion Host being compromised.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html","title":"Linux Bastion Hosts on the AWS Cloud"}],"answers":[{"id":"205062c31d482ee937ff645c845dba33","text":"Build the Bastion Host from the AWS Bastion AMI","correct":false},{"id":"f16e7d50eb7d520eb2104bb73820ae91","text":"Install Fail2Ban on the Bastion Host","correct":true},{"id":"bac7e3fe44c6180ec86d68334b027d40","text":"Allow only TCP port 22 from 0.0.0.0/0 in the Security Group","correct":true},{"id":"e4baede75c62ff192032aa1048885c6c","text":"Remove all packages that are not used","correct":true},{"id":"ea54b90fc7659554d53c42962e2b83a5","text":"Log all SSH access attempts","correct":false}]},{"id":"463d990a-0af1-4e11-ad8a-c379444c02fd","domain":"automation","question":"A government agency currently runs all of their AWS workloads in a single region. Services utilized include S3, EC2, ECS, RDS, CloudFront, and Route 53 in multiple accounts. Their new business continuity plan calls for readiness in a separate AWS region in case disaster recovery is needed. Which approach will provide them with the most efficient way to manage their primary and business continuity environments?","explanation":"By default, CloudFormation templates are tied to a single account and a single region. However, CloudFormation allows for the creation of a custom resource that can launch a nested stack in another account or region with the appropriate IAM roles setup. The CloudFormation parameter and mappings sections don't provide cross-region functionality. Creating templates in each account would also work, but will require significant maintenance to keep resource definitions in-sync across all the templates.","links":[{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/multiple-account-multiple-region-aws-cloudformation/","title":"Multiple-account, multiple-Region AWS CloudFormation"}],"answers":[{"id":"fabf8fa8f7205c00448ae603a1d1af90","text":"Create AWS CloudFormation templates in a single account and configure the CloudFormation mappings section for the appropriate primary and business continuity regions","correct":false},{"id":"21d658a249d3a95d1de0860519bd585b","text":"Create an AWS CloudFormation template in a single account that defines custom resources to launch nested stacks into the other accounts and regions","correct":true},{"id":"b3128e59899200446191df0bbc118793","text":"Create AWS CloudFormation templates in each account that provision stacks with resources into the primary and business continuity regions using the CloudFormation 'Region' parameter","correct":false},{"id":"12eb00153c980c0e9e1fec8d03035f78","text":"Create AWS CloudFormation templates in each account and each region that provision stacks with the resources for their specific accounts/regions","correct":false}]},{"id":"066a63c9-1a0c-454f-8eeb-628657c4b7b3","domain":"security-comp","question":"As a security administrator for your company, the development team has asked for your advice on protecting their web product running on AWS against SQL injection attacks. Recently, there have been several cases where attackers have tried to insert certain malicious SQL queries to extract data from a database that stores confidential customer data. The development team manages and runs the database on EC2 running behind a load balancer. What advice would you give to the team to proactively protect against these kinds of attacks?","explanation":"There are several firewall services that AWS has provided including AWS WAF, AWS Shield, and AWS Firewall Manager. But in this case an ACL with WAF would be the most appropriate. AWS Firewall Manager simplifies your administrative and maintenance tasks across multiple accounts and resources for AWS WAF. AWS WAF is a web application firewall that lets you monitor the HTTP and HTTPS requests that are forwarded to a load balancer. You can block/allow all requests except the ones your specify. AWS Shield Advanced would protect against DDOS attacks. AWS Config would only provide notifications and thus would be a reactive solution to attacks.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html","title":"What Are AWS WAF, AWS Shield, and AWS Firewall Manager?"}],"answers":[{"id":"3b888c9ab75dfc1fd31b6fdcec298c41","text":"Use AWS Config to monitor the application. Set a rule to notify the development team when a malicious attack occurs.","correct":false},{"id":"5cfd6d4faff387749033b7f3e493f870","text":"Create a WAF Access Control List (ACL) with a rule to explicitly block the SQL injection attacks. Attach the ACL to the load balancer.","correct":true},{"id":"c84b52c0e32a45fc862e101beb233230","text":"Activate AWS Shield Advanced. Although costly, it will protect the application with a 24/7 response team from AWS, and full system and financial restoration after an attack.","correct":false},{"id":"3e1ffae7dc069fcf4bdce431a89b4792","text":"Create a rule in AWS Firewall Manager to explicitly block the IP addresses that were listed as the attackers.","correct":false}]},{"id":"414ac705-4dc4-4261-9523-5439c70ee19e","domain":"data-man","question":"You are running a relational database on a provisioned IOPS volume that is set to handle a moderate amount of traffic during the month. You know to expect a 10x spike in traffic during the final three days of each month due to month-end processing. How would you architect your storage environment to meet this expected increase in demand?","explanation":"With Elastic Volumes, you can increase volume size, adjust performance, or change the volume type while the volume is in use. You can continue to use your application while the change takes effect. Using CloudWatch alarms to automate these workflows is best practice. A reserved instance would not help in scaling to meet increased demand. Multi-AZ is for failover/disaster recovery purposes. Attaching multiple volumes is not best practice as it would increase cost and waste storage space during periods of low demand.","links":[{"url":"https://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/","title":"Amazon EBS Update â€“ New Elastic Volumes Change Everything"}],"answers":[{"id":"870c3d2a2d0fd0b784490ec327392d9e","text":"Purchase an AZ-specific reserved instance for your relational database in order to gain the benefit of reserved capacity.","correct":false},{"id":"d49d9044d5ba871697b4be060e80701e","text":"Enable multi-AZ for your RDS instance to account for the increased demand and spread the load between at least two instances.","correct":false},{"id":"8df9d9e9da10ed671385be6f7b1a0ffc","text":"Use a CloudWatch alarm to watch for a volume that is running at or near its IOPS limit. Initiate a workflow and approval process that could provision additional IOPS or change the type of the volume.","correct":true},{"id":"afe5d1141b5bb2e9227d1d7d8adeb777","text":"Attach multiple Provisioned IOPS volumes for your relational database in order to meet the expected increase in demand.","correct":false}]},{"id":"e05ee44b-cd10-4658-9853-ff5cea9c9d32","domain":"automation","question":"The company has started experiencing deployment issues due to the increasing complexity of the application and the lack of a structured testing and release process. The DevOps team of the company plans to set up a continuous integration pipeline in AWS to improve the stability of the releases and through the enforcement of the use of automated tests. The Head of DevOps has been instructed to use managed services as much as possible to reduce the maintenance overhead of the continuous integration pipeline. How can the DevOps team accomplish this?","explanation":"CodeBuild and CodePipeline are managed services that can be used to easily build a continuous integration pipeline. CodeBuild can run the tests and CodePipeline can manage the pipeline steps for the CI testing and deployment pipeline. Given that managed services are preferred, running Jenkins in an EC2 instance is not the priority option. AppSync is for building GraphQL powered APIs and is not used for continuous integration pipeline requirements.","links":[{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/how-to-create-pipeline.html","title":"Use CodePipeline with CodeBuild to Test Code and Run Builds"}],"answers":[{"id":"4c32bcc37cbaab42d77738b8b6875d19","text":"Use AppSync and CodeBuild for the continuous integration pipeline.","correct":false},{"id":"8adba880488851800b50283a6de55215","text":"Use Jenkins in an EC2 instance and CodePipeline for the continuous integration pipeline.","correct":false},{"id":"ce1176f044958de744d567d7ac7d0534","text":"Use Jenkins in an EC2 instance and AWS Step Functions for the continuous integration pipeline.","correct":false},{"id":"6574dc863e2d0855e66841be7aee54e7","text":"Use CodeBuild and CodePipeline for the continuous integration pipeline.","correct":true}]},{"id":"cb3a3e4a-87a1-4810-a732-ab1818b84b1d","domain":"data-man","question":"Your company's on-premises CRM software uses file storage. The marketing department would like to add a new social media module which will require a large increase in storage capacity. There is no capital budget to purchase additional storage servers, so the decision is made to place the new module's data on Amazon Elastic File System (EFS). A leader of the application team raises concerns about the latency that could be incurred with a single application accessing data both on-premises and in the cloud. How would you architect the solution to minimize the possibility of poor application performance?","explanation":"Either AWS Direct Connect or AWS VPN is required to connect on-premises servers to Amazon EFS. Bursting Throughput mode is the default mode for EFS file systems, scaling up as the size of a filesystem grows. Provisioned Throughput mode can provide higher throughput for applications with requirements greater than those of Bursting Throughput mode. Max I/O Performance mode will only benefit highly parallelized applications, which CRM generally is not.","links":[{"url":"https://aws.amazon.com/efs/","title":"Amazon Elastic File System"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/performance.html#throughput-modes","title":"Amazon EFS Performance"}],"answers":[{"id":"9d857d0961d3644ba26dec63c2d911e2","text":"Have the CRM application connect to the AWS cloud over an AWS Direct Connect. Configure the EFS file system in Provisioned Throughput mode","correct":true},{"id":"ed115154d20878d7d538a3557109c6e2","text":"Connect the CRM application to the AWS cloud over an AWS Direct Connect. Configure the EFS file system in Max I/O Performance mode","correct":false},{"id":"7b828048a4ab8b3c896ce413de929519","text":"Have the CRM application connect to the AWS cloud over an AWS VPN. Implement the EFS file system in both Bursting Throughput and Max I/O Performance modes","correct":false},{"id":"6ebf148cfe4cebe47a593afb84737882","text":"Connect the CRM application to EFS through an AWS Service Endpoint. Deploy the EFS file system in both Provisioned Throughput and Max I/O Performance modes","correct":false}]},{"id":"4c7fb750-0ec0-4c9f-8dc6-378122edf97a","domain":"automation","question":"The engineering team of a digital marketing company has a lot of AWS Lambda functions directly created and managed using the AWS Console. The CTO has mandated that the code and the deployments are managed using templates and the code is stored in a code repository to enable proper version control processes. How can the team achieve this?","explanation":"SAM templates and CloudFormation templates can be used to manage the Lambda function code. Out of all the options, only CodeCommit can be used directly as a managed service for a code repository. S3 buckets are not used directly as a code repository.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"What is SAM"}],"answers":[{"id":"a85a26cd33fe99adb584452fa780dce2","text":"Use CloudFormation templates to manage the lambda function code. Use S3 buckets for the code repository.","correct":false},{"id":"b670d764967a3aa65a1424279e37291c","text":"Use SAM templates to manage the lambda function code. Use S3 buckets for the code repository.","correct":false},{"id":"c5fe89ee64d944e98f26b2db3fa7cea2","text":"Use SAM templates to manage the lambda function code. Use CodeCommit for the code repository.","correct":true},{"id":"f33ec453646a2074aa930a61f466fc1a","text":"Use CloudFormation templates to manage the lambda function code. Use ECR for the code repository.","correct":false}]},{"id":"85c8beb3-4040-4c16-80a2-28699caea7f7","domain":"mon-rep","question":"Your company is running dozens of EC2 instances. What kind of a solution would give near real-time visualizations of multiple EC2 instance metrics at once?","explanation":"You can gather the necessary metrics together in CloudWatch Dashboards for complete operational visibility.","links":[{"url":"https://aws.amazon.com/cloudwatch/","title":"CloudWatch"}],"answers":[{"id":"af39109a1cd1a96dc8fc03cad521e886","text":"Visualize the metrics with QuickSight.","correct":false},{"id":"1ac4cde26a39fcabf5405c352b7bdff9","text":"Send the metrics to S3 and visualize them with S3 analytics.","correct":false},{"id":"eaa240abb4f0731fca4c2e20cbbbfefe","text":"Add the metrics into a CloudWatch Dashboard.","correct":true},{"id":"beef56bb880b285559c0254491f4d5c9","text":"Organize the metrics into a CloudFront panel.","correct":false}]},{"id":"6b5ed706-afce-4eda-8d2c-dc54e1741a8e","domain":"dep-prov","question":"You are running a WordPress site on an EC2 instance. The site gets visitors from all over the world and they are sometimes complaining about slow page load times. To serve content to your visitors faster, what could you do?","explanation":"S3 static web hosting only supports static websites, not dynamic sites like WordPress. Changing the tenancy won't change the instance specs. Scaling up the instance might help in another scenario, but here the issue is latency and transfer speed. A CloudFront distribution would cache your content close to your visitors and resolve the slow load times. As an added benefit, the caching would also take some load off the instance.","links":[{"url":"https://aws.amazon.com/cloudfront/","title":"CloudFront"}],"answers":[{"id":"333dd3e9883af7f7cc6ece108e9ffe30","text":"Scale up the instance to a one with more CPU power","correct":false},{"id":"e393aadc6f1e8478bfc3cc962b86e18c","text":"Move the site to S3 static web hosting","correct":false},{"id":"29db6de8b90b19b898fa59f6320deba7","text":"Place a CloudFront distribution in front of the instance","correct":true},{"id":"fea505586259520090752b2fb572d489","text":"Change the tenancy to a dedicated instance to get more CPU power","correct":false}]},{"id":"cde5021e-5b37-406b-b25a-1bdb489d3b24","domain":"security-comp","question":"Following a recent security event, a SysOps administrator has been asked to provide details of source IP addresses of requests to a website which is hosted on EC2 instances behind an Application Load Balancer. Where can the administrator find these details?","explanation":"Application Load Balancer (ALB) Access Logs record details of client connections which include the client's IP address and port.  CloudTrail logs AWS API calls so will not provide client IP addresses, neither will CloudWatch Custom Metrics which are for logging performance metrics.  EC2 instances will log the ALB's internal IP address as the source unless specifically configured to record the true source IP by using the x-forwarded-for header, which is not enabled by default.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html#access-log-entry-format","title":"ALB Access Log Entries"}],"answers":[{"id":"6a219c87573826721cb51b987140a267","text":"CloudTrail Event Trail","correct":false},{"id":"9a19403fef543b4899ec570ad1a29ca6","text":"CloudWatch Custom Metrics","correct":false},{"id":"8480ea5c787566c9a8bd2a608c725a06","text":"ALB Access Logs","correct":true},{"id":"43bc48b76d9918101fb772b4cfc58235","text":"/var/log/httpd/","correct":false}]},{"id":"2a16f1cd-530d-4e30-ad08-d89afae34484","domain":"mon-rep","question":"You create a new DynamoDB table with the provisioned read and write capacity units set to 5. The auto scaling feature is enabled for both read and write. And the target utilization is set as 70%. After monitoring the table for some time, you notice that there are two CloudWatch alarms related to the table. The description of one alarm is \"ConsumedWriteCapacityUnits < 150 for 15 datapoints within 15 minutes\". Which action do you need to take to address the alarm?","explanation":"DynamoDB manages the throughput capacities automatically with the auto scaling feature. The alarms are used for the feature and no action is required. There is no need to disable the feature or modify the provisioned capacities.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/AutoScaling.html","title":"Manage throughput capacity automatically with DynamoDB Auto Scaling"}],"answers":[{"id":"2131aeffdfb01948cc4943432a680327","text":"You need to adjust the provisioned read and write capacities to a higher value such as 10.","correct":false},{"id":"3a5208c005673a46313dce67b9e2dd57","text":"You should disable the auto scaling feature for the table.","correct":false},{"id":"859412aa0d0666ab4c2b8d20707c8f41","text":"They are fake alarms. You can manually delete them from the console.","correct":false},{"id":"252cd5486e4ae9685450c3e9ad208b05","text":"No action is required as the alarms are used for auto scaling for the DynamoDB table.","correct":true}]},{"id":"c9f0e61e-627b-421e-8a57-0d04983c25c4","domain":"security-comp","question":"You are a consultant working for a company who has recently completed their migration from an on-premise data centre to AWS. Most of the migration has been for EC2 instances, which have been sized to match the specifications they were originally using on-premise (CPU, memory, etc.). They have setup a Business Support plan with AWS. The technical manager is unhappy with the high costs, and wants to find ways to reduce them. What would the simplest way be to find ways to reduce their AWS costs in the short-term?","explanation":"This is a very common scenario for businesses migrating to the cloud, and discovering the operational expenditure (OPEX) costs of AWS. AWS Trusted Advisor has a lot of simple and effective recommendations for Cost Optimization. Some may not be applicable in your case, but it is a very easy way to find potential options for reducing your costs. These features are unlocked with the AWS Support Plans of Business or Enterprise. CloudWatch metrics can be very useful for right-sizing your instances (aligning the needs of the application workload with the instance specifications), but CloudWatch will also automate this to an extent as well by finding under-utilized instances. Reducing your support plan is usually an unwise move for production workloads, despite their cost, as they can be very important when outages are experienced. Advocating for a transition to PaaS and SaaS is definitely a strategic cost-saving measure, but it forms part of a long term business strategy, since it involves significant resources, both in time and money","links":[{"url":"https://aws.amazon.com/premiumsupport/technology/trusted-advisor/","title":"AWS Trusted Advisor"},{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Cost-Optimization-Pillar.pdf","title":"AWS Whitepaper - Cost Optimization Pillar"}],"answers":[{"id":"39788d9f10797f3b8c876dbe95022c0d","text":"Advocate a transition to more cost-effective PaaS and SaaS solutions","correct":false},{"id":"52107942e028b953519341a78f6815ca","text":"Inspect the CloudWatch metrics to better right-size the instances","correct":false},{"id":"b4e67747b2a23a55a53554b964d1ab9b","text":"Reduce the expensive AWS Support Plan to lower costs","correct":false},{"id":"55af961ef2471aec130c45657098b110","text":"Investigate recommendations from AWS Trusted Advisor's automated checks","correct":true}]},{"id":"189a554a-f950-4ba1-b500-05d6f2a13384","domain":"security-comp","question":"You are a SysOps Administrator for your organization in charge of managing several S3 buckets. A new company policy mandates that all S3 buckets use server-side encryption. You are also required to manage the keys yourself and the keys cannot be stored anywhere else. What S3 encryption feature would you use to adhere to policy?","explanation":"Server-side encryption is about protecting data at rest. Using server-side encryption with customer-provided encryption keys (SSE-C) allows you to set your own encryption keys. The only thing you do is manage the encryption keys you provide. Because you manage encryption keys on the client side, you manage any additional safeguards, such as key rotation, on the client side. AWS manages the encryption keys for SSE-S3 and stores the keys for SSE-KMS.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Protecting Data Using Server-Side Encryption with Customer-Provided Encryption Keys (SSE-C)"}],"answers":[{"id":"096d2d4900fa2fc44e97e4747c1a2200","text":"S3 SSE-C","correct":true},{"id":"0f0c44bcfedfa4e1752e65264f55bfb8","text":"S3 SSE-S3","correct":false},{"id":"8fa7273504fc1c77d5a894cedbc9aa74","text":"S3 SSE-KMS","correct":false},{"id":"afd402405a2c75553efc755f303924ea","text":"S3 CloudHSM","correct":false}]},{"id":"43f0527f-8ffc-49c2-8dd8-f55203c05f15","domain":"data-man","question":"A company has a local data center that stores satellite images and the company plans to migrate the image files to AWS S3 or Glacier. The total amount of data is about 100TB. The local network speed is slow so it is not applicable to transfer the files over the internet. Which of the provided options is the best to migrate the data to AWS?","explanation":"AWS Snowball is a recommended data transport solution that accelerates moving terabytes to petabytes of data to AWS. AWS Transfer for SFTP uses the internet so it is eliminated. VPN also relies on the network connection and it cannot accelerate the data transfer. AWS Storage File Gateway is a storage service to integrate with on-premises server. It is not used to migrate data to AWS.","links":[{"url":"https://docs.aws.amazon.com/whitepapers/latest/aws-overview/migration-services.html#aws-snowball","title":"Migration and Transfer solutions"}],"answers":[{"id":"d21889436bedfa9ee6bd66e73efdc3f0","text":"Configure the AWS Transfer for SFTP service to seamlessly migrate files to AWS S3 or Glacier.","correct":false},{"id":"49088421573ec1c3f93f7588fb78704f","text":"Create an AWS Snowball job and transfer files to the Snowball hardware. After the device is shipped back, AWS is in charge of storing data in S3 or Glacier.","correct":true},{"id":"4713a94f713bbca5a4e46d58447eb1cf","text":"Configure the VPN direct connection from the local data center to AWS VPC. Copy over the files using the high speed intranet.","correct":false},{"id":"8ebed8f00ea6cd51a35c7bfbc4a1b000","text":"Create a high speed AWS Storage File Gateway to map all the local files to S3 or Glacier.","correct":false}]},{"id":"f988ca16-ff44-497e-aae5-876954a55a31","domain":"security-comp","question":"You are creating a fleet of EC2 instances that will be inside an autoscaling group. These EC2 instances will need to write a custom metric to CloudWatch and will need the appropriate permissions with which to do this. What is the most secure way to enable this?","explanation":"you should create an IAM role with CloudWatch permissions and modify the autoscaling launch configuration to use EC2 instances that have been assigned the new role.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/using-service-linked-roles.html#create-service-linked-role","title":"IAM: Creating a Service-Linked Role"}],"answers":[{"id":"5764c31d8e5f450a679416b744d2d853","text":"Create a unique user in IAM with CloudWatch permissions and modify the autoscaling group to include a boot strap script that passes the EC2 instance that users credentials.","correct":false},{"id":"5a06900e462d7f086d273697c7a6abdc","text":"Create a unique user in IAM with CloudWatch permissions and store these credentials in GitHub. Have the EC2 instances pull these credentials when they need to log to CloudWatch.","correct":false},{"id":"29ed526af182672c01bd543082494019","text":"Create an IAM role with CloudWatch permissions and assign this to RDS. The existing EC2 instances will automatically be able to report to CloudWatch via RDS.","correct":false},{"id":"abefd699f3f65202335f75e9e67df3a9","text":"Create an IAM role with CloudWatch permissions and modify the autoscaling launch configuration to use EC2 instances that have been assigned the new role.","correct":true}]},{"id":"1a45301ef-de9d-42bb-842d-8c1a42220a08","domain":"mon-rep","question":"There is increasing demand of your application running on EC2, and you need to monitor available memory space to ensure you can scale with demand. How would you monitor this on AWS?","explanation":"Memory and disk space utilization is a custom metric that is CloudWatch does NOT collect natively. Users must install the CloudWatch agent to collect metrics for memory and disk space. Neither the EC2 Dashboard nor the CloudWatch Dashboard natively provides the ability to monitor memory. You much install the CloudWatch Agent on your instances. AWS would not provide this report as these are specific to your EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/mon-scripts.html & https://aws.amazon.com/blogs/aws/amazon-cloudwatch-user-defined-metrics/","title":"CloudWatch Custom Metrics"}],"answers":[{"id":"25084caeeca98bb0ed5317e16eb25f5b","text":"Utilize the CloudWatch Dashboard to view memory and disk metrics that are available by default.","correct":false},{"id":"4a31b453359b5547f03d47279651a6c7","text":"Install the CloudWatch Agent on your instance to monitor memory metrics.","correct":true},{"id":"f5537acc0c2715be1415c64741ce5ed7","text":"Check the EC2 Dashboard to monitor instance metric details.","correct":false},{"id":"fcf91ec5e036123e3b515882a4d079eb","text":"Create a Support Case to AWS and request a report on available memory space on your instances.","correct":false}]},{"id":"95096463-bf44-4a55-a938-134e17096ace","domain":"security-comp","question":"Instance 'A' and instance 'B' are running in two different subnets 'A' and 'B' of a VPC. Instance 'A' is not able to ping instance 'B'. Which of the following is a possible reason for this failure?","explanation":"The NACL on subnet B does not allow outbound ICMP traffic; and the security group attached to instance B does not allow inbound ICMP traffic.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_ACLs.html#ACLs","title":"Network ACL Basics"}],"answers":[{"id":"788e0ab5d1b2c372b5d80c26c17c6a71","text":"The NACL on subnet B does not allow outbound ICMP traffic; and the security group attached to instance B does not allow inbound ICMP traffic.","correct":true},{"id":"48173a79d09d626e62e08c080f3dafcb","text":"The route table of subnet 'A' has no target route to subnet 'B'; and the security group attached to instance B does not allow inbound ICMP traffic.","correct":false},{"id":"b683f2644731441134b6c0db51d38f6e","text":"The policy linked to the IAM role on instance 'A' is not configured correctly; and the NACL on subnet 'B' does not allow outbound ICMP traffic.","correct":false},{"id":"87877573324ed4201e723046eb1d8409","text":"The security group attached to instance 'B' does not allow inbound ICMP traffic; the policy linked to the IAM role on instance 'A' is not configured correctly.","correct":false}]},{"id":"a9593b23-49e7-4831-b16d-b7618fd07bfd","domain":"mon-rep","question":"Which of the following ELB response Codes indicates a normal, successful response from the registered instances.","explanation":"A HTTPCode_Backend_2XX  indicates a normal, successful response from the registered instances.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-cloudwatch-metrics.html#loadbalancing-metrics-clb","title":"CloudWatch Metrics for Your Classic Load Balancer"}],"answers":[{"id":"4cbb9bc9e8892ec2b03ce9300089bbae","text":"HTTPCode_Backend_2XX","correct":true},{"id":"e7415e6c2943791d842013f7aba6c120","text":"HTTPCode_Backend_4XX","correct":false},{"id":"e12e4cbddc5e0433d4f8b642c591b631","text":"HTTPCode_Backend_3XX","correct":false},{"id":"ed7ec39cbf617481ed14efc52061f350","text":"HTTPCode_Backend_5XX","correct":false}]},{"id":"b4ca6c23-e1b7-4e8d-970b-9799a990126e","domain":"automation","question":"What happens when one of the resources in a CloudFormation stack cannot be created successfully?","explanation":"By default, the “automatic rollback on error” feature is enabled. This will cause all AWS resources that AWS CloudFormation created successfully for a stack up to the point where an error occurred to be deleted. This feature enables you to rely on the fact that stacks are either fully created, or not at all, which simplifies system administration and layered solutions built on top of AWS CloudFormation.","links":[{"url":"https://aws.amazon.com/cloudformation/faqs/","title":"What happens when one of the resources in a stack cannot be created successfully?"}],"answers":[{"id":"03c1a80b2ab11433c3c6468b8fefec72","text":"The \"automatic rollback on error\" feature is enabled, deleting all resources created up to the point of the failure.","correct":true},{"id":"98b3aa08dc4c9826ee43acd20f3d400f","text":"CloudFormation will rollback the creation of the resource that failed.","correct":false},{"id":"c951223fd02f1849373afe7edde6a1dc","text":"CloudFormation will simply continue, then ask you to create the resource manually.","correct":false},{"id":"8d79a78919c954fac95764cd824334ca","text":"CloudFormation will stop the stack creation process and request manual intervention.","correct":false}]},{"id":"3714015f-1a0e-4b58-b904-42d21b082ce4","domain":"dep-prov","question":"You are running an EC2 instance with an attached EBS volume. Which of the following applies to EBS volumes?","explanation":"You cannot create snapshots from EBS volumes when hibernation is enabled on an instance. You can take a snapshot of an attached root volume, however this is not recommended as it may result in data inconsistency. If a snapshot is taken of an encrypted volume, it is automatically encrypted. Encrypted snapshots can be shared with other users of specific AWS accounts. For others to use your shared, encrypted snapshot, you must also share the CMK key that was used to encrypt it. Users with access to your encrypted snapshot must create their own personal copy of it and then use that copy to restore the volume.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html","title":"Creating Amazon EBS Snapshots"}],"answers":[{"id":"615c6b61cf777a5a029a4d97f7e0d897","text":"You cannot take a snapshot of an attached root volume.","correct":false},{"id":"d433815b2c570bc61e97ae01aad4e24c","text":"You can create snapshots from instances for which hibernation is enabled.","correct":false},{"id":"be7cc695163e3cfbe4fce331a5431ffe","text":"Snapshots that are taken from encrypted volumes are automatically encrypted.","correct":true},{"id":"ce3d4a8b603387b4c447b51080ecb934","text":"Encrypted snapshots cannot be shared with other users.","correct":false},{"id":"f1854d1c449a2c9492159c401571eb3e","text":"You can create snapshots from instances for which hibernation is disabled.","correct":true}]},{"id":"3f043cde-54b2-42c7-9a19-7153fe5b6e95","domain":"high-avail","question":"Your customer has asked about cost-savings opportunities with AWS. They've noted that their EC2 instances are on most, if not all, the time but metrics show that aggregate CPU utilization is low. Demand for their application is also unpredictable. They want to cut costs around their EC2 fleet. Which of the below suggestions would you recommend to your customer to maximize savings?","explanation":"AWS Auto Scaling monitors your applications and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost. AWS Auto Scaling makes scaling simple with recommendations that allow you to optimize performance, costs, or balance between them. With auto scaling you can scale-out Amazon EC2 instances seamlessly and automatically when demand increases, shed unneeded Amazon EC2 instances automatically and save money when demand subsides, and scale dynamically based on your Amazon CloudWatch metrics, or predictably according to a schedule that you define. Purchasing reserved instances, although cheaper than on-demand, would not necessarily cut costs. Since demand is unpredictable you may be purchasing a commitment that you may not use. There is no indication that the application will be running for at least a year. This is true even after right-sizing. Storing snapshots of EBS in S3 is indeed cheaper than storing EBS volumes but that does not address the issue of the EC2 instances themselves.","links":[{"url":"https://aws.amazon.com/autoscaling/","title":"AWS Auto Scaling"}],"answers":[{"id":"89a84b7404990525469a3025ab3b5116","text":"Decrease the instance sizes for those instances with low CPU utilization. Purchase standard reserved instances after right-sizing the instances.","correct":false},{"id":"99040729979583a2eb85e3502b484989","text":"Purchase convertible reserved instances for your EC2 fleet. They will experience up to 66% savings compared to on-demand costs and will have the option to change their instance types if the application needs change.","correct":false},{"id":"a8dd2caf5c16147c7b1b6bd321b6558d","text":"Take snapshots of the EBS volumes attached to the EC2 instances and store them in S3. Delete the EBS volumes as storing in S3 is a cheaper alternative than EBS storage costs.","correct":false},{"id":"76a2f03f07c2ade7d896075a501c6bc5","text":"Utilize auto scaling groups for the EC2 fleet. Set up a scaling policy that will launch EC2 instances when CUP utilization is above a threshold, and release instances when CPU utilization is below a threshold.","correct":true}]},{"id":"113a7914-1249-4e12-a748-03392c0570e8","domain":"high-avail","question":"You are a Security Administrator for your company. Your CIO wants to ensure that company data is highly available in multiple AWS Regions. What would you suggest to your CIO as the most effective approach?","explanation":"Deploying a multi-AZ RDS instance would only make it fault tolerant between Availability Zones, and not AWS Regions. Creating a Lambda function and creating/deploying EBS snapshots into different AWS Regions would both be an administrative and operational burden. The easiest, most effective, way is to utilize S3 Cross Region Replication","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 Cross Region Replication"}],"answers":[{"id":"a4ca2ada50730e36dd0f3302f60ab0dc","text":"Create multiple snapshots of your company data on EBS volumes. Deploy those EBS volumes on EC2 instance in different AWS Regions.","correct":false},{"id":"6e22da724261694b4ecf8fa105ef5174","text":"Enable Cross-Region Replication on your bucket to copy objects to a destination bucket in another AWS Region.","correct":true},{"id":"f876473fb6289d5a1e3e6d449713b0e7","text":"Copy the company data to an RDS instance. Deploy a multi-AZ configuration for your RDS instance to make it highly available.","correct":false},{"id":"fbde7989c5f0da5bb91bb5593f9c8e4e","text":"Create a Lambda function that downloads data from your S3 Bucket and executes a PUT operation to upload copied objects into a new bucket in a new Region.","correct":false}]},{"id":"fe87b3bd-e952-4f75-9b0e-3583fe879ad6","domain":"data-man","question":"Your manager has informed you that due to compliance issues, all data stored in company S3 buckets must be encrypted as soon as possible.  What is the quickest way to ensure all of this data is encrypted to meet the requirements?","explanation":"The easiest and quickest way to encrypt data in a bucket is to use Server Side Encryption, because Client Side Encryption will encrypt the files before sending to S3 and therefore will only work on newly uploaded files, we can discount any Client Side Encryption options first.  Of the remaining Server Side Encryption options, we can remove any method of managing keys ourselves, as this creates an overhead, so using S3 Managed Keys (SSE-S3) will be the quickest way to encrypt objects in a bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Server-Side Encryption"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Client-Side Encryption"}],"answers":[{"id":"1a4d7384bee05f19390352598fbc5fb6","text":"Enable Server-Side Encryption with Customer-Provided Keys on each S3 bucket","correct":false},{"id":"d16f34464ccb19afe4b04ca69703c59e","text":"Encrypt new data using AWS KMS–Managed Customer Master Key and add to S3 bucket","correct":false},{"id":"56f875bcb7f1ca2bd789c15f1cdc5c37","text":"Enable Server-Side Encryption with AWS KMS-Managed Keys on each S3 bucket","correct":false},{"id":"873764e12ed3764f29ba07e9fcdb622a","text":"Enable Server-Side Encryption with S3-Managed Keys on each S3 bucket","correct":true}]},{"id":"11a06ef4-bb74-456d-ba26-e7852eba3c7e","domain":"mon-rep","question":"A custom web application has been deployed to AWS.  The development team want to know when a specific .NET counter hits a threshold. Which service allows this?","explanation":"Custom operating system metrics can be pushed to AWS by using CloudWatch Custom Metrics. CloudWatch events refer to events around AWS resources but not within an EC2 instance.  X-Ray allows transaction tracing throughout applications but would not push .NET metrics to AWS.","links":[{"url":"https://aws.amazon.com/blogs/mt/query-for-the-latest-windows-ami-using-systems-manager-parameter-store/","title":"Query for the Latest Windows AMI using Systems Manager Parameter Store"}],"answers":[{"id":"0c810b936071c67e7bc9845d93416bc2","text":"AWS X-Ray and Alarms","correct":false},{"id":"957649c9aaeda66468ced97b30d4ce29","text":"CloudWatch Events and Alarms","correct":false},{"id":"ce8086df6e4acbf892ecfe8075412a33","text":"AWS CloudWatch Insights and Alarms","correct":false},{"id":"9d53eb372c233c0124733016585613fc","text":"CloudWatch custom metrics and Alarms","correct":true}]},{"id":"0e17eb91-9745-4365-8b54-5ebb2c6ffeb5","domain":"data-man","question":"A company wants to create a disaster recovery account involving creating snapshots of RDS, EC2 instances and EFS.  There are additional business and regulatory backup compliance requirements such as backups must be kept for three years but then must be destroyed.  Your manager wants to know how you could go about taking scheduled snapshots and deleting them once the retention period is expired with the lowest cost and operational overhead.","explanation":"AWS Backup is a centralised place to create backups of your EBS, RDS, and EFS resources.  There is no additional cost for setting up backup plans and retention policies, and this is a managed service so it's a perfect option to present to your manager.","links":[{"url":"https://aws.amazon.com/backup/","title":"AWS Backup"}],"answers":[{"id":"52b5e3e90161fce097eca53313efd955","text":"Use AWS Data Recovery Manager to create a storage vault and automated backup and retention rules.","correct":false},{"id":"8be1adb291f4f253ef46691652254d1f","text":"Browse the AWS Marketplace and purchase a backup tool which can run in your AWS account and perform the backup for you.","correct":false},{"id":"fc24b51d19eedb53ab68e9e1569c9458","text":"Use AWS Backup to create a vault and a Backup Plan to take backups on a schedule and automatically delete them once expired.","correct":true},{"id":"d75279ac650753a76148e6ac6c1b380e","text":"Your team should write some Lambda functions which are triggered by CloudWatch Events on a cron expression.  Create another lambda to delete snapshots once they are expired.","correct":false}]},{"id":"55e3410c-cf36-4a46-948a-95e2440003fd","domain":"mon-rep","question":"You are running an Application Load Balancer (ALB) in front for a fleet of web servers running on EC2. These servers are in a public subnet. Your customers connect to the ELB domain name to access web servers using HTTP. You want to know your customers' IP addresses to gain metrics into where your customers are located. This information will be helpful for improving your application based on the location of your customers. How would you collect log data for your ELB?","explanation":"The X-Forwarded-For request header helps you identify the IP address of a client when you use an HTTP or HTTPS load balancer. Because load balancers intercept traffic between clients and servers, your server access logs contain only the IP address of the load balancer. Elastic Load Balancing stores the IP address of the client in the X-Forwarded-For request header and passes the header to your server. If you were using TCP protocol (rather than HTTP), no additional configuration would be needed. CloudTrail is not appropriate as it only shows data regarding API requests sent within your AWS account. CloudWatch and Lambda would be an administrative burden and are not necessary.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html","title":"HTTP Headers and Classic Load Balancers"}],"answers":[{"id":"0fcaa257260dc2e705852935fcc43979","text":"Modify the application code to pull the client IP into the X-Forwarded-For header so the web servers can parse the information.","correct":true},{"id":"db95fed268eaf12b5b9c069f8256be2f","text":"Enable CloudTrail on your ELB and push the logs to an S3 bucket. Search the logs using Athena or download them as a CSV to identify the IP addresses of your customers.","correct":false},{"id":"c790427146d378ddfcfb7c4e0821a00c","text":"No additional configuration is needed. The proxy protocol will pass the client IP automatically, and you can check the ELB logs to find this information.","correct":false},{"id":"ee23873239420b48da4e1d7e54294f34","text":"Enable CloudWatch logs for your application and push the logs to a custom CloudWatch metric. Use Lambda to parse through the log files to search and extract the client IP addresses into a DynamoDB table.","correct":false}]},{"id":"daab371e-09f1-4d56-ae18-ac01147c8d31","domain":"automation","question":"Your organisation is growing their AWS footprint and wants to build a dashboard for their hybrid infrastructure.  They use a mix of on-premises Linux and Windows machines, and new AWS EC2 instances. There are around 1500 on-premises VMs which your CTO ambitiously wants to manage with a centralised configuration tool.  How can your organization simplify the management of the patching and inventory of both the on-premises and cloud instances from one central AWS account?","explanation":"Microsoft patching is only available for on-premises instances under the 'advanced-instances' tier of Systems Manager.  The standard Systems Manager tier also only enables you to register a maximum of 1,000 servers per AWS account per AWS Region. If you need to register more than 1,000 servers or VMs in a single account and Region, then you need to use the advanced-instances tier. Since there are over 1,000 servers, and a mix of Windows and Linux workloads, the organisation needs to enable Systems Manager Advanced-Instances before it can perform inventory and patching of the whole hybrid fleet using SSM.","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-managedinstances.html","title":"Setting Up AWS Systems Manager for Hybrid Environments"}],"answers":[{"id":"b99a0eb336123271439fdc9e65a6eace","text":"You can patch on-premises Linux VMs using AWS Systems Manager, however patching of on-premises Windows instances is not supported using AWS Systems Manager.","correct":false},{"id":"34c2b7a9390e3561fd7641103bc12575","text":"Use AWS Systems Manager Managed Instances to inventory and patch instances via the SSM agent.","correct":true},{"id":"59d2c9186d25dac05a2935b57bd9c708","text":"Enable AWS Systems Manager Advanced-Instances and use Systems Manager to inventory and patch the instances via the SSM agent.","correct":false},{"id":"dc3a64c07de1193f3276dfd13990fbc3","text":"Enable AWS Systems Manager Enterprise to inventory and patch instances via the SSM agent.","correct":false}]},{"id":"571b9603-45b6-45b1-aa47-68849ac814bb","domain":"automation","question":"A big-box retailer runs their in-store point-of-sale system on EC2 linux instances. All of the infrastructure is managed as part of a CloudFormation stack. The web servers are part of an Auto Scaling Group. The application only needs to be available during business hours from 9:00am until 6:00pm. What would be the best way to scale the web servers cost efficiently based on demand?","explanation":"Authoring the CloudFormation template to include an AutoScaling:ScheduledAction resource to increase the Auto Scaling Group's MinSize and MaxSize values at 9:00am, and another AutoScaling:ScheduledAction resource to decrease the Auto Scaling Group's MinSize and MaxSize values at 6:00pm will save costs for the retailer during non-business hours. CloudFormation conditions control whether certain resources are created or whether certain resource properties are assigned a value during stack creation or update, but don't control the actions of an Auto Scaling Group. Using an Auto Scaling Group scheduled action provides more streamlined automation than using a Lambda function. CloudFormation mappings are key/value pairs that can be used to specify conditional parameter values, but they have no impact on the Auto Scaling Group unless they are used to create a resource.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"What is AWS CloudFormation?"},{"url":"https://s3-us-west-2.amazonaws.com/cloudformation-templates-us-west-2/AutoScalingScheduledAction.template","title":"Cloud Formation Sample Template for Time-based Auto Scaling"}],"answers":[{"id":"0db6203397832efddcbca893f96ba1b6","text":"Include AutoScaling:ScheduledAction resources in the CloudFormation template that change Maxsize, MinSize, and Recurrence values based on business hours","correct":true},{"id":"a0f99978bb65910b10b75a32e1b92a2a","text":"Create AutoScaling:ScheduledAction conditions in the CloudFormation template that change Maxsize and MinSize values based on business hours","correct":false},{"id":"725933a9f7ea7ef281e2decf6cefadae","text":"Configure AutoScaling:ScheduledAction mappings in the CloudFormation template with Maxsize, MinSize, and Recurrence values based on business hours","correct":false},{"id":"765dccb8332e2036eb70a0b6276e7285","text":"Use CloudWatch Events to trigger a Lambda function at business opening and closing that adjusts the Auto Scaling Group's MinSize and MaxSize accordingly","correct":false}]},{"id":"8f2d3d61-092d-429c-a109-69ab00fa4065","domain":"mon-rep","question":"AWS Cost Management encompasses a number of services to help you to organize, control and optimize your AWS costs and usage.  Which of the following Cost Management related tools gives you the ability to set alerts when costs or usage are exceeded?","explanation":"The correct answer is AWS Budgets.  AWS Cost Explorer lets you visualize, understand, and manage your AWS costs and usage over time. AWS Cost & Usage Report lists AWS usage for each service category used by an account and its IAM users and finally, Reserved Instance Reporting provides a number of RI-specific cost management solutions to help you better understand and manage RI Utilization and Coverage.","links":[{"url":"https://aws.amazon.com/aws-cost-management/aws-budgets/","title":"AWS Budgets"}],"answers":[{"id":"824fd559c917b4ae56f36787b886eb81","text":"AWS Cost & Usage Report","correct":false},{"id":"eef79d956328d5e4ec426d448cc53c74","text":"Reserved Instance Reporting","correct":false},{"id":"e32a801c8e0beab6abb9361e937365be","text":"AWS Budgets","correct":true},{"id":"c7f176d72688fd87853e31b84159d541","text":"AWS Cost Explorer","correct":false}]},{"id":"44eb75dc-1cf8-47bc-a6c4-7eb3551d39ad","domain":"dep-prov","question":"Your team uses Docker to build and install a new application. You need to deploy it with Amazon Elastic Container Service (Amazon ECS). You create an Auto Scaling group using an ECS optimized AMI as the ECS cluster. You also define a task definition and specify the number of tasks that will run on the cluster. Which of the following is responsible for starting and stopping tasks when it receives a request from Amazon ECS?","explanation":"The ECS optimized AMI has the ECS container agent installed and it communicates with the ECS service. It sends information about the current running tasks to Amazon ECS, and schedules tasks whenever receiving requests from Amazon ECS. ECS task definition does not schedule tasks. Fargate agent is used for Fargate instead of ECS. Elastic Container Registry saves Docker images but does not start/stop ECS tasks.","links":[{"url":"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html","title":"ECS agent"}],"answers":[{"id":"1f773c4abe01e9ac9ea69a8467588e92","text":"Amazon Elastic Container Registry.","correct":false},{"id":"77d3861f206ed0b395e521eef335a70e","text":"The ECS container agent running on ECS container instances.","correct":true},{"id":"6da0c2a81f282023e97f7cb2e6d2afde","text":"The Amazon ECS task definition.","correct":false},{"id":"69c4feff2c34858d768595502051dddb","text":"AWS ECS Fargate agent.","correct":false}]},{"id":"0a54c671-954d-4e52-8a46-83eadcf029cd","domain":"mon-rep","question":"Which of the following are valid alarm statuses in CloudWatch?","explanation":"The three alarm statuses are OK, INSUFFICIENT_DATA and ALARM.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html","title":"About CloudWatch Alarms"}],"answers":[{"id":"9de6d0a670ae5a0dee31a6318aa00e8d","text":"ALARM","correct":true},{"id":"e0aa021e21dddbd6d8cecec71e9cf564","text":"OK","correct":true},{"id":"320f86f60f25459ba5550e000b2c3929","text":"ALERT","correct":false},{"id":"f5d0aa0db6ffc40d938f1412b89d946c","text":"INSUFFICIENT_DATA","correct":true}]},{"id":"983c6fbc-20eb-4389-a91f-491d1f1e230b","domain":"networking","question":"You have a simple VPC with a single public subnet and a security group that allows access from source 0.0.0.0/0. Although you have both an Internet Gateway and Elastic IP specified for your instance, you are still unable to reach the instance via SSH. What have you forgotten to do?","explanation":"For the outside world to be able to communicate with your instance, you must allow inbound traffic on both the Security Group and the Route Table.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#AddRemoveRoutes","title":"Adding and Removing Routes from a Route Table"}],"answers":[{"id":"93b61a7d33d3f54dee0f2c7dfd033254","text":"You haven't associated the Internet Gateway with the Security Group.","correct":false},{"id":"9c4da4b8220f1bcf509bc4cd3ccd943f","text":"You forgot to associate the Security Group with the Route Table.","correct":false},{"id":"1e8881ac02fb21089d364fb6f88436a7","text":"You have forgotten to associate the Elastic IP with the private IP.","correct":false},{"id":"cb7394a526c29652c88dc22d58ad386a","text":"You have failed to associate the Internet Gateway with the custom Route Table.","correct":true}]},{"id":"56b58c2e-0c37-4b6e-a9e5-79d362200641","domain":"networking","question":"You are a network administrator for your organization that is working to move into the Cloud. You are tasked with connecting your on-premises corporate network with AWS network. You have created a VPC in AWS, with an IP CIDR range of 10.0.1.0/16. You have launched an EC2 instance within a subnet in your VPC. Your external corporate network has a CIDR range of 172.16.0.0/12. How would you set up the destination on the route table so that the subnet in your AWS VPC connects to your external corporate network?","explanation":"A route table contains a set of rules that you can direct where network traffic in your subnet is directed to. If you are setting up a route to your external corporate network from your VPC, the destination must be the CIDR range of your external corporate network. 0.0.0.0/16 is the destination for the open Internet. 10.0.1.0/16 is the CIDR range for your own subnet, which would not work. 192.168.192.168/32 is the instance metadata and would not connect to your corporate network.","links":[{"url":"https://docs.aws.amazon.com/en_pv/vpc/latest/userguide/VPC_Route_Tables.html","title":"Route Tables"}],"answers":[{"id":"14eecdfdcb09e543dbbaf8bfb2df4e0f","text":"Set the destination CIDR as 192.168.192.168/32 for the traffic in your subnet to go.","correct":false},{"id":"83f6f90763fb37e1a55fafd4ca6ad17c","text":"Set the destination CIDR as 10.0.1.0/16 for the traffic in your subnet to go.","correct":false},{"id":"7b02a9ed0632530a998a9a41da156695","text":"Set the destination CIDR as 172.16.0.0/12 for the traffic in your subnet to go.","correct":true},{"id":"0b4c0e7099a39c83801d4570c9dc6c27","text":"Set the destination CIDR as 0.0.0.0/16 for the traffic in your subnet to go.","correct":false}]},{"id":"d4d6b4d3-64db-49bf-82b9-882f2b18137e","domain":"data-man","question":"You are considering moving an on-premise SQL Server cluster into AWS, using EC2 instances rather than RDS.  You need to recommend the most suitable EBS volume type for the cluster to use, but also pair it with a suitable EC2 instance type.  You know that the throughput must be good, but the most important thing is to maintain a consistent level of IOPS under normal load which can increase to a much higher level at busy times.  Choose the best option from the following EC2 and EBS pairings.","explanation":"The question states that you require consistent IOPS which means the io1 Provisioned IOPS type is the best choice of the two EBS types available, and therefore the correct answer must have io1 as an option.  Of the remaining two answers, either EC2 families would work.  We know from experience that databases do utilise as much memory as is available, so choosing an r5 family is plausible, however we need to use our extended knowledge of EC2 families to know that X1e was specifically created to run high performance databases and the final answer will therefore contain an io1 EBS volume and the X1e EC2 option.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"Amazon EC2 Instance Types"},{"url":"https://aws.amazon.com/ebs/features/","title":"Amazon EBS features"},{"url":"https://aws.amazon.com/blogs/database/new-memory-optimized-amazon-ec2-instance-types-drive-database-workloads/","title":"New, Memory-Optimized Amazon EC2 Instance Types Drive Database Workloads"}],"answers":[{"id":"b28dd6770d9036a2f719c5f4cfc7cecc","text":"Throughout Optimised (st1) EBS volumes with X1e EC2 instances","correct":false},{"id":"78c33d688d1822c44c657b33bb0e5080","text":"Throughout Optimised (st1) EBS volumes with c5 EC2 instances","correct":false},{"id":"27e1d3ca80c5e8a728f7916a73f98ec4","text":"Provisioned IOPS (io1) EBS volumes with X1e EC2 instances","correct":true},{"id":"7b472a990561e6ad0996ca48c955594b","text":"Provisioned IOPS (io1) EBS volumes with r5 EC2 instances","correct":false}]},{"id":"4a4c6ce8-b38c-4905-8705-d5bbfb0ee4b2","domain":"mon-rep","question":"You have an Auto Scaling group resource in your AWS account. The desired number of instances has been changed from 2 to 0 recently and all instances were terminated because of it. You want to know when and how the resource was created and who modified the desired number. Which service can help you to quickly get the information?","explanation":"You can quickly get the configuration history in the AWS Config configuration timeline including who and when the resource was created or modified. A new CloudTrail does not help as it only records new events. Athena may work however it is not as easy as AWS Config. CloudWatch metrics cannot provide the required configuration information.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/view-manage-resource-console.html","title":"Viewing configuration details in AWS Config"}],"answers":[{"id":"8d084da5294ed862175582c9670af840","text":"Create a new CloudTrail and save the events to CloudWatch Logs. Search for the Auto Scaling group resource in the logs.","correct":false},{"id":"25787092d8b6523e05e0155400bcc0bf","text":"Check the Auto Scaling group resource in AWS Config and inspect the configuration timeline for the resource.","correct":true},{"id":"65d77f35794d925b20ff78961bb4c1df","text":"Check the CloudWatch metrics for the Auto Scaling group resource. CloudWatch metrics can record the data for 6 weeks.","correct":false},{"id":"9a2b6d3211e9c6531d8bf6f6ff2e8351","text":"Save all CloudTrail events to an S3 bucket. Perform SQL queries in the bucket via Athena.","correct":false}]},{"id":"7d7ac6a5-ba31-4418-9d4c-6da76657dbf2","domain":"networking","question":"You are designing a network with a bastion host (jump box) for security. Your network admins will SSH in to the bastion host and then on to other EC2 instances in a private subnet. You need your bastion host to be highly available. How should you build this environment?","explanation":"There has been is a much discussion about resilient Bastion design. The ELB does not add much value in this situation. Although you can get around it the ELB session timeouts will cause an SSH session to become disconnected if idle.  The answer with two AZs is a trap of the type you will see on the exam.  While 2x AZs would be ideal, the WHOLE answer must be correct, not just part of it. You should never use an ELB IP address for business as it is ephemeral and may change at any time.  DNS convectional round-robin will achieve the resiliency needed, as would an R53 Failover policy. The answer with two subnets does not exclude 2x AZs even though it does not stipulate it. Another design option you might see is EC2 Auto-Recovery or an Autoscaling group of Max=1 & Min=1 so that if the Bastion Host fails it is recreated automatically. ","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html","title":"Bastion Hosts on AWS - Architecture"},{"url":"https://en.wikipedia.org/wiki/Round-robin_DNS","title":"DNS convectional round-robin"},{"url":"hhttps://aws.amazon.com/blogs/aws/new-auto-recovery-for-amazon-ec2/","title":"Auto Recovery for Amazon EC2"}],"answers":[{"id":"01a3b5d266f7455e0d0cfc25070de365","text":"Create 2 Bastion EC2 instances in separate availability zones. Place these instances behind an elastic load balancer, and ask your SysAdmins to connect to the ELB's public IP Address.","correct":false},{"id":"d5cfd03aad43f4cb7329ceb07c3b288d","text":"Create 2 Bastion EC2 instances in the same subnet. Create a DNS entry in Route53 which uses Round Robin DNS and points to each instance. Tell your SysAdmins to connect using the new DNS entry.","correct":false},{"id":"c87a02a4d83b0d5310563e4b700e303a","text":"Create 2 Bastion EC2 instances in different subnets. Create a DNS entry in Route53 which uses Round Robin DNS and points to each instance. Tell your SysAdmins to connect using the new DNS entry.","correct":true},{"id":"cb402e295d67552ab9dfcffabcfb0dcb","text":"Create 1 Bastion EC2 instance in a private subnet. Connect to this EC2 instance using a site to site VPN. Configure your router to automatically reconnect if the VPN is dropped.","correct":false}]},{"id":"2db1ee7d-fe0a-4556-ad28-5731b36c2eca","domain":"networking","question":"You need a load balancer with support for TCP connections and preserving the source IP address. What load balancer should you choose?","explanation":"Proxy Load balancer isn't a real thing. Network Load Balancer and Classic Load Balancer both support TCP connections. However, only Network Load Balancer supports preserving the source IP address. ","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/","title":"Elastic Load Balancing features"}],"answers":[{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false},{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":false},{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":true},{"id":"898665d0778b0435cd2b64ff8a8512c2","text":"Proxy Load balancer","correct":false}]},{"id":"46293632-1540-45c7-91df-7b6815a27847","domain":"security-comp","question":"Which of the following names is not a valid IAM role name?","explanation":"Names of users, groups, roles, policies, instance profiles, and server certificates must be alphanumeric, including the following common characters: plus (+), equal (=), comma (,), period (.), at (@), underscore (_), and hyphen (-). CompanyMarketing#Role is therefore not an acceptable role name.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_iam-limits.html","title":"Limitations on IAM Entities and Objects"}],"answers":[{"id":"d8c8f0893b0743d016015e108e9d2ab9","text":"MarketingRole@Company","correct":false},{"id":"dc6e80f51a713e21ec697bead75c1667","text":"Company.Marketing_Role","correct":false},{"id":"a1b18d40d2aedd805efd8bc59f1d6969","text":"Company,Marketing,Role","correct":false},{"id":"e414a871abd69eafb829412a3a873a36","text":"CompanyMarketing#Role","correct":true},{"id":"7ab3a687b4689245604f8981502bdf09","text":"Company--Marketing+Role","correct":false}]},{"id":"082f8b00-13da-4a51-918c-f976a16580ca","domain":"high-avail","question":"You have a web application that queries ElastiCache to cache your database queries. You are using Memached with ElastiCache and you use CloudWatch metrics to monitor your memcached performance. You notice that two metrics, Evictions (The number of non-expired items the cache evicted to allow space for new writes) and GetMisses (The number of get requests the cache has received where the key requested was not found), are getting very high. What should you do to scale your environment further?","explanation":"You should increase the number of nodes in your Memcached cluster or increase the size of each node in your cluster.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CacheMetrics.Memcached.html","title":"Metrics for Memcached"}],"answers":[{"id":"3678711f6b0323c2c64b95f85b586d6d","text":"Migrate from Memcached to Redis.","correct":false},{"id":"ba0c29a489d86a1d6386e6b65cbd93d3","text":"Use CloudFront as an alternative caching engine.","correct":false},{"id":"fdc0f2a5336b08f741567e4b5c2cc2a0","text":"Decrease the number of nodes in your memcached cluster or decrease the size of each node in your cluster.","correct":false},{"id":"e97e7e506a3503958146ba4d62e89c26","text":"Increase the number of nodes in your Memcached cluster or increase the size of each node in your cluster.","correct":true}]},{"id":"84adda98-8315-454d-b0c1-b6478c5c0d98","domain":"mon-rep","question":"You are performing an update to all of your application servers, however some of your applications are failing following the upgrade and you notice that this seems to only be affecting servers with a specific application profile. How can you easily identify which of your systems are likely to be affected?","explanation":"AWS Config is a service that enables you to assess, audit and evaluate the configurations of your AWS resources.","links":[{"url":"https://aws.amazon.com/config/faq/","title":"AWS Config FAQs"}],"answers":[{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"055f466b265e26667e0bb23ddffc7970","text":"Run Command","correct":false},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"9deb03cd21d41a691cdc24bfaab2820c","text":"Inspector","correct":false}]},{"id":"d3ba2fd5-b275-4485-a2c3-12c264fdd9ff","domain":"dep-prov","question":"You are trying to SSH into your EC2 instance and you get a \"Permission denied (publickey)\" error. Which of the following are the most likely causes of this error?","explanation":"If you connect to your instance using SSH and get any of the following errors, \"Host key not found in [directory]\", \"Permission denied (publickey)\", or \"Authentication failed, permission denied\", verify that you are connecting with the appropriate user name for your AMI *and* that you have specified the proper private key (.pem) file for your instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html","title":"Troubleshooting: Connecting to Your Instance"}],"answers":[{"id":"334acb0dcf7f1f56bc449066c8cab4b6","text":"The instance's security group is misconfigured.","correct":false},{"id":"99e7bf54cfff54e73272a9034be64f6c","text":"There is an issue with the AWS infrastructure.","correct":false},{"id":"51ba58459b06a9c8a6e1d38f220f5d65","text":"You have supplied an invalid or otherwise improper private key (.pem) file.","correct":true},{"id":"eb07107df739e65e6a8f465acdc3a501","text":"You have provided an incorrect username for your AMI type.","correct":true}]},{"id":"cb89f655-931a-4755-a01c-07b9abf46363","domain":"data-man","question":"Your payment processing system stores 300 GB of data in an Amazon RDS database and 1 TB of data in an Amazon Elastic File System (EFS). A human error incident occurs resulting in files being mistakenly deleted from the EFS. With no backup of the files, the data needs to be reconstructed from other sources. You're tasked with ensuring that future recoveries from unintentional corruptions and deletions from the EFS can be accomplished in a more expeditious manner. Which solution will provide the most efficient recovery capability?","explanation":"AWS DataSync makes it simple and fast to move large amounts of data between on-premises storage, S3, and EFS. A DataSync agent on an EC2 instance can access a source file system and write the data to a target EFS file system. AWS DataSync performs transfers much faster than open source tools like rsync. EFS currently does not provide a snapshot capability. The EFS API doesn't currently provide the capability to read file system directories.","links":[{"url":"https://aws.amazon.com/datasync/","title":"AWS DataSync"},{"url":"https://aws.amazon.com/about-aws/whats-new/2019/05/aws-datasync-now-supports-efs-to-efs-transfer/","title":"AWS DataSync Now Supports EFS-to-EFS Transfer"}],"answers":[{"id":"f0aa146fd12f8b90653556e359f3a5a5","text":"Implement an Amazon CloudWatch event to periodically invoke an AWS Lambda function. Have the Lambda function create an EC2 Linux instance that uses rsync to write files from the primary file system to a backup file system. Have the EC2 instance also write details about the backup to an Amazon DynamoDB table, and send backup logs to Amazon S3","correct":false},{"id":"d14180fd4210358f6de8f3e00fa219b9","text":"Configure EFS snapshots for the file system. In the EFS management console, designate when the snapshots will run and what the retention time frame should be","correct":false},{"id":"d358ff9f00701597b983db08178191be","text":"Implement an Amazon CloudWatch event to periodically invoke an AWS Lambda function. Have the Lambda function read the primary file system's directory via the EFS API and write updated files from the primary file system to a backup file system. Have the Lambda function also write details about the backup to an Amazon DynamoDB table, and send backup logs to Amazon S3","correct":false},{"id":"c008c80d4f7240b74aa18b5301bd2f80","text":"Install an AWS DataSync agent on an EC2 instance and mount the primary EFS file system. Implement an Amazon CloudWatch event to periodically publish a message to an Amazon Simple Notification Service topic. Have a script on the EC2 instance receive the notification and invoke DataSync to update a backup EFS file system","correct":true}]},{"id":"6fd27cf3-e84d-4a26-875c-7695a786a998","domain":"networking","question":"Two EC2 instances in two VPCs cannot ping each other. Both instances are located in private subnets. Which of the following would help you troubleshoot the problem? Select two.","explanation":"You can only peer VPCs, not individual subnets. There must also exist a route between the peered VPCs. Subnet security policy isn't a real thing although Network ACLs could be considered as such. VPC endpoint policy controls access to S3 or DynamoDB, not to a peered VPC.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html","title":"What is VPC Peering?"}],"answers":[{"id":"d6d0388ad6ed9fa8508ce01fce126328","text":"Check that there is a peering connection between the subnets","correct":false},{"id":"19b59f579598d8721b6507a457658f92","text":"Check that a subnet security policy allows ping","correct":false},{"id":"088c1791b9d25f53b479820769d14995","text":"Check that there is a peering connection between the VPCs","correct":true},{"id":"e88fa7d7390ad4d45912151c4e94b106","text":"Check that a VPC endpoint policy allows ping","correct":false},{"id":"b60b61736af41d60dfcadf8fde5d83b6","text":"Check that a route exists between the VPCs","correct":true}]},{"id":"d69480f4-f12c-471d-bf7f-f6b0994a441f","domain":"mon-rep","question":"You are supporting an online gaming platform which runs on a number of application servers behind an Application Load Balancer, your Security Architect asks you to start monitoring HTTP requests from users to your application? Which of the following can you use to achieve this?","explanation":"Request Tracing can be used to track HTTP requests from clients to targets. CloudWatch monitors performance metrics, Trusted Advisor makes recommendations based on best practices for security, performance and cost optimization. Cloud Trail monitors API calls within your account. ","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-request-tracing.html","title":"Request Tracing on Application Load Balancer"}],"answers":[{"id":"50ed91980adb1dac23689554eb719277","text":"CloudWatch metrics","correct":false},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"e86c7149423f18f89a2a67af3295477a","text":"Request Tracing","correct":true},{"id":"f0d36f4f7323e9b431c82349dcc3ab89","text":"CloudTrail Logs","correct":false}]},{"id":"a8d6d4f3-6877-4e89-9e7c-c6f83b83e1de","domain":"automation","question":"A small business has a monolithic application utilizing several EC2 instances. The technology consultant has suggested to the engineering team of the business that the application is containerized to improve the deployment and scaling processes of the team. The engineering team processes both critical and non-critical workloads within the application. Given the size of the application and the number of transactions being processed by the system, the CFO has instructed the engineering team to ensure that the setup must be as cost-effective as possible without introducing the risk of data loss for critical workloads. How can the engineering team accomplish this?","explanation":"On-demand EC2 instances should be used for critical workloads and spot instances can be used for non-critical workloads. ECR (Elastic Container Registry) is not used to run container processes. Instead, it is used to store container images. For containerization requirements, ECS (Elastic Container Service) is used to manage container workloads. Step Functions is used for orchestrating different processes and can not be used by itself to manage the workloads.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-high-scale-web-on-spot-instances/","title":"Running High-Scale Web Applications on Spot Instances"}],"answers":[{"id":"ddf2c2e29f2118061f6a160054593338","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECR and spot EC2 instances for non-critical workloads.","correct":false},{"id":"b8864524b96a467a8f1023b5a2c9f003","text":"Use Step Functions and on-demand EC2 instances for the critical workloads. Use Step Functions and spot EC2 instances for non-critical workloads.","correct":false},{"id":"47e42a6e665f0a913236e5580553e3ad","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECS and spot EC2 instances for non-critical workloads.","correct":true},{"id":"1d3682fdb0beec13b13a37502cfb3108","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use Step Functions and on-demand EC2 instances for non-critical workloads.","correct":false}]},{"id":"05d71be4-026e-433e-bd8b-eb4a3929ba63","domain":"automation","question":"A development team wants to use the latest Windows AMI whenever they launch an EC2 instance. Which service will allow them to query the AWS-managed Parameter Store namespace to retrieve the newest AMI for their CloudFormation template?","explanation":"AWS publish the latest AMI IDs for Operating Systems in AWS-managed parameters in the Parameter Store.  By using a Custom Resource in Lambda you can retrieve the relevant AMI ID and return it to the CloudFormation service, that way ensuring that your templates always use the newest AMI.","links":[{"url":"https://aws.amazon.com/blogs/mt/query-for-the-latest-windows-ami-using-systems-manager-parameter-store/","title":"Select AMI using Systems Manager Parameter Store"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources-lambda.html","title":"AWS Lambda-backed Custom Resources"}],"answers":[{"id":"2751cfe1530d4333f0bdac2d7b7c21bd","text":"CloudFormation using AWS Systems Manager Parameter Store","correct":true},{"id":"8c19fb5ff9d451c3f315e96ca8563b84","text":"CloudFormation Linked Parameters","correct":false},{"id":"dc0efa07b1be89f7cfd1ab666df2f949","text":"CloudFormation Custom Resource using Lambda","correct":true},{"id":"cdf3a2f6faa3abf891b952dde17eb469","text":"CloudFormation Template Transformation","correct":false},{"id":"7eb8f6238570dc713a360eae3029648f","text":"CloudFormation Mappings","correct":false}]},{"id":"fa546ba1-3d10-4f56-8cca-03f69c7bb141","domain":"mon-rep","question":"You have a task to maintain a CloudFormation template for a new application. The template contains resources for an AutoScaling Group, a Launch Configuration and a Classic Load Balancer. To monitor the application running status, you need to create a new CloudWatch Log Group. The Launch Configuration user data in the template is modified to install the CloudWatch Agent and configuration files. Which resource should you also create in the CloudFormation template for the CloudWatch Log Group to work?","explanation":"The CloudFormation stack should create a CloudWatch Log Group resource. A Log Group is a group of log streams. The correct resource type is AWS::Logs::LogGroup. Other resources types such as AWS::CloudWatch::Dashboard, AWS::Logs::Destination or AWS::Logs::LogStream are unnecessary or invalid.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-logs-loggroup.html","title":"Create CloudWatch log groups in CloudFormation"}],"answers":[{"id":"753205d9356936ff0505312dd82f15ed","text":"A resource with the resource type as AWS::Logs::LogStream.","correct":false},{"id":"5d8b7a94aecd66edf0bbbac7a39b9010","text":"A resource with the resource type of AWS::Logs::LogGroup.","correct":true},{"id":"b763f5ea4415de324920f7c7c639e4ac","text":"An AWS::Logs::Destination resource where the logs are sent to.","correct":false},{"id":"546e068e392aafa083829c464e843ed2","text":"A CloudWatch dashboard with the resource type AWS::CloudWatch::Dashboard.","correct":false}]},{"id":"2bd13304-db2d-4120-9487-7e13d7008a63","domain":"dep-prov","question":"EC2 instances are launched from Amazon Machine Images (AMIs). A given public AMI:","explanation":"An AMI cannot be launched into another region. To launch an AMI into a region other that the one in which it was created, the AMI must be copied to that other region first.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"9ba6ee29e152b251b8fc17d5d2aca126","text":"Can be used to launch EC2 instances in any AWS region.","correct":false},{"id":"5a70861f841598d574b8ebd61e20cfc1","text":"Can only be used to launch EC2 instances in the same AWS Availability Zone (AZ) as the AMI is stored.","correct":false},{"id":"3b690d9883c0bbec853ffdc3be150208","text":"Can only be used to launch EC2 instances in the same AWS country as the AMI is stored.","correct":false},{"id":"7096f3da806d7b3014ab808eb74d213a","text":"Can only be used to launch EC2 instances in the same AWS region as the AMI is stored.","correct":true}]},{"id":"3f8d157d-c9a7-4e65-81ca-23495248c13a","domain":"high-avail","question":"Which of the following is part of the failover process for a Multi-Availability Zone RDS instance","explanation":"The DNS record for the RDS endpoint is changed from primary to standby.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"The Multi-AZ Failover Process"}],"answers":[{"id":"d0bb9a7c3d4da6a24f1f7d977b81210c","text":"The IP of the primary DB instance is switched to the standby DB instance.","correct":false},{"id":"7150d3c0aa88b4f548178e7ee6748ce3","text":"The failed RDS DB instance reboots.","correct":false},{"id":"837a3731c4c25be7e91a8d02984a08fd","text":"A new DB instance is created in the standby availability zone.","correct":false},{"id":"aa56a93d275a00fbbc67b186e8b7683c","text":"The DNS record for the RDS endpoint is changed from primary to standby.","correct":true}]}]}}}}
