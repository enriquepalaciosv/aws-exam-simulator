{"data":{"createNewExamAttempt":{"attempt":{"id":"cdb931f6-f7c0-4540-8203-9c90bea183c7"},"exam":{"id":"edd4cb52-2972-4ccb-a167-be3700cd09a9","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"81dc73a3-27d5-4080-99ab-d75edfa081b0","domain":"ResilientDesign","question":"You successfully configure VPC Peering between VPC-A  and VPC-B. You then establish an IGW and a Direct-Connect connection in VPC-B. Can instances in VPC-A connect to your corporate office via the Direct-Connect service as well as connect to the Internet via the IGW?","explanation":"VPC peering only routes traffic between source and destination VPCs. VPC peering does not support edge-to-edge routing.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html","title":"Invalid VPC Peering Connection Configurations"}],"answers":[{"id":"d823d585a3fbbbcb9b921454f7d3bd62","text":"VPC peering does not support edge-to-edge routing.","correct":true},{"id":"6ce9df55ff92945dc320411540661454","text":"Yes: VPC Peering is designed to route traffic between the VPCs.","correct":false},{"id":"bdb763fa01cc1ea95bbab61b10394fea","text":"Instances in VPC-A will be able to access the corporate office, but not the Internet.","correct":false},{"id":"3542ee08d9923e029f120a6dc9b3d9db","text":"Instances in VPC-A will be able to access the Internet, but not the corporate office.","correct":false}]},{"id":"9deb393a-9a4d-46e5-b4d7-42fc4a6ce528","domain":"ResilientDesign","question":"You have been approached about storing some files used several times a month in AWS. These files need to be rapidly available when requested. It is acceptable for these files to be unavailable due to an Availability Zone outage. Which of the following S3 Storage Tiers is best suited for this request?","explanation":"S3 One Zone-IA is for data that is accessed less frequently, but requires rapid access when needed. S3 One Zone-IA is ideal for customers who want a lower-cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#__","title":"Amazon S3 Storage Classes - One Zone-Infrequent Access"}],"answers":[{"id":"0f351a927f8079b4ee16870680ccc746","text":"S3 One Zone IA","correct":true},{"id":"a4172aee8a692bd73f2781afe65fda72","text":"S3 Infrequently Accessed","correct":false},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false}]},{"id":"38ef90f0-2aba-4d4b-ada7-da42c65e057b","domain":"SecureSolutions","question":"There is a requirement to launch an AWS EC2 instance. The instance went from pending state to terminated state immediately after restarting it. What could be possible reasons for the instance termination?","explanation":"An instance could get terminated during launch or restart if: the EBS Volume Limit exceeded; an EBS Snapshot is corrupt; an EBS root volume is encrypted and does not have permission to access the KMS Key for decryption; and, the instance store-backed AMI that is used to launch the instance is missing a required part file.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html","title":"Amazon EC2 Launch Issues"}],"answers":[{"id":"8abfca6f4f8d89032e129b9f9ca43fa1","text":"An EBS Snapshot is corrupt.","correct":true},{"id":"695e9653895aaae42d926723df22c02b","text":"Only on-demand and reserved instance can be restarted. Spot instances cannot be restarted.","correct":false},{"id":"a1c2596d4b7f0ed157ccc7ea980c7b3b","text":"The root EBS volume is encrypted and missing permissions to access the KMS key for decryption.","correct":true},{"id":"b892c187f86580b57d005289701fa8d5","text":"EBS volume has reached its limit.","correct":true},{"id":"85d6641bc71a96c5d17ebf9073fbef70","text":"Data in the AWS EC2 instance store does not persist across reboot, it was terminated.","correct":false}]},{"id":"1ea8aa1e-9454-49b0-b4e2-379eadf674e0","domain":"CostOptimized","question":"You are an employee at a communications firm that is in the process of migrating its data to Amazon S3. The data will be stored in buckets and is sent to customers to do as they see fit. However, certain data is frequently changed when customers request revisions, while the rest of the data is rarely changed. You must be able to immediately access certain data while minimizing costs. Which S3 storage class should you choose?","explanation":"While S3 Glacier is a low-cost storage class, it is for data archiving and thus not ideal for frequent access or changes to data. And S3 One Zone-Infrequent Access is also low-cost, but it does not address the frequently changed data. Although S3 Standard is a suitable choice, since it addresses frequent access, it is not the least expensive choice for the less frequently accessed data. If it was hard to determine which data is frequently changed and which isn’t, S3 Standard might have been the most cost-effective choice. But in this case, S3 Intelligent Tiering is. Intelligent Tiering stores data in two access tiers: one tier is optimized for frequently accessed data while the other is a lower-cost tier for infrequent access.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":true},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false},{"id":"5605213ade8877d8d601580dbd0a8aa2","text":"S3 One Zone-Infrequent Access","correct":false}]},{"id":"4dbb13ea-c707-4846-9f49-584095a20625","domain":"ResilientDesign","question":"You are investigating a performance issue on a MYSQL RDS database and discover that there is only a single DB instance in a single Availability Zone for this database. This goes against your organisation's availability requirements, which specify that the application must automatically remain available during AZ outages and with minimal interruption. This needs to be addressed, along with the performance issue. How would you go about resolving this, while keeping cost to a minimum?","explanation":"When in a Multi-AZ configuration, the secondary database instance is not \"active\" and cannot be read from or written to by clients. This rules out using the secondary instance to address the performance issue. Putting a read replica in a different AZ can help with redundancy, however the read replica will need to be promoted manually in case of a disaster, resulting downtime while this takes place. As this scenario requires that there is minimal interruption to service in case of a AZ outage, any answer using the Read Replica for availability can be discounted. This leaves using a Multi-AZ configuration with a Read Replica as the only valid option.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"Amazon RDS Multi-AZ Deployments"},{"url":"https://aws.amazon.com/blogs/aws/amazon-rds-for-mysql-promote-read-replica/","title":"Amazon RDS for MySQL – Promote Read Replica"}],"answers":[{"id":"9a2f983568edc620fc3719d40f9ea028","text":"Modify the database to be Multi-AZ to address the availability requirement, and deploy a read replica to improve performance","correct":true},{"id":"92df2c8707d1018172156f0e95fd5b26","text":"Deploy a Read Replica for the database into a different AZ to address the availability requirement. Create another read replica in primary zone to improve performance.","correct":false},{"id":"43a8b1df93731fc791a9c59882df77b7","text":"Modify the database to be Multi-AZ to address the availability requirement. This will also address the performance issue as there will now be 2 instances for reads and writes.","correct":false},{"id":"ebda44f0999233da222783fb1a8079dc","text":"Deploy a Read Replica for the database into a different AZ. This will address the performance issue, and can be used in case of a AZ outage","correct":false}]},{"id":"c55f22ae-80d0-4959-b174-d829799c0ebe","domain":"SecureSolutions","question":"An AWS VPC allows you to:","explanation":"With a VPC, you can connect your cloud resources to your own IPSec VPN connections.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html","title":"AWS Managed VPN Connections"}],"answers":[{"id":"965dceca3b86aea95ef5de037128780c","text":"None of these.","correct":false},{"id":"b6d6372266b9d9c86bea479d7e2ed72f","text":"Forget about security: AWS does it all for you.","correct":false},{"id":"80b64cf6fc3a37e7c804ff0db69f8916","text":"Provision unlimited S3 resources.","correct":false},{"id":"f7ddabca6bedcc81b8b193a009967f58","text":"Connect your cloud resources to your own IPSec VPN connections.","correct":true}]},{"id":"3a6323db-58c8-4ddf-a758-288887c972ed","domain":"CostOptimized","question":"You are a small business startup and wanted to host a website for your business. You purchased a Reserved EC2 instance with all upfront payment with one year commitment. Because of difficulties, the website hosting is given to a third party provider to host the website. As the reserved EC2 instance is not required anymore, what are the options available?","explanation":"Reserved instances provide significant savings on Amazon EC2 costs compared to on-demand instance pricing. Reserved instances are not physical instances, but rather a billing discount applied to the use of on-demand instances in AWS account. The Reserved instance applies to a single instance type, platform, scope, and tenancy over a term. Reserved instances once purchased cannot be cancelled. But the unused reserved instances can be sold in the Reserved Instance Marketplace if the eligibility criteria are met. The Reserved Instance Marketplace is a platform that supports the sale of third-party and AWS customers' unused Standard Reserved Instances, which vary in term lengths and pricing options.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html","title":"Reserved Instance Marketplace"}],"answers":[{"id":"86529fdb220411c4056281091b93c2eb","text":"Reserved instance purchases cannot be cancelled. But if the business need changes, these reserved instances may be sold in the Reserved Instance Marketplace.","correct":true},{"id":"fe819908a4d33b8ae37ab227c535e0f7","text":"The reserved instance purchase can be cancelled so that AWS will refund the EC2 instance cost for the remaining tenure.","correct":false},{"id":"cd9f297f2ab1b919d62d05c2aaa09984","text":"The reserved instance can be transferred to another account owned by your friend for a cheaper rate.","correct":false},{"id":"df56e478b94b7cf467346bbdd6b7fb2b","text":"Terminate the EC2 instance so that there will not be any running cost. Submit a request to AWS to refund the cost for remaining tenure.","correct":false}]},{"id":"ab704d26-226d-4951-b238-549daba176a5","domain":"ResilientDesign","question":"What is the durability of S3 - IA?","explanation":"S3 Standard - IA is designed for the same 99.999999999% durability as S3 Standard and Amazon Glacier.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#Infrequent_Access","title":"S3 Infrequent Access"}],"answers":[{"id":"19fb9916968211db983d13bffe0cc6af","text":"99.99%","correct":false},{"id":"78262a35fc5fdefbb7740ac7102b8cc4","text":"99.999999999%","correct":true},{"id":"ebb51b0b7e8f1fcf89ef483709bd61c6","text":"99.9%","correct":false},{"id":"91009c0d8d2ec85d07a48cb81bfcfb0d","text":"99%","correct":false}]},{"id":"7589448c-e00c-4c64-9d5f-04e10ac556e4","domain":"CostOptimized","question":"An enterprise is planning to move its on-premise application to AWS cloud. The enterprise planned to build the non-production applications first as a proof of concept, and the governance team has provided approval for downtime for a brief period if cost can be compensated. You recommend spot instances as this satisfies the scenario explained above. Do vCPU limits apply when requesting a spot instance?","explanation":"Amazon EC2 is transitioning on-demand instance limits from the current instance count-based limits to vCPU-based limits to simplify the limit management experience for AWS customers. Beginning September 24, 2019, customers can opt in to vCPU-based instance limits. Count-based instance limits will not be available or supported after November 8, 2019. The vCPU-based limits only apply to running on-demand instances and does not apply when purchasing reserved or spot instances.","links":[{"url":"https://aws.amazon.com/ec2/faqs/","title":"Amazon EC2 compute service features"}],"answers":[{"id":"1fe04947ca4403eb3588fb87310de29e","text":"vCPU limits apply to reserved instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false},{"id":"34394b797e4a477511982b1ac4a38d19","text":"vCPU limits apply only to on-demand instances and do not apply for spot instances.","correct":true},{"id":"a4fb94942aaa43d251b18a4126ce6d18","text":"In AWS, only instance count based limits exist and there is no concept of vCPU limits.","correct":false},{"id":"9bfb4cfa201ec7e2242c7df2c0d39906","text":"vCPU limits apply to spot instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false}]},{"id":"8ce0cff9-4e62-41cb-8edd-a45f0b2a2bd3","domain":"Performant","question":"You have a application that is running in an EC2 instance that performs some heavy processing on sales data stored in S3. This sales data is first loaded into memory and numerous operations are performed on it before it is written back to S3. During the processing phase, a large amount of temporary data is created which is not needed once processing completes. This data needs to be stored on as low-latency storage as possible - which of the below storage types should you use?","explanation":"Although all 4 options would work, Instance Store has the lowest latency as it is located on the same physical infrastructure as the EC2 instance. As data permanency is not required, Instance Store is the best choice.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","title":"AWS Instance Store"}],"answers":[{"id":"41c96096fbbf551daa42cd6455c15603","text":"Instance Store","correct":true},{"id":"43fd7af2adc3101adebb61366bf16df2","text":"Provisioned IOPS SSD","correct":false},{"id":"248c1b0bcb74394beb4a08030c4a6847","text":"EBS","correct":false},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":false}]},{"id":"239bfe21-1dd1-4978-a518-52d7be85cf56","domain":"SecureSolutions","question":"You need to restore an object from Glacier class in S3. Which of the following will help you do that?","explanation":"When discussing GLACIER it is important to distinguish between the storage-class 'Glacier' use by S3, and the 'S3-Glacier' service. When using Glacier Tier in S3, objects moved into Glacier storage are still managed by S3. Meaning S3 management interfaces, such as the API and Console, need to be used to interact with the objects in question. However, when using the S3-Glacier service, objects placed in the Glacier storage are managed via the S3-Glacier service, meaning it's management interfaces need to be used","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/restoring-objects.html","title":"Restoring objects from Glacier class in S3"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/restore-archived-objects.html","title":"Restoring S3 Archived objects"},{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/restore-s3-object-glacier-storage-class/","title":"Restoring S3 Archived objects with CLI (s3api not s3)"}],"answers":[{"id":"4896195ad6b3c8d2e0061f7df703cc2c","text":"Using the S3 REST API","correct":true},{"id":"95668976125050f1b25d5a3b893d912c","text":"Using the Glacier API","correct":false},{"id":"b2f31642b1d69fc886a2b9d175e65fcd","text":"Using the S3 sub-command from the AWS CLI","correct":false},{"id":"1102c67f86255d43e0d7083aae2d7871","text":"Using the AWS S3 Console","correct":true}]},{"id":"bee3fc3a-4738-4c3f-b6ad-e6f25e600772","domain":"Performant","question":"Which of the following are types of virtualization available on AWS?","explanation":"The two different types of virtualization available are Hardware Virtual Machine (HVM) & Paravirtual Machine (PVM)","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#instance-virtualization-type","title":"EC2 Virtualization Types"}],"answers":[{"id":"5136698bc5a65f152fe16da0719dd612","text":"Paravirtual Machine (PV)","correct":true},{"id":"4b796a884a8b85e9857127deafecc5e7","text":"Hardware Virtual Machine (HVM)","correct":true},{"id":"fc9184bf07a56c1342576d092d7cdf15","text":"Physical Virtual Machine (PVM)","correct":false},{"id":"e526c533a9df6aff264b1313a0908f9d","text":"Cloud Virtual Machine (CVM)","correct":false}]},{"id":"d759f777-8830-47ae-ac99-038049debd8c","domain":"SecureSolutions","question":"As a solutions architect, you notice that one of the IAM roles in your company's AWS account has not been used for a year. What's the recommended course of action?","explanation":"If a role has not been in use for a very long time, it's best to delete it and its associated permissions as a security measure. However, you must make sure that there are no EC2 instances running with the role you are about to delete. Removing a role from a running EC2 instance linked to it will break any applications running on the instance.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_manage_delete.html","title":"Deleting Roles or Instance Profiles"}],"answers":[{"id":"47865d465f7ee9291a6a7955bb192b38","text":"Continue to monitor activity associated with the role.","correct":false},{"id":"191a23ce196611912881e94971f9a19e","text":"Check for any Amazon EC2 instances running with the role. If there are none, delete the role and its associated permissions.","correct":true},{"id":"49113178e5bef494be62b3a0ca9d622b","text":"Delete the role and its associated permissions.","correct":false},{"id":"e478f7c2a4052004cfe4e32a8d71c106","text":"Leave the role alone; you never know when you might need it.","correct":false}]},{"id":"f3e923a2-2e1a-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You want to track the amount of money you ideally want your company to spend for EC2 data transfers every month. Which of the following actions will accomplish that?","explanation":"AWS Cost Explorer is for providing information that you can use to track and manage costs, but it doesn’t enable the creation of budgets; that’s what AWS Budgets is for. If the question was strictly addressing cost, then creating a Cost budget with AWS Budgets would have been the correct answer. However, your concern is specifically with a usage type, which is EC2 data transfers. In this case, you would need to create a Usage budget with AWS Budgets and receive alerts when your defined threshold is met.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/budgets-managing-costs.html","title":"Managing Your Costs with Budgets"}],"answers":[{"id":"4407cc58412e1c4727ad336bd8b8453f","text":"Create a Reservation budget with AWS Budgets.","correct":false},{"id":"e7f799a3bc73b229cd75d773a9d7f547","text":"Create a Usage budget with AWS Budgets.","correct":true},{"id":"8d35bf16b7d263f4ab864e392d023e54","text":"Enable AWS Cost Explorer","correct":false},{"id":"41e006394cc745a90a25e57065b658c2","text":"Create a Cost budget with AWS Budgets.","correct":false}]},{"id":"ce9877b8-de12-428e-8ff5-9900b8e817f2","domain":"Performant","question":"You have some EC2 instances in a private subnet that need access to an S3 bucket.  There is a requirement that traffic does not traverse the Internet. Which of the following can be used to achieve this?","explanation":"A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html","title":"VPC Endpoints"},{"url":"https://aws.amazon.com/blogs/aws/aws-privatelink-update-vpc-endpoints-for-your-own-applications-services/","title":"Private link announcement"}],"answers":[{"id":"8ca0f1328403ec0d05ed995272d74715","text":"NAT Gateway","correct":false},{"id":"3fdc04800c36e2177d81c4431616f533","text":"Internet Gateway","correct":false},{"id":"8f9d3edc1ed25845346d7d64e087edbe","text":"NAT Instance","correct":false},{"id":"a0b2b99d905954d58da91017a81d3059","text":"VPC Gateway Endpoint","correct":true}]},{"id":"33082520-edb1-41d0-8b6e-fa2f43c3a6a2","domain":"ResilientDesign","question":"You have been tasked with the creation of a highly available website that serves static content from EC2 instances. Which of the following is not a requirement to accomplish this goal?","explanation":"While an SQS queue can be an important part of a decoupled web application, it is not required when hosting a highly available static website on EC2. An auto scaling group configured to deploy EC2 instances in multiple subnets located in multiple availability zones allows an application to remain online despite an instance or AZ failure.","links":[{"url":"https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf","title":"Fault Tolerance and High Availability"}],"answers":[{"id":"4bf22bd2ec00ce8656941ab4941f1bab","text":"An auto-scaling group","correct":false},{"id":"b30e76c0e28a8979554e0da16b91238f","text":"A multi-AZ deployment","correct":false},{"id":"4a7bf4c9871ab5d9a4cdcf72a1b29de9","text":"Multiple subnets","correct":false},{"id":"3b92e08f936523bf2c3b0abb698f73ba","text":"An SQS queue","correct":true}]},{"id":"2edec957-8dde-4a46-a4af-5c65142d38c3","domain":"ResilientDesign","question":"Which of the following Route 53 policies allow you to a) route data to a second resource if the first is unhealthy, and b) route data to resources that have better performance?","explanation":"Failover Routing and Latency-based Routing are the only two correct options, as they consider routing data based on whether the resource is healthy or whether one set of resources is more performant than another.  Any answer containing location based routing (Geoproximity and Geolocation) cannot be correct in this case, as these types only consider where the client or resources are located before routing the data.  They do not take into account whether a resource is online or slow.  Simple Routing can also be discounted as it does not take into account the state of the resources.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"d1333c4521b08ff7084ea38f02e7fd41","text":"Geolocation Routing and Latency-based Routing","correct":false},{"id":"f44dc584b393fd984b1646d677520fb0","text":"Failover Routing and Simple Routing","correct":false},{"id":"6cc2be97f86de8b660b1fbafb18a890f","text":"Failover Routing and Latency-based Routing","correct":true},{"id":"6036d720543b35a606bc0c2a682b27cf","text":"Geoproximity Routing and Geolocation Routing","correct":false}]},{"id":"f85240a5-118e-4367-b2ed-0c442a60bec4","domain":"ResilientDesign","question":"You currently have a web application that uses two EC2 instances and you want 75% of the web traffic to go to one server and the other 25% to go to the other. Which of the following routing policies should you choose?","explanation":"You need a weighted routing policy because you want to be able to set the proportions traffic routed to your servers. A simple routing policy would have been ideal if you had a single server. Although failover and geolocation routing policies are for routing traffic to more than one resource, the former is ideal for configuring active-passive failover, and the latter is for specifying location rather than traffic proportions.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"7388404ef116c3ff812bfd290b094d9e","text":"Failover","correct":false},{"id":"582368ac8232617ead14ac74ccc40ea9","text":"Weighted","correct":true},{"id":"1fbb1e3943c2c6c560247ac8f9289780","text":"Simple","correct":false},{"id":"323d4eb70b252acb4a04eaf9e0882597","text":"Geolocation","correct":false}]},{"id":"6d368e1f-484b-4536-91ec-6055d5916c49","domain":"Performant","question":"You have developed a file-sharing website for a large corporate entity. They require that the site to be protected from a regional failure. Which S3 service should you use to achieve this? ","explanation":"S3 with Cross-Region Replication automatically replicates data across AWS regions. With CRR, every object uploaded to an S3 bucket is automatically replicated to a destination bucket in a different AWS region that you choose.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 - Cross-Region Replication"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr-what-is-isnot-replicated.html","title":"S3 - Replication guidelines"}],"answers":[{"id":"73d38a622e5878dd1ecfb83678260bd5","text":"S3 - Cross-Region Replication","correct":true},{"id":"5bd8bda263020cb57b990acb7d5d7218","text":"S3 - RRS with Data Pipeline to DynamoDB","correct":false},{"id":"431cc9c5e56b3f9120509ea377024fbc","text":"Configure S3 to trigger a Lambda function, which will take an object uploaded to S3 and automatically replicate it to an EBS volume.","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false}]},{"id":"2466b024-1f81-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"You work as a website administrator at a real estate developer. The company’s website uses S3 to store pictures of the single-family homes it builds. The company recently released a brand-new elevation for one of its most popular models, which is called 'Greenberry C.' So far, there’s only one picture of the 'Greenberry C', so you want to ensure that it is not accidentally deleted by enabling the object lock feature. Which of the following actions will accomplish that?","explanation":"Amazon S3 object lock prevents an object from being deleted or overwritten. Object lock is enabled at the bucket level; when creating the bucket, you can select the feature to lock objects in it. However, once the bucket has been created, you cannot enable object lock, you will have to contact customer support to do so. Right-click is not a valid option - you must select the object then go to Properties, Object lock.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/object-lock.html","title":"How Do I Lock an Amazon S3 Bucket?"}],"answers":[{"id":"49cd0706698c83f66fe5b9deb203a420","text":"Contact customer support.","correct":true},{"id":"2c6b543047434bd3ad31060693bc8e5b","text":"Enable object lock at the object level.","correct":false},{"id":"84bd7d36c453cdfc1f04955deb54c376","text":"Enable object lock at the bucket level.","correct":true},{"id":"a92ccdd56e18b47fbb5d18c2c342ca6f","text":"Right-click the picture and choose the object lock option.","correct":false}]},{"id":"e1d6c1bd-4d28-44dd-8c24-f71fe1f7fd56","domain":"CostOptimized","question":"An intern comes to you with a problem. To save time, they had stored some data on an unused data volume of an EC2 instance and stopped the instance for the weekend. When they returned on Monday and restarted the instance, they discovered that the data was gone and what to understand why. What would you suggest? ","explanation":"The most likely answer is that the unused volume on the EC2 instance was an instance-store volume. Instance-store volumes are ephemeral, meaning that they cease to exist if powered off.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","title":"About Instance Store"}],"answers":[{"id":"88de86ec665e01de2e878cfb4d2ebf45","text":"The instance failed to connect to the volume on Monday.","correct":false},{"id":"3f6c001d39e433b32fe99dcce1515a2e","text":"The EBS volume failed over the weekend.","correct":false},{"id":"18466b20b58938619a41bb378cca740e","text":"The EBS volume was not large enough to store the data.","correct":false},{"id":"31d0851f98c4c0e8a3f49f0559d0b47b","text":"The data volume used was not standard EBS storage.","correct":true}]},{"id":"c138fec3-1027-4dc1-9215-b9108252ffab","domain":"Performant","question":"You have a production application that is on the largest RDS instance possible, and you are still approaching CPU utilization bottlenecks. You have implemented read replicas, ElastiCache, and even CloudFront and S3 to cache static assets, but you are still bottle-necking. What should your next troubleshooting step be?","explanation":"If your application requires more compute resources than the largest DB instance class or more storage than the maximum allocation, you can implement partitioning, thereby spreading your data across multiple DB instances.","links":[{"url":"https://aws.amazon.com/rds/faqs/","title":"See 'Q: How can I scale my DB instance beyond the largest DB instance class and maximum storage capacity?'"}],"answers":[{"id":"062e544e8a9ad6c5491af7b0e682e372","text":"You should provision a secondary RDS instance and then implement and ELB to spread the load between the two RDS instances.","correct":false},{"id":"637dc8debb4ed3bebabdb2faf2cc89c3","text":"You should implement database partitioning and spread your data across multiple DB Instances.","correct":true},{"id":"d7a5a5cf870141d209e3e9cda6322823","text":"You have reached the limits of public cloud. You should get a dedicated database server and host this locally within your own data center.","correct":false},{"id":"f08b245b716a56cb1a5a93fe863992a0","text":"You should consider using RDS Multi-AZ and using the secondary AZ nodes as read only nodes to further offset load.","correct":false}]},{"id":"58c6fa98-66ec-4fe9-9870-78876228bfd5","domain":"SecureSolutions","question":"Your Security team is concerned about a recent spate of attacks making use of SYN, ACK and UDP floods to target websites in your industry. They want to make sure that appropriate protections are in place for your infrastructure for when you eventually become a target of this particular attack, as any downtime in your application has significant cost impact. Unfortunately your manager has stated that the budget is a bit tight - and wants you to make sure any protections implemented come at minimal extra cost - how would you proceed?","explanation":"SYN, ACK and UDP flood attacks are common DDoS style attacks. AWS Shield Standard, which comes for free with all AWS services, includes protection from these types of attacks. As budget is a major factor, \"Do nothing\" is the correct answer as you already have protection. Although deploying WAF will give much more robust security, this is not the primary concern in this scenario due to the extra costs, and the fact that the protections you are after are included in the Shield Standard product make this answer incorrect. Deploying extra instances in standby will be an extra cost as well, and they may never be needed. As this type of attack is automatically protected against, you should not need to deploy extra instances to cope with it.","links":[{"url":"https://aws.amazon.com/shield/getting-started/","title":"Getting Started with AWS Shield"}],"answers":[{"id":"f2e849409beda014a4933314b0e1ce0d","text":"Deploy extra instances in a \"Cold Standby\" state, so that when you are attacked you have infrastructure on standby ready to take over","correct":false},{"id":"094be5110a86ae39df636deb8d20af19","text":"Do nothing until an attack actually happens, then deploy extra instances to take the load until the attack is over.","correct":false},{"id":"cd88ce600576fcc630878b5e374835a5","text":"Do nothing","correct":true},{"id":"3877e96d087d4be7bc8acca2df611d56","text":"Deploy a WAF in front of your web services to protect from these types of attacks","correct":false}]},{"id":"79861610-5123-41e0-b0ff-52cee5365540","domain":"SecureSolutions","question":"You are about to encrypt the data in your S3 buckets, and you need a solution to enable the use of a customer master key (CMK) as an added layer of protection against unauthorized access. In addition, this solution must provide you with an audit trail that shows you when and who used the CMK. Which of the following choices denote this type of encryption?","explanation":"Generally speaking, SSE is actually correct. However, the question is asking for a specific type of server-side encryption. SSE-S3 is another possible answer, since it encrypts the objects in the S3 buckets and Amazon S3 manages the encryption keys. However, the CMK and audit trail attributes are missing from this choice. With SSE-KMS, you get the CMK addition for added protection, as well as the audit trail, which is why SSE-KMS is the right answer. SSE-C is not the right choice because you, rather than Amazon, would manage the keys.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Server-Side Encryption"},{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html","title":"Server-Side Encryption: Using SSE-KMS"}],"answers":[{"id":"772996341baeebbfac39d70e8ed5a300","text":"Server-Side Encryption with AWS Key Management Service (SSE-KMS)","correct":true},{"id":"c76bcbd057118544ba0ccb76a8a22e46","text":"Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)","correct":false},{"id":"9b7e6d7280803d9f9a6072b4421611fc","text":"Server-Side Encryption with Customer-Provided Keys (SSE-C)","correct":false},{"id":"a8d0fb2ecae10336e81eec65375a4abe","text":"Server-Side Encryption","correct":false}]},{"id":"f8d65d36-54ed-4e56-b834-28ce0b81d1dc","domain":"ResilientDesign","question":"Which of the following components are not part of Amazon ECS?","explanation":"Service Discovery makes it easy for containers within an ECS cluster to discover and connect with each other, using Route 53 endpoints. Task Definitions define the resource utilisation and configuration of tasks, using JSON templates. Task Scheduling allows you to run batch processing jobs run on a schedule.  File Storage is not a component of ECS.  Storage within ECS is handled by EBS volumes attached to the underlying EC2 instances and not by ECS itself.","links":[{"url":"https://aws.amazon.com/ecs/features/","title":"Amazon Elastic Container Service Features"}],"answers":[{"id":"24bbdaf375ddacbe3973587b50d98790","text":"Service Discovery","correct":false},{"id":"bad3bdff2e2f94dfef18eaff5b083c20","text":"Task Definitions","correct":false},{"id":"b7b5c32036d1bb9dd91e97886fc1b1f3","text":"Task Scheduling","correct":false},{"id":"f95e8e0f0b7d916cc84d1098655eaa1e","text":"File Storage","correct":true}]},{"id":"2eb2dc18-2e15-11ea-978f-2e728ce88125","domain":"Performant","question":"Your project manager (PM) tasked you with launching a Windows server to create and host a website for a federal agency. The PM is especially interested in using an AWS service that makes it easy to combine all the components needed for the website. He also favors that this solution provide predicable monthly pricing; he doesn’t want any surprises in cost. What AWS service is the correct choice?","explanation":"For a low and predictable price every month, Lightsail delivers all that you would need to create, host, and maintain the website in a cloud environment. You will not only get the virtual machine, but also features such as a managed database, SSD-based storage, data transfer, DNS management, and a static IP. Although you can use EC2, you will still need to configure some of these aforementioned features in addition to launching an instance, and its costs will vary according to usage.","links":[{"url":"https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-frequently-asked-questions-faq","title":"Frequently Asked Questions in Amazon Lightsail"}],"answers":[{"id":"b21eea42e76007ac061cf37a5a41037d","text":"Lightsail","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"1dd30e8d60c2a200781dbcc9286f0919","text":"Elasticsearch Service","correct":false}]},{"id":"8db02025-839b-4cba-9396-3bf3d30f5c41","domain":"ResilientDesign","question":"You are a system administrator and you need to take a consistent snapshot of your EC2 instance. Your application holds large amounts of data in cache that is not written to disk automatically. What would be the best approach to taking an application consistent snapshot?","explanation":"As you need an application consistent snapshot, your best option would be to shutdown the EC2 instance and detach the EBS volume, then take the snapshot.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html","title":"Creating an EBS Snapshot"}],"answers":[{"id":"35151eb8d8b2db302878d62b44030835","text":"In the AWS console, take a snapshot and ensure that the 'application consistent' check box is ticked.","correct":false},{"id":"0ca1045c8304935b9a8a2966f9558b13","text":"Shut down the EC2 instance and detach the EBS volume, then take the snapshot.","correct":true},{"id":"8f8e16b428381fb3d36f848931c82fb2","text":"Take a snapshot in real time using the EC2 API.","correct":false},{"id":"f9074c78a685a4482c46191309041432","text":"Take a snapshot using the AWS CLI.","correct":false}]},{"id":"e9205ab6-d7ce-4708-b92d-e6814f79c6d4","domain":"ResilientDesign","question":"The dashboard application for multiple company contact centers requires fast update response times for a large number of concurrent users. Call center metric data is stored in an Oracle version 11 database. Which architecture will provide high-availability and the low response times needed for this mission-critical data?","explanation":"Since the dashboard updates are needed across multiple contact centers, leveraging read-only replicated databases will provide fast response times. Amazon RDS doesn’t support read replicas for Oracle version 11, so hosting the database on EC2 and replicating the data with Oracle Data Guard is the only viable solution. AWS Database Replication Service is not an offered service, and using EBS snapshots won't provide real-time replication.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/oracle-database/overview.html","title":"Oracle Database on AWS"}],"answers":[{"id":"de5ad68debdabd478d7d4f66542b9ca8","text":"An Amazon RDS Oracle Instance with AWS Database Replication Service","correct":false},{"id":"c1e824f46134bc6696eba635f30df032","text":"An Amazon RDS Oracle instance with Multi-AZ and Read Replicas","correct":false},{"id":"0129ed97e5c2ec017bdc05d836f10049","text":"Oracle hosted on Amazon EC2 in multiple Availability Zones with Oracle Data Guard replication","correct":true},{"id":"5ee29b50026caa8c20c9e469f93b5a2a","text":"Oracle hosted on Amazon EC2 in Multiple Availability Zones with EBS snapshots","correct":false}]},{"id":"772793a3-5d9f-43bd-bb76-179e8dbc8253","domain":"ResilientDesign","question":"An enterprise is looking to implement Amazon SQS as a messaging service to integrate multiple application components which are hosted in AWS. Which of the following are true about Amazon SQS?","explanation":"Amazon SQS stores all messages within a region and can store messages across AZs within the region. Data transfer between Amazon SQS and Amazon EC2 or AWS Lambda within a single region is free.","links":[{"url":"https://aws.amazon.com/sqs/","title":"Application Integration Service"}],"answers":[{"id":"93aceaf2019b6438fdc9de7c79d18dee","text":"Amazon SQS stores all messages and message queues across several highly-available AWS regions with multiple redundant Availability Zones.","correct":false},{"id":"6e7cab4c58ce36e1f4e1acc709c9996e","text":"Data transfer cost between Amazon SQS and Amazon EC2 or AWS Lambda within a single region is free.","correct":true},{"id":"d9860cb4ca904902096df550eb91902e","text":"Data transfer cost between Amazon SQS and Amazon EC2 or AWS Lambda within a single region incur a standard data transfer rate.","correct":false},{"id":"0648fd50f7cdc581d31b8dfe410ce275","text":"Amazon SQS stores all messages and message queues within single AWS region within an Availability Zone.","correct":false},{"id":"fb65f20dafe54ebea9013ceb9e10b8d2","text":"Amazon SQS stores all messages and message queues within a single highly-available AWS region with multiple redundant Availability Zones.","correct":true}]},{"id":"56bf1d42-e120-46cf-8324-6b624b3c0beb","domain":"Performant","question":"Which of the following services can stream configuration changes and notifications recorded by AWS Config and use email as the endpoint?","explanation":"AWS Config records configuration changes in resources, and it streams those changes and notifications to an SNS topic. Users subscribed to the topic receive email notifications of the changes. Although SES is an email service, Config does not use it to send email notifications. CloudWatch is for monitoring resources, not for recording their configuration changes. SQS is a message queuing service and is not used with Config.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/notifications-for-AWS-Config.html","title":"Notifications that AWS Config Sends to an Amazon SNS Topic"}],"answers":[{"id":"f7be29c9a4de2fe0c3ced5ca83552403","text":"Amazon Simple Notification Service (SNS)","correct":true},{"id":"2e03b43594eb74bc8c1a23deeb4774ef","text":"Amazon Simple Email Service (SES)","correct":false},{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":false},{"id":"64fdb9de34f1179f1b0a667717e6fba3","text":"Amazon Simple Queue Service (SQS)","correct":false}]},{"id":"264e918f-a0f1-4013-8873-1fafcbd2e3c2","domain":"SecureSolutions","question":"Your company’s Technical Writer needs to know all the Internet protocols that Amazon Route 53 uses to perform health checks. Which of the following are the protocols?","explanation":"AWS offers three protocol choices to use to perform Route 53 health checks. They are HTTP and HTTPS, which operate at the application layer; and TCP, which operates at the transport layer. IMAP is an application-layer protocol that is not offered as a choice when configuring the health check.","links":[{"url":" https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html","title":"How Amazon Route 53 Checks the Health of Your Resources"}],"answers":[{"id":"0b787be1ef17df10d26758673ae24325","text":"IMAP","correct":false},{"id":"b136ef5f6a01d816991fe3cf7a6ac763","text":"TCP","correct":true},{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":true},{"id":"293c9ea246ff9985dc6f62a650f78986","text":"HTTP","correct":true}]},{"id":"00be4bb5-a556-48d8-a95c-cac6852e76ba","domain":"CostOptimized","question":"You are operating a popular TV Show news website using a static site generator (SSG) with the resulting HTML pages being served from S3. The vast majority of pages are less than 85 KB in size. After 60 days, new episode page access drops off significantly. Which of the following statements are true?","explanation":"Similar to the STANDARD storage class, STANDARD_IA objects are available for millisecond access.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html","title":"Storage Classes"}],"answers":[{"id":"ff55b529dbaaea1355acdc097ad29298","text":"The ONEZONE_IA storage class is as durable as STANDARD_IA, but it is less available and less resilient.","correct":true},{"id":"0c8d66b9d1503b991d171f09f8943ee1","text":"Using the STANDARD_IA storage class, these older pages are stored redundantly across 3 or more geographically separated facilities.","correct":true},{"id":"a32b993ff0fa61fd0da4533f7fc8f1be","text":"Using the STANDARD_IA storage class, Amazon S3 charges you for 128 KB per object if it is less than 128 KB in size.","correct":true},{"id":"b84620799ba94f53d53c1aa19f69bb8a","text":"While objects in the STANDARD storage class are available for millisecond access, accessing STANDARD_IA objects is slightly slower.","correct":false}]},{"id":"912352c0-d2a0-4e7c-89cd-d4ee66445744","domain":"CostOptimized","question":"You have been asked to design a scalable solution for a simple customer service survey that is shown online after each of the ~10 million chat bot interactions per month: Emoticons for 3 rating options ('positive', 'neutral' and 'negative') are to be presented with the expectation that about 10% of users submit their feedback. The bot is public facing and operates 24x7. Select a feasible and most cost effective solution.","explanation":"RDS alone is more expensive than any of the serverless solutions and therefore not an option here. Because of this use case's simplicity (i.e. no request validation, rate limiting, authentication/authorization, etc. required), there is essentially no need for a Lambda fronting API Gateway. Given the described requirements (load and availability), an ALB is more expensive as it's billed hourly.","links":[{"url":"https://serverless-training.com/articles/save-money-by-replacing-api-gateway-with-application-load-balancer/","title":"Saving Money By Replacing API Gateway With Application Load Balancers Lambda Integration"},{"url":"https://aws.amazon.com/blogs/networking-and-content-delivery/lambda-functions-as-targets-for-application-load-balancers","title":"Lambda functions as targets for Application Load Balancers"},{"url":"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/browser-invoke-lambda-function-example.html","title":"Invoking a Lambda Function in a Browser Script"}],"answers":[{"id":"b63327b72ecc6921a7e43eb0f786a3fe","text":"You invoke a Lambda function on demand in a browser script using the AWS SDK for JavaScript. For that to work you will need to create an Amazon Cognito identity pool with access enabled for unauthenticated identities and include the identity pool ID in your code to obtain credentials for the browser script. The function writes the submitted rating value to a DynamoDB table.","correct":true},{"id":"39329c7ee88152a625a8d565e6b38f36","text":"You front your Lambda that writes the ratings to a DynamoDB table with an ALB.","correct":false},{"id":"852949aded12102365acbeb1052394f9","text":"You develop a proper API and use an API Gateway, Lambda and DynamoDB solution","correct":false},{"id":"909f43a37c73caa5e0c764e4d8d8201c","text":"Given the expected load, you are better off with an Elastic Beanstalk app and RDS such as PostgreSQL or MySQL","correct":false}]},{"id":"a52e1e35-7e4b-450a-86cd-5bd8ac49d26b","domain":"Performant","question":"You are running a very database intense application on AWS using Amazon Aurora. As your traffic grows you decide to add two additional aurora replicas to help alleviate the load on the database. You need to ensure that read traffic is load balanced evenly across these two nodes. What should you connect your EC2 webservers to for read traffic?","explanation":"Multi node clusters normally publish a number of different connection URLs so that your application can connect to the 'service' not to specific physical instances which might individually become offline.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Overview.Endpoints.Types","title":"Types of Aurora Endpoints"}],"answers":[{"id":"9de4bdbfccafcbf2b30249ea7c72b254","text":"Reader Node","correct":false},{"id":"45d894b3628bfc9ddb17432b8a0eb29d","text":"Cluster Endpoint","correct":false},{"id":"956ef5c190f68445ccb3209bbcef0d8e","text":"Cluster Node","correct":false},{"id":"b3df0666ef172efc5714f2925d0444e4","text":"Reader Endpoint","correct":true}]},{"id":"7719a68f-21aa-425f-8c29-73591c37f264","domain":"Performant","question":"A mobile gaming company would like to provide real-time, customized flash offers as a result of events that occur in their new multi-player adventure game. The mobile user interface was developed with the AWS Mobile SDK, and some device actions generate REST API calls. Events are also detected by the game's backend server code. All offers presented and accepted need to be retained to determine take-rate metrics for future campaigns. Which architecture will provide the most scalable and cost effective solution?","explanation":"Using Kinesis and SQS to decouple the architecture provides the most scalable solution. S3 provides the most cost effective persistent data store for later take-rate analysis. Answer one does not provide persistent storage for offers presented, which will be used for generating take-rate metrics. Answer two is a tightly coupled architecture which could be improved with asynchronous communication between the EC2 instances and the mobile backend. Answer three will incur higher costs due to it's use of RDS, which is not needed in this case since AWS analytic services provide schema-on-read access to simply structured S3 data.","links":[{"url":"https://d1.awsstatic.com/architecture-diagrams/ArchitectureDiagrams/serverless-analytics-for-mobile-gaming.pdf?did=wp_card&trk=wp_card","title":"Serverless Real-Time Analytics for Mobile Gaming"}],"answers":[{"id":"893d664f68918ed796784a3176db90ae","text":"Have the mobile device and backend server code write events to an Amazon SQS queue. Create EC2 instances in an Auto Scaling Group that read from the SQS queue and match events with campaigns in an S3 Parquet file. Have the EC2 instances send matched offers to the backend server via Amazon SQS for forwarding to the mobile device.","correct":false},{"id":"d48a48df84b7761da880dd9edeca8aa5","text":"Have mobile device and backend server code write events to Amazon Kinesis Data Streams. Configure a Lambda function as the consumer of the stream. The Lambda function compares events with a campaigns table in DynamoDB to determine matches for offers. Matched offers are written to S3, and to an Amazon SQS queue to be picked up by the backend server for forwarding to the mobile device","correct":true},{"id":"30d3ccf0bea954b3a8245bf84c8fb6e2","text":"Have the mobile device and backend server code write events to Amazon DynamoDB. Create a Lambda function that reads from DynamoDB and matches events with campaigns in another DynamoDB table. Have the EC2 instances send matched offers to the backend server via WebSocket for forwarding to the mobile device.","correct":false},{"id":"e5c36bf51ecc4b4fdf5f7cf329e8c814","text":"Have mobile device and backend server code write events to Amazon Kinesis Data Streams. Configure a Lambda function as the consumer of the stream. The Lambda function compares events with a campaigns table in an S3 Parquet file to determine matches for offers. Matched offers are written to Amazon RDS, and to an Amazon SQS queue to be picked up by the backend server for forwarding to the mobile device","correct":false}]},{"id":"9ddc17c5-4849-4869-b79f-a7e2b6630be1","domain":"Performant","question":"Which AWS service should you use to host MySQL, MariaDB, Oracle, SQL Server, or PostgreSQL database where you do not need to manage the underlying operating system?","explanation":"Amazon RDS is available on several database instance types - optimized for memory, performance or I/O - and provides you with six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle, and Microsoft SQL Server.","links":[{"url":"https://aws.amazon.com/rds/","title":"AWS RDS: Available Engines"}],"answers":[{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true},{"id":"1574cf43006500eb74cc583eef4a8b87","text":"EC2 with EBS","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":false}]},{"id":"66262de0-506e-4e56-901b-e49a60aa0c6d","domain":"ResilientDesign","question":"You are testing an application that uses EC2 instances to poll an SQS queue. At this stage of testing, you have verified that the EC2 instances can retrieve messages from the queue, but your coworkers are complaining about not being able to manually retrieve any messages from the queue from their on-premises workstations. What is the most likely source of this problem?","explanation":"Short polling may fail to retrieve messages sometimes, but if no messages can be retrieved after multiple attempts, permissions are the more likely cause.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-authentication-and-access-control.html","title":"Authentication and Access Control for Amazon SQS"}],"answers":[{"id":"d16cb376900ea9c06c68759d668824d1","text":"It's not possible to poll an SQS queue manually.","correct":false},{"id":"6536a818dab64143ae0178e357e5e841","text":"Your coworkers do not have permission to access the SQS queue.","correct":true},{"id":"38672a9de56ddbc170a51a046d074146","text":"Short polling is occasionally leaving messages behind.","correct":false},{"id":"574a8d560b8f2dd210703546008b8c64","text":"SQS queues accept traffic only from within AWS.","correct":false}]},{"id":"19b5d27c-16ad-11ea-8d71-362b9e155667","domain":"Performant","question":"You set up a static website for a client using S3. However, upon clicking the website endpoint, you realize that you can’t access the website. What do you have to do to enable access without affecting other buckets and objects in the AWS account?","explanation":"Denied access to S3 object is not a technical problem, so there’s no need to notify AWS Support. Right-clicking the object will not get you on the path to enable website access, and the 'Block public access' setting is not valid in a Bucket Policy. And while you can edit public access through the 'Block public access (account settings)' option, it will affect not just the object you want to access; it will apply to all buckets and objects in the account. Ultimately, you will need to click the S3 object serving the client’s website content, click the Permissions tab, click Edit under 'Block public access', uncheck 'Block all public access', and click Save, so that you can access the website endpoint.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html","title":"Example - Setting Up a Static Website Using a Custom Domain"}],"answers":[{"id":"0d1a711860d50694ee751e52b1c419d4","text":"Click 'Block public access (account settings)', click Permissions in the menu, click Edit, uncheck 'Block all public access' if necessary, and click Save Changes.","correct":false},{"id":"70009581d58fa2c9030c0bf7c14fc4d7","text":"Contact AWS Support by creating a case explaining the problem.","correct":false},{"id":"b32a8996f05ca1f442f0c79df948d47f","text":"Right-click the S3 object serving the website content, click Bucket Policy in the menu, click Edit, ensure 'Block public access' is set to 'false', and click Save.","correct":false},{"id":"59bd8c47f35dc26b0f3226441682ff62","text":"Click the S3 object serving the website content, click the Permissions tab, click Edit under 'Block public access', uncheck 'Block all public access', and click Save.","correct":true}]},{"id":"05ab8679-89d2-4db7-83f2-6cd0a315ae13","domain":"CostOptimized","question":"Amazon Web Services offers 4 different levels of support. Which of the following are valid support levels?","explanation":"The correct answers are Enterprise, Business, Developer. The 4th level is Basic.  Remember that Free Tier is a billing rebate not an account type or support level.","links":[{"url":"https://aws.amazon.com/premiumsupport/compare-plans/","title":"AWS Support Plans"}],"answers":[{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"5ef2f1c1df8b6b0fed2186a0abe18f50","text":"Free Tier","correct":false},{"id":"7effe80425095de4d5b996a01e4f00a3","text":"Corporate","correct":false},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":true},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":true}]},{"id":"52cf0185-4629-47ac-8779-4ec4ffd9cc06","domain":"SecureSolutions","question":"You have an EC2 instance with a Security Group attached. This security group is configured to only allow inbound traffic from 192.168.0.0/24. A collegue has also configured a NACL on the subnet that the instance resides on, and this NACL is configured to block all traffic, except where the source or destination is in 192.168.0.0/24. What will happen when an instance with an IP of 192.168.1.12 tries to connect to your instance on port 80?","explanation":"With inbound traffic, NACLs are evaluated before Security Groups. As the NACL is configured to only allow traffic from 192.168.0.0/24 and the IP 192.168.1.12 does not fall within that range, it will be blocked by the NACL before reaching the Security Groups.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"c885215eb76a3baac02ca8ea6da9a7b4","text":"The NACL will block the traffic before it is evaluated by the security group","correct":true},{"id":"eb5d4be456a62dd4f884a4b47c45fd46","text":"The traffic will be blocked simultaneously by the Security Group and NACL","correct":false},{"id":"5298f0866dac220c6bbad6d2da2163d8","text":"The traffic will be allowed as it is still within a private range","correct":false},{"id":"d3d7c67e2cf8c1d1cb89971fd90c2b72","text":"The security group will block the traffic before it is evaluated by the NACL","correct":false}]},{"id":"24984439-79ad-4ddd-874e-0cf8800affa0","domain":"Performant","question":"You are running a Cassandra database that requires access to tens of thousands of low-latency IOPS. Which of the following EC2 instance families would best suit your needs?","explanation":"High I/O instances use SSD-based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require tens of thousands of IOPS.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/#highio-instances","title":"High I/O Instances"}],"answers":[{"id":"00ce754caeddc3589b864a8e5d665fe7","text":"High I/O instances","correct":true},{"id":"5a09e6d2f372cf15511772f8f380afc0","text":"Dense Storage Instances","correct":false},{"id":"750fc21187d18139777ca329bb74df13","text":"Memory Optimized Instances","correct":false},{"id":"5cd383d698034a613d2efaeb78ade93d","text":"Cluster GPU Instances","correct":false}]},{"id":"f368c76f-83f3-4a1f-b29d-f844fe380353","domain":"ResilientDesign","question":"Which of the below services create entities that only exist in the region that they are created in by default?","explanation":"IAM, SNS, Route 53 and CloudFront are all global services, with in-built redundancy, these entities are available in all regions. VPC and DynamoDB store all their entities and data in a redundant fashion in the region they were created in, and EC2 stores the data and objects in the AZ it was created in. S3 is a little more tricky - although it can be seen as a \"Global\" service as data can be accessed from anywhere, that data only exists in the region that the bucket was created in by default","links":[],"answers":[{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"0893147538c21c827dc499b4852934e3","text":"Route 53","correct":false},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"d85c80578ad0849a611c1056b63e385c","text":"VPC","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"41dff7155cc7aeb11c06434f6a450bb3","text":"IAM","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":false}]},{"id":"17702990-2dcd-11ea-978f-2e728ce88125","domain":"Performant","question":"A multinational corporation needs an AWS service that delivers its web content on a global level. Which one of the following AWS services will accomplish that?","explanation":"CloudFront is the AWS service used for delivering web content to users. The other three choices are for AWS management and governance, rather than content delivery like CloudFront. CloudWatch monitors AWS resources and applications, Config records configuration changes, and CloudTrail increases visibility into user and resource activity.","links":[{"url":"https://aws.amazon.com/cloudfront/","title":"Amazon CloudFront"}],"answers":[{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":false},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":false},{"id":"dfdfd742376f1e718ab36a8a1ee9143e","text":"Amazon CloudFront","correct":true}]},{"id":"d27e19ed-c0a1-430f-b5df-5e792077aaa4","domain":"Performant","question":"Your existing on-premise servers rely on Memcached to provide memory object caching. If you were to move to AWS, how might you preserve this functionality?","explanation":"ElastiCache is a web service that makes it easy to set up, manage, and scale a distributed in-memory cache environment in the cloud. It provides a high-performance, scalable, and cost-effective caching solution, while removing the complexity associated with deploying and managing a distributed cache environment.","links":[{"url":"https://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/WhatIs.html","title":"About ElastiCache"}],"answers":[{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":true},{"id":"8f3e091d35aa63444fb3aeeecc74eaf3","text":"Elastic MapReduce","correct":false},{"id":"769c10500364777e54f2a7c646b7c699","text":"Install Memcached on EC2","correct":false},{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false}]},{"id":"57f5e909-774f-43b9-9718-c0b61fc8225c","domain":"SecureSolutions","question":"You are currently running an application in a production environment and you want to ensure that it is free of vulnerabilities. Which of the following AWS services would you use to accomplish this?","explanation":"You will need Amazon Inspector to perform a security assessment. Not only does it identify vulnerabilities in your application, it will also spot deviations from security best practices. AWS Shield and WAF protect the application from attacks that exploit vulnerabilities, rather than identify them. And Trusted Advisor only provides recommendations on how to improve security.","links":[{"url":"https://docs.aws.amazon.com/inspector/latest/userguide/inspector_introduction.html","title":"What is Amazon Inspector?"}],"answers":[{"id":"543096643aa6d28d9fac278e9257783d","text":"Amazon Inspector","correct":true},{"id":"769f2c629067645d4b60e13009500c9f","text":"AWS Web Application Firewall (WAF)","correct":false},{"id":"41a831f771ef9bece59ed5160e335ae7","text":"AWS Trusted Inspector","correct":false},{"id":"637d82e8a7206e87344161109cf7112d","text":"AWS Shield","correct":false}]},{"id":"18196faa-35f6-4a0b-b91b-c62326bbd9bf","domain":"CostOptimized","question":"A team is designing the architecture for a new application with full CI/CD testing.  They want to implement feature branch testing based on pull requests to master.  A Pull Request should cause a full deployment to be run on that feature branch being pulled so that a tester can run through functional tests.  What would you recommend the team does to automate this process at the lowest cost?","explanation":"CloudFormation allows AWS to automatically deploy the infrastructure required to deploy the application for testing.  The infrastructure code can be stored alongside application code to allow the application to be deployed in a fully-isolated infrastructure which can be destroyed once integration testing is complete.  CloudWatch Events (and not CloudTrail) enables pull request events to trigger a deployment.  Finally Amazon EC2 Spot Fleet allow us to deploy a set of EC2 instances at the lowest cost. Reserved Instances are better-suited to pre-purchasing compute capacity which you will use for a fixed period of time - it is not cost-effective to pre-purchase EC2 capacity just to perform integration testing.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html","title":"How Spot Fleet Works"},{"url":"https://ec2spotworkshops.com/amazon-ec2-spot-cicd-workshop.html","title":"CI/CD and Test Workloads with EC2 Spot Instances"}],"answers":[{"id":"e4f3730b2899903ad8a6c27eb2693ff2","text":"Configure CloudWatch Events to trigger a deployment based on pull requests","correct":true},{"id":"9d9cce9ec8f58e568222274098cf9b08","text":"Use Amazon EC2 Reserved Instance and Amazon CloudFormation to deploy a testing environment at lowest cost","correct":false},{"id":"cb82b20f57a6882ec563593d14dfb01b","text":"Configure AWS CloudTrail to log pull request events and trigger a deployment","correct":false},{"id":"254cbe0fa6a5e0b25dd7841402f05e7e","text":"Use Amazon EC2 Spot Fleet and Amazon CloudFormation to deploy an integration testing environment at lowest cost","correct":true}]},{"id":"e62d3927-3172-4d89-a2f2-b70a62da50d7","domain":"CostOptimized","question":"What are the key instance attribute variables that determine reserved instance price?","explanation":"Reserved instances provide significant savings on Amazon EC2 costs compared to on-demand instance pricing. Reserved instances are not physical instances, but rather a billing discount applied to the use of on-demand instances in your account. These on-demand instances must match certain attributes, such as instance type and region, in order to benefit from the billing discount. A reserved instance has four instance attributes that determine its price. They are Instance Type, Scope, Tenancy, Platform. The attributes also determine how the reserved instance is applied to a running instance in your account.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","title":"Reserved Instance Attribute"}],"answers":[{"id":"e5a48e08950e10c8e11c7de25d41b2ae","text":"Instance Type, Scope, Tenancy, Platform","correct":true},{"id":"f7925fb10a7a695858fd864c7a5ba10b","text":"Instance Type, Usage/Load, Tenancy, Network","correct":false},{"id":"8f1f69be4b7932f83f66e28cfee82568","text":"Instance Type, Scope, Tenancy, Network","correct":false},{"id":"6650ae9522d5793a5a4f0818eba78ed6","text":"Instance Type, Usage/Load, Tenancy, Platform","correct":false}]},{"id":"5d2b3bb0-3bb8-41e0-9e90-7fd70629b5f3","domain":"CostOptimized","question":"You’re researching third-party backup solutions to backup 10 TB of data nightly to Amazon S3. File restores won’t be needed often, but when they are, they’ll need to be available in under five minutes. Your analysis shows that you will exceed your budget for backup storage and you need to find a way to reduce the estimated monthly costs. How should you modify the solution to achieve the cost reduction needed?","explanation":"Most third-party backup solutions write data to S3, but not all write directly to Glacier via the API. This is the most direct solution, and you’ll want to choose one that does. Moving data with S3 lifecycle rules probably won’t be recognized by the third-party software, creating an out of sync situation, and Glacier is more cost effective than the S3-Standard-Infrequent Access storage class.","links":[{"url":"https://aws.amazon.com/glacier/","title":"Amazon S3 Glacier"}],"answers":[{"id":"c883be39f5cb08a918d59df1f92a1bed","text":"Write the data directly to the S3 Standard-Infrequent Access Storage Class","correct":false},{"id":"61439f45264a1150586115b18980c024","text":"Create an S3 lifecycle rule to move the data immediately to Amazon S3 Glacier","correct":false},{"id":"e4e3dfa7fa011d21f5b7a4182f3c4d4a","text":"Choose a third-party backup solution that leverages AWS Storage Gateway to write data to Amazon S3 Glacier","correct":false},{"id":"e7a458c861e5ca337fcdc05bf5a06004","text":"Choose a third-party backup solution that writes directly to the Amazon S3 Glacier API","correct":true}]},{"id":"b864406d-be60-4f6a-82dc-9160d5585ca0","domain":"SecureSolutions","question":"Your manager has noticed that some members of your team are using the AWS Account Root User to undertake certain tasks.  They have asked you to confirm when is it correct procedure to use the Root User.  Choose from the correct options.","explanation":"You cannot use policies within your account to explicitly deny access to the Root user. However, if an IAM user accidentally revokes their own permissions, you can sign in as the Root user to edit policies and restore those permissions.  All other options are valid uses of the AWS Account Root User.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html","title":"The AWS Account Root User"},{"url":"https://docs.aws.amazon.com/general/latest/gr/aws_tasks-that-require-root.html","title":"AWS Tasks That Require AWS Account Root User Credentials"}],"answers":[{"id":"5799714fbea5ac62293b5ace786552dd","text":"Closing an AWS Account","correct":true},{"id":"fe713e15c6b90a9c07f22b8fd92d6f70","text":"Using IAM policies to deny Root account access","correct":false},{"id":"d0623de1aeb9bae95ad7fd9df219e156","text":"Submitting a Request to perform an external penetration test that isn't a permitted service","correct":true},{"id":"e7e875a434ddf25dfe250989b53ca2ce","text":"Move the level of your AWS Support Plan from Business to Enterprise","correct":true},{"id":"767fe082a112680443e319c832c4f06f","text":"Create a CloudFront Key Pair","correct":true}]},{"id":"b1f70ce6-0e60-408d-b911-395f6238f5e7","domain":"CostOptimized","question":"Your legal team has just identified a significant confidentiality breach in your web site and you have instructions to take all content down immediately. which of the following statements are correct.","explanation":"While the first 1000 invalidation paths per month are free, additional invalidation paths are charged for per request.  There is a limit of 3000 concurrent individual invalidation, however you can stage them or combine then with wildcard path invalidations.  It takes time for the invalidation instruction to circulate and pull down content from all edge locations.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Invalidation.html","title":"CloudFront Invalidation"},{"url":"https://aws.amazon.com/blogs/aws/simplified-multiple-object-invalidation-for-amazon-cloudfront/","title":"Multiple Object Invalidation for CloudFront"}],"answers":[{"id":"27cf368fc73e24fe8c1fa2823bd75179","text":"Invalidation are effective immediately on request.","correct":false},{"id":"e21d19a175e9c402d4ce86ca522c4514","text":"Invalidation requests can be cancelled if you issue the cancellation instruction in time.","correct":false},{"id":"ad95f0498b65e02aed5aa16a59b6c2a6","text":"You cannot invalidate more that 3000 files in CloudFront at a time.","correct":false},{"id":"74d845824030304a665a29b3d252dcb6","text":"Versioning object names can be used in place of invalidation if you set it up ahead of time.","correct":true},{"id":"3e5e72b6232c6205e16547a888294e05","text":"Only under certain circumstances will CloudFront invalidations be charged to your account.","correct":true}]},{"id":"8932e37a-2160-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"Which of the following scenarios are examples of scaling an IT architecture horizontally?","explanation":"To scale horizontally is to increase the number of AWS resources, such as adding more EC2 or RDS instances. Resizing an EC2 instance type from r5.large to r5.2xlarge for more CPU and memory power is scaling vertically, since it involves increasing the specifications of a single AWS resource as needed. Resizing an RDS instance type from db.t3.large to db.t3.medium, thus reducing its memory and compute power, is also an example of scaling vertically.","links":[{"url":"https://d1.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf","title":"Architecting for the Cloud"}],"answers":[{"id":"798a6e2c9b0b7ce731005506e89947d6","text":"Resizing an RDS instance type from db.t3.large to db.t3.medium for half the memory power","correct":false},{"id":"b8928baef0692c76994aa9cc183e5cc5","text":"Resizing an EC2 instance type from r5.large to r5.2xlarge for twice the amount of CPU and memory power","correct":false},{"id":"d2ed8876ad5d876850ebcde76e28bd9f","text":"Adding two more EC2 instances","correct":true},{"id":"67c96e88044c732523807882de714af3","text":"Adding two more RDS instances","correct":true}]},{"id":"176bd1a3-b3e8-4c3c-9921-28d83bdada07","domain":"ResilientDesign","question":"Which of the following statements are true?","explanation":"Be clear about the meaning of the terms Availability, Durability & Resilient.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"},{"url":"https://aws.amazon.com/s3/reduced-redundancy/","title":"S3 Reduced Redundancy Storage"}],"answers":[{"id":"012e8dcc5fad05d9c1c912d6445392af","text":"S3-RRS provides 99.99% durability","correct":true},{"id":"da8bfe5d95dde1d95483782050e21075","text":"S3-Standard is designed for 11-nines availability","correct":false},{"id":"f06957dc3a39f41ed53e9dacbed9ea14","text":"S3-Standard provides 99.99% availability.","correct":true},{"id":"496a94c1faa1463c556c49c59561c7aa","text":"S3-Standard is designed for 11-nines durability.","correct":true},{"id":"bd3cdbd6cb4f1c07310bfd9a4b19ff32","text":"S3-OneZone-IA carries the risk that the destruction of a Datacentre will result in data loss.","correct":true}]},{"id":"b974c044-33bf-4fe8-9edd-1cdac5b32fa5","domain":"Performant","question":"Your new cost tracking application runs on AWS Lambda and Amazon RDS PostgreSQL. All testing has shown that the software is ready for production. Shortly after launch, users begin complaining about performance issues. After some investigation, you suspect a database query problem. What approach will you take to diagnose and resolve the problem in the most operationally efficient way?","explanation":"RDS Performance insights provides an easy-to-understand dashboard for detecting performance problems on both RDS and Aurora database instances. You can monitor SQL queries that caused load and I/O waits, and you can identify the users and hosts through which the queries ran. A slow running query using a DISTINCT clause for a one-to-many join will benefit from removing the DISTINCT clause and adding an EXISTS qualifier to the WHERE clause. Using a native PostgreSQL tool like pgBadger will work, but it requires extra work to set logging parameters in the RDS parameter group. Adding a GROUP BY clause will not improve performance in this case.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_PerfInsights.html","title":"Using Amazon RDS Performance Insights"},{"url":"https://aws.amazon.com/blogs/database/optimizing-and-tuning-queries-in-amazon-rds-postgresql-based-on-native-and-external-tools/","title":"Optimizing and tuning queries in Amazon RDS PostgreSQL based on native and external tools"}],"answers":[{"id":"436d7294f9c14ac6bd54f376404a16f3","text":"Install a PostgreSQL native tool like pgBadger on an EC2 instance to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to remove the DISTINCT clause and add an EXISTS qualifier to the WHERE clause.","correct":false},{"id":"cb046ece5a7170684077db42c1f41742","text":"Use RDS Performance Insights to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to remove the DISTINCT clause and add an EXISTS qualifier to the WHERE clause.","correct":true},{"id":"04ad0f28212ab7830934651ac9ec003b","text":"Install a PostgreSQL native tool like pgBadger on an EC2 instance to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to add a GROUP BY clause.","correct":false},{"id":"2b25e3600ffb4b52d5931af53bb18834","text":"Use RDS Performance Insights to identify the slow running query. Upon inspection, you notice the suspected query uses a DISTINCT clause for a one-to-many join. Modify the query to add a GROUP BY clause.","correct":false}]},{"id":"b6275c5c-1ac1-4382-9ee0-540d5b7e499a","domain":"SecureSolutions","question":"A contract management application stores its content in Amazon Simple Storage Service. The documents are encrypted with AWS Key Management Service keys. A security engineer imports a new Customer Master Key, manually rotates the keys, and deletes the previous key. The IT service center begins to receive calls that those trying to retrieve older contracts are receiving 'data inaccessible' errors. What needs to be done to resolve the issue?","explanation":"KMS supports keeping older versions of imported keys available, but in this case, the security team neglected to do so. Unfortunately, the contract documents need to be re-encrypted. AWS does not offer a KMS Sync operation or a KMS Restore capability. KMS won't be able to tie a re-imported key back to the older documents.","links":[{"url":"https://aws.amazon.com/kms/","title":"AWS Key Management Service (KMS)"},{"url":"https://aws.amazon.com/kms/faqs/","title":"AWS Key Management Service FAQs"}],"answers":[{"id":"ce9a8e2d9aba9a5b8e82432d3220852e","text":"Perform a KMS Restore to re-establish the relationship between older contract documents and the previous key","correct":false},{"id":"ab06ac4163b2759feeed0c0255c614fc","text":"Perform a KMS Sync operation to align all of the documents with the new Customer Master Key","correct":false},{"id":"cd5e0e6c549884e3e0c9aa1630412b3c","text":"Re-import the previous key into KMS and rotate the keys again","correct":false},{"id":"ebe28348d4f30f69bfa81ccded9bae95","text":"Re-encrypt the contract documents with the new Customer Master Key","correct":true}]},{"id":"5dcee06e-bd95-4dfd-8540-5c54ae7c5fd3","domain":"SecureSolutions","question":"Your application stores your customers' sensitive passport information in S3. You are required by law to encrypt all data at rest. Company policy states that you must maintain control of your encryption keys. For ease of management, however, you do not want to implement or maintain a client-side encryption library. Which S3 encryption option should you use to secure your data at rest?","explanation":"Use SSE-C (C ≈ customer controlled) if you want to maintain your own encryption keys, but don’t want to implement or leverage a client-side encryption library.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html","title":"S3 - SSE-C"}],"answers":[{"id":"1562bb9d2d9567740605dcb1ccab5c80","text":"SSE-S3","correct":false},{"id":"e17194408dc439e1658a544965724d44","text":"SSE-KMS","correct":false},{"id":"472035b16201f5505380c16ec3eb8518","text":"SSE-C","correct":true},{"id":"bac271f02854883c6bc665637d0a5de6","text":"Amazon S3 Encryption Client","correct":false}]},{"id":"8c7d8c0b-3c91-4d63-9adb-87636a5b8306","domain":"Performant","question":"You are managing a website hosted in an AWS EC2 instance. The logs are stored in Amazon S3. Which of the following is a serverless interactive query service that can be used for analyzing data in S3 to troubleshoot performance issues?","explanation":"Query services like Amazon Athena, data warehouses like Amazon Redshift, and sophisticated data processing frameworks like Amazon EMR, all address different needs and use cases. Amazon Redshift provides the fastest query performance for enterprise reporting and business intelligence workloads, particularly those involving extremely complex SQL with multiple joins and sub-queries. Amazon EMR makes it simple and cost-effective to run highly distributed processing frameworks such as Hadoop, Spark, and Presto when compared to on-premise deployments. Amazon EMR is flexible and can run custom applications and code, and define specific compute, memory, storage, and application parameters to optimize analytics requirements. Amazon Athena provides the easiest way to run ad-hoc queries for data in S3 without the need to setup or manage any servers.","links":[{"url":"https://docs.aws.amazon.com/athena/latest/ug/when-should-i-use-ate.html","title":"Instant Data Analytics Service"}],"answers":[{"id":"13f4833f14110af4cb2943f6ee04ec0c","text":"Amazon Athena","correct":true},{"id":"cc5cafce27b070d7c2d800486d23fda0","text":"Amazon RedShift","correct":false},{"id":"469d12a9b614674fd9a6d9168d1494ec","text":"Amazon EMR","correct":false},{"id":"6d54c710d35b106057d416187bc27ac9","text":"Amazon Glue","correct":false}]},{"id":"6af2d489-ba4c-49a6-a1b5-b7b41d27ec82","domain":"ResilientDesign","question":"Your team is designing a new competitive intelligence application for the sales team. Account executives will be able to pull the latest information on another company's product pricing while at customer locations. The application will allow for retrieval of information by product type, version, size, and a number of other characteristics. The database administration team will not support MySQL databases due to professional preferences. Which storage architecture will provide the best resiliency with the least amount of downtime?","explanation":"Amazon Aurora delivers high performance and availability with read replicas, point-in-time recovery, continuous backup, and replication across three Availability Zones. It's active-passive nature requires a brief pause in database activity if a failover from the primary instance to the secondary instance is required. Aurora currently only offers active-active Multi-Master functionality for MySQL databases. Due to the requirement for data join activity, Elastic File System is not a good option. Oracle RAC doesn't run natively on EC2.","links":[{"url":"https://aws.amazon.com/rds/aurora/","title":"Amazon Aurora"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-multi-master.html","title":"Working with Aurora Multi-Master Clusters"}],"answers":[{"id":"ebdeb996034c5e0f763c6591b82cc77f","text":"Use an Amazon Aurora PostgreSQL database accessed by Amazon Elastic Container Service containers","correct":true},{"id":"768cf4db1c73a7ca24f37004c5206aab","text":"Deploy an Oracle RAC cluster on Amazon EC2 accessed by EC2 instances in an Auto Scaling Group","correct":false},{"id":"07e09461587d7848b81bfb4e0daeabb5","text":"Deploy an Amazon Aurora PostgreSQL Multi-Master cluster accessed by AWS Lambda functions","correct":false},{"id":"6da917908387b9af39547c6e9ab8534d","text":"Implement an Amazon Elastic File System accessed by AWS Lambda Functions","correct":false}]},{"id":"2aad5b9a-23aa-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"As a Solutions Architect helping to develop and add an unabated stream of web applications, you worry that the company’s cloud architecture is increasingly getting more complicated, making it difficult to track the applications’ performance. Which AWS service checks how applications are performing and helps to identify and resolve issues?","explanation":"AWS Trusted Advisor is for optimizing the cloud environment and does not specifically address applications. Although AWS CloudWatch monitors applications and can direct you to issues with them, it does not fix errors. And Amazon Inspector is a security assessor, not an application performance tracker. Only AWS X-Ray helps to optimize the performance of applications by identifying and fixing their issues.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/aws-xray.html","title":"What is AWS X-Ray?"}],"answers":[{"id":"5714e9332e476d05d9a1763a1b10be50","text":"AWS CloudWatch","correct":false},{"id":"543096643aa6d28d9fac278e9257783d","text":"Amazon Inspector","correct":false},{"id":"3dc993924bceb799c7009d281aa91408","text":"AWS X-Ray","correct":true},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":false}]},{"id":"0b32b547-cba2-4db6-bd51-fa085a318c33","domain":"SecureSolutions","question":"You are working for a real estate company and you need to be able to record configuration changes to Amazon RDS DB Instances, DB Subnet Groups, DB Snapshots, DB Security Groups, and Event Subscriptions. Which AWS service should you use to achieve this?","explanation":"You can use AWS Config to continuously record configurations changes to Amazon RDS DB Instances, DB Subnet Groups, DB Snapshots, DB Security Groups, and Event Subscriptions and receive notification of changes through Amazon Simple Notification Service (SNS).","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/WhatIsConfig.html","title":"About AWS Config"}],"answers":[{"id":"74c9a0ed16e6de2d66b6b9663ac3e5cb","text":"CloudAudit","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false}]},{"id":"55400906-0fbf-11ea-8d71-362b9e155667","domain":"Performant","question":"You are currently designing a log processing application that requires an EBS volume that can support throughput-intensive workloads of up to 500 MB/s while keeping costs relatively low. Which of the following EBS volume types is the best choice?","explanation":"A Throughput Optimized HDD is the correct answer because it is designed for throughput-intensive workloads, such as: log processing, big data, MapReduce, Kafka, data warehouse and ETL; which have large data sets and I/O sizes and support up to 500 MB/s. Although both the General Purpose SSD and the Provisioned IOPS SSD could easily meet the required IOPS, they are more costly options. Cold HDD is a low-cost solution, it is more suitable for less frequently accessed workloads.","links":[{"url":"https://aws.amazon.com/ebs/features/ ","title":"Amazon EBS Features"}],"answers":[{"id":"c01eb4fc3413d489e9258ff97066ee1d","text":"General Purpose SSD","correct":false},{"id":"43fd7af2adc3101adebb61366bf16df2","text":"Provisioned IOPS SSD","correct":false},{"id":"21a9eab81bfbbe0ba71336bf88d5feea","text":"Cold HDD","correct":false},{"id":"acdd848c4ecdd949a1afa61eeb675655","text":"Throughput Optimized HDD","correct":true}]},{"id":"a37fb7a3-3a49-40f0-b688-1d34af35855e","domain":"SecureSolutions","question":"Contractual requirements mandate the use of AWS CloudHSM as an encryption solution. Application performance is a secondary, but important, concern. Where within your AWS infrastructure should you place the HSM appliances?","explanation":"To decrease latency (and improve application performance), it's best to place your HSMs as close to your EC2 instances as possible.","links":[{"url":"https://aws.amazon.com/cloudhsm/details/#Secure_VPC_access","title":"HSMs and Latency"}],"answers":[{"id":"81903e4cb00fb844367c771fd69072e7","text":"Locating HSM appliances near your EC2 instances decreases network latency, which improves application performance.","correct":true},{"id":"9df85d664730c5be05001eb90f0aca61","text":"To increase performance, you should locate the HSM as close to the majority of your customers as is possible.","correct":false},{"id":"65c5c381d9312c40bb261deb3ddc7bcd","text":"To increase security, you should place the CloudHSM appliances in their own, private subnet.","correct":false},{"id":"b1b0304054038e008892902f9ecb32b6","text":"To increase security, you should place the HSM appliances on your side of the VPN that connects to AWS.","correct":false}]},{"id":"15c0f4d7-ac13-40b0-98fb-2d8fd8b077ee","domain":"Performant","question":"You have been asked to advise on a scaling concern.  The client has an elegant solution that works well.  As the information base grows they use CloudFormation to spin up another stack made up of an S3 bucket and supporting compute instances.  The trigger for creating a new stack is when the PUT rate approaches 100 PUTs per second.  the problem is that as the business grows that number of buckets is growing into the hundreds and will soon be in the thousands.  You have been asked what can be done to reduce the number of buckets without changing the basic architecture.","explanation":"Until 2018 there was a hard limit on S3 puts of 100 PUTs per second.  To achieve this care needed to be taken with the structure of the name Key to ensure parallel processing.  As of July 2018 the limit was raised to 3500 and the need for the Key design was basically eliminated. Disk IOPS is not the issue with the problem. The account limit is not the issue with the problem.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","title":"S3 Request rates - Whats new"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html","title":"S3 Request rates documentation"},{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage classes"}],"answers":[{"id":"c1ee6963e6cab066324cc7e832d9ea3d","text":"Change the trigger level to around 3000 as S3 can now accommodate much higher PUT and GET levels.","correct":true},{"id":"b183896b9af1543c0b43e9540b244954","text":"Set up multiple accounts so that the per account hard limit on S3 buckets is avoided.","correct":false},{"id":"906c60dd95d60014479c321de23c5a4c","text":"Refine the key hashing to randomise the name Key to achieve the potential of 300 PUTs per second.","correct":false},{"id":"0196ee21bff2d4c35c191d0973220d3c","text":"Upgrade all buckets to S3 provisioned IOPS to achieve better performance.","correct":false}]},{"id":"fe9ae041-a875-409d-a515-fdf8bb97d0ba","domain":"ResilientDesign","question":"At your company, you're repeatedly building large architectures for different business units using AWS resources for services like IAM, Amazon RDS, Amazon VPC, and Amazon EC2. You would like to automate creation of these resources using a tool within the AWS ecosystem. Which service would provide this functionality?","explanation":"AWS CloudFormation is a service that helps you model and set up your Amazon Web Services resources so that you can spend less time managing those resources and more time focusing on your applications that run in AWS. Both Serverless Framework and Terraform provide similar functionality, but they are not AWS services.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"What is AWS CloudFormation?"}],"answers":[{"id":"bcf6eb183b7da148701bcc059a34675f","text":"AWS Elastic Beanstalk","correct":false},{"id":"8679a1944db93938a65e47107be5d2b8","text":"AWS CloudFormation","correct":true},{"id":"227fe747d683bdbeec5df298b4f65dc7","text":"Serverless Framework","correct":false},{"id":"303e96f80576360d0c7b07ae7528fa4b","text":"Terraform","correct":false}]},{"id":"40bd28c9-dee5-42d8-bc1b-1822db4e5243","domain":"ResilientDesign","question":"An enterprise has a large customer base and sends marketing emails (such as special offers and discounts), transactional orders (such as order confirmations) and correspondence emails (such as newsletters) to all customers. They engaged you to set up an email platform that provides an easy and cost-effective way to send and receive emails using their own email address and domains, and also wanted to set email auto-responders and email unsubscribe systems. Which AWS service below best matches the requirement?","explanation":"Amazon Simple Email Service (Amazon SES) is a highly scalable and cost-effective service for sending and receiving email. Amazon SES eliminates the complexity and expense of building an in-house email solution or licensing, installing, and operating a third-party email solution. Amazon WorkMail is a suite of office tools which help manage daily email workflow. With WorkMail, it is not possible to send transaction email or email newsletters. Amazon WorkMail uses Amazon SES to send and receive mail.","links":[{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/sending-email.html","title":"Setting up Simple Email Service"}],"answers":[{"id":"224510290621b43664ba1741744d7c57","text":"Amazon Active Directory Email Service","correct":false},{"id":"f25bb6e1bd825ac7b88a0340c5d8f4ec","text":"Amazon WorkMail","correct":false},{"id":"ca50f9e142e8d3e5e8fa73cf07d1a437","text":"Amazon Integrated Email solution","correct":false},{"id":"09e915452f715da52789fa62d9dd5291","text":"Amazon Simple Email Service","correct":true}]},{"id":"18f5f9ac-72ae-44e6-a607-875acd4b7508","domain":"CostOptimized","question":"Your company is moving their entire 20 TB data warehouse to the cloud. With your current bandwidth, it would take 2 months to transfer the data. Which service would you use to quickly get your data into AWS?","explanation":"At that amount of data and those bandwidth restrictions, Snowball would be the most expedient choice.","links":[{"url":"https://aws.amazon.com/snowball/faqs/#when-to-use","title":"When to Use Snowball"}],"answers":[{"id":"c0429b6a658dd488f7262d983c7e02bb","text":"Snowball","correct":true},{"id":"25e163616bb5cc20c769ad3e8b7a0703","text":"Multipart Upload","correct":false},{"id":"cdd0d04de2b79c78e792aec6263d2d3d","text":"DirectConnect","correct":false},{"id":"a8e1dc43989241e706e31c52d23be15c","text":"S3 with Transfer Acceleration","correct":false}]}]}}}}
