{"data":{"createNewExamAttempt":{"attempt":{"id":"f53ad72f-ac31-4b39-914c-d64ce5935820"},"exam":{"id":"ca924ca3-ac88-4313-822b-807068af0f17","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"3dc35381-00ad-4390-a31b-23a8340f4d57","domain":"SecureSolutions","question":"A co-employee approaches you with the need to access DynamoDB tables consisting of raw web analytics data to complete a required document on your company’s Data Warehouse processes. This is the only time in which the employee needs to access this information, and he needs such access for this day alone. What is the most appropriate course of action?","explanation":"Documenting your company’s Data Warehouse processes is a required task, so you simply can’t refuse access to the DynamoDB tables. However, it must be done in a way that does not risk the access of data by unauthorized users. That definitely rules out giving the employee your user credentials. And while you can simply create an IAM user, this action is for people who need continued and constant access; this employee only needs information from the database within a one-day window. Ultimately, the best course of action is to assign the appropriate IAM role to the employee to access the tables for this day, then remove the role assignment.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/authentication-and-access-control.html","title":"Identity and Access Management in Amazon DynamoDB"}],"answers":[{"id":"5cf22da28e8e107eaa66dc1f724a6e34","text":"Create an IAM user for the employee to access the tables.","correct":false},{"id":"2b88f12405ab69024649b137e9e3ff74","text":"Refuse access to the tables.","correct":false},{"id":"dd83c17dcfcf3b3acbb7200de7c2b473","text":"Give the employee your user credentials.","correct":false},{"id":"890c7f1c8bb33b06433d48f55f6a49d5","text":"Assign the appropriate IAM role to the employee to access the tables.","correct":true}]},{"id":"6d368e1f-484b-4536-91ec-6055d5916c49","domain":"Performant","question":"You have developed a file-sharing website for a large corporate entity. They require that the site to be protected from a regional failure. Which S3 service should you use to achieve this? ","explanation":"S3 with Cross-Region Replication automatically replicates data across AWS regions. With CRR, every object uploaded to an S3 bucket is automatically replicated to a destination bucket in a different AWS region that you choose.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 - Cross-Region Replication"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr-what-is-isnot-replicated.html","title":"S3 - Replication guidelines"}],"answers":[{"id":"5bd8bda263020cb57b990acb7d5d7218","text":"S3 - RRS with Data Pipeline to DynamoDB","correct":false},{"id":"431cc9c5e56b3f9120509ea377024fbc","text":"Configure S3 to trigger a Lambda function, which will take an object uploaded to S3 and automatically replicate it to an EBS volume.","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"73d38a622e5878dd1ecfb83678260bd5","text":"S3 - Cross-Region Replication","correct":true}]},{"id":"6ff5a65b-eaf6-440a-b652-a87cda695ee7","domain":"ResilientDesign","question":"Which of the following is NOT a valid EC2 instance type?","explanation":"D2, C4, M3 are all valid EC2 instances.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types - Overview"}],"answers":[{"id":"f1c6eb6f4e48eb34ab40b2987d4976a8","text":"M3","correct":false},{"id":"c4d62b6dcca08e5caf06c01889282859","text":"D2","correct":false},{"id":"10cabbedf836057c57d03730b32c6fa5","text":"Z2","correct":true},{"id":"b713e6323a68d3ddabf4855826c50148","text":"C4","correct":false}]},{"id":"bdfff765-ad59-45a9-9e3c-605a3d2ad9d7","domain":"ResilientDesign","question":"You have been asked to set up an EFS storage solution for a project team.  Which of the following tasks do you need to complete ?","explanation":"It is necessary to set up the bi-directional network permissions, normally with Security Groups. You will connect the EFS Target to your EC2 instance with a 'mount' statement. You do not need to stipulate the size or format the volume. AWS provide a nominally unlimited file system ready for you to use.  As normal under the shared security model AWS will ensure that the EFS system is secure, but you are responsible for the access control security inside the EFS file space provided to you.","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html","title":"EFS - How It Works"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/limits.html","title":"EFS limits"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/security-considerations.html","title":"EFS Security"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/accessing-fs-create-security-groups.html","title":"EFS Security Groups"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/wt1-getting-started.html","title":"Mounting and EFS target"}],"answers":[{"id":"417164507c199eb8b0fb1daa3bae285c","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EFS target","correct":true},{"id":"9a0eabcd19e62a99932848808a473c0f","text":"mount EFS vol to your EC2 instance using 'mount -t nfs -o xxxx '.","correct":true},{"id":"30f2e62c04d187f6e6f58e730e462680","text":"Configure a Security Group to allow admin traffic on port 22 to connect to the EFS system.","correct":false},{"id":"8388b16ddec8dec25d6caba4dbe7f8cb","text":"specify and provision disk capacity on the EFS system using 'fdisk' and 'mkfs -t xfs'.","correct":false},{"id":"9bc552892ca2c2c5be9e7c352fc0cdc8","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EC2 server.","correct":true},{"id":"7f41c759c946659e0ef49f87f6684503","text":"Set Linux file system permissions on the presented EFS volume using 'chmod' and 'chown'.","correct":true}]},{"id":"25300a43-201c-49eb-b139-8d9716469803","domain":"Performant","question":"Which of the following are examples of scaling an IT architecture horizontally to support a web application?","explanation":"To scale horizontally is to increase the number of AWS resources in your cloud environment. So, adding instances and read-replicas are correct. By comparison, resizing an EC2 instance type is an example of scaling vertically, not horizontally, since you would be increasing the specifications of a single AWS resource as needed. Terminating an unused instance is not a valid answer because it is not an example of scaling; rather, it is an example of elasticity or cost-optimizing your environment.","links":[{"url":"https://d1.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf","title":"Architecting for the Cloud"}],"answers":[{"id":"ac078f0c4ec332bce4f049e85fdce843","text":"Resizing an EC2 instance type for four times the amount of CPU and memory power","correct":false},{"id":"d2ed8876ad5d876850ebcde76e28bd9f","text":"Adding two more EC2 instances","correct":true},{"id":"eb4cfd0fba202e21e1f495bf4b215f7d","text":"Adding an RDS database read-replica","correct":true},{"id":"0409e3c213672b1502a0caa251e12494","text":"Terminating an EC2 instance that’s barely used.","correct":false}]},{"id":"57ee57eb-5b47-45ff-8c95-42b35bb8e719","domain":"ResilientDesign","question":"A Multi-AZ RDS deployment will automatically fail-over as a result of which two of the following?","explanation":"Amazon RDS detects and automatically recovers from the most common failure scenarios for Multi-AZ deployments so that you can resume database operations as quickly as possible without administrative intervention. Amazon RDS automatically performs a failover in the event of any of the following: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, Storage failure on primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"Failover Process for Amazon RDS"}],"answers":[{"id":"8851c500044adfe0ba4a247acdb86eda","text":"Loss of network connectivity to the Primary","correct":true},{"id":"215b7e6d7f48e4225c06a3c50bf400d2","text":"Loss of availability in primary Availability Zone","correct":true},{"id":"7b75b57dbe879950151e7a40cf0aed41","text":"A region-wide loss of service","correct":false},{"id":"7ecc550bc4f7f4c4d01c334d359bb0d9","text":"Loss of availability in standby Availability Zone","correct":false}]},{"id":"08e0015b-27bf-4b30-8ad0-eb5b6bcad4f3","domain":"Performant","question":"The company you work for is considering a move to AWS, but they are concerned that their current, 50Mbps connection will not be able to handle the 100 TB of data that need to be migrated without causing unacceptable downtime. As their solutions architect, which AWS service would you recommend to move this data?","explanation":"Given the amount of data to be moved and the speed of the connection, Snowball would be the fastest and most economical solution.","links":[{"url":"https://docs.aws.amazon.com/snowball/latest/ug/using-appliance.html#snowball-data-transfer","title":"Transferring Data With Snowball"}],"answers":[{"id":"c0429b6a658dd488f7262d983c7e02bb","text":"Snowball","correct":true},{"id":"a8e1dc43989241e706e31c52d23be15c","text":"S3 with Transfer Acceleration","correct":false},{"id":"5ba49687f2f5ade4cd1c756a7e9024e3","text":"AWS Storage Gateway","correct":false},{"id":"cdd0d04de2b79c78e792aec6263d2d3d","text":"DirectConnect","correct":false}]},{"id":"6a2430bd-d84d-4d98-948b-c1f9e4130752","domain":"Performant","question":"Which of the following protocols is not supported with an Classic Load Balancer?","explanation":"Amazon's Classic ELB supports the following protocols: HTTP, HTTPS, TCP, and SSL.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html","title":"Listeners for Your Classic Load Balancer"}],"answers":[{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":false},{"id":"293c9ea246ff9985dc6f62a650f78986","text":"HTTP","correct":false},{"id":"c728a49363c9a93a43a7e7f232b5a54a","text":"FTP","correct":true},{"id":"765553e6c7ac8592c389acb9878a050a","text":"SSH","correct":true}]},{"id":"264e918f-a0f1-4013-8873-1fafcbd2e3c2","domain":"SecureSolutions","question":"Your company’s Technical Writer needs to know all the Internet protocols that Amazon Route 53 uses to perform health checks. Which of the following are the protocols?","explanation":"AWS offers three protocol choices to use to perform Route 53 health checks. They are HTTP and HTTPS, which operate at the application layer; and TCP, which operates at the transport layer. IMAP is an application-layer protocol that is not offered as a choice when configuring the health check.","links":[{"url":" https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html","title":"How Amazon Route 53 Checks the Health of Your Resources"}],"answers":[{"id":"b136ef5f6a01d816991fe3cf7a6ac763","text":"TCP","correct":true},{"id":"0b787be1ef17df10d26758673ae24325","text":"IMAP","correct":false},{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":true},{"id":"293c9ea246ff9985dc6f62a650f78986","text":"HTTP","correct":true}]},{"id":"09223b1a-2169-4791-94b1-9ecf1716c8eb","domain":"Performant","question":"Which of the following AWS services store data as key-value pairs?","explanation":"Both DynamoDB and S3 use key-value pairs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html","title":"Working With S3 Objects"},{"url":"https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs","title":"DynamoDB Data Models"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false}]},{"id":"181cab5b-23af-4947-8821-51ed16f55a7d","domain":"ResilientDesign","question":"A large jewelry distributor has installed their new inventory application in a development environment on AWS. After completing their testing, they're ready to deploy the application into its production environment. They've been using VPN connections for the development phase, but they need to upgrade to a higher resiliency network connection scheme to communicate back and forth from other on-premises business applications that are mirrored across two data centers. Testing results indicate that some transactions may require more than a 1.25 Gbps connection to ensure a quality customer experience. Which network architecture will provide the appropriate resiliency for this inventory application?","explanation":"For critical production workloads like an inventory application that require high resiliency, it is recommended to have one connection at multiple locations. Such a topology ensures resilience to connectivity failure due to a fiber cut or a device failure as well as a complete location failure. Use of a Direct Connect Gateway will provide access to any AWS Region from any Direct Connect location. Installing separate connections terminating on separate devices in more than one location gives another layer of resiliency, but that configuration, along with its added costs, is not necessary for this use case. Creating separate connections to only a single Direct Connect location from a single data center does not mitigate the risk of full facility outages. AWS doesn't recommend using a VPN as a backup for connections that require speeds greater than 1 Gbps.","links":[{"url":"https://aws.amazon.com/directconnect/","title":"AWS Direct Connect"},{"url":"https://aws.amazon.com/directconnect/resiliency-recommendation/","title":"AWS Direct Connect Resiliency Recommendations"}],"answers":[{"id":"6dd9941a3ca38128754b0fb66f8642cb","text":"Install two AWS Direct Connect connections to an AWS Direct Connect location from two different network devices in one data center. Create another two AWS Direct Connect connections to a different AWS Direct Connect location from two different network devices in the other data center.","correct":false},{"id":"508aa0084ed6faa994e17273231899f1","text":"Create an AWS Direct Connect connection from one data center to an AWS Direct Connect location. Install another AWS Direct Connect connection from the other data center to a different AWS Direct Connect location.","correct":true},{"id":"8a967bd089e29673bac3c13fd00105ca","text":"Implement an AWS Direct Connect connection from one data center to an AWS Direct Connect location. Establish a VPN connection from the other data center as a backup.","correct":false},{"id":"a4c6c0827f35637ae33dfd03b1b3e0f6","text":"Configure two AWS Direct Connect connections to an AWS Direct Connect location from two different network devices in one data center.","correct":false}]},{"id":"800d5598-41b8-45b0-8ed1-282e298da6d1","domain":"SecureSolutions","question":"Your company hosts a popular web application that connects to an Amazon RDS MySQL DB instances running in a private subnet created with the default ACL settings. Your security department has identified a DoS attack originating from a suspicious IP address. How can you protect the subnets from this attack?","explanation":"A network access control list (ACL) is another layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. Network ACLs and security groups apply different types of filtering and can be used together.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"4f16db81b73ca177c79c3244e13c35a2","text":"Change the Inbound Security Groups to deny access from the suspicious IP address.","correct":false},{"id":"ba87fc8ccb2ecf3a22e7ec386b502f39","text":"Change the Inbound NACL to deny access from the suspicious IP address.","correct":true},{"id":"8dcd632682257a9e6db8658fd01c07f9","text":"Change the Outbound Security Groups to deny access from the suspicious IP address.","correct":false},{"id":"6ca751c9ece11db6ef98b0c5a39d0694","text":"Change the Outbound NACL to deny access from the suspicious IP address.","correct":false}]},{"id":"15c91139-c33f-4583-8864-dba8207c73a0","domain":"Performant","question":"Your organisation is running a business critical application with a backend MySQL DB that has been experiencing performance issues due to an increase in customers hitting the website. Management are concerned that the existing solution will not handle the anticipated customer growth over the next 12 months and any outages could lead to a loss in potential revenue.\\n You’ve been asked to develop a suitable AWS cloud based solution that will best meet the requirements of the organisation and require minimal operational overhead. Which AWS DB service will be most suitable for your organisation?","explanation":"Aurora natively maintains 2 copies of your data in each availability zone (3 AZs x 2 = 6 copies) within a region providing the highly available solution needed for this scenario. It also supports storage autoscaling and CPU and Memory scaling. Aurora also provides up to 5 times improved performance over a traditional DB installation.  MySQL and PostgreSQL support multi-AZ deployments and read replicas, but this requires additional configuration. CPU, memory and storage scaling is not automated and requires additional configuration and design consideration. Redshift does not support Multi-AZ deployments.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/","title":"Amazon Aurora FAQs"}],"answers":[{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false},{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":true},{"id":"f52a9d91766886fb3a524dd06d1581cb","text":"Redshift","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false}]},{"id":"6686ab14-14fd-11ea-8d71-362b9e155667","domain":"ResilientDesign","question":"You want a storage solution to store all e-commerce sales numbers processed on a daily basis. Notably, this solution must be designed in a way that protects against accidental deletion of data. Which of the following actions will satisfy your requirements?","explanation":"Enabling versioning will mean that if someone accidentally deletes an object, S3 would insert a delete marker to make that the current object version. In addition, you can always restore the previous object version if needed. Although storing data in three S3 buckets gives you an extra layer of protection, users can still delete the objects in both buckets. With a new EBS snapshot, the changes made since the last one are lost. And Redshift is the least likely response, since it is used for data warehousing rather than simple straightforward storage.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"Using Versioning"}],"answers":[{"id":"2a3b97d09893c4810970c8557d4e9933","text":"Store the sales numbers in an EBS volume and create snapshots at the end of each day.","correct":false},{"id":"7b87e237a929b789241cfd271cfbf5eb","text":"Store the sales numbers in three S3 buckets and in different AWS Regions.","correct":false},{"id":"a402eb2caf5dae12b4abc6d85c669024","text":"Store the sales numbers in an S3 bucket and enable versioning.","correct":true},{"id":"be181d98494c2caf02d54e25874885ac","text":"Store the sales numbers in a Redshift cluster.","correct":false}]},{"id":"8c8d1581-f004-4d00-a8a0-503b69a1f4d7","domain":"Performant","question":"You've migrated a legacy workflow application that is written in Java 1.4 from an on-prem server to a single M5 EC2 instance configured in an auto scaling group with a max-size of 1 across multiple AZs in the Asia Pacific (Sydney) region. It periodically checks a database for new and updated records and sends out email notifications. In the logs, you see frequent timeout errors. What could be a possible cause and how can you fix this?","explanation":"Amazon EC2 throttles traffic on port 25 of all EC2 instances by default, but you can request for this throttle to be removed or change to another port. In this example, you are not using SES and therefore, its endpoints or sending limits are irrelevant.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-port-25-throttle/","title":"How do I remove the throttle on port 25 from my EC2 instance?"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-connect.html","title":"Connecting to the Amazon SES SMTP Endpoint"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/regions.html","title":"Regions and Amazon SES"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-issues.html","title":"Amazon SES SMTP Issues"}],"answers":[{"id":"8a122c9945f5b1a081e098fdeadc94fe","text":"You might have reached your Amazon email sending limits. To increase that, open a Sending Limit case in the AWS Support Center.","correct":false},{"id":"cdf61badb6564eb5121bb15b0dba57d6","text":"You change an application properties file and update the currently used port from 25 to 2587, build a new AMI with that new version and configure your launch configuration to use that.","correct":true},{"id":"3d9ae95c23fe7b09220f12c62ff95f17","text":"Amazon SES Endpoints are only available in the US East (N. Virginia), US West (Oregon) and EU (Ireland) regions. You cannot migrate your legacy app until SES becomes available in Australia.","correct":false},{"id":"385f853c6ca8754ad8dc4289fd42413e","text":"The app uses the standard JavaMail API on port 25. Amazon EC2 throttles traffic on that port of all EC2 instances by default, but you can request for this throttle to be removed.","correct":true}]},{"id":"27f1f472-2ea9-43e0-b75d-6be01c620049","domain":"CostOptimized","question":"You have a website that allows users in third world countries to store their important documents safely and securely online. Internet connectivity in these countries is unreliable, so you implement multipart uploads to improve the success rate of uploading files. Although this approach works well, you notice that when an object is not uploaded successfully, incomplete parts of that object are still being stored in S3 and you are still being charged for those objects. What S3 feature can you implement to delete incomplete multipart uploads?","explanation":"You can create a lifecycle policy that expires incomplete multipart uploads, allowing you to save on costs by limiting the time non-completed multipart uploads are stored.","links":[{"url":"https://aws.amazon.com/blogs/aws/s3-lifecycle-management-update-support-for-multipart-uploads-and-delete-markers/","title":"S3 Lifecycle Management - Incomplete Multipart Uploads"}],"answers":[{"id":"ee966c2ebd84a4f7add1d9ceabe082c9","text":"Have S3 trigger DataPipeling Auto-delete.","correct":false},{"id":"5ff7e884d027004938c218aafa63c215","text":"S3 Lifecycle Policies","correct":true},{"id":"86d93427d74df0b30713341818e3d556","text":"S2 Reduced Redundancy Storage","correct":false},{"id":"bc5e8477b1dde2747a8cb281160b01f7","text":"Have CloudWatch trigger a Lambda function that deletes the S3 data.","correct":false}]},{"id":"28221b23-1edf-4afd-bf2e-0c681d53ce7d","domain":"ResilientDesign","question":"Which of the following statements about an Amazon SQS standard queue is true?","explanation":"Understand the fundamental differences between Standard and FiFo, and the volume or capacity differences.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html","title":"SQS Standard Queues"}],"answers":[{"id":"dc88f4345d4040dc97b69e420b6710f6","text":"SQS will deliver your message at least once, and guarantees that it will not create duplicates of that message.","correct":false},{"id":"3c41b0e4131dbb7da1914721523b42c0","text":"SQS will deliver your message at least once in FIFO order.","correct":false},{"id":"323f27bf40546901f5d6900427b43fdf","text":"SQS will deliver your message at least once, but cannot guarantee the order in which the messages will be delivered.","correct":true},{"id":"5178787674f59478ee4f9e034cbd5609","text":"SQS will deliver your message at least once, but cannot guarantee that it will not create duplicates of that message.","correct":true}]},{"id":"9d65d585-d756-42e0-83bb-d8a7f4c83e82","domain":"ResilientDesign","question":"You need to take a snapshot of an EBS volume.  You are concerned about the volume and instance becoming unavailable until the snapshot is complete.  Which of these statements best describe the facts that will allow you to assess the duration of the outage?","explanation":"in General terms a snapshot has two parts; the snapshot catalogue, and the copy off of the data.  Sometimes called 'the snapshot'.  During the catalogue phase all changed files and blocks are catalogued, locked, and a change log is started.  This is a relatively fast process for most disk file systems and is the only part of the process during which the disk cannot be accessed.  the 2nd phase is the slow part during which the data is copied to the backup system.  The system is not locked during this phase. The actual duration when the system is unavailable is most closely related to how many files or blocks have changed since the last backup as this is the only portion of the data that is relevant to the incremental backup (snapshot).","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"Amazon EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html","title":"Creating an Amazon EBS Snapshot"},{"url":"https://help.acloud.guru/hc/en-us/search?utf8=%E2%9C%93&query=ebs+snapshot","title":"EBS Snapshot KBs"},{"url":"https://aws.amazon.com/blogs/aws/new-lifecycle-management-for-amazon-ebs-snapshots/","title":"New – Lifecycle Management for Amazon EBS Snapshots"}],"answers":[{"id":"071b64034823256c8ea3bb0048764787","text":"The duration of the outage is only related to the initial cataloguing phase.","correct":true},{"id":"3ac42d808544b4ab0806225881c0e525","text":"The duration of the outage is determined by the number of files changed since the last backup.","correct":true},{"id":"0462d5d8fc0d1947c3ed97376ea2ceba","text":"The duration of the outage is the time it takes to copy all the files from the disk to the backup.","correct":false},{"id":"c18929ab2ad2fc22f4c285962aaa39c8","text":"The duration of the outage is determined by the number of files on the disk.","correct":false},{"id":"6e2f1ca114ad32c09d2c423450ab61e5","text":"The duration of the outage is determined by the size of the server.","correct":false},{"id":"26583a3f6db686ba6c478f8ee3badf00","text":"The duration of the outage is determined by the age of the server.","correct":false},{"id":"aae5747a54a5f12a114ff2d92fd668c7","text":"The duration of the outage is determined by the number of files changed since the server was commissioned.","correct":false}]},{"id":"bee3fc3a-4738-4c3f-b6ad-e6f25e600772","domain":"Performant","question":"Which of the following are types of virtualization available on AWS?","explanation":"The two different types of virtualization available are Hardware Virtual Machine (HVM) & Paravirtual Machine (PVM)","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#instance-virtualization-type","title":"EC2 Virtualization Types"}],"answers":[{"id":"fc9184bf07a56c1342576d092d7cdf15","text":"Physical Virtual Machine (PVM)","correct":false},{"id":"e526c533a9df6aff264b1313a0908f9d","text":"Cloud Virtual Machine (CVM)","correct":false},{"id":"5136698bc5a65f152fe16da0719dd612","text":"Paravirtual Machine (PV)","correct":true},{"id":"4b796a884a8b85e9857127deafecc5e7","text":"Hardware Virtual Machine (HVM)","correct":true}]},{"id":"389f02f0-27ea-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"Which of the following layers of DDoS attacks does AWS automatically address?","explanation":"AWS automatically addresses DDoS attacks at the network and transport layers, which are Layer 3 and Layer 4, respectively.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-responding.html","title":"Responding to DDoS Attacks"}],"answers":[{"id":"5ab5764b458bd4674dffe82c5f1cda53","text":"Layer 1","correct":false},{"id":"73d19b475178ae97c94ed26431e3b138","text":"Layer 4","correct":true},{"id":"537c230a6d35c80a253f85b1c6d607c4","text":"Layer 7","correct":false},{"id":"9041d5d59c0e46d987baf883fd77e227","text":"Layer 3","correct":true}]},{"id":"70c6a808-0d5d-40d3-9b62-aa2fd031a543","domain":"CostOptimized","question":"You have three AWS payer accounts consolidated under an AWS Organization . Which of the below statements is TRUE for purposes of volume discounts?","explanation":"If you have multiple accounts, your charges will decrease because AWS combines usage from all accounts in the organization to qualify you for volume pricing discounts.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html","title":"Consolidated Billing for Organizations"}],"answers":[{"id":"a6cd99e8b1bbcfc82e184acc9f28eede","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled in each account","correct":false},{"id":"98e718508cd32b9ffb27d8648e9129d0","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to","correct":true},{"id":"4fb1af36b069dca73268eedbfab53e7b","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled at the Organisation level","correct":false},{"id":"c9c2416d95c8112070b7a5b032629fdf","text":"Usage in each account will be evaluated individually to determine the volume discount it is individually entitled to","correct":false}]},{"id":"912352c0-d2a0-4e7c-89cd-d4ee66445744","domain":"CostOptimized","question":"You have been asked to design a scalable solution for a simple customer service survey that is shown online after each of the ~10 million chat bot interactions per month: Emoticons for 3 rating options ('positive', 'neutral' and 'negative') are to be presented with the expectation that about 10% of users submit their feedback. The bot is public facing and operates 24x7. Select a feasible and most cost effective solution.","explanation":"RDS alone is more expensive than any of the serverless solutions and therefore not an option here. Because of this use case's simplicity (i.e. no request validation, rate limiting, authentication/authorization, etc. required), there is essentially no need for a Lambda fronting API Gateway. Given the described requirements (load and availability), an ALB is more expensive as it's billed hourly.","links":[{"url":"https://serverless-training.com/articles/save-money-by-replacing-api-gateway-with-application-load-balancer/","title":"Saving Money By Replacing API Gateway With Application Load Balancers Lambda Integration"},{"url":"https://aws.amazon.com/blogs/networking-and-content-delivery/lambda-functions-as-targets-for-application-load-balancers","title":"Lambda functions as targets for Application Load Balancers"},{"url":"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/browser-invoke-lambda-function-example.html","title":"Invoking a Lambda Function in a Browser Script"}],"answers":[{"id":"852949aded12102365acbeb1052394f9","text":"You develop a proper API and use an API Gateway, Lambda and DynamoDB solution","correct":false},{"id":"39329c7ee88152a625a8d565e6b38f36","text":"You front your Lambda that writes the ratings to a DynamoDB table with an ALB.","correct":false},{"id":"b63327b72ecc6921a7e43eb0f786a3fe","text":"You invoke a Lambda function on demand in a browser script using the AWS SDK for JavaScript. For that to work you will need to create an Amazon Cognito identity pool with access enabled for unauthenticated identities and include the identity pool ID in your code to obtain credentials for the browser script. The function writes the submitted rating value to a DynamoDB table.","correct":true},{"id":"909f43a37c73caa5e0c764e4d8d8201c","text":"Given the expected load, you are better off with an Elastic Beanstalk app and RDS such as PostgreSQL or MySQL","correct":false}]},{"id":"1b16d00d-84a4-4eb9-ae8a-ab80164b5ecb","domain":"Performant","question":"You have suggested moving your company's web servers to AWS, but your supervisor is concerned about cost. Which of the following deployments will give you the most scalable and cost-effective solution?","explanation":"An Auto-Scaling group of EC2 instances will exactly match the demand placed on your servers, allowing you to pay only for the compute capacity you actually need.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/WhatIsAutoScaling.html","title":"About Auto-Scaling"}],"answers":[{"id":"1ca0609c964d5e68f5fa0a3d5b4316e0","text":"None of these options","correct":false},{"id":"e436264760a9cf93907c10a4cca07f7f","text":"A solution that's built to run 24/7 at 100% capacity, using a fixed number of T2 Micro instances","correct":false},{"id":"b9cb1e18890012ba94c27400d7c8ac95","text":"A hybrid solution that leverages on-premise resources","correct":false},{"id":"145e94d64c554621a473e4aa18e95b1f","text":"An EC2 auto-scaling group that will expand and contract with demand","correct":true}]},{"id":"cd86c07d-478b-4dc0-8e79-4b61bbdfc377","domain":"CostOptimized","question":"An online tutoring company used AWS Organizations to create an organization to consolidate and manage its AWS accounts. The organization has three accounts called production, development, and testing. As per company policy, all accounts use identical Linux EC2 instances that are in the same region and configured with default tenancy. The production account has seven Reserved regional EC2 instances to support its production environment. Last month, the testing account used two On-Demand EC2 instances running 24/7, while the development account used three On-Demand EC2 instances running 24/7. Because of a decrease in usage last month, the production account used only five of its reserved EC2 instances. How is the organization billed for EC2 instance usage last month?","explanation":"Unused Reserved EC2 instances can offset the cost of equivalent On-Demand EC2 instances. The higher cost of two On-Demand instances is replaced by the lower cost of two unused Reserved instances. Additionally, because AWS Organizations is enabled consolidated billing is enabled as well.","links":[{"url":"https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-reservation-models/consolidated-billing.html","title":"Reserved Instances and AWS Organization"}],"answers":[{"id":"34d273571ee761d7887b5dc69462e039","text":"The company is billed for five Reserved instances and, none of the On-Demand instances since this is covered by the excess of Reserved instances.","correct":false},{"id":"b0feba15d706ec58daef8b79049aa2b9","text":"The company is billed for seven Reserved instances and three On-Demand instances.","correct":true},{"id":"c9b739a791ede1c8bea892ec7326479e","text":"The company is billed for seven Reserved instances and two On-Demand instances.","correct":false},{"id":"bc2784c0ecdc81e04ad8ad582c89f961","text":"The company is billed for seven Reserved instances and all five On-Demand instances because consolidated billing is not enabled.","correct":false}]},{"id":"f83080c3-ee9d-4ca9-ada5-f94b6642d2f2","domain":"CostOptimized","question":"Your company is running an older version of Windows on employees' desktops/laptops which will be going off of mainstream support in the near future. The most current version of Windows will require a large capital investment to purchase more powerful hardware to run it. All desktops/laptops require access to the Internet as well as access to multiple business applications running on Amazon EC2 web servers in the AWS cloud. Your manager has tasked you with determining how to move the company's desktops/laptops to the most current version of Windows. Which architecture will provide the most cost effective solution?","explanation":"Amazon Workspaces provides the capability to serve virtual cloud-based desktop sessions to your desktop/laptop users (either Windows or Linux). It eliminates the need for powerful hardware, and it removes the burden of individual desktop/laptop software maintenance. AppStream is not needed to access the Internet, nor is it needed to serve the EC2 applications in this use case since a browser can be used from WorkSpaces to access the web servers. A NAT Gateway is preferred to an Internet Gateway since all traffic is initiated from the desktop/laptop, instead of from out on the Internet. WorkSpaces provides for creating an authentication directory, so creating one separately is not needed. WorkSpaces also creates an ENI for each session inherently.","links":[{"url":"https://docs.aws.amazon.com/workspaces/latest/adminguide/amazon-workspaces.html","title":"What is Amazon WorkSpaces?"},{"url":"https://aws.amazon.com/blogs/desktop-and-application-streaming/why-customers-are-moving-their-windows-desktops-to-the-cloud-with-aws/","title":"Why Customers Are Moving Their Windows Desktops to the Cloud with Amazon WorkSpaces"}],"answers":[{"id":"7c8f5d29af4240a4ec8c68eaa488e933","text":"Use Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use an Internet Gateway in the same VPC to provide access to the Internet. Provision an AWS Managed Microsoft AD instance and link it to your on-premises Active Directory for user authentication.","correct":false},{"id":"e33c2a9e2b05853b6c1f1bc548357068","text":"Implement Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use Amazon AppStream to provide access to the Internet and to serve the EC2 applications to the desktops/laptops.","correct":false},{"id":"7c9f90a44ccdb77a69453cc39d1fdba7","text":"Implement Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use an Internet Gateway in the same VPC to provide access to the Internet. Provision Elastic Network Interfaces in the same VPC to connect the desktops/laptops to the EC2 applications.","correct":false},{"id":"58e179301471d5f030ad1b404a5c527f","text":"Deploy Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use a NAT Gateway in the same VPC to provide access to the Internet.","correct":true}]},{"id":"1f0f9717-876a-4bb8-954b-aaf22341de42","domain":"SecureSolutions","question":"You need to enable SSH remote connectivity to an EC2 instance in your AWS environment from a remote PC with IP 130.194.52.28. The EC2 instance is in a public subnet with an assigned public IP and the NACL rules already enable SSH connectivity. Which of the following is the most secure way to configure the instance’s Security Group?","explanation":"As security groups are stateful, to enable connectivity to the EC2 instance from a remote PC you only need to define an INBOUND rule. Once the Inbound connection is established, outbound connectivity is allowed, therefore answers with outbound rules are incorrect. The most secure configuration is to allow only the specific remote PCs IP address IN on port 22. It is NOT advisable to allow inbound Port 22 from any device.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups for Your VPC"}],"answers":[{"id":"7ff22bed410d419cce536fba059b1c8f","text":"Inbound: Allow ALL Ports from 130.194.52.28/32 \\n Outbound: Allow ALL Ports to 130.194.52.28/32","correct":false},{"id":"d037560d28a612a64cc8779c242342af","text":"Inbound: Allow SSH (Port 22) from 130.194.52.28/32","correct":true},{"id":"cc24113553ebdfe466a6f9cebcca2ae3","text":"Inbound: Allow SSH (Port 22) from 0.0.0.0/0 \\n Outbound: Allow ALL Ports To 0.0.0.0/0","correct":false},{"id":"e8db63151589b254c79e001cda4a9c5c","text":"Inbound: Allow SSH (Port 22) from 0.0.0.0/0","correct":false},{"id":"ce4ef70d7e0a6c5e9eb256dd2b9f74f0","text":"Inbound: Allow SSH (Port 22) from 130.194.52.28/32 \\n Outbound: Allow SSH (Port 22) to 130.194.52.28/32","correct":false}]},{"id":"e7685041-5997-4788-9e77-4ec3abb76e30","domain":"Performant","question":"As a Solutions Architect, you advise on team planning activities. A team is building an application that must store persistent JSON data and be able to have an index. Data access must remain consistent if there is high traffic volume. What service should you recommend to the team?","explanation":"Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. The data stored in DynamoDB is JSON format, making it the perfect data store for this requirement.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html","title":"What is Amazon DynamoDB?"}],"answers":[{"id":"8679a1944db93938a65e47107be5d2b8","text":"AWS CloudFormation","correct":false},{"id":"f7415e33f972c03abd4f3fed36748f7a","text":"Amazon Redshift","correct":false},{"id":"ecafbaed9f41dac736e496a7cd234ce4","text":"Amazon DynamoDB","correct":true},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false}]},{"id":"390ab5d8-2fc2-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"As a Cloud Solutions Architect, you have been tasked to set up an enterprise-class database with six-way replication across three Availability Zones. This measure is proposed to strengthen the database’s fault tolerance to disk failures. Which of the following engines will enable you to do that?","explanation":"Aurora is the database engine that provides six-way replication of each database volume across three Availability Zones. The other responses are just like Aurora in that they are relational database engines that offer Multi-AZ deployments. However, Oracle, MariaDB, and MySQL do not have this specific ability.","links":[{"url":"https://aws.amazon.com/rds/aurora/faqs/","title":"Amazon Aurora FAQs"}],"answers":[{"id":"7f9733e208088b1ce6df3d4be1765396","text":"MariaDB","correct":false},{"id":"30162ed78b6c10f731411f2fc440c24f","text":"Oracle","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"69670a9d53817d1ec89e685997343ce2","text":"Amazon Aurora","correct":true}]},{"id":"7240e60f-f337-4116-be42-8df912212cfd","domain":"Performant","question":"What is the minimum time interval granularity for the data that Amazon CloudWatch receives and aggregates?","explanation":"The minimum time interval for CloudWatch is 1 minute.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch.html","title":"CloudWatch - Detailed Monitoring"}],"answers":[{"id":"f77eb9f1b917ba78f6eb2ce8ede0a0e4","text":"1 minute","correct":true},{"id":"70abb32fcb0c9e8194526d1eef15eb05","text":"10 minutes","correct":false},{"id":"4adcc26418f545df76ab44c53fc55702","text":"5 minutes","correct":false},{"id":"3d393dc956fea776f25db075df639cb1","text":"30 seconds","correct":false}]},{"id":"2403cf92-cd58-4ade-8a82-52be2b2a6b5b","domain":"SecureSolutions","question":"Your Security team is concerned about a recent spate of large-scale DDoS attacks on other providers in your industry. You have a number of internet-exposed services in your business, and any potential outage has significant financial impact. The security team wants to be informed of any attack as it happens, and would like some assistance from AWS to help mitigate an attack should one happen. You currently have WAF deployed, and an Enterprise support agreement in place, but which of the below extra steps would you recommend","explanation":"AWS Shield Standard does not include notification of any attacks detected, therefore can be eliminated straight away. Although WAF can be used during a DDoS attack to help mitigate the attack with custom block rules, there are no in-built DDoS protections with WAF as these are provided by Shield. AWS has a dedicated DDoS Response Team (DRT) to assist during any DDoS attacks - however in order to access them, you need to be on an Enterprise or Business support agreement, and relevant to this scenario, have purchased Shield Advanced. This combined with the alerting of attacks that is available with Shield Advanced make purchasing Shield Advanced the most appropriate choice. ","links":[{"url":"https://aws.amazon.com/shield/getting-started/","title":"Getting Started with AWS Shield"},{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-overview.html#ddos-drt","title":"How AWS Shield Works"}],"answers":[{"id":"6afd0c59a36c013760fbb187d8bbb415","text":"Purchase AWS Shield Advanced, and during an attack lodge a support request asking for assistance from AWS","correct":true},{"id":"b41f4d516374b164d0a2c054a39dfe3f","text":"Enable rate limiting on your load balancers, and during an attack lodge a support request using your Enterprise support agreement for assistance","correct":false},{"id":"191789dacb98c2ed977f4a62437a00af","text":"Enable the inbuilt AWS WAF DDoS protections, use SNS to notify when an attack is detected. During an attack lodge a support request using your Enterprise support agreement for assistance","correct":false},{"id":"b8ede9969b12d6122fcef9029ff00b52","text":"By default all AWS services are automatically protected against DDoS attacks by AWS Shield - nothing extra needs to be done. During an attack lodge a support request using your Enterprise support agreement for assistance","correct":false}]},{"id":"2bf7c178-22a7-4278-b5b0-53cc05846468","domain":"ResilientDesign","question":"Your company is migrating an on-premise 15 TB PostrgreSQL database to AWS. The company expects this database to triple in size and has a business requirement of synchronous replica lag be under 100 ms. Which AWS RDS service will meet the requirement best?","explanation":"Aurora Cluster can grow up 64 TB in size and replica lag is less than 100 ms after the primary instance has written an update.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.html","title":"Amazon Aurora DB Clusters"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Replication.html","title":"Amazon Aurora Replicas"},{"url":"https://forums.aws.amazon.com/thread.jspa?threadID=230133","title":"notes form teh AWS support forum"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Limits.html","title":"RDS limits"}],"answers":[{"id":"30162ed78b6c10f731411f2fc440c24f","text":"Oracle","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"69670a9d53817d1ec89e685997343ce2","text":"Amazon Aurora","correct":true},{"id":"0284c831e4dee575b707cc920ab09ae6","text":"PostrgreSQL","correct":false}]},{"id":"08233176-e11b-410e-98eb-25ca6e2eebcb","domain":"ResilientDesign","question":"A large enterprise has a distributed application in its own data center and relies on message brokers to connect and co-ordinate different systems. Message Brokers serve as the backbone for their IT environment and ultimately their business services. The enterprise has started to move some of its applications to the cloud and is looking for a cloud message broker solution so that the on-premise applications can interact with cloud-based application components. Which of the following services best suit the customer requirements?","explanation":"Amazon MQ is recommended for messaging between on-premises and cloud application components. It also supports industry-standard APIs and protocols such as JMS, AMQP and MQTT. Amazon SQS is best utilized as a messaging solution between components entirely on AWS. Amazon Step Functions is a fully managed service which makes it easy to co-ordinate components of distributed applications using visual workflows. Amazon SNS is a managed publish/subscribe service which reliably delivers messages to all valid AWS endpoints.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-activemq-in-a-hybrid-cloud-environment-with-amazon-mq/","title":"AWS Application Integration Services"}],"answers":[{"id":"55daa020bacdf7e4ae1a33c9f14c45b3","text":"Amazon SNS","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true},{"id":"860f0e709d06a1c1529c01a39cdfd798","text":"Amazon Step Functions","correct":false},{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":false}]},{"id":"9217f221-d436-4a41-a625-280ddc5dc210","domain":"SecureSolutions","question":"You have just created two EC2 instances in your VPC and have allocated them IPs on the same subnet (10.0.1.0/24). A default security group has been created, and you have added both instances to it. The two instances need to communicate with each other. What else do you need to do to allow this to happen?","explanation":"Since both instances are in the same subnet and connectivity is within the subnet, NACL rules do not apply to traffic between the two instances. Only Security Group settings are required to support the required connectivity between the instances and the default settings enable this.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups for Your VPC"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"351b5d48765db8ce844bc356643d3f1b","text":"NACL rules will need to be added to allow for the required Inbound and Outbound traffic, security group rules are not needed since they share the same Security Group.","correct":false},{"id":"1cb99d8ab36453c1d339711c8cf27808","text":"Since both instances are in the same Subnet, additional security group rules are needed to allow the required inbound and outbound traffic.","correct":false},{"id":"4fb4682a32431d9fb34f70e83161654c","text":"NACL rules will need to be added to allow the required Inbound and Outbound traffic, security group entries are also required to allow the required inbound and outbound traffic.","correct":false},{"id":"e7cca5653481d2b3786aec2bdede2165","text":"Since both instances are in the same subnet and have the same security group, connectivity will be enabled by default, so nothing extra is required.","correct":true}]},{"id":"680c52c8-07f9-4f32-9cdb-ede2e267faa6","domain":"ResilientDesign","question":"Your organisation is planning on storing mission-critical data in Redshift. This data has high value and is frequently used for business decisions, so management has decided that a 99.999% availability SLA is needed. How would you achieve this with RedShift?.","explanation":"RedShift does not currently support Multi-AZ or Multi-Region deployments, so neither of these are valid options, and with an SLA of 99.9% neither is not doing anything extra. AWS recommends running multiple clusters when true high availability is required, and making sure they are kept in sync. Note that there no automated synchronisation options for RedShift clusters, and this must be handled outside of RedSift (e.g. with Kinesis)","links":[{"url":"https://aws.amazon.com/redshift/sla/","title":"RedShift SLA"},{"url":"https://aws.amazon.com/redshift/faqs/","title":"RedShift FAQ"},{"url":"https://aws.amazon.com/blogs/big-data/building-multi-az-or-multi-region-amazon-redshift-clusters/","title":"Building Multi-AZ or Multi-Region Amazon Redshift Clusters"}],"answers":[{"id":"aebe0fe52f1dc1589726d832f1ec5d97","text":"Use a Multi-AZ Redshift Cluster","correct":false},{"id":"77d03cf39a714f11e72a87578d5f20e0","text":"This level of SLA is built into RedShift so there is no need to do anything extra.","correct":false},{"id":"d675283647d42878fe1f19b1b2789e1f","text":"Use a Multi-Region Redshift Cluster","correct":false},{"id":"0e3881a1bf5e96676203a9fc439bd048","text":"Deploy a second RedShift Cluster in another AZ and ensure all writes happen to both clusters","correct":true}]},{"id":"cdb5b6d9-37bb-41e5-bd69-985dabcc7bd0","domain":"SecureSolutions","question":"You are hosting a web application that runs on a number of Web Servers in public subnets and Database Servers in private subnets. A NAT Instance is being used for connectivity to the internet for the Private Subnets. The NAT Instance is now becoming a bottleneck, and you are looking to replace it with NAT Gateway. Which of the following would ensure high availability for the NAT Gateway?","explanation":"If you have resources in multiple Availability Zones and they share one NAT gateway, in the event that the NAT gateway’s Availability Zone is down, resources in the other Availability Zones lose internet access. To create an Availability Zone-independent architecture, create a NAT gateway in each Availability Zone and configure your routing to ensure that resources use the NAT gateway in the same Availability Zone.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","title":"NAT Gateways"}],"answers":[{"id":"5ae78abee9f8fe1afe2ab443a4480098","text":"Disable source/destination check on the NAT Instances","correct":false},{"id":"18c2392152bcb34e4f0933dfcff0de2b","text":"Deploy a NAT Gateway in 2 Regions","correct":false},{"id":"b0b35801e71ae33d446780112d8438dc","text":"Deploy a NAT Gateway in 2 Availability Zones","correct":true},{"id":"8956081d09cf7a5203cbb2fe0a9cbd9e","text":"Deploy a NAT Gateway along with the NAT Instance","correct":false}]},{"id":"8a4cd8a8-183f-11ea-8d71-362b9e155667","domain":"CostOptimized","question":"Your company recently expressed interest in upgrading to an AWS Support plan that provides infrastructure event management and incident response for the launch of a business-critical application. Which of the following support plans will satisfy your company's requirements?","explanation":"Each AWS account comes with Basic Support, so Basic is not the answer. Either the Business or the Enterprise plan grants access to AWS Infrastructure Event Management, the program your company needs for assistance with launching the application. The Enterprise plan, however, provides up to a 15-minute response time if the business-critical application goes down; the Business plan does not offer this option. In addition, the Busines Plan does not include Infrastructure Event Management - you need to pay an additional fee for this. Therefore the Enterprise plan is the only option that provides the appropriate level of incident response and infrastructure event management required.","links":[{"url":"https://console.aws.amazon.com/support/plans/home?#/","title":"AWS Support Plans"},{"url":"https://aws.amazon.com/premiumsupport/programs/iem/","title":"AWS Infrastructure Event Management"}],"answers":[{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":false},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true}]},{"id":"2d66a68a-db0b-46af-93f2-8fbb712d7f8d","domain":"ResilientDesign","question":"Which of the following are the application integration services enable communication between decoupled components in order to build a scalable and more resilient solution?","explanation":"Amazon SQS, Amazon MQ and Amazon App Sync are AWS application integration services. Application integration services enable communication between decoupled components within micro-services, distributed systems, and serverless applications so you can easily build scalable and more resilient solutions. Amazon DataSync is AWS Migration and Transfer service and is not an integration service. AWS SES is a cloud-based email sending service designed for customer engagement.","links":[{"url":"https://aws.amazon.com/products/application-integration/?nc2=h_m1","title":"AWS Application Integration Services"}],"answers":[{"id":"71f398f7b21d60364b4a577a13a1271f","text":"Amazon Data Sync","correct":false},{"id":"335523617c1b39d5772d3e75b7da2014","text":"AWS Simple Email Service (SES)","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true},{"id":"b65c2d4cd3e247c1554f92a08e6ea48b","text":"Amazon App Sync","correct":true},{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":true}]},{"id":"9cfdc945-a7e0-479c-9bcc-973f9ebfd7dc","domain":"CostOptimized","question":"You want to set up 2 CloudWatch alarms in addition to the 6 you already have to monitor your cloud environment. It has been 13 months since you created your AWS account, and you want to avoid being charged for creating the alarms. What should you do?","explanation":"Upon signing up for an AWS account, you will get a range of service usage that will never cost you anything. Such offers include 10 alarms with CloudWatch. That’s why creating the alarms is the correct answer. Contacting support is wrong because it’s not necessary to request a service increase limit. Avoiding creating new alarms is also wrong because there’s no term limits on the CloudWatch alarm offer; it’s always free. Creating more alarms in this case is still free of charge because the free offer is limited to 10 CloudWatch alarms.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsm.page-all-free-tier=1","title":"AWS Free Tier"}],"answers":[{"id":"d8991b206aa9d731ab999eddedf26d6e","text":"Go ahead and create the alarms; you can have up to 10 CloudWatch alarms without being charged.","correct":true},{"id":"a336fb6001d622e126c7d02da7ab218f","text":"Go ahead and create the alarms; CloudWatch alarms are always free of charge, regardless of number.","correct":false},{"id":"222fcbee1f68dae67b4406597659a622","text":"Contact AWS Support for a service increase limit.","correct":false},{"id":"3e9a7ae3a0c82f4aaf031d7400a3774f","text":"Do not create the alarms; you will be charged, since you get a maximum of 10 alarms with CloudWatch for the first 12 months after your account sign-up.","correct":false}]},{"id":"39236967-6c02-4608-9ddb-9ae5cb590e7f","domain":"CostOptimized","question":"You purchased a reserved instance for hosting your website with a term of one year as this has significant cost savings compared to on-demand instances. What happens to this instance after one year?","explanation":"The reserved instance type has significant cost benefit when compared to the on-demand instance type when purchased in advance with one or three years term. Reserved instances are not physical instances, but rather a billing discount applied to the use of on-demand instances in the account you own. Reserved instances do not renew automatically; when they expire, you can continue using the EC2 instance without interruption, but you are charged on-demand rates.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","title":"Amazon Elastic Compute Cloud - Reserved Instance Type"}],"answers":[{"id":"c97c0ee2fa55e86eeebafc57a4831b3a","text":"The reserved instance will be terminated automatically after one year, with a termination warning notice.","correct":false},{"id":"4c1a861266ab02cfae787e36ebfe54b4","text":"The EC2 instance continues to run without interruption, but the instance is billed at the on-demand rate.","correct":true},{"id":"c412194739de1b9b17bd8734ab35aaa5","text":"The reserved instance will be shutdown automatically after one year and a 2 weeks of notice will be provided by AWS to either renew or terminate.","correct":false},{"id":"85f13ce18baa70ee478fe656e5b02ca6","text":"The reserved instance will renew automatically if the auto-renew option is set to true.","correct":false}]},{"id":"c4ce254d-d835-4beb-b096-153d84bada07","domain":"SecureSolutions","question":"Which of the following services allows you to access the service's underlying operating system?","explanation":"Access to the underlying operating system is granted for Elastic Map Reduce and Elastic Beanstalk. The others are managed services.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html","title":"About Elastic Beanstalk"},{"url":"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html","title":"About EMR"}],"answers":[{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"8d4c0b2cef256d21ab680366c8b1c6bf","text":"EMR","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false}]},{"id":"d87fd5d8-0ab7-4f87-a1c1-0635871020ca","domain":"SecureSolutions","question":"You work for a security company that stores highly sensitive documents on S3. One of your customers has had a security breach and, as a precaution, they have asked you to remove a sensitive PDF from their S3 bucket. You log in to the AWS console using your account and attempt to delete the object. You notice that versioning is turned on, and when you dig a little deeper you discover that you cannot delete the object. What may be the cause of this?","explanation":"Only the owner of an Amazon S3 bucket can permanently delete a version.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/delete-or-empty-bucket.html","title":"Deleting and Emptying S3 Buckets"}],"answers":[{"id":"34815cde786bfe064a8e2da0c0dfdcb6","text":"You cannot delete the object because you are not the bucket owner.","correct":true},{"id":"96952afde438b94cf1de90e31b71d6bd","text":"You must be logged in as a Super User to delete objects.","correct":false},{"id":"6cca1efe9e60d13f3b73e61daaa6ba12","text":"S3 server-side encryption is preventing you from doing this.","correct":false},{"id":"be0a836d5e8a55696d3634aff7f51473","text":"You can never permanently delete an object on S3 after versioning is enabled.","correct":false}]},{"id":"1024766e-2157-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"When setting up the properties of an S3 bucket, which of the following options should you select to track storage cost?","explanation":"You need to label your S3 buckets with tags to track their storage costs. AWS will use the tags to organize costs in a cost allocation report. Object-level logging is for using AWS CloudTrail to record object-level API activity, server access logging is for logging requests for access to the bucket, and versioning is for keeping all versions of an object in the same bucket - not for tracking costs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/CostAllocTagging.html","title":"Using Cost Allocation S3 Bucket Tags"}],"answers":[{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":true},{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":false},{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":false},{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false}]},{"id":"224816bc-81de-4041-b9a2-ab1803d63d99","domain":"Performant","question":"When selecting an EC2 instance type for your application, it's important to know which of the following?","explanation":"Of the answers offered, the EC2 instance you choose will be determined by the number of I/O operations needed, as well as the anticipated amount of memory required. There are other parameters that should be considered, but they are not offered in the answers.","links":[{"url":"https://aws.amazon.com/blogs/aws/choosing-the-right-ec2-instance-type-for-your-application/","title":"Choosing the Right EC2 Instance Type for Your Application"}],"answers":[{"id":"be2609e7224408870bec457e4543dc43","text":"The location from which most traffic comes","correct":false},{"id":"795975d59cca09b9dd3c399bd1fa0694","text":"The required number of I/O operations","correct":true},{"id":"85cd6a6aa0cb511c3446cfa8debd918b","text":"The memory requirements","correct":true},{"id":"b136ff6aee5c126f394aab8ea0eb4662","text":"The peak expected usage","correct":false}]},{"id":"b3a1037c-cf70-4aa6-b9a1-7e93c8af196c","domain":"SecureSolutions","question":"What is the order traffic will traverse from your computer through Security Groups (SG) & Network ACLs (NACLs) to an EC2 instance  and back to your computer?","explanation":"When traffic is sent from your computer to an EC2 instance, it first arrives an Internet Gateway(IG)/Virtual Private Gateway(VPG) in the VPC. It then proceeds through the Router and a Route Table will determine which subnet the traffic needs to be delivered to. Since NACLs are applied to subnets, it will decide if the traffic may continue into the subnet or not based on the NACL. Next, any SGs applied directly to EC2 instances will be evaluated, and a determination will be made to allow traffic to the instance. With traffic having made it to the instance, it will then <reply?> to your computer. The SG will allow all traffic back, then the NACL will decide whether to allow the outbound traffic or not before routing back to the IG/VPG and on to you.”","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html#VPC_Security_Comparison","title":"Comparison of Security Groups and Network ACLs"}],"answers":[{"id":"84adaea97aece19c53983dfbc6403788","text":"SG inbound -> NACL inbound -> NACL outbound -> SG outbound","correct":false},{"id":"fdd6ebc8dac366562f246b4cb8b9d87b","text":"NACL inbound -> SG inbound -> NACL outbound -> SG outbound","correct":false},{"id":"afa70880d48613e4de285569dc0395da","text":"SG inbound -> NACL inbound -> SG outbound -> NACL outbound","correct":false},{"id":"7d87a1e978653a0a4cf193c8c9aff134","text":"NACL inbound -> SG inbound -> SG outbound -> NACL outbound","correct":true}]},{"id":"536131e1-bbd8-4ef5-b765-4bd089487b28","domain":"Performant","question":"Your on-premise servers are running low on disk storage space, but your company is not yet ready for a complete move to the public cloud. You've been tasked with finding an interim storage solution that also offers backup and archiving capabilities. Which AWS service would you recommend to meet this immediate need?","explanation":"Storage Gateway is a storage solution that provides on-premise capacity while taking advantage of some of the benefits of Cloud Storage.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/StorageGatewayConcepts.html#storage-gateway-cached-concepts","title":"Gateway-Cached Volumes Architecture"}],"answers":[{"id":"759533f205f8af35f7da47dc76331eee","text":"Storage Gateway with Gateway-Stored Volumes.","correct":false},{"id":"cdd0d04de2b79c78e792aec6263d2d3d","text":"DirectConnect","correct":false},{"id":"c0429b6a658dd488f7262d983c7e02bb","text":"Snowball","correct":false},{"id":"04567b32a7bb8490dda99a0fe4c3323a","text":"Storage Gateway with Gateway-Cached Volumes","correct":true}]},{"id":"8b4f4f4a-0f1e-420a-9115-3ddde644cecc","domain":"Performant","question":"Your application's has a rapid upscale and usage peaks at 90% during the hours of 9 AM and 10 AM everyday. All other hours require only 10% of the peak resources. What is the best way to scale your application so you're only paying for max resources during peak hours?","explanation":"Proactive cyclic scaling is scaling that occurs at a fixed interval (daily, weekly, monthly, quarterly. The proactive approach can be very effective when the upscale is large and rapid and you cannot wait for the delays of a sequence of auto-scaling steps.)","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/schedule_time.html","title":"Scheduled Scaling"}],"answers":[{"id":"d08473e23d73d31785239196c7ef5064","text":"Proactive cyclic scaling","correct":true},{"id":"6acf192ec915189144dfc5769ea5905a","text":"Reactive event-based scaling","correct":false},{"id":"00464894fd00bf415d119e5a89bd61a4","text":"Proactive event-based scaling","correct":false},{"id":"1c8add13dc251f42618a5622a1a04714","text":"Reactive cyclic scaling","correct":false}]},{"id":"c55f22ae-80d0-4959-b174-d829799c0ebe","domain":"SecureSolutions","question":"An AWS VPC allows you to:","explanation":"With a VPC, you can connect your cloud resources to your own IPSec VPN connections.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_VPN.html","title":"AWS Managed VPN Connections"}],"answers":[{"id":"80b64cf6fc3a37e7c804ff0db69f8916","text":"Provision unlimited S3 resources.","correct":false},{"id":"b6d6372266b9d9c86bea479d7e2ed72f","text":"Forget about security: AWS does it all for you.","correct":false},{"id":"965dceca3b86aea95ef5de037128780c","text":"None of these.","correct":false},{"id":"f7ddabca6bedcc81b8b193a009967f58","text":"Connect your cloud resources to your own IPSec VPN connections.","correct":true}]},{"id":"69e2d5c3-0b46-43b6-b5d5-cf1021256e41","domain":"SecureSolutions","question":"Meridian Media Services is migrating their customer facing online applications to AWS. They've experienced revenue impacting DDoS attacks in the past and would like to mitigate that risk going forward. They have both in-house developed and COTS applications that will run on EC2. CloudFront will be used for content delivery. Which security services should they implement to reduce the risk of DDoS interruptions?","explanation":"AWS Shield is a managed DDoS protection service that safeguards applications running on AWS. AWS Shield Standard provides comprehensive availability protection for CloudFront and Route 53, and AWS Shield Advanced gives higher levels of protection for EC2, ELB, and other AWS services.","links":[{"url":"https://aws.amazon.com/shield/","title":"AWS Shield"}],"answers":[{"id":"4506e0fedb041a54663245c51aa25e81","text":"Leverage the standard version of AWS Shield at no fee to protect CloudFront. Deploy AWS Shield Advanced for a fee to protect the EC2 instances.","correct":true},{"id":"e34a57da0c06cbb3d1f5743459c20306","text":"Use the standard version of Amazon GuardDuty at no fee to protect CloudFront. Implement Amazon GuardDuty Advanced for a fee to protect the EC2 instances.","correct":false},{"id":"62879f82a5496e13612fab26735c4e32","text":"Rely on the standard version of AWS Shield to protect both CloudFront and the EC2 instances as they are both included at no fee.","correct":false},{"id":"10bfd36d94ade6e61b462d7c05c3065a","text":"Apply the standard version of Amazon GuardDuty to protect both CloudFront and the EC2 instances as they are both included for a small fee.","correct":false}]},{"id":"955a81c8-335f-4c4c-9841-5092fb517bba","domain":"ResilientDesign","question":"A team is migrating a three-tier web application to AWS.  Currently the application runs from a single server which stores session information about user transactions.  As part of migration the team wants to take advantage of the High Availability that AWS provides by deploying on to simple low specification ec2 instances across multiple Availability Zones.  The team is aware that the application might provide an inconsistent experience if users are load-balanced between servers storing different state information.  Which options may allow you to move the application into AWS with minimal additional delay?","explanation":"The best answer here is to use sticky sessions on the ELB. This will route requests from a user to the same server every time, ensuring their session details are preserved.  Route 53 weighted or multi-value routing will not ensure routing to the same server each time. It is possible to share certain types of EBS volumes across ec2 instances, however they cannot be across AZs, and the EBS types would not fall into the description 'simple low specification'.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-target-groups.html#sticky-sessions","title":"Sticky Sessions"},{"url":"https://aws.amazon.com/blogs/aws/new-multi-attach-for-provisioned-iops-io1-amazon-ebs-volumes/","title":"Multi-Attach for Amazon EBS Volumes"}],"answers":[{"id":"f159b6f5434eb8067673b979c8b8bea6","text":"Deploy the application to two EC2 instances and enable sticky sessions on the Elastic Load Balancer","correct":true},{"id":"5617928a445d24401162686f8b7c099d","text":"Deploy the application to two EC2 instances and use Route 53 multi-value routing to send users to the same server each time","correct":false},{"id":"6f54375e0f74acb0a1a330c3bc2ec01a","text":"Deploy the application to two EC2 instances and use Route 53 to perform weighted routing of users to the same server each time","correct":false},{"id":"f6d1002ac85996490667b2b8fee9586d","text":"Deploy the application to two EC2 instances with shared EBS storage to share the session details between instances","correct":false}]},{"id":"aad18b7b-a805-45b3-9b77-66eecf097e97","domain":"CostOptimized","question":"Your AWS environment contains several on-demand, EBS-backed EC2 instances dedicated to a project that has just been canceled. Your supervisor does not want to incur charges for these on-demand instances, but also does not want to lose the data just yet because there is a chance the project may be revived in the next few days. What should you do to minimize charges for these instances in the meantime?","explanation":"Stopping an EBS-backed on-demand instance will stop the charges and preserve the data.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html","title":"Stopping and Starting Your Instances"}],"answers":[{"id":"bcf45b66b85859c34f9a1bc2e2e3d537","text":"Explain your situation to AWS Support and ask them to hold your instances for you.","correct":false},{"id":"3e9091dfa36a1ab60c68658d5b630b61","text":"Terminate the instances.","correct":false},{"id":"1c1cacea035822ccf211f7f588b085fe","text":"Stop the instances as soon as possible.","correct":true},{"id":"ad806d84c4f630fa88693a83dc990289","text":"Take snapshots of the EBS volumes and sell the instances on the In-Demand Instance Marketplace.","correct":false}]},{"id":"c07cbbaf-7a26-44d9-9e50-86908c1ac754","domain":"ResilientDesign","question":"A football scoreboard app uses an AWS Lambda backend to retrieve game information stored in an Amazon DynamoDB database. An EC2 instance reads multiple Amazon Kinesis streams of scores and stats and writes them to the database. Two app users sitting side-by-side at a restaurant refresh the scoreboard at the same time and get different stats for the same game. What should the app developers do to resolve this?","explanation":"DynamoDB is eventually consistent by default, and may not reflect the results of a recently completed write since data is automatically replicated across three facilities in an AWS region for durability. You can request strongly consistent reads that reflect all previous writes. Consolidating Kinesis streams probably won't help since Kineses producers are generally singular data sources (all stats of a specific type will come from one producer). Replacing Lambda with EC2 will have cost consequences, and in this case will probably result in an undesirable stateful architecture. Timestamp information will not resolve an eventual consistency issue.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","title":"DynamoDB Read Consistency"}],"answers":[{"id":"95bc7fe6a012dc37b025c1cb8fe566e7","text":"Replace Lambda with an EC2 instance that synchronizes reads of the data with database updates","correct":false},{"id":"c606fec0599df4127dba2d5df85a283f","text":"Store score and stat updates timestamps in the database to ensure the most recent information is served by the Lambda backend ","correct":false},{"id":"c151deab4b337fd8377eed0413d50903","text":"Consolidate the Kinesis streams into a single stream to avoid writing different results to the database","correct":false},{"id":"a8da8441084c1a5b79e47be3f6f98a0d","text":"Have the Lambda function perform a strongly consistent read from the database","correct":true}]},{"id":"2ce2d6e0-2252-424b-a96a-9035a47d0d8d","domain":"ResilientDesign","question":"You have a requirement that all objects stored in a particular bucket be copied to another region. You have enabled Cross Region Replication from the source bucket to the target bucket, but objects are not appearing in the target bucket as expected.  What are some possible reasons this could be happening?","explanation":"S3 doesn't replicate objects retroactively. S3 doesn't chain replications of CRR. S3 can't copy objects with SSE-C.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr-what-is-isnot-replicated.html","title":"What Does Amazon S3 Replicate?"}],"answers":[{"id":"ae8c36cabd222a45126c72828b824823","text":"The objects created with server-side encryption using customer-provided (SSE-C) encryption keys.","correct":true},{"id":"a5e0172eb202b849afb9d7bb30be8539","text":"The objects existed before you added the replication configuration to the source bucket.","correct":true},{"id":"f41cf0b95c577e75d1f18894d41c387a","text":"The object does not have lifecycle configuration enabled.","correct":false},{"id":"51a9e582824a1f789301122142991445","text":"The objects in the source bucket are replicas that were created by another cross-region replication.","correct":true},{"id":"61987ebda14757b2f1b5f4750a70f487","text":"The object tags in the source bucket have not been assigned.","correct":false},{"id":"d6b42f1fd5dcafc64053f48b9d85ad6d","text":"The objects in the source bucket for which the bucket owner has permissions to read objects and ACLs.","correct":false}]},{"id":"f87e20a7-e0a1-4096-a8b5-4baa66869f0a","domain":"Performant","question":"You have an RDS database that has moderate I/O requirements. Which storage medium would be best to accommodate these requirements?","explanation":"Amazon RDS General Purpose (SSD) Storage would be the most suitable. It offers cost-effective storage that is ideal for a broad range of workloads.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","title":"RDS Storage Types"}],"answers":[{"id":"140b1dc5d7fa0d7f14e67024dbc354ec","text":"Amazon RDS Elastic Storage","correct":false},{"id":"e774a96af9adfaa2402148c9828271e7","text":"Amazon RDS Magnetic Storage","correct":false},{"id":"0db6de47eed9671e44098c2117fe8916","text":"Amazon RDS Cold Storage","correct":false},{"id":"a257df0abf37db5da9b921f8222eab2a","text":"Amazon RDS General Purpose (SSD) Storage","correct":true}]},{"id":"fa1bda16-305f-4828-b6ad-7283e0871b17","domain":"ResilientDesign","question":"You manage a Ruby on Rails application that lives on a cluster of EC2 instances. Your website occasionally experiences brief, strong, and entirely unpredictable spikes in traffic that overwhelm your EC2 instance resources and freeze the application. As a result, you're losing recently submitted requests from end users. You use Auto Scaling to deploy additional resources to handle the load during spikes, but the new instances don't spin-up fast enough to prevent the existing application servers from freezing. Which of the following will provide the most cost-effective solution in preventing the loss of recently submitted requests?","explanation":"Neither increasing the size of your EC2 instances nor maintaining additional EC2 instances is cost-effective, and pre-warming an ELB signifies that these spikes in traffic are predictable. The cost-effective solution to the unpredictable spike in traffic is to use SQS to decouple the application components.","links":[{"url":"https://aws.amazon.com/sqs/details/","title":"About SQS"}],"answers":[{"id":"c0b360995bf53c751147bc20838b7649","text":"Increase the size of your existing EC2 instances.","correct":false},{"id":"6db3854f95cc6b24174021466671b1ac","text":"Ask AWS support to pre-warm the Elastic Load Balancer.","correct":false},{"id":"8369c6dde55e9f75a78d9cf464140a27","text":"Keep a large EC2 instance on standby.","correct":false},{"id":"3e72cba47f2e1a3f598502fa537cd4fd","text":"Use Amazon SQS to decouple the application components and keep the requests in queue until the extra Auto-Scaling instances are available.","correct":true}]},{"id":"eb7c5d7d-09d6-4dee-bf55-d97a53af72f2","domain":"SecureSolutions","question":"Your organisation is about to deploy a new website into their AWS environment that will publish news articles created by your content team, which will reside on the URL “www.cloud-news.com”. This website makes use of two EC2 austoscaling groups to serve content - one is for publicly accessible content and one for members-only content. An in-house developed authentication mechanism redirects users to “members.cloud-news.com” to access the members-only content. Which load balancer configuration is most appropriate for this architecture?","explanation":"The load balancer needs to be able to look at the hostname of the request and redirect it to the appropriate EC2 Autoscaling group - this requires the ability to do host-based routing, which is a feature of ALBs and is not available in NLBs. As we are routing to a different hostname, the path is irrelevant - only host-based will work, and the condition for this on an ALB is \"host-header\"","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/ ","title":"Load Balancing Features"}],"answers":[{"id":"1d8d6c68ab28d0288ad4747f3e53f1e4","text":"Use a Network Load Balancer in a public subnet, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the \"path-pattern\" condition on each listener rule to redirect users to the appropriate target group.","correct":false},{"id":"c6e704e1b985b6cd50ffe0d7750681ff","text":"Use a Network Load Balancer in a public subnet, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the \"host-header\" condition on each listener rule to redirect users to the appropriate target group.","correct":false},{"id":"9748d8cbee76d8e5ee49130319e6dabc","text":"Use an Application Load Balancer, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the “path-pattern” condition on each listener rule to redirect users to the appropriate target group.","correct":false},{"id":"512616e676f1cc76a267567948528f9e","text":"Use an Application Load Balancer, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the \"host-header\" condition on each listener rule to redirect users to the appropriate target group.","correct":true}]},{"id":"cd934b42-8753-4bfe-b53e-7e3150a52532","domain":"CostOptimized","question":"A medical laboratory is deploying an online application for customers to retrieve both current and historical test result information. The data for each test will be stored in Parquet formatted files on a single server with replication for redundancy. The application will require fast response to present the information once a user selects a specific test. Which storage architecture will provide the best performance and cost efficiency?","explanation":"Amazon EBS General Purpose SSD volumes provide substantial performance for interactive application workloads. EBS Provisioned IOPS SSD volumes provide high performance as well, but at a higher cost. Amazon S3 is not a good architectural choice for transactional workloads, and Amazon EFS is not required since the application will run on a single server.","links":[{"url":"https://aws.amazon.com/ebs/features/","title":"Amazon EBS Features"}],"answers":[{"id":"9c60fc99b53c9ed52adb77523afa1026","text":"Amazon Elastic Block Store with Provisioned IOPS SSD Drives","correct":false},{"id":"56339fcc83f54c52fb7a1b84d3841507","text":"Amazon Simple Storage Service with Transfer Acceleration","correct":false},{"id":"e32a986c4040754d7c67f2974e1bf240","text":"Amazon Elastic Block Store with General Purpose SSD drives","correct":true},{"id":"d41d58ba72de81bfae50c0582edb34d0","text":"Amazon Elastic File System with NFS mounts","correct":false}]},{"id":"f354dcdd-8250-4f18-a666-c1da3a174154","domain":"ResilientDesign","question":"You are configuring your application load balancer to enable users to access your application, which is in a staging environment and only has a private IP address. Which of the following schemes will enable this type of access?","explanation":"When configuring load balancers, you get two scheme choices, which are internet-facing and internal. If the users were to access the application through the Internet, then internet-facing would be the correct answer. Internal load balancing is right in this instance because the internal scheme choice will create an internal load balancer for routing requests from the users to the application with the private IP address.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-internal-load-balancers.html","title":"Internal Classic Load Balancers"}],"answers":[{"id":"e82fcc3d0c37dcaf93bb7b620da3c563","text":"Internet-facing","correct":false},{"id":"b206a1b4ea1097761f78e8876f6da779","text":"External","correct":false},{"id":"afbf0897a5a83fdd873dfb032ec695d3","text":"Internal","correct":true},{"id":"ef85538ce0d687a7f414634e39f842dc","text":"User-facing","correct":false}]},{"id":"bce7cb5d-687e-4e77-a516-1cde22e6f4e8","domain":"Performant","question":"How quickly can objects be restored from Glacier?","explanation":"You can expect most restore jobs initiated via the Amazon S3 APIs or Management Console to complete in 3-5 hours. Expedited restore is available at a price. ","links":[{"url":"https://aws.amazon.com/glacier/faqs/#dataretrievals","title":"Retrieving Data From Glacier"}],"answers":[{"id":"6619a70f8ab8877e4131643fb8ded723","text":"2 hours","correct":false},{"id":"72ab9d0304d3e84c6aa2dd15eda282f2","text":"1 hour","correct":false},{"id":"0d714869027c4e08ea9b2943d9bd704e","text":"30 minutes","correct":false},{"id":"99d888e6893ac480abd21ecb8a18e060","text":"3-5 hours","correct":true}]},{"id":"c487c002-443f-4d86-bdde-a915adb7924d","domain":"ResilientDesign","question":"You have chosen to use S3 - OneZone-IA with your cloud application. Which limitations have you considered in doing so?","explanation":"In exchange for a significant cost savings, 1Zone-IA has the same Durability as S3, but a lower Availability SLA.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/?nc=sn&loc=3","title":"S3 Storage Classes"}],"answers":[{"id":"3ffe3458e13ccc426e49a1893b78a3f3","text":"1Zone-IA has a 3 - 5 hour data recovery windows.","correct":false},{"id":"e0a1c69e07da2a370da0dedf28084491","text":"1Zone-IA offers only 99.50% durability. Therefore you have to design your application to re-create any objects that may be lost.","correct":false},{"id":"bcddbe2d89ec46d45172296d890040c3","text":"1Zone-IA is available only in the US-STANDARD region.","correct":false},{"id":"4068f35933f215b2818a03234567736a","text":"1Zone-IA requires supplementary Access Control Lists.","correct":false},{"id":"a86f1cf2d99a9643587b837f464b5ef8","text":"1Zone-IA offers only 99.50% availability. Therefore you have to design your application to re-create any objects that may be temporally unavailable.","correct":true}]},{"id":"18196faa-35f6-4a0b-b91b-c62326bbd9bf","domain":"CostOptimized","question":"A team is designing the architecture for a new application with full CI/CD testing.  They want to implement feature branch testing based on pull requests to master.  A Pull Request should cause a full deployment to be run on that feature branch being pulled so that a tester can run through functional tests.  What would you recommend the team does to automate this process at the lowest cost?","explanation":"CloudFormation allows AWS to automatically deploy the infrastructure required to deploy the application for testing.  The infrastructure code can be stored alongside application code to allow the application to be deployed in a fully-isolated infrastructure which can be destroyed once integration testing is complete.  CloudWatch Events (and not CloudTrail) enables pull request events to trigger a deployment.  Finally Amazon EC2 Spot Fleet allow us to deploy a set of EC2 instances at the lowest cost. Reserved Instances are better-suited to pre-purchasing compute capacity which you will use for a fixed period of time - it is not cost-effective to pre-purchase EC2 capacity just to perform integration testing.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html","title":"How Spot Fleet Works"},{"url":"https://ec2spotworkshops.com/amazon-ec2-spot-cicd-workshop.html","title":"CI/CD and Test Workloads with EC2 Spot Instances"}],"answers":[{"id":"254cbe0fa6a5e0b25dd7841402f05e7e","text":"Use Amazon EC2 Spot Fleet and Amazon CloudFormation to deploy an integration testing environment at lowest cost","correct":true},{"id":"e4f3730b2899903ad8a6c27eb2693ff2","text":"Configure CloudWatch Events to trigger a deployment based on pull requests","correct":true},{"id":"cb82b20f57a6882ec563593d14dfb01b","text":"Configure AWS CloudTrail to log pull request events and trigger a deployment","correct":false},{"id":"9d9cce9ec8f58e568222274098cf9b08","text":"Use Amazon EC2 Reserved Instance and Amazon CloudFormation to deploy a testing environment at lowest cost","correct":false}]},{"id":"f11b087b-c82c-479f-aae3-d8937d5b3dee","domain":"ResilientDesign","question":"Following an acquisition, a company on-boarded a large number of IAM users into their account. What service will allow the account administrator to check if the company is approaching allowed IAM user service limit?","explanation":"AWS Trusted Advisor provides a service limits recommendation category that performs checks for service usage limits. Number of IAM users is one of the service limit checks performed by AWS Trusted Advisor.","links":[{"url":"https://aws.amazon.com/premiumsupport/technology/trusted-advisor/best-practice-checklist/","title":"AWS Trusted Advisor Best Practice Checks"}],"answers":[{"id":"113b1ad9ce6cdc3a37ad8475bc9bb2b2","text":"AWS Systems Manager","correct":false},{"id":"526775c1622cd0e7b703eb8d4a83d657","text":"AWS Service Catalog","correct":false},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":true},{"id":"d189bb1b260dc3da48b6e6f5e1ec6879","text":"AWS Personal Health Dashboard","correct":false},{"id":"85c0418befdeed397590cda97cf6d876","text":"AWS Managed Services","correct":false}]},{"id":"6853a0e8-ce9d-4d37-a7af-b235c0d5fc05","domain":"SecureSolutions","question":"To establish a successful site-to-site VPN connection from your on-premise network to an AWS Virtual Private Cloud, which of the following must be configured?","explanation":"You must have a VPC with Hardware VPN Access, an on-premise Customer Gateway, and a Virtual Private Gateway to make the VPN connection work.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/NetworkAdminGuide/Introduction.html#Summary","title":"Setting Up a VPN Connection"}],"answers":[{"id":"ade419f8f6139a9769e4b0131d39f641","text":"A Virtual Private Gateway","correct":true},{"id":"de8b5ba929b3369272eb1146eb6f3f64","text":"A VPC with Hardware VPN Access","correct":true},{"id":"d776301586e8b5388ed61cd90c180467","text":"A NAT instance","correct":false},{"id":"e04ddd768294b403207504bfa9eb006c","text":"A private subnet in your VPC","correct":false},{"id":"3d989f6e836bff71e5a2d4a288d70000","text":"An on-premise Customer Gateway","correct":true}]},{"id":"8c9f0c40-1d4b-4d37-a24a-9996d90c99c9","domain":"Performant","question":"You want to contact AWS Technical Support regarding ensuring enough capacity to autoscale for busy periods.  You remember that you have a Basic Support plan. Which of the following case types can you open with this support plan?","explanation":"There are three types of AWS Support cases you can open; they are Account and Billing Support, Service Limit Increase, and Technical Support. Customer Service does not exist as a case type, which eliminates 'Customer Service'. With the Basic plan, you can open either an Account and Billing Support or a Service Limit Increase case. To open a Technical Support case, you will need to get a Developer, Business, or Enterprise plan. So, 'Technical Support' is the wrong response; 'Account and Billing Support' and 'Service Limit Increase' are correct.","links":[{"url":"https://docs.aws.amazon.com/awssupport/latest/user/getting-started.html","title":"Features of AWS Support Plans"}],"answers":[{"id":"d073dd2e04eae29e3dd076f213f01fe3","text":"Service Limit Increase","correct":true},{"id":"d5552e0564007d93ff5937a9cb3bc491","text":"Customer Service","correct":false},{"id":"fec5f90e9985e1f7b8cc6752739ce9b1","text":"Technical Support","correct":false},{"id":"88d14dddd26c18290989cf3ac6ef6141","text":"Account and Billing Support","correct":true}]},{"id":"2a2db64e-2e02-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You wish to set up a WordPress website consisting of 4 webpages for your client, who recently founded a logo creation business. Based on the client’s specifications, you will create one webpage that gives a summary of the company and its services, a second one that provides a brief professional biography of the founder, a third one that showcases the business owner’s portfolio, and a fourth one that serves as the contact information page and simply contains an email and phone number. Three of the four webpages will include images which the client doesn’t expect will change much, if at all. Using the EC2 service to set up the website, which of the following instance types would be the most cost-effective choice?","explanation":"Based on the client’s specifications, it doesn’t seem like this website requires an elevated level of compute, memory, storage, or networking power. So, a general purpose instance would be the most cost-effective choice.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types"}],"answers":[{"id":"4e8e31d149d66214d0c06fd9ee8b877b","text":"Compute optimized","correct":false},{"id":"a97bdc2a34beb1500a16c5a5f41d3234","text":"Memory optimized","correct":false},{"id":"e65781ecdb4e2c3e7af2864d7b875e57","text":"Accelerated computing","correct":false},{"id":"3da02f3f7a678b5e2c167fb35dcea8f5","text":"General purpose","correct":true},{"id":"b4820282379b9534539d339e1d898f2b","text":"Storage optimized","correct":false}]},{"id":"6e46373a-f81d-4469-8ad0-7251ab8aedc8","domain":"Performant","question":"You have an active NoSQL database which is hosted in DynamoDB. The DynamoDB table is queried by a Lambda function which is responding to requests made by individual users via API-Gateway. Your application peaks at 4pm each day with literally 100,000’s of requests per second. During this time your application becomes sluggish. Which step below may help to improve your applications performance.","explanation":"DAX is an obvious solution if the queries are hitting the same data frequently and the total set of re-read data does not exceed the size of the DAX. Re platforming is possible but will add complication. The Aurora answer refers to the 'cluster endpoint'. This would focus all traffic on the single Write node not the multiple Read replicas.","links":[{"url":"https://aws.amazon.com/dynamodb/dax/","title":"DynamoDB Accelerator (DAX)"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Overview.Endpoints.Types","title":"Types of Aurora Endpoints"}],"answers":[{"id":"8b119eee795f3c32a2d1f9ebff37bae9","text":"Host the web front end on S3 using static website hosting. Use a combination of CloudFront and Elasticache to help distribute the load.","correct":false},{"id":"8966ac7acedbe0ee7b1f05790a1cf747","text":"Enable DynamoDB Accelerator to deliver an in memory cache to increase performance.","correct":true},{"id":"cfa63e0907a36062a7762af5c7808fb7","text":"Migrate the database from DynamoDB to Amazon Aurora and provision 15 read replicas. Update the application to send all read traffic to the cluster endpoint.","correct":false},{"id":"5b96dd7f94ff3a1e6a339b7d4bfc8322","text":"Re-architect the application to use a Network Load Balancer and a 3 EC2 instances in 3 different Availability Zones.","correct":false}]}]}}}}
