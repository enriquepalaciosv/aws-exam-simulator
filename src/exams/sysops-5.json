{"data":{"createNewExamAttempt":{"attempt":{"id":"1aacfea4-5584-488a-8b92-2661b3446966"},"exam":{"id":"afe7badc-9a8b-4e47-9b84-3e27b15fb639","title":"AWS Certified SysOps Administrator - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"7a7b01a3-cf61-4bbc-89f5-99065fc48b61","domain":"dep-prov","question":"Which of the following might help resolve an InsufficientInstanceCapacity error when launching an instance?","explanation":"If you get an InsufficientInstanceCapacity error when you try to launch an instance or restart a stopped instance, AWS does not currently have enough available On-Demand capacity to service your request. To resolve the issue, you can: wait a few minutes and then submit a launch request again; submit a new launch request without specifying an Availability Zone; or submit a new launch request using a different instance type. Requesting an instance limit increase will help with resolving an InstanceLimitExceeded error but will not help with an InsufficientInstanceCapacity error. Requesting an increase to an Amazon EBS volume limit will help with a VolumeLimitExceeded error but will not help with an InsufficientInstanceCapacity error.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity","title":"Troubleshooting Instance Launch Issues"}],"answers":[{"id":"c7a40da6d0e8fc9e5508f87e2279a25a","text":"Request an instance limit increase on a per-region basis","correct":false},{"id":"07c7108aae2d4850d8cd2e2e92a24cad","text":"Wait a few minutes and then submit a launch request again","correct":true},{"id":"6466bc1f56521a662522f33ad6f71f30","text":"Request an increase to the Amazon EBS volume limit","correct":false},{"id":"154758dad301ec2c98aa017346291b16","text":"Submit a new launch request using a different instance type","correct":true},{"id":"8ed67781418ab44be37b294251671f76","text":"Submit a new launch request without specifying an Availability Zone","correct":true}]},{"id":"113a7914-1249-4e12-a748-03392c0570e8","domain":"high-avail","question":"You are a Security Administrator for your company. Your CIO wants to ensure that company data is highly available in multiple AWS Regions. What would you suggest to your CIO as the most effective approach?","explanation":"Deploying a multi-AZ RDS instance would only make it fault tolerant between Availability Zones, and not AWS Regions. Creating a Lambda function and creating/deploying EBS snapshots into different AWS Regions would both be an administrative and operational burden. The easiest, most effective, way is to utilize S3 Cross Region Replication","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 Cross Region Replication"}],"answers":[{"id":"fbde7989c5f0da5bb91bb5593f9c8e4e","text":"Create a Lambda function that downloads data from your S3 Bucket and executes a PUT operation to upload copied objects into a new bucket in a new Region.","correct":false},{"id":"a4ca2ada50730e36dd0f3302f60ab0dc","text":"Create multiple snapshots of your company data on EBS volumes. Deploy those EBS volumes on EC2 instance in different AWS Regions.","correct":false},{"id":"6e22da724261694b4ecf8fa105ef5174","text":"Enable Cross-Region Replication on your bucket to copy objects to a destination bucket in another AWS Region.","correct":true},{"id":"f876473fb6289d5a1e3e6d449713b0e7","text":"Copy the company data to an RDS instance. Deploy a multi-AZ configuration for your RDS instance to make it highly available.","correct":false}]},{"id":"582d1290-8099-4ef5-8f80-ea6043cc32d7","domain":"security-comp","question":"You are a Sys Ops Administrator for your organization. During a routine security audit, you discovered several vulnerabilities in the operating systems of your EC2 fleet. Your EC2 fleet consists of over 250 instances. How would you resolve the security issues within your EC2 fleet in the most effective manner?","explanation":"AWS Systems Manager Patch Manager automates the process of patching managed instances with both security related and other types of updates. You can use Patch Manager to apply patches for both operating systems and applications. Amazon GuardDuty is a security monitoring service that analyzes VPC Flow Logs, CloudTrail Events, and DNS logs. It would not be effective in applying patches to EC2. Amazon Inspector could help identify EC2 with security vulnerabilities, but the findings generated by Amazon Inspector depend on your choice of rules packages included in each assessment template, the presence of non-AWS components in your system, and other factors. You are responsible for the security of applications, processes, and tools that run on AWS services. Similar to Amazon Inspector, AWS Config would not help in applying patches to your entire fleet.","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-patch.html","title":"Systems Manager"}],"answers":[{"id":"b966c9e66f79563a38283cf5493db53e","text":"Use AWS Config to identify the EC2 instances with vulnerabilities based on security rules. Isolate these instances and install the patch updates to fix the vulnerabilities.","correct":false},{"id":"6256bbd45632da9b813aac4c9411f564","text":"Have Amazon Inspector assess the instances and send metric data to CloudWatch. Set up a CloudWatch Event to trigger a Lambda function that will install the patch to instances with the vulnerability.","correct":false},{"id":"20ebac0f0e1509a9f9b321e86861fdff","text":"Deploy Amazon GuardDuty which will create a unique finding ID for each vulnerability in CloudWatch. Automate security patch updates with Lambda to the instances that are associated with a GuardDuty finding ID.","correct":false},{"id":"2161bb4bdfc887d3c242cee80467ae30","text":"Deploy the security patch using RunCommand with AWS Systems Manager for the entire fleet of EC2 instances.","correct":true}]},{"id":"afb14785-ba2f-4fea-b819-21804b895752","domain":"mon-rep","question":"You use the CloudWatch Agent to collect system-level metrics in an EC2 instance and send them to AWS CloudWatch. Then you create a CloudWatch alarm based on the mem_available metric. The alarm status is OK for some time but it suddenly becomes “Insufficient data”. The EC2 instance is still up and running. Its status checks also pass. How would you resolve the problem?","explanation":"The CloudWatch agent is responsible for transmitting metrics data to CloudWatch. If the agent is not running properly, CloudWatch will not receive the metrics and the alarm will become \"Insufficient data\". You should check the running status of the CloudWatch agent process. Adjusting alarm threshold does not help as the CloudWatch alarm still does not receive data from the agent.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html","title":"Amazon CloudWatch Alarms"}],"answers":[{"id":"00e24de8460e88befdad35029ca80303","text":"Adjust the defined threshold of the alarm. The threshold may be too high for the reported data.","correct":false},{"id":"86fa960aa5069a37c3dec9725cba235a","text":"Create an image for the EC2 instance and launch a new EC2 instance using the AMI. Terminate the original instance.","correct":false},{"id":"d6dcf40b4663a8af0717c19f3c8c3c6e","text":"Delete the CloudWatch alarm and recreate a new one as the connection may get hung.","correct":false},{"id":"f116df32e8b60a8f3d2d7c1d5d4182eb","text":"Check if the CloudWatch agent is running properly. Restart the process if it is not running.","correct":true}]},{"id":"a8d6d4f3-6877-4e89-9e7c-c6f83b83e1de","domain":"automation","question":"A small business has a monolithic application utilizing several EC2 instances. The technology consultant has suggested to the engineering team of the business that the application is containerized to improve the deployment and scaling processes of the team. The engineering team processes both critical and non-critical workloads within the application. Given the size of the application and the number of transactions being processed by the system, the CFO has instructed the engineering team to ensure that the setup must be as cost-effective as possible without introducing the risk of data loss for critical workloads. How can the engineering team accomplish this?","explanation":"On-demand EC2 instances should be used for critical workloads and spot instances can be used for non-critical workloads. ECR (Elastic Container Registry) is not used to run container processes. Instead, it is used to store container images. For containerization requirements, ECS (Elastic Container Service) is used to manage container workloads. Step Functions is used for orchestrating different processes and can not be used by itself to manage the workloads.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-high-scale-web-on-spot-instances/","title":"Running High-Scale Web Applications on Spot Instances"}],"answers":[{"id":"1d3682fdb0beec13b13a37502cfb3108","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use Step Functions and on-demand EC2 instances for non-critical workloads.","correct":false},{"id":"b8864524b96a467a8f1023b5a2c9f003","text":"Use Step Functions and on-demand EC2 instances for the critical workloads. Use Step Functions and spot EC2 instances for non-critical workloads.","correct":false},{"id":"47e42a6e665f0a913236e5580553e3ad","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECS and spot EC2 instances for non-critical workloads.","correct":true},{"id":"ddf2c2e29f2118061f6a160054593338","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECR and spot EC2 instances for non-critical workloads.","correct":false}]},{"id":"900f9fd7-73bb-4c66-a64f-66d0c4d363a9","domain":"mon-rep","question":"A medical technology startup is experiencing tremendous growth in their business. As a result, the demand for AWS infrastructure for their applications is increasing dramatically each week. They've exhausted a number of AWS service limits in the past, resulting in customer experience issues. They'd like to be more proactive in requesting limit increases before problems arise. What would be the best way to monitor their service limit posture to be able to avoid potential service limit issues in the future?","explanation":"Creating a Lambda function to refresh Trusted Advisor service Limit checks gives you control over how often you'd like to test for increasing usage thresholds. CloudWatch Events will capture status events from Trusted Advisor for alerting through SNS. AWS Service Quotas allows you to view and manage your service limits from a central location, but it requires creation of CloudWatch Alarms for alerting. AWS Systems Manager does not monitor service quotas. AWS Trusted Advisor requires Amazon CloudWatch Events rules to relay service limit statuses to SQS. Any notification solution can be utilized for alerting (SNS, SQS, Slack, etc.)","links":[{"url":"https://aws.amazon.com/solutions/limit-monitor/?did=sl_card&trk=sl_card","title":"AWS Limit Monitor"},{"url":"https://docs.aws.amazon.com/servicequotas/latest/userguide/intro.html","title":"What Is Service Quotas"}],"answers":[{"id":"a3e54b0eba982df36f58025b0255a252","text":"Use AWS Service Quotas to generate alarms when service limit usage reaches a desired threshold. Forward these alarms to a Lambda Slack Notifier function to write the alerts to a Slack channel","correct":false},{"id":"4a85b8ab34b877cb3e2b1e66c551633a","text":"Configure AWS Systems Manager with desired thresholds for service limit usage alerts. Create Amazon CloudWatch Events rules to trigger a Lambda Slack Notifier function that writes alerts to a Slack channel","correct":false},{"id":"621515daca03b3a42e964175ceb4cb55","text":"Regularly invoke a Lambda function to refresh AWS Trusted Advisor Service Limit checks. Create Amazon CloudWatch Events rules to send status events to an Amazon Simple Notification Service topic when individual service limit usages reach desired thresholds","correct":true},{"id":"e4bca64a87a0aa8a60cf82026592f852","text":"Configure AWS Trusted Advisor to forward service limit statuses (OK, WARN, and ERROR) to an Amazon Simple Queue Service queue. Have a Lambda function trigger when a message is written to the queue, and publish WARN and ERROR statuses to an Amazon Simple Notification Service topic","correct":false}]},{"id":"bd76b805-8568-4083-a962-3eebb610d4fc","domain":"dep-prov","question":"You've been given the responsibility for creating an automated deployment approach to provision EC2 instances for every application in your department's portfolio. Each application requires a different set of software libraries, and all EC2 instances are members of Auto Scaling Groups. Deployments must complete within a limited time window as part of the department's overall DevOps strategy, and AWS CloudFormation will be used for infrastructure-as-code. Which architecture will provide for the fastest deployments in the most operationally efficient manner?","explanation":"Creating an AMI at the time of CloudFormation stack creation or update helps to ensure that the latest binaries are included in an Auto Scaling Launch Configuration while avoiding potentially long waits for Auto Scaling instances to be provisioned. Bootstrapping software downloads during Auto Scaling instance launch will potentially result in long wait times. Using CloudFormation metadata to indicate which software binaries need to be used in Auto Scaling Launch Configurations is not supported functionality. Not automatically keeping the AMIs up to date means that a significant level of effort will be needed to keep AMIs current with new software releases in each EC2 instance configuration.","links":[{"url":"https://aws.amazon.com/blogs/infrastructure-and-automation/enable-fast-bootstrapping-of-your-auto-scaled-instances-using-dynamically-created-images/","title":"Speed up instance bootstrapping by using dynamically created images"}],"answers":[{"id":"02bf56251e14a50de6e835ecd38ab66a","text":"Create complete Amazon Machine Images for each application's EC2 configuration. Configure a CloudFormation Stack for each application that creates Auto Scaling Groups for each instances corresponding AMI","correct":false},{"id":"df623f37652f3a2b4441a7c1de625ab8","text":"Create base Amazon Machine Images for each application's EC2 configuration. Use CloudFormation to specify that the Auto Scaling Launch Configuration use the base AMIs, and use CloudFormation metadata to indicate which software binaries need to be used in Auto Scaling Launch Configurations during CloudFormation stack creations and updates","correct":false},{"id":"d53fd253be12fb9ac6c1f9d04b0590f3","text":"Create base Amazon Machine Images for each application's EC2 configuration. Use CloudFormation to specify that the Auto Scaling Launch Configuration use the base AMIs, and bootstrap software downloads from public sources for each application at the time of instance launch","correct":false},{"id":"ff704c3738fe0246d98c17f8a497e999","text":"Create an EC2 instance for each application's full software configuration. For each application, have CloudFormation invoke an AWS Lambda function that creates an Amazon Machine Image for the EC2 instance. Include the AMI in the Auto Scaling Group Launch Configuration specified by CloudFormation","correct":true}]},{"id":"daf6b2b4-fed3-47fd-a6c8-7fce838a6543","domain":"security-comp","question":"What is the name of the API call used to request temporary security credentials from the AWS platform when federating with Active Directory?","explanation":"AssumeRoleWithSAML provides a set of temporary security credentials for users who have been authenticated via a SAML authentication response.","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithSAML.html","title":"AssumeRoleWithSAML"}],"answers":[{"id":"9c7a6a871dd64a673837a44ccfdecf49","text":"ShowMeTheSAML","correct":false},{"id":"d6db28cc32e24b1d1c39831f43e5d8b8","text":"GetSAMLRole","correct":false},{"id":"92379b50a98b2cd0366ee58621f3d4a4","text":"CovertRoleToSAML","correct":false},{"id":"e19dc096230f8dc3a7e2b56f94d309a2","text":"AssumeRoleWithSAML","correct":true}]},{"id":"f0c47538-7997-40fc-9c82-27eea818fac2","domain":"security-comp","question":"A company has started running its e-commerce application in container workloads in AWS. The e-commerce application is running its web tier in Amazon ECS and the database tier in RDS all inside a VPC. Under the AWS shared responsibility model, which activities is AWS NOT responsible for?","explanation":"AWS takes care of the underlying software for managed services. For services such as EC2, the instance hypervisor and underlying hardware are managed and maintained by AWS. It is the customer's responsibility to monitor and manage the memory utilization of the containers in services such as ECS and EKS.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"9abfc73643ea9090379aae3cd89400d1","text":"Patching the instance hypervisor","correct":false},{"id":"1dfb8644f2cce2dca687a152b45b7d54","text":"Patching the database instance software of RDS","correct":false},{"id":"ac7ca331a57c32d9975616bf91327c82","text":"Monitoring and managing the memory utilization of the containers","correct":true},{"id":"b7a8057898c923210f320a3bcccbcbca","text":"Maintaining the underlying hardware infrastructure of the instances used by ECS","correct":false}]},{"id":"f8749352-7a95-4aaf-a1a7-70de2f8facf0","domain":"dep-prov","question":"A development team deploy a new application in AWS EC2 using an Auto Scaling Group. In the ASG, they want to use a mix of On-Demand and Spot instances. There should be at least two On-Demand instances and for the others, the percentage of Spot instances is 50%. They also need to configure the maximum price for the Spot instances. What is the best method to achieve this requirement?","explanation":"Launch Template can help configure the instances distribution strategy when an ASG is launched. The strategy includes Optional On-Demand Base, On-Demand Percentage Above Base, etc. Launch Configuration does not allow configuring this. Besides, Launch Configuration is not able to be modified after being created.","links":[{"url":"https://aws.amazon.com/blogs/aws/new-ec2-auto-scaling-groups-with-multiple-instance-types-purchase-options/?&trk=ha_a131L000005uJTZQA2&trkCampaign=pac-edm-2019-spot-sitemerch-autoscalingblog&sc_ichannel=ha&sc_icampaign=Adoption_Campaign_pac-edm-2019-spot-site_merch-adoption-all-auto_scaling_console_test&sc_ioutcome=Enterprise_Digital_Marketing","title":"EC2 Auto Scaling Groups With multiple instance types & purchase options"}],"answers":[{"id":"020bbb4cf8305f987526000924d942b4","text":"Use a Launch Configuration to launch an ASG. When the instances distribution strategy needs to be modified, copy the Launch Configuration and create a new one. Use it to relaunch a new ASG.","correct":false},{"id":"47afae7bf180988889ad1a5ed004bb79","text":"Launch an ASG using a Launch Configuration that contains a default instances distribution strategy. Modify the Launch Configuration if the strategy needs to be adjusted.","correct":false},{"id":"289591ad3dd2996c30ad5d609b122afa","text":"Create a Launch Template and use it to launch an Auto Scaling Group. Configure the instances distribution strategies such as the maximum Spot price and percentage.","correct":true},{"id":"29c62395907be45de54c51d312876036","text":"Create a Launch Configuration and configure how the instances are distributed between On-Demand and Spot instances. Launch an ASG with the Launch Configuration.","correct":false}]},{"id":"8c1dec5f-627d-4f25-af24-119b092ca2ef","domain":"high-avail","question":"A client asks you how they can make their current database running on AWS highly available. The client is running a MySQL RDS database in us-west-1. The client does not currently have a Multi-AZ deployment. The client wants to know what the benefits are with a Multi-AZ deployment as it would incur additional costs to their AWS bill. How would you explain the benefits to the customer?","explanation":"Amazon RDS Multi-AZ deployments provide enhanced availability and durability for databases. When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone. In case of an infrastructure failure, Amazon RDS performs an automatic failover to the standby. It does not lower latencies nor does it increase read performance. It cannot tolerate the failure of a single AWS Region as failure of a Region would implicate failure of all the Availability Zones within that Region.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"Amazon RDS Multi-AZ Deployments"}],"answers":[{"id":"6772f4dc3173a8dd298656b65d2b6efa","text":"Multi-AZ makes it faster for application servers to access the database by reading data at a quicker rate.","correct":false},{"id":"4983004598ef3be1bb46819c748a09ab","text":"Multi-AZ tolerates the failure of a single Availability Zone. It also allows higher availability during maintenance tasks.","correct":true},{"id":"aa4c2ced080ae70c33f36fe825b972ce","text":"Multi-AZ lowers latencies for application servers when they are accessing the database in multiple Availability Zones.","correct":false},{"id":"834345e14f96992b8d4b2e785595f697","text":"Multi-AZ tolerates the failure of a single Region. It also allows higher availability during maintenance tasks.","correct":false}]},{"id":"11a06ef4-bb74-456d-ba26-e7852eba3c7e","domain":"mon-rep","question":"A custom web application has been deployed to AWS.  The development team want to know when a specific .NET counter hits a threshold. Which service allows this?","explanation":"Custom operating system metrics can be pushed to AWS by using CloudWatch Custom Metrics. CloudWatch events refer to events around AWS resources but not within an EC2 instance.  X-Ray allows transaction tracing throughout applications but would not push .NET metrics to AWS.","links":[{"url":"https://aws.amazon.com/blogs/mt/query-for-the-latest-windows-ami-using-systems-manager-parameter-store/","title":"Query for the Latest Windows AMI using Systems Manager Parameter Store"}],"answers":[{"id":"957649c9aaeda66468ced97b30d4ce29","text":"CloudWatch Events and Alarms","correct":false},{"id":"9d53eb372c233c0124733016585613fc","text":"CloudWatch custom metrics and Alarms","correct":true},{"id":"0c810b936071c67e7bc9845d93416bc2","text":"AWS X-Ray and Alarms","correct":false},{"id":"ce8086df6e4acbf892ecfe8075412a33","text":"AWS CloudWatch Insights and Alarms","correct":false}]},{"id":"1a37a76e-3c69-4ae6-8ae3-5b0db850807c","domain":"mon-rep","question":"You need to monitor memory utilization of an EC2 instance. How could you achieve this?","explanation":"Monitoring memory utilization requires the installation of the CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html","title":"Collecting Metrics and Logs from Amazon EC2 Instances and On-Premises Servers with the CloudWatch Agent"}],"answers":[{"id":"c5d4aec73235f6dc0fda6738ef7c93f9","text":"Install CloudWatch Agent on the instance and have it collect memory utilization metrics.","correct":true},{"id":"8b901f2e0a6136525aaf5ffcb881b223","text":"EC2 instance memory utilization is monitored by default.","correct":false},{"id":"30041d2fc11ea9b43497c2fe847b6461","text":"From the EC2 console, enable memory ulitization metric for the instance.","correct":false},{"id":"e1771db5f560892163019427b6f3742c","text":"From the CloudWatch console, enable memory ulitization metric for the instance.","correct":false}]},{"id":"a73df876-d426-4e85-8387-ebcb549a678c","domain":"dep-prov","question":"To register targets and correctly route requests, the Application Load Balancer's listeners need a rule that specifies a ________ .","explanation":"You register targets with a target group. To route requests to the targets in a target group, specify the target group in a rule for one of the listeners for your load balancer.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-target-group.html","title":"Creating a Target Group"}],"answers":[{"id":"1f6a4e9b062bf087b6ef57465c893d58","text":"Target Group","correct":true},{"id":"b682dc481b1877dbaaec615eaed0b7d8","text":"Target Type","correct":false},{"id":"e91131f524dfb0d7ef8c247be493d660","text":"Registered Target","correct":false},{"id":"67f9cd8e61172174cf748a9b4c4c64f3","text":"Routing Configuration","correct":false}]},{"id":"27109f2b-2906-43cb-90b4-3e2bcfad7ab8","domain":"high-avail","question":"You are a consultant working for a global company. They are hosting their companies CRM web application on-premise across servers in three different countries. Amazon Route 53 is being used as their DNS Provider. When the servers in one of the countries goes down, traffic starts to drop instead of being redirected to the two working sites. Corporate policies prohibit client data being stored or transferred through a Public Cloud Provider. What would the simplest solution be to their issue?","explanation":"Multivalue Answer Routing will perform simple health checks on IP addresses before sending traffic to them. This has advantages over a simple routing, where an outage of one of the IP Addresses would result in failures to connect. Corporate policies prohibit in this scenario the storage or transfer of client data from the CRM through a Public Cloud Provider. This effectively rules out the migration to EC2, or the use of CloudFront as a CDN. Transferring DNS to an on-premise service may allow for more flexibility and abilities to write special health checks, but it would certainly not be the most simple option","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Amazon Route 53 Routing Policies"}],"answers":[{"id":"dcfd51b6eec1175ce379fb23d19ec48f","text":"Transfer their DNS Zone to on-premise DNS servers to allow administrators more power to respond to outages","correct":false},{"id":"bad6a2c2cd6a244c640ffb67243421bd","text":"Migrate the servers to EC2 in three different regions to prevent outages in local datacentres","correct":false},{"id":"abb8f1f2096c4f271cf6c11ab4be0ab4","text":"Implement CloudFront as a CDN for their website, ensuring global fault tolerance","correct":false},{"id":"1ed8875652253a24ebf466592454a1be","text":"Use a Multivalue Answer Routing Policy on their Route 53, including the Health Checks to detect outages","correct":true}]},{"id":"46d872a7-bf30-4880-9cbd-3a63c50fb75e","domain":"mon-rep","question":"You need to enable a CloudWatch alarm to alert you if an EC2 instance which holds a key customers database goes over 100% CPU Utilization for more than two minutes. Which service should you use?","explanation":"Detailed Monitoring collects data at 1 minute intervals, whereas Basic or Standard Monitoring is every 5 minutes. Artifact allows you to check which industry and regulatory compliance standards AWS adheres to.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html","title":"CloudWatch Detailed Monitoring"}],"answers":[{"id":"3d3e141cae28c035547bafe32dea1423","text":"CloudTrail Expedite","correct":false},{"id":"60b018772cea138af5a8c452ed694734","text":"AWS Artifact","correct":false},{"id":"af64135daff929ae7e26207cfae5e24a","text":"CloudWatch Standard Monitoring","correct":false},{"id":"96778f7d823daef4c612d60aa5bf2312","text":" CloudWatch Detailed Monitoring","correct":true}]},{"id":"217a427c-502e-401f-b0e1-9a1794748dd2","domain":"dep-prov","question":"You have designed your corporate AWS infrastructure so that all applications will reside in private subnets to reduce the chance of unauthorised attack from the Internet. However, you have been reminded that some people may need SSH access to these applications from the Internet, under certain circumstances.  You decide to install a Bastion Host in a public subnet to allow SSH access through to the applications for these people.  Which of the following options can be used to reduce the chance of the Bastion Host being compromised?","explanation":"Firstly, let us discount building from a Bastion AMI as this doesn't exist and we can also remove options that include logging, because although they are useful to find who attempted access, they don't reduce the chance of attack.  Implementing any or all of the remaining options will add to the \"strength in depth\" philosophy and could prevent the Bastion Host being compromised.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/linux-bastion/architecture.html","title":"Linux Bastion Hosts on the AWS Cloud"}],"answers":[{"id":"205062c31d482ee937ff645c845dba33","text":"Build the Bastion Host from the AWS Bastion AMI","correct":false},{"id":"bac7e3fe44c6180ec86d68334b027d40","text":"Allow only TCP port 22 from 0.0.0.0/0 in the Security Group","correct":true},{"id":"f16e7d50eb7d520eb2104bb73820ae91","text":"Install Fail2Ban on the Bastion Host","correct":true},{"id":"ea54b90fc7659554d53c42962e2b83a5","text":"Log all SSH access attempts","correct":false},{"id":"e4baede75c62ff192032aa1048885c6c","text":"Remove all packages that are not used","correct":true}]},{"id":"095bed19-081d-4865-acff-d6f9bc29eb7c","domain":"automation","question":"Which of the following is the only required component of a CloudFormation template?","explanation":"As the primary purpose of CloudFormation is to create a collection of related AWS resources, the Resources section is the only required section of a CloudFormation template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"}],"answers":[{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false},{"id":"7df96b18c230f90ada0a9e2307226338","text":"Templates","correct":false},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true}]},{"id":"4871ce12-9da0-4e28-b1e4-373560dbdffa","domain":"automation","question":"A telecommunications company sends out monthly bills to their customers. Usage is accumulated during the month by nightly batch jobs that process call details. The company is in the process of migrating the billing system to AWS to reduce costs. What approach will provide them with the most cost effective solution for the compute portion of their nightly batch runs?","explanation":"AWS Batch provides allocation strategies to consider capacity and throughput in addition to cost when provisioning instances for jobs. This is a newer feature that provides more flexibility than the previous scheme that chose an instance that was the best fit based on vCPU, memory, and GPU requirements. Creating a pool of EC2 Reserved Instances might result in unused capacity if workload requirements change. Lambda is not currently available as a compute resource for AWS Batch.","links":[{"url":"https://aws.amazon.com/batch/","title":"AWS Batch"},{"url":"https://aws.amazon.com/blogs/compute/optimizing-for-cost-availability-and-throughput-by-selecting-your-aws-batch-allocation-strategy/","title":"Optimizing for cost, availability and throughput by selecting your AWS Batch allocation strategy"}],"answers":[{"id":"8633cd86b6633324660fa073362c2f98","text":"Schedule jobs with AWS Batch into a pool of EC2 Reserved Instances that contains enough servers for the minimum number of jobs that will be run on any one night. Use an Auto Scaling Group to provision Spot Instances to handle any additional demand.","correct":false},{"id":"3220afaa7c6fd31e7a8d35ce1e2df1fa","text":"Configure AWS Batch to choose an instance type for each job based on vCPU, memory, and GPU requirements at the lowest cost.","correct":false},{"id":"96ef18a4d93470acb7dbd558eb666ca3","text":"Specify AWS Lambda as the compute resource for AWS Batch. Invoke the appropriate Lambda functions for each job.","correct":false},{"id":"0bb4d60773589240e55a5a506ee84275","text":"Use AWS Batch allocation strategies to define capacity, throughput, and cost priorities for instance type provisioning.","correct":true}]},{"id":"eba4823a-9cb9-440a-99cd-38f38ed3c10d","domain":"mon-rep","question":"An IoT company is producing a large stream of records and events and aims to store the event records in a persistent storage service of AWS. The CTO of the company has instructed the Solutions Architect of the IoT company to provide a solution that has the least amount of work required to set up and manage the data stream setup. How can the Solutions Architect accomplish this?","explanation":"Out of all the options, S3 will have the least storage costs and can easily be integrated with AWS Kinesis Firehose as a target destination of event records. The AppSync real-time support is for web and mobile applications. For an event bridge requirement that processes logs and event records from IoT sources, the Kinesis family of services is the primary option for handling realtime data streaming requirements. Given the amount of records to be stored, EBS is not a reliable solution and is also not a target destination for Kinesis.","links":[{"url":"https://aws.amazon.com/blogs/big-data/persist-streaming-data-to-amazon-s3-using-amazon-kinesis-firehose-and-aws-lambda/","title":"Amazon Kinesis Firehose"}],"answers":[{"id":"03c8bfac94e1e7b5ad38f4d55bdb2f6b","text":"Use AWS AppSync and Lambda for the real-time data streaming service and DynamoDB for the storage.","correct":false},{"id":"532a348bf03c7431c7f01baea9a4e380","text":"Use AWS Lambda and API Gateway for the real-time data streaming service and S3 for the storage.","correct":false},{"id":"cd4cace18ffdaa97f0968c443e1ffd16","text":"Use AWS Kinesis Firehose for the real-time data streaming service and S3 for the storage.","correct":true},{"id":"5ced4482b5eafc08a6df5d246887a232","text":"Use AWS Kinesis Firehose for the real-time data streaming service and AWS EBS for the storage.","correct":false}]},{"id":"5d1249a6-960b-4540-8631-50875e04850d","domain":"mon-rep","question":"A company is using a site-to-site AWS VPN connection with static routing to allow connectivity between its corporate office and a VPC in AWS. The SysOps Administrator wants to get notified if the connection goes down. What’s the most effective way to accomplish this?","explanation":"AWS support won't do this for you. The other options would work, however, creating a CloudWatch alarm is the simplest option.","links":[{"url":"https://docs.aws.amazon.com/vpn/latest/s2svpn/monitoring-cloudwatch-vpn.html","title":"Monitoring VPN Tunnels Using Amazon CloudWatch"}],"answers":[{"id":"a05514224184194909112ecdabb8b939","text":"Write a Lambda function to check the TunnelState metric every minute and send an SNS notification if necessary.","correct":false},{"id":"759ca4c838619fc5548932dc516de2cf","text":"Create a CloudWatch alarm to track the TunnelState metric and send an SNS notification if necessary.","correct":true},{"id":"4ca2750b50a6661dbeff47ae8524ff24","text":"Set up a cron job in an EC2 instance to confirm the TunnelState metric every minute and send an SNS notification if necessary.","correct":false},{"id":"b9f0b72860ab9c76417cf3f4c3ec6c98","text":"Ask AWS support to monitor the connection and send an SNS notification if necessary.","correct":false}]},{"id":"557a8cbf-ffb7-492a-b24a-7662b95c6269","domain":"automation","question":"A startup is planning to migrate their existing on-premise application to AWS. The company is already using Chef as the configuration management tool to manage their on-premise application and is looking to continue using Chef to manage their AWS resources. In addition to this, the team is looking to use a managed service to reduce the overhead of managing its PostgreSQL databases. How can the team accomplish this?","explanation":"OpsWorks is a managed service for Chef and Puppet and can easily be used to deploy and manage resources utilizing the Chef recipes already prepared. CloudFormation uses AWS's own engine to process and convert JSON or YAML templates to AWS resources. For requirements involving Chef and Puppet, OpsWorks is the primary (and only) managed service. For managed database service requirements, Aurora, RDS, and DynamoDB can be used as the managed database.","links":[{"url":"https://aws.amazon.com/opsworks/","title":"OpsWorks"}],"answers":[{"id":"33b2bf9a830d2dddb0570706a774902f","text":"Use OpsWorks for the configuration management requirements. Use RDS for the database management requirements.","correct":true},{"id":"378e25243c4a87f77553aed4ddbb2808","text":"Use ECS for the configuration management requirements. Use Athena for the database management requirements.","correct":false},{"id":"5b18a2364c2c69356af48e23e5347e81","text":"Use Elastic Beanstalk for the configuration management requirements. Use DynamoDB for the database management requirements.","correct":false},{"id":"ce66fcb736d2db75172e1c56777a36e1","text":"Use CloudFormation for the configuration management requirements. Use Aurora for the database management requirements.","correct":false}]},{"id":"bc7cd5cf-6c7b-4f45-bb7c-5700451bd9aa","domain":"data-man","question":"You are managing an S3 bucket that contains business critical objects for your operations department. You are tasked with optimizing the storage costs of the bucket. You've identified 130 objects in the bucket that need to be available but can be recreated by your department. What would you do to optimize your costs?","explanation":"Amazon recommends using One Zone-IA if you can recreate the data if the Availability Zone fails, and for object replicas when setting cross-region replication (CRR). Use Standard-IA for your primary or only copy of data that can't be recreated. S3 Standard would not be a cost-effective solution, and S3 Glacier does not provide millisecond retrieval times and would not fulfill the availability requirement.","links":[{"url":"https://docs.aws.amazon.com/en_pv/AmazonS3/latest/dev/storage-class-intro.html","title":"Amazon S3 Storage Class"}],"answers":[{"id":"9b7e1e30e477deece7a8b6d9eecd9331","text":"Set the storage class to S3 Standard-IA","correct":false},{"id":"daeec30860ad314818a31cb7ea5ba05e","text":"Set the storage class to S3 Standard","correct":false},{"id":"901f665e98aabd9853d4e0f9d3031ac2","text":"Set the storage class to S3 Glacier","correct":false},{"id":"98c96ddb15112194ea3d2c44c1addd3b","text":"Set the storage class to S3 One Zone-IA","correct":true}]},{"id":"5660d734-c8d8-404c-b683-3d43db3c17e1","domain":"mon-rep","question":"You are a SysOps Administrator for your company. Your CFO notices that costs have increased steadily for the past year, and tasks you with analyzing cost and usage of the company’s AWS environment based on tagged resources. What is the most effective way to analyze your company’s AWS spend?","explanation":"Choose Cost Explorer to track and analyze your AWS usage. Cost Explorer is free for all accounts and can filter by Region, purchase option, tags, among other things. Trusted Advisor provides areas to optimize costs but doesn't provide cost and budget reports. Developing a Lambda function to calculate spend would be an administrative burden, and so would comparing different AWS Config environments. Both would require manual efforts to leverage AWS' pricing API. It's much more efficient to utilize AWS' free Cost Explorer with built-in reporting functionality.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-getting-started.html","title":"AWS Billing and Cost Management"}],"answers":[{"id":"c307cf10883e9081648ee198aebeb387","text":"Download cost optimization and budgeting reports from Trusted Advisor as a CSV. Filter downloaded data by tags.","correct":false},{"id":"dbbdf8cec2b6f9217bcf2d39ad3ac859","text":"Create a Lambda function that is invoked for every CloudTrail Event. Have the Lambda function calculate spend based on each AWS services’ API calls using the tag key.","correct":false},{"id":"343d6ae3fa3cd5f44bce786dbe8e8b8b","text":"Use AWS Config to evaluate the configuration of your AWS environment last year. Create a custom rule to analyze by tag. Compare last year’s configuration to this year's and calculate the difference in spend.","correct":false},{"id":"b1204a52a0664ddd8a75b740204e6b88","text":"Enable the Cost Explorer tool to track and analyze your AWS usage. Filter spend by tags.","correct":true}]},{"id":"aba20312-a023-419f-b495-12e7dd2c6577","domain":"mon-rep","question":"In which of the following are your CloudTrail logs stored?","explanation":"Logs are stored in S3. You must specify a storage  bucket name to enable CloudTrail.","links":[{"url":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-find-log-files.html","title":"Finding Your CloudTrail Log Files"}],"answers":[{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"7b1fb630c85b556e31fa54e3d2b6201a","text":"An EBS Volume","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false}]},{"id":"216ba36a-8f55-47f4-80c8-44ac20c3a739","domain":"security-comp","question":"A new project is beginning in your company. The project utilizes two S3 buckets. All of the project members already have IAM user accounts provisioned. New members might join the project later on and some might leave before it's finished. What's the easiest way to configure access to the S3 bucket?","explanation":"All of the proposed solutions are technically feasible. However, you should grant the permissions on the whole group rather than for every individual user. If additional users require the same access, you can give it to them by adding them to the group. When a user no longer needs access to a resource, you can remove them from the group.","links":[{"url":"https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf","title":"AWS Security Best Practices"}],"answers":[{"id":"cde3f9182db55502f071cdb552e75a7c","text":"Create two bucket policies, one for each bucket. Allow access for all the IAM users in the bucket policies.","correct":false},{"id":"606624dc111236ee567ddebb534beb0c","text":"Create two IAM policies, each allowing access to a bucket. Attach the policies to a group where you add all the IAM users.","correct":true},{"id":"9b0876d4f2d9fd237877d5748604315b","text":"Create two IAM policies, each allowing access to a bucket. Attach the policies to all the IAM users.","correct":false},{"id":"80920c27da15505dd506eeabd067fc3f","text":"Create an IAM role which can access the buckets. Create inline policies to allow each IAM user to assume the role.","correct":false}]},{"id":"0260f2a1-85f9-489c-b235-461207089452","domain":"networking","question":"You are a network administrator for your organization and have been tasked to address a recent security threat to your application that sits in a subnet. VPC flow logs show that malicious activity has been coming from a specific IP address source. You need to add an extra layer of security to control traffic coming into your VPC from that IP address. How would go about making your application secure from the malicious IP source?","explanation":"You can associate a network ACL with multiple subnets; however, a subnet can be associated with only one network ACL at a time. When you associate a network ACL with a subnet, the previous association is removed. Amazon WAF is not applied at the subnet level. AWS Config will only set your AWS resources as compliant to rules you set, but it won't prevent any external traffic from accesses your resources. As best practice, start by creating rules for your NACL in increments (for example, increments of 10 or 100) so that you can insert new rules where you need to later on.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"b78c14382f6b1586c4a8016924d49783","text":"Add a rule to the NACL to explicitly deny traffic coming from the malicious IP source. Insert the rule as a lower number from the desired traffic from the same port.","correct":true},{"id":"cd96a1230ce2e15c29f01e30180e1d67","text":"Associate another NACL to the subnet holding the application. Add rule as the lowest number to the second NACL that explicitly denies traffic from the malicious IP source.","correct":false},{"id":"03bb7768562d89b49c918ae64b4183f9","text":"Configure an AWS Config rule to detect traffic originating from the malicious source. Configure a Lambda function to block the IP address whenever the Config rule is triggered.","correct":false},{"id":"e81b37b199479422fa7a10cb981356d9","text":"Activate the WAF with your VPC flow log. Add the malicious IP source address to the WAF's blacklist.","correct":false}]},{"id":"08cb4706-7aac-48de-a4c8-c7e742aeb4d9","domain":"data-man","question":"A Multi-AZ RDS deployment will automatically fail-over as a result of which two of the following?","explanation":"Amazon RDS detects and automatically recovers from the most common failure scenarios for Multi-AZ deployments so that you can resume database operations as quickly as possible without administrative intervention. Amazon RDS automatically performs a failover in the event of any of the following: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, Storage failure on primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"Failover Process for Amazon RDS"}],"answers":[{"id":"7b75b57dbe879950151e7a40cf0aed41","text":"A region-wide loss of service","correct":false},{"id":"215b7e6d7f48e4225c06a3c50bf400d2","text":"Loss of availability in primary Availability Zone","correct":true},{"id":"7ecc550bc4f7f4c4d01c334d359bb0d9","text":"Loss of availability in standby Availability Zone","correct":false},{"id":"8851c500044adfe0ba4a247acdb86eda","text":"Loss of network connectivity to the Primary","correct":true}]},{"id":"f0bf5535-d6d8-4188-aa8c-9cefd40e2218","domain":"security-comp","question":"You have just created an IAM group for your development team. You want to give them access to be able to access an S3 bucket  - Which policy type is best used to achieve this?","explanation":"IAM Identity based policies can be in-line or managed policies that enable you to restrict user, role or group access to services and actions within the VPC","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html","title":"Policies and Permissions"}],"answers":[{"id":"33b02b9157e2a10758df1edb0fa38865","text":"Service Control Policy","correct":false},{"id":"eeec60437e6675cbd890b5f482628cfc","text":"Identity-based Policy","correct":true},{"id":"8e2ddf5878aac8b5d22a6acab856040d","text":"Access Policy","correct":false},{"id":"2d53d9afa60c8a03ddae8baa0cb72fb2","text":"Resource-based Policy","correct":false}]},{"id":"a4edb410-e5e5-40b4-9335-1da82639c2e3","domain":"networking","question":"You work for an investment bank, supporting a mission critical stock market data processing application running on EC2 and consuming real-time data feeds from your on-premises systems. Your traders are complaining that the system is sometimes very slow to refresh the data and you suspect that this is due to fluctuations in available network bandwidth between AWS and your datacentre. What improvement can you suggest to give users a consistent experience and improve performance for users?","explanation":"AWS Direct Connect is a network service that provides an alternative to using the Internet to connect customer's on premise sites to AWS.","links":[{"url":"https://aws.amazon.com/directconnect/faqs/","title":"Direct Connect FAQs"}],"answers":[{"id":"a60c49fc87050d8b3c698515938d624b","text":"Configure S3 Transfer Acceleration to move the data into AWS much faster","correct":false},{"id":"5d5c067abd490006c21d11ff221c552a","text":"Configure a Direct Connect connection between your data center and AWS","correct":true},{"id":"3225172eff8d104a4744f0ee6f50d836","text":"Configure an additional Elastic IP for each of your application servers to increase the network bandwidth","correct":false},{"id":"35461a11ab55ba8f2b7eb1d3fcc15eff","text":"Scale out your application servers","correct":false}]},{"id":"e105d8a7-6333-48d8-9610-7c2f9ad73991","domain":"mon-rep","question":"There has been a steady rise in costs with your AWS bill, and the security team has noticed that there has been an increase in the number of requests, even though the number of IAM users has decreased due to employee turnover and down-sizing. The CISO has tasked you with identifying whether recent requests to the AWS account's environment were made with temporary security credentials for a role or federated user. How would you go about identifying this?","explanation":"A trail enables CloudTrail to deliver log files to an Amazon S3 bucket. By default, when you create a trail in the console, the trail applies to all AWS Regions. The trail logs events from all Regions in the AWS partition and delivers the log files to the Amazon S3 bucket that you specify. Additionally, you can configure other AWS services to further analyze and act upon the event data collected in CloudTrail logs. The userIdentity element contains details about the type of IAM identity that made the request, and which credentials were used. If temporary credentials were used, the element shows how the credentials were obtained. Identify Federation is used for access to an account. Config will not log API activity. Lambda cannot scrape an entire account; it needs to access an S3 bucket of CloudTrail logs to take any action.","links":[{"url":"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-user-identity.html","title":"CloudTrail userIdentity Element"},{"url":"https://docs.aws.amazon.com/config/latest/developerguide/log-api-calls.html","title":"Logging AWS Config API Calls with AWS CloudTrail"}],"answers":[{"id":"41e73582d973a777c1838270973c1a5a","text":"Create a Lambda function that is triggered daily that scrapes the account for requests from any assumed roles. Have the Lambda function revoke access if any requests are non-compliant.","correct":false},{"id":"97ddb7778b0f9f5decefb8013df4d710","text":"Set up Identity Federation with SAML. Create IAM roles and create policies for employees to assume with the correct permissions. Log all requests using the Credential report.","correct":false},{"id":"4ffef50c6af5fe0e395fb58ca8319f05","text":"Record all ongoing events in the AWS account using AWS Config. Create a CloudWatch alarm to send an SNS topic when an identity under AssumeRole makes a request to the account.","correct":false},{"id":"73e4bf9add9c239534c52f8a03fb95fb","text":"Create a CloudTrail log to deliver files to an Amazon S3 bucket. Use Amazon Athena to query the logs to search for the userIdentity element.","correct":true}]},{"id":"f0c663f6-c133-4064-93f1-5a68ec604f86","domain":"networking","question":"A company is developing a software product on AWS. The product requires some dependencies on an external software application developed by another company. In order for the product to run properly, it must connect with the external software that has a configured AWS PrivateLink to run some tasks. Both companies want the connection between the product and the external application to be secured privately and not over the open Internet. How would you configure this connection?","explanation":"An interface VPC endpoint is required to use AWS PrivateLink. In this case, since the external software application has configured a PrivateLink, connecting the interface VPC endpoint to the PrivateLink will provide private connectivity. A VPN connection and Direct Connect are best suited for connectivity between AWS and an on-premise data center. A VPC endpoint is more appropriate in this case. Cross account access would not apply in this case.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/what-is-amazon-vpc.html#what-is-privatelink","title":"What Is Amazon VPC?"}],"answers":[{"id":"a295a681bdc68fccdefa0245a0f3cb22","text":"Create a IAM role for the product. Enable cross account access for the product to communicate with the external software application to run its dependencies.","correct":false},{"id":"396ed1524965dd42f15a5584a5df2111","text":"Set up a VPN connection between a gateway endpoint on your VPC and a customer gateway in the external company's VPC. Encrypt the IPSec tunnel to ensure private connectivity.","correct":false},{"id":"82d6bd6a8ad9b046abc832a10aab46ec","text":"Configure a Direct Connect connection between your software product and the external software application's VPC. Data traversed over this connection will be private.","correct":false},{"id":"125e90bd89dd9a655f80754756185ade","text":"Put the product within a VPC and configure a VPC endpoint for the external application. Use the elastic network interface in the subnet with a private IP address.","correct":true}]},{"id":"99568617-996c-454f-98ce-c120f3ea2c38","domain":"automation","question":"By default, what status message will you see if your CloudFormation stack encounters an error during creation?","explanation":"You will see the ROLLBACK_IN_PROGRESS message if your CloudFormation stack encounters an error during creation.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-describing-stacks.html","title":"Describing Your Stacks"}],"answers":[{"id":"31f5c2cdf809b189d85d0dfcc0d7a7b4","text":"DELETE_IN_PROGRESS","correct":false},{"id":"d2884fa6c360974bc033ce3ab23c63f6","text":"STACK_ERROR","correct":false},{"id":"f3337297902478338063007adf324783","text":"ERROR_STACK_DELETE","correct":false},{"id":"0ad1f7c4221eb5f69b578b85f24935d0","text":"ROLLBACK_IN_PROGRESS","correct":true}]},{"id":"723a6cb2-65a0-454f-b391-8647401fa54d","domain":"networking","question":"A photo sharing application is growing in popularity.  The application uses S3 to store photographs. Your boss has asked you how you can improve the upload and download times for your end users?","explanation":"S3 upload and download times can be improved by enabling Transfer Acceleration. This leverages Points of Presents (PoPs) in the CloudFront network to provide connection points closer to users, thereby improving transfer speeds.  Disabling Object Versioning or enabling Intelligent Tiering would not affect upload or transfer speeds.  Lastly, BitTorrent support is for publicly-available files and is designed to increase availability of files and reduce S3 costs but does not improve upload and download times from the S3 service itself.","links":[{"url":"https://docs.aws.amazon.com/en_pv/AmazonS3/latest/dev/transfer-acceleration.html","title":"Amazon S3 Transfer Acceleration"}],"answers":[{"id":"792c81205244e2382feec0be4a8a8716","text":"Enable S3 BitTorrent support","correct":false},{"id":"5c6679012efaeb73c2123036ba676303","text":"Enable S3 Transfer Acceleration on your buckets","correct":true},{"id":"3992a5af710f81ade0226fff00fedf2d","text":"Enable S3 Intelligent Tiering","correct":false},{"id":"26b2f3dfb7078bf49a2aafd952d45a13","text":"Disable S3 Object Versioning","correct":false}]},{"id":"16482bd7-28fc-4d2d-8d24-37ad0a771da2","domain":"data-man","question":"You have been hired by an airline who has just had a MAJOR security breach exposing the full text of their customers and their credit card details. The company has fired most of their IT security team over the breach and it is your job to make immediate changes to prevent this from happening in the future. Your company has their production application on AWS and uses the following services – EC2 with EBS, RDS, EFS and S3. You need to apply encryption at rest to all 4 services ASAP. Which service can you apply encryption to immediately, without a data migration?","explanation":"Only S3 allows you to enable encryption after the bucket or object has been created and without requiring a migration. All the other services need encryption to be enabled at creation time, so you will need to create a new encrypted EBS, EFS or RDS resource and then migrate to it.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/default-bucket-encryption.html","title":"S3 Encryption"}],"answers":[{"id":"248c1b0bcb74394beb4a08030c4a6847","text":"EBS","correct":false},{"id":"f332127ba5ee3389e4c5cff45ac9a518","text":"EFS","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false}]},{"id":"6c456d08-f571-4a63-833d-ef8c49757ef4","domain":"automation","question":"You have an application running on several Amazon EC2 instances in an Auto Scaling group attached to an Elastic Load Balancer. You check the ELB logs in the S3 bucket and realize that instances that fail the ELB health checks are not being replaced. How would you troubleshoot this issue?","explanation":"The default health checks for an Auto Scaling group are EC2 status checks only. If an instance fails these status checks, the Auto Scaling group considers the instance unhealthy and replaces it. If you've attached one or more load balancers or target groups to your Auto Scaling group, the group does not, by default, consider an instance unhealthy and replace it if it fails the load balancer health checks. To do this, configure the Auto Scaling group to use Elastic Load Balancing health checks. The listener rules determines how your load balancer routes request traffic, and the trace ID traces request through your ELB.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-elb-healthcheck.html","title":"Amazon EC2 Auto Scaling"}],"answers":[{"id":"9bc372b00a1c40e68b34b0d3e9f6edc3","text":"Update the listener rules on the load balancer to allow for health checks on the ELB.","correct":false},{"id":"ba4ba5112eec0a2ca6312a45f8834c76","text":"Check the access logs permissions. Adjust the log permissions to allow ELB to write logs to the S3 logs bucket.","correct":false},{"id":"e5f3d2525407af983596253361c1af26","text":"Configure the Auto Scaling group to use ELB health checks to have the Auto Scaling group replace the instance.","correct":true},{"id":"9283050a2c9b87649381de2f1f54a3e7","text":"Configure request tracing on the load balancer to update the X-Amzn-Trace-Id header before sending the request to the Auto Scaling group.","correct":false}]},{"id":"fb5f0c80-43c7-455e-9e9a-095d0883e920","domain":"networking","question":"Your company has set up a new server environment in a VPC. You already have applications running in several other VPCs in the same AWS Region. There is a requirement for the newly set up VPC to be able to connect to and communicate with the resources in the already existing VPCs. How would you set up the VPC so that they can communicate with each of the other VPCs?","explanation":"A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them. Instances in either VPC can communicate with each other as if they are within the same network. You can create a VPC peering connection between your own VPCs, or with a VPC in another AWS account within a single region. A Direct Connect connection is used to connect an on-premises data center and AWS. You cannot set up an IPSec tunnel between different VPCs. Storage Gateway is a hybrid cloud storage service that gives you on-premises access to virtually unlimited cloud storage. Remember VPC connections are not transitive -- if there exists a connection between A and B, and another between B and C, you cannot assume connection between A and C. A and C must have their own VPC connection.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-peering.html","title":"VPC Peering"}],"answers":[{"id":"4883b19e9bcd0d2be72e729819f32630","text":"Configure VPC peering connection between the new server environment VPC and each of the existing VPCs.","correct":true},{"id":"5b7aae32966b04d80669d81a98bcd002","text":"Set up an IPSec tunnel between the new server environment VPC and each of the existing VPCs.","correct":false},{"id":"771101ce4f7e94bd471af7490926cde0","text":"Configure a Storage Gateway connection between the new server environment VPC and each of the existing VPCs.","correct":false},{"id":"ac4676fa941307afa0aacecfbb409545","text":"Configure a Direct Connect link between the new server environment VPC with each of the existing VPCs.","correct":false}]},{"id":"592837f2-71d3-4e62-a250-9318ea373e4f","domain":"security-comp","question":"You are a Cloud Administrator for your company. You have many employees who need to run internal applications that access the company's AWS resources. The employees already have user identities in the company's identity and authentication system, and your CISO doesn't want to create a separate IAM user for each company employee. You've confirmed with your developers that the applications' identity stores are not compatible with SAML 2.0. How would you implement a secure solution for your employees to access AWS resources?","explanation":"If your identity store is not compatible with SAML 2.0, then you can build a custom identity broker application to perform a similar function. The broker application authenticates users, requests temporary credentials for users from AWS, and then provides them to the user to access AWS resources. Creating IAM Users for each employee is not an option. Amazon Cognito is for mobile and web-based application scenarios. A permissions boundary is not a viable solution.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_federated-users.html","title":"Providing Access to Externally Authenticated Users (Identity Federation)"}],"answers":[{"id":"b24b7cff8ae14f5cf1fabc8e93a55cec","text":"Build a custom identity broker application to verify that employees are signed into the company's authentication system, then obtains temporary security credentials for the employees.","correct":true},{"id":"e59f83de64b3549683dca23ce954c76f","text":"Create IAM Users for the employees and group them into IAM Groups for administrative purposes since your identity provider is incompatible with SAML 2.0.","correct":false},{"id":"65e9ecf1544f3bd1ca9f6dce4aef9dcf","text":"Create a permissions boundary around a role that correspondence to the allowed actions for your company's employees. Allow each employee to assume that role. Create a Lambda function that will automatically deny allow if the employee's permissions exceed the boundary.","correct":false},{"id":"04b52fca3576444ec1bdbe890cb9b2c8","text":"Use Amazon Cognito with public identity provider services for your employees. Link your employees' credentials with a third-party IdP that is compatible with OpenID Connect (OIDC) to grant access to AWS resources.","correct":false}]},{"id":"edaeeffd-65ec-4d45-8f2d-f37d50773681","domain":"dep-prov","question":"You create an Oracle database in AWS RDS for an application. As the database instance needs to integrate with an S3 bucket, you want to configure an IAM role for the database to read and write the bucket objects. You already have an IAM role for EC2 and the EC2 instance can use the role to transfer files from and to the bucket properly. However, when you try to add the same role to the database, the role cannot be found. What is the reason and how to fix it?","explanation":"The trust entity of the IAM role must include rds.amazonaws.com for a RDS database to assume it. The existing role only contains the trust entity of ec2.amazonaws.com so it cannot be used for RDS. The resource and action parts of the role should be good as EC2 can work with S3 properly. Policies of an IAM role do not have the “principal” part.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-s3-integration.html","title":"RDS integrates with S3"}],"answers":[{"id":"edb854c1df5fa32a6d19c322a736f525","text":"The permissions of the IAM role do not list the resource of the S3 bucket.","correct":false},{"id":"d0d2809faf6ff80ea9807995d483b3e0","text":"For the RDS database to assume the role, the IAM policy should allow the action of \"rds:*\".","correct":false},{"id":"9b1ce3b64821b8efb42f867e68acfbae","text":"The IAM role needs to add a principal of RDS so that any RDS instance can assume the role to integrate with S3.","correct":false},{"id":"d87fa6b85878f5af177443f4c2aa638f","text":"The trust entity of the role is the service of EC2 instead of RDS. You should create a new role for the RDS service to assume.","correct":true}]},{"id":"3f2da740-c544-4f1e-91c5-82a11619c457","domain":"automation","question":"An engineer has been instructed to generate a CloudFormation template that creates an ElastiCache cluster automatically when in production mode. How should the engineer accomplish this?","explanation":"This use case involves the use of a parameter (input) and a condition that changes the behavior of the template depending on the parameter. With the use of CloudFormation conditions, only one template is used instead of multiple similar templates","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/conditions-section-structure.html","title":"CloudFormation - Conditions Section Structure"}],"answers":[{"id":"778d1401e9dd6d35d4355b56d7c12d3f","text":"Use a parameter for the environment. Add a condition in the CloudFormation template to create the ElastiCache resource only when environment = production.","correct":true},{"id":"7c59d26f19f71a761bc0b00e8194713f","text":"Use SAM templates instead of CloudFormation templates to manage the differences between environments.","correct":false},{"id":"59d4d9c4627999c1d25bf01e7b161b6b","text":"Create two templates. One for the production template with the ElastiCache cluster and another without the ElastiCache cluster.","correct":false},{"id":"944e9640a5444863d4993d2e7da7719e","text":"Use nested CloudFormation stacks with one stack creating an ElastiCache resource and another without the ElastiCache resource.","correct":false}]},{"id":"5b71bc80-b7ef-4fde-86f0-1a73d1d63e4c","domain":"high-avail","question":"You are an AWS administrator and have set up an Elastic Load Balancer inside a VPC. The ELB spans several Availability Zones. The ELB sits in front of a web application running on Amazon EC2. You notice that incoming traffic is not being evenly distributed across the AZs. How would you solve this issue?","explanation":"Traffic not evenly distributed across the instances in multiple AZs means the traffic is going to only specific EC2 instances. This happens when either the instances which are not receiving the traffic are unhealthy, or the instances that are receiving the traffic are holding on to the session. Since there is no mention of unhealthy instances, disabling sticky sessions on the ELB is the best answer. Increasing the number of subnets and/or instances will not solve the problem as users will remain stuck to the original instance. Increasing the frequency of health checks will have no impact to force even distribution of traffic.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html","title":"Configure Sticky Sessions for Your Classic Load Balancer"}],"answers":[{"id":"b7116d2a43d8462c83e8b93fda085c71","text":"Disable sticky sessions on the ELB.","correct":true},{"id":"c0d9e44a3e92d6d91864058257e9922c","text":"Add additional subnets within your ELB and configure your ELB to span the new subnets.","correct":false},{"id":"d532ac3048a69a5902a79b51bc219bd3","text":"Increase the number of EC2 instances behind the ELB.","correct":false},{"id":"e23eea1cecbc63f7423de00e65f29614","text":"Increase the frequency of the health checks to the EC2 instances running your application.","correct":false}]},{"id":"29e51c05-d93d-4868-9c14-8c7940bf9d4c","domain":"security-comp","question":"The CFO has raised concerns about rising AWS costs and has asked you to look into this potential issue. When you look at CloudTrail logs you notice that certain IAM Users in multiple AWS accounts within your organization are using AWS services without discretion, and these services are not relevant to their business functions. How would you implement security policies to limit which AWS services these users can access in the most effective way?","explanation":"Creating IAM policies for each IAM User is not best practice and can become an administrative burden. AWS GuardDuty does not provide IAM-related services, and thus is irrelevant. It is not possible to view CloudTrail logs at the OU level. The best solution is to use Service Control Policies (SCPs) to govern use of the AWS environment at the OU level.","links":[{"url":"https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html","title":"AWS Organizations: Service Control Policies (SCPs)"}],"answers":[{"id":"93faedb0826b3c6a97423da318c0b775","text":"Use AWS GuardDuty to detect and monitor each IAM Users' activity to document unauthorized behavior.","correct":false},{"id":"633fa64e9f9d9f6b601b4400d9ca6b30","text":"Identify the IAM Users within each Organizational Unit. Attach IAM policies to each user to restrict access based on each users' job function.","correct":false},{"id":"c6d620763c9f148cf7eaab8ef0467d62","text":"Send CloudTrail logs at the Organizational Units' level to CloudWatch Events. Use Lambda to change IAM permission to DENY any AWS service if users attempt to use non-business critical services.","correct":false},{"id":"5b2ff64d8adf96a19f7dc89c3b3d76ef","text":"Attach a Service Control Policy at the Organization Unit to blacklist AWS Services that all Accounts under the OU shouldn't use.","correct":true}]},{"id":"dff22820-ec03-46d8-aa62-cc85ddd8fe19","domain":"dep-prov","question":"An old on-premises application is migrated to AWS EC2. The EC2 instances are managed by an Auto Scaling Group. You need to create a Load Balancer to route the traffic to the ASG. The SSL traffic should be terminated at the Load Balancer and you want to configure the Load Balancer to route client requests based on the value of a custom HTTP header. Which type of the Load Balancer should you choose?","explanation":"All types of Elastic Load Balancers support SSL offloading. However only the Application Load Balancer supports the HTTP header-based routing as it operates at the application layer and HTTP/HTTPS is a layer 7 protocol.","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/#compare","title":"Elastic Load Balancing features"}],"answers":[{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":true},{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":false},{"id":"2493298314dcf1d9722b3269375198cd","text":"HTTP Load Balancer","correct":false},{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false}]},{"id":"c461c835-6e0c-4e18-8717-1b5acabe2af9","domain":"security-comp","question":"When using Active Directory to authenticate to AWS, which of the following answers contains the correct steps, in the correct order?","explanation":"","links":[{"url":"https://aws.amazon.com/blogs/security/enabling-federation-to-aws-using-windows-active-directory-adfs-and-saml-2-0/","title":"Enabling Federation to AWS Using Windows Active Directory"}],"answers":[{"id":"02f2ce639c41ae03c1c6099c33593f80","text":"The user navigates to the AWS console. The user enter in their active directory single sign on credentials in to AWS. The user's web browser receives a SAML assertion from AWS. The user is then able to access the AWS Console.","correct":false},{"id":"e4464cfa98c814aa81123b2d97940a77","text":"The user navigates to ADFS webserver. The user enter in their single sign on credentials. The user's web browser receives a SAML assertion from the AD server. The user's browser then posts the SAML assertion to the AWS SAML end point for SAML and the GiveUserSAMLAccess API request is used to request temporary security credentials. 5) The user is then able to access the AWS Console.","correct":false},{"id":"921a6f41c6e7d2fcc0ec098002081e0a","text":"Federating with Active Directory is not possible with AWS.","correct":false},{"id":"3bab42a50feb364e054cbed66a94e7aa","text":"The user navigates to ADFS webserver. The user enter in their single sign on credentials. The user's web browser receives a SAML assertion from the AD server. The user's browser then posts the SAML assertion to the AWS SAML end point for SAML and the AssumeRoleWithSAML API request is used to request temporary security credentials. 5) The user is then able to access the AWS Console.","correct":true}]},{"id":"c1701920-538e-488e-bbb1-d94d9bc2c547","domain":"data-man","question":"You are managing an S3 bucket containing confidential financial information for your finance department. The CFO downloads a reporting file but notifies you saying the data on the file is wrong. He claims the report should show updated numbers. You are sure you uploaded the most up-to-date file just moments ago. How would you explain the situation to your CFO?","explanation":"Amazon S3 offers eventual consistency for overwrite PUTS and DELETES in all Regions. Amazon S3 achieves high availability by replicating data across multiple servers within AWS data centers. If a PUT request is successful, your data is safely stored. However, information about the changes must replicate across Amazon S3, which can take some time. IAM user policies would not get around eventual consistency. The HEAD operation retrieves metadata from an object without returning the object itself. This implementation of the GetObjectTagging operation returns the tags associated with an object.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Amazon S3 Data Consistency Model"}],"answers":[{"id":"e194d5d020090f2f6e93c362d734b897","text":"Explain to the CFO that he needs to retrieve the object using the HEAD request.","correct":false},{"id":"6ae999a93c1570782ac4d7afbe01bfdc","text":"Explain to the CFO that Amazon S3 offers eventual consistency for overwrite PUTS and DELETES in all Regions.","correct":true},{"id":"0bb0509d4fa0d3e4e91e07eb79dabb78","text":"Explain to the CFO you need to the update the IAM user policy to allow GET requests for new versions.","correct":false},{"id":"f9c3ce12a732ecf526c8cb22da10a5f6","text":"Explain to the CFO that he needs to perform the s3:GetObjectTagging action to specify the right version of the object.","correct":false}]},{"id":"88de3a5c-b9ce-46eb-928f-f0f909bfe5dd","domain":"networking","question":"You own the registered domain name cloudcanines.com and are trying configure Route53 to map the DNS name to the DNS name of your Elastic Load Balancer. Which Route53 record can you use to achieve this?","explanation":"cloudcanines.com is a Zone Apex and you can't create a CNAME record at the zone apex. Instead you need to use an alias record to map the Zone Apex to the Elastic Load Balancer","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html","title":"Route53 Record sets"}],"answers":[{"id":"de46eab399f3ea0bbf1912c1d14a1544","text":"Zone Apex","correct":false},{"id":"0b98720dcb2cc6fd60358a45dfbc5b87","text":"MX","correct":false},{"id":"adc4bfdb0829dae99e3699393e3fbaa4","text":"CNAME","correct":false},{"id":"effdb9ce6c5d44df31b89d7069c8e0fb","text":"Alias","correct":true}]},{"id":"ac509f33-b7fd-483a-a610-b5744bc89943","domain":"automation","question":"An organization wants to understand when the infrastructure it is deploying from CloudFormation has been manually changed by a rogue developer in the team.  Which three services would help to detect changes and determine who performed the change?","explanation":"AWS CloudFormation Drift detection allows for you to identify changes over time of resources, when compared to the Cloudformation stack which created them.  The AWS Config managed rule 'cloudformation-stack-drift-detection-check' allows for a drift check to be initiated.  Any stacks with drift can be flagged as a non-compliant stack.  AWS Config can also provide you with a timeline of modified resources, along with the associated CloudTrail event that caused the configuration to change.. including which IAM role or user performed the change.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2018/11/aws-cloudformation-now-supports-drift-detection/","title":"AWS CloudFormation Now Supports Drift Detection"},{"url":"https://aws.amazon.com/about-aws/whats-new/2018/11/aws-config-launches-a-new-aws-config-rule-to-support-aws-cloudformation-stack-drift-detection/","title":"AWS Config Launches a New AWS Config Rule to Support AWS CloudFormation Stack Drift Detection"}],"answers":[{"id":"28408acf54ab04fe847fd24957e528d9","text":"AWS CloudWatch Logs","correct":false},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":true},{"id":"b00e2e3d5e092e8527268afe49e5a5e2","text":"AWS CloudFormation Change Sets","correct":false},{"id":"7c1c0a0eb09dcbcd9acf3ade0b16cb91","text":"AWS Guard Duty","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"3c4dbfbe3fe821153b16f5a7b3e98a96","text":"AWS CloudFormation Drift","correct":true}]},{"id":"78ad6dfb-14bd-44bf-a5a4-4af2076aae23","domain":"networking","question":"As your company's lead network administrator, you are helping the development team set up a VPC for an application in their AWS account. The application requires a network configuration such that the web servers of the application have connectivity to the Internet, and the database servers have VPN-only connectivity to the corporate network servers. What VPC set up would support this desired configuration? (Select all that apply)","explanation":"The scenario requires a VPC with an internet gateway, a virtual private gateway, a public subnet, and a VPN-only subnet. One route table has a route to the virtual private gateway in a private subnet. Another route table is explicitly associated with the public subnet. The custom route table has a route to the internet (0.0.0.0/0) through the internet gateway. A NAT instance in another private subnet would not allow Internet connectivity. The Direct Connect connection is unnecessary. The requirements does not allow placing database servers in public subnets.","links":[{"url":"https://docs.aws.amazon.com/en_pv/vpc/latest/userguide/VPC_Route_Tables.html","title":"Route Tables"}],"answers":[{"id":"4d167d5d0ddda70960f354da47b72e33","text":"Place the web servers in a private subnet. Associate a route table to the private subnet that has a route to a NAT instance in another private subnet.","correct":false},{"id":"d7235003c798151a119f9b00b31cce7f","text":"Place the database servers in a public subnet with Direct Connect. Set up a Direct Connect connection to the servers in your on-premises environment.","correct":false},{"id":"31d58d613e8532ad19cdb0c73912f36d","text":"Place the database servers in a private subnet. Associate a route table to the private subnet that has a route to a virtual private gateway.","correct":true},{"id":"ac748fb5daa7fcaff151922fb2c482a4","text":"Place the database servers in a public subnet. Associate a route table to the public subnet that has a route to the Internet through the Internet Gateway.","correct":false},{"id":"f8f4044343da77cd7ab9710d8b6f5067","text":"Place the web servers in a public subnet. Associate a route table to the public subnet that has a route to the Internet through the Internet Gateway.","correct":true}]},{"id":"85c8beb3-4040-4c16-80a2-28699caea7f7","domain":"mon-rep","question":"Your company is running dozens of EC2 instances. What kind of a solution would give near real-time visualizations of multiple EC2 instance metrics at once?","explanation":"You can gather the necessary metrics together in CloudWatch Dashboards for complete operational visibility.","links":[{"url":"https://aws.amazon.com/cloudwatch/","title":"CloudWatch"}],"answers":[{"id":"1ac4cde26a39fcabf5405c352b7bdff9","text":"Send the metrics to S3 and visualize them with S3 analytics.","correct":false},{"id":"af39109a1cd1a96dc8fc03cad521e886","text":"Visualize the metrics with QuickSight.","correct":false},{"id":"eaa240abb4f0731fca4c2e20cbbbfefe","text":"Add the metrics into a CloudWatch Dashboard.","correct":true},{"id":"beef56bb880b285559c0254491f4d5c9","text":"Organize the metrics into a CloudFront panel.","correct":false}]},{"id":"4f95f73a-fabd-44b4-a043-0bdee8159a99","domain":"security-comp","question":"You are a SysOps Administrator running security checks throughout your AWS environment. Your AWS account recently launched a new application and you need to ensure access to the application's web servers is restricted to certain ports. How would you implement a policy so that SSH traffic from port 3389 is restricted?","explanation":"The restricted-common-ports checks whether the incoming SSH traffic for the security groups is accessible to the specified ports. The rule is COMPLIANT when the IP addresses of the incoming SSH traffic in the security group are restricted to the specified ports. This rule applies only to IPv4. Amazon Inspector helps to identify security vulnerabilities as well as deviations from security best practices in applications, but not for security groups.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/restricted-common-ports.html","title":"AWS Config rules"}],"answers":[{"id":"c2e5ba2c7f9b96b874027fd22e836d7d","text":"Restrict the application to run only on Linux/Unix instances.","correct":false},{"id":"3bd73de961085bba965e8589f52a6c08","text":"Install the Amazon Inspector agent on your application to run automated security assessments to identify and restrict any SSH traffic originating from port 3389.","correct":false},{"id":"6e274e1e00f14fe4302875974cf5b4c1","text":"Architect your application using the IPv6 communications Internet Protocol.","correct":false},{"id":"3783cbf28ccda5bf3b6aa20d913bb34e","text":"Set up and activate the restricted-common-ports AWS Config rule.","correct":true}]},{"id":"44323aa9-db88-4c8e-8594-5af3edab91b8","domain":"networking","question":"You're consulting for a consumer electronics company that markets its products globally. A new customer-facing application will be deployed in seven AWS Regions worldwide. Business logic will be handled by microservices deployed on EC2 instances in each region. The data layer will be hosted on Amazon Aurora in a single AWS Region. Which architecture will provide the highest performing solution for end users?","explanation":"A Route 53 latency routing policy will send requests to the destination with the lowest latency, generally resulting in the best performance. A Route 53 geolocation routing policy will probably not provide better performance than a latency routing policy. Even though targets may be physically closer, they may involve more network hops. Geolocation policies are generally used to serve localized content. Application Load Balancers work well for microservice architectures since targets can be registered as a specific port on an EC2 instance. CloudFront path patterns are for routing different file types, not for distinguishing origins in different regions.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html","title":"What Is an Application Load Balancer?"}],"answers":[{"id":"8f8597399845c09e57ce08b6791b3ab0","text":"Deploy the EC2 instances behind an ELB Network Load Balancer in each region and set each one up as an Amazon CloudFront origin. Create path patterns to route all requests to the load balancer in the desired region","correct":false},{"id":"562b2939dfd8d3940e82593f75d73725","text":"Implement an Amazon Route 53 record set for the application with a geolocation routing policy. Use an ELB Network Load Balancer in front of the EC2 instances in each region","correct":false},{"id":"915fca3a9a0bf0eaf51de3fe684ef9e0","text":"Configure an Amazon Route 53 record set for the application with a geolocation routing policy. Implement an ELB Application Load Balancer in front of the EC2 instances in each region","correct":false},{"id":"9a5a8c536cd4c0209770d8e9b9897abd","text":"Create an Amazon Route 53 record set for the application with a latency routing policy. Deploy an ELB Application Load Balancer in front of the EC2 instances in each region","correct":true}]},{"id":"8c2f5b35-c8f5-403a-a81d-bba09882e8d8","domain":"mon-rep","question":"An e-commerce company has a web application in an autoscaling group of EC2 instances behind an application load balancer. The logs produced by the web framework being used are written inside a folder stored inside the ephemeral storage of the EC2 instance. During a sale which caused the number of instances to spike, a developer has pushed changes that introduced a bug which caused some of the transactions to be rejected and stored in the web application logs. Unfortunately, the number of instances have already scaled down before the DevOps team can retrieve and process the logs. What can be performed to allow the DevOps team to troubleshoot the issues better?","explanation":"If the CloudWatch Logs Agent is installed in the EC2 Instances, the logs are automatically synced to CloudWatch logs which will allow the users to check the logs in CloudWatch even if the instances are already terminated. S3 buckets cannot be attached to the EC2 instance as a storage source. Installing the KCL (Kinesis Client Library) will not solve the loss of log files problem. KCL is primarily used to extract event records from Kinesis streams. Enabling VPC flow logs will not solve the issue with loss of log files. It will only help capture the IP traffic information in the network traffic.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html","title":"CloudWatch - EC2 Instance"}],"answers":[{"id":"f799ec7601ff751c04b1cc214830bd17","text":"Attach an S3 bucket to the EC2 instance as a storage source","correct":false},{"id":"6c0b75c8b0b0fe4c8762bb0309dcc1c2","text":"Install the KCL in the EC2 instances","correct":false},{"id":"b6ece95734ff5e848d698b5028d5ae36","text":"Enable VPC Flow Logs","correct":false},{"id":"5b7dc5b6acee7f66def0e505bf37544f","text":"Install and set up the CloudWatch Logs Agent in the EC2 instances","correct":true}]},{"id":"23e299c8-e80d-4333-b726-4f8ef1e89cfc","domain":"security-comp","question":"You want to restrict who can access a specific bucket that the development team use to store artifacts from their development pipeline. What kind of in-line policy will you need to use to insure this access","explanation":"Resource based policies are inline policies that restrict access to a specific resource, a good example of this is an S3 bucket policy.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html","title":"Policies and Permissions"}],"answers":[{"id":"eeec60437e6675cbd890b5f482628cfc","text":"Identity-based Policy","correct":false},{"id":"8e2ddf5878aac8b5d22a6acab856040d","text":"Access Policy","correct":false},{"id":"2d53d9afa60c8a03ddae8baa0cb72fb2","text":"Resource-based Policy","correct":true},{"id":"33b02b9157e2a10758df1edb0fa38865","text":"Service Control Policy","correct":false}]},{"id":"f5213e28-c41d-4552-810a-7aa8f5ba2a1c","domain":"networking","question":"A Developer is unable to connect to an EC2 instance in a VPC. A SysOps Administrator investigates the connectivity issue. Going through a troubleshooting checklist, which conditions should be checked? Select two.","explanation":"Internet gateways allow all traffic and that cannot be configured. EC2 instances always have a private IP but a public IP is required for internet access. Security groups are stateful so only an allow rule for incoming traffic is required.","links":[{"url":"","title":""}],"answers":[{"id":"578d4a14aed3e21944a0f081460e32af","text":"The security group has an allow rule for outgoing traffic.","correct":false},{"id":"8b476944980fce87668c22d0c40470e9","text":"The internet gateway associated with the VPC allows outgoing traffic.","correct":false},{"id":"08eefee7811ea91e42e46ba287ff5d6a","text":"The security group has an allow rule for incoming traffic.","correct":true},{"id":"f9b2c3489abcbefefb1b289a51e33ccb","text":"The internet gateway associated with the VPC allows incoming traffic.","correct":false},{"id":"692e30da816ea07b3744e393cbbd28cd","text":"The instance has a private IP address.","correct":false},{"id":"50be1cda181093d2df7e72aed5f80ab8","text":"The instance has a public IP address.","correct":true}]},{"id":"5d0c33cd-3b30-46ae-937a-7ffe3350e8d0","domain":"automation","question":"Which of the following services is used to develop and deliver infrastructure as code?","explanation":"CloudFormation is used for Infrastructure-as-Code.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"About CloudFormation"}],"answers":[{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"a907a7338c1fb3821fbe8ed113c64b33","text":"CloudHSM","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true}]},{"id":"7e182684-0217-472e-a62a-53d34cbd972c","domain":"dep-prov","question":"You have been asked to decouple an application by utilising SQS.  The application dictates that messages on the queue can be delivered more than once, but must be delivered in the order that they have arrived, and also must allow for efficient, repeated polling of the queue.  Which of the following options are most suitable?","explanation":"This question has two parts which need to be considered, the type of queue and the type of polling.  The question states that messages, \"can be delivered more than once\" but, \"must be delivered in the order that they have arrived\", which means that it can only be a FIFO queue as it is the only SQS type which will deliver messages in order, regardless of how many times the message is delivered.  The question also states that the queue, \"must allow for efficient polling\" and in this case long polling is the most efficient and cost effective option in situations where the queue will be polled constantly.  The correct answer is therefore to configure a FIFO SQS queue with long polling enabled.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html","title":"Amazon SQS FIFO (First-In-First-Out) Queues"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-long-polling.html","title":"Amazon SQS Long Polling"}],"answers":[{"id":"2a55c515f67b00a75c46c6d27e2cc2ed","text":"Configure a FIFO SQS queue and enable short polling","correct":false},{"id":"a078e24ae55cd5b1c779ffdfdfd8fcf9","text":"Configure a FIFO SQS queue and enable long polling","correct":true},{"id":"13aac3121a54296c93468234033a5608","text":"Configure a standard SQS queue and use long polling","correct":false},{"id":"8ced375cf136690dd622d3bdc98e16c2","text":"Configure a standard SQS queue and use default polling","correct":false}]},{"id":"74489755-3525-47c8-89c0-c840d59c5f54","domain":"dep-prov","question":"It is not possible to share an AMI across AWS Regions.","explanation":"You can copy an Amazon Machine Image (AMI) within or to another AWS region using the AWS Management Console, the AWS command line tools or SDKs, or the Amazon EC2 API. Copying a source AMI results in an identical but distinct target AMI with its own unique identifier.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html#copy-amis-across-regions","title":"Cross-Region AMI Copy"}],"answers":[{"id":"2a861232a02567f87d2cdbd622fbc89d","text":"False. AMIs must be copied to another region. One cannot simply share them.","correct":true},{"id":"f827cf462f62848df37c5e1e94a4da74","text":"True","correct":false},{"id":"f8320b26d30ab433c5a54546d21f414c","text":"False","correct":false},{"id":"129cfa3cabe8c0069adacf27b64e1022","text":"True, but only if you have sufficient permissions.","correct":false}]},{"id":"4fa7de17-2f03-4b83-a519-e00b011ca644","domain":"security-comp","question":"You are a SysOps Administrator for your organzation. The organization has one AWS account that all users share. You are asked by the CISO to make access to AWS secure and manageable. What would be the best solution?","explanation":"AWS Single Sign-On makes it easy to centrally manage access to all of your AWS accounts. It supports Security Assertion Markup Language (SAML) 2.0 so you don't have to create IAM users for every individual in your organization. The other solutions would be an administrative and unnecessary burden, while encrypted login credentials using KMS is not used for AWS access.","links":[{"url":"https://docs.aws.amazon.com/en_pv/singlesignon/latest/userguide/iam-auth-access.html &https://docs.aws.amazon.com/cli/latest/reference/sts/assume-role-with-saml.html","title":"AWS Single Sign-On"}],"answers":[{"id":"678d5bab1e8e14c5f9a7055f83d2aa56","text":"Set up an AWS Organization to manage accounts and apply permissions boundaries. Set up IAM users and group them in the appropriate OU.","correct":false},{"id":"48371df9efaa3423dc8c9153f0af03c3","text":"Group Active Directory users and mirror their permissions with IAM policies. Create IAM users in AWS and group them into IAM groups that correspond to the Active Directory Group.","correct":false},{"id":"b18f21a1b9a12f45b180d3ba09d175a0","text":"Configure a SAML federation between AWS and your organization's Active Directory. Set up Active Directory groups with AWS IAM groups to manage user permissions.","correct":true},{"id":"0949ef9615ffc62f343f10d27d0bea2e","text":"Encrypt Active Directory logins using AWS KMS. Store encrypted logins in an RDS table. When users access AWS, set up permissions to decrypt the credentials to securely access AWS resources.","correct":false}]},{"id":"466da628-4a01-43da-ba82-90215f555b37","domain":"data-man","question":"A mobile application which runs its backend data storage and processing in AWS experienced an outage last night.  According to AWS there was scheduled maintenance on a number of EC2 instances in your VPC.  You should have caught this but you did not.. Your company recently invested in Business Support for your Production account.  As a SysOps engineer you have been asked to ensure that planned maintenance on AWS services that affect you, as well as known outages in the region, are logged into your IT department ticketing system.  The notifications should be in a human-readable format.  Which services will help you to do this in an efficient manner?","explanation":"AWS Health is an API service which provides programmatic access to AWS health events for Business and Enterprise Support customers.  CloudWatch Events allows you to intercept AWS Health events, and has the ability to convert a Health event into human-readable format by performing transforms on the properties of the Health event.  AWS SNS allows the transformed events to be delivered to a variety of destinations including HTTP endpoints, or via email in order to integrate into your ticketing systems.","links":[{"url":"https://docs.aws.amazon.com/health/latest/ug/what-is-aws-health.html","title":"What is AWS Health?"},{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/CloudWatch-Events-Input-Transformer-Tutorial.html","title":"Tutorial: Use Input Transformer to Customize What is Passed to the Event Target"}],"answers":[{"id":"c500e0084c698c714d39fa45e73c194f","text":"AWS Health, CloudTrail and AWS Simple Notification Service","correct":false},{"id":"f9118d24e7ab0d46eccea1c43f5db58d","text":"AWS Personal Health Dashboard, CloudTrail and AWS Lambda","correct":false},{"id":"cb52f85bdee5c92ebdded1c692c43685","text":"AWS System Status, CloudTrail and SES","correct":false},{"id":"ab911b3e904a12c5461f69cab52931d4","text":"AWS Health, CloudWatch Events and AWS Simple Notification Service","correct":true}]},{"id":"5dddbe8f-a62f-4692-b8a5-61e1ff70f722","domain":"high-avail","question":"You run a popular desktop application which is hosted on a fleet of EC2 instances behind an autoscaling group. After three years you are about to release version 9, which millions of people have been waiting for with excitement. When you released version 8, 8 years ago your website crashed from the demand. You need to prevent this from happening on this release. What AWS service could you use to assist with this?","explanation":"CloudFront works together with your website and speeds up delivery of your content by caching it at Edge Locations local to your users","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/HowCloudFrontWorks.html","title":"CloudFront"}],"answers":[{"id":"52c99d94be86aed6ff572f5dd85fc5c9","text":"Use AWS Shield to protect the software update from too many users attempting to download it at once","correct":false},{"id":"3ea178bab502b44ed89d0a22b2fcfa78","text":" Host the update on a single T2 nano instance on EC2 and publish the public IP address to your customers to download","correct":false},{"id":"e994c20e96f7f92075129815a13774c3","text":"Host the update in AWS Aurora and turn on Aurora Accelerator to keep pace with the demand","correct":false},{"id":"e5e2e10e37ff47a42272a2c0335fca65","text":"Use Cloudfront to cache the software update at Edge Locations so as to keep up with the demand","correct":true}]},{"id":"e05ee44b-cd10-4658-9853-ff5cea9c9d32","domain":"automation","question":"The company has started experiencing deployment issues due to the increasing complexity of the application and the lack of a structured testing and release process. The DevOps team of the company plans to set up a continuous integration pipeline in AWS to improve the stability of the releases and through the enforcement of the use of automated tests. The Head of DevOps has been instructed to use managed services as much as possible to reduce the maintenance overhead of the continuous integration pipeline. How can the DevOps team accomplish this?","explanation":"CodeBuild and CodePipeline are managed services that can be used to easily build a continuous integration pipeline. CodeBuild can run the tests and CodePipeline can manage the pipeline steps for the CI testing and deployment pipeline. Given that managed services are preferred, running Jenkins in an EC2 instance is not the priority option. AppSync is for building GraphQL powered APIs and is not used for continuous integration pipeline requirements.","links":[{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/how-to-create-pipeline.html","title":"Use CodePipeline with CodeBuild to Test Code and Run Builds"}],"answers":[{"id":"4c32bcc37cbaab42d77738b8b6875d19","text":"Use AppSync and CodeBuild for the continuous integration pipeline.","correct":false},{"id":"ce1176f044958de744d567d7ac7d0534","text":"Use Jenkins in an EC2 instance and AWS Step Functions for the continuous integration pipeline.","correct":false},{"id":"6574dc863e2d0855e66841be7aee54e7","text":"Use CodeBuild and CodePipeline for the continuous integration pipeline.","correct":true},{"id":"8adba880488851800b50283a6de55215","text":"Use Jenkins in an EC2 instance and CodePipeline for the continuous integration pipeline.","correct":false}]},{"id":"55e3410c-cf36-4a46-948a-95e2440003fd","domain":"mon-rep","question":"You are running an Application Load Balancer (ALB) in front for a fleet of web servers running on EC2. These servers are in a public subnet. Your customers connect to the ELB domain name to access web servers using HTTP. You want to know your customers' IP addresses to gain metrics into where your customers are located. This information will be helpful for improving your application based on the location of your customers. How would you collect log data for your ELB?","explanation":"The X-Forwarded-For request header helps you identify the IP address of a client when you use an HTTP or HTTPS load balancer. Because load balancers intercept traffic between clients and servers, your server access logs contain only the IP address of the load balancer. Elastic Load Balancing stores the IP address of the client in the X-Forwarded-For request header and passes the header to your server. If you were using TCP protocol (rather than HTTP), no additional configuration would be needed. CloudTrail is not appropriate as it only shows data regarding API requests sent within your AWS account. CloudWatch and Lambda would be an administrative burden and are not necessary.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html","title":"HTTP Headers and Classic Load Balancers"}],"answers":[{"id":"c790427146d378ddfcfb7c4e0821a00c","text":"No additional configuration is needed. The proxy protocol will pass the client IP automatically, and you can check the ELB logs to find this information.","correct":false},{"id":"ee23873239420b48da4e1d7e54294f34","text":"Enable CloudWatch logs for your application and push the logs to a custom CloudWatch metric. Use Lambda to parse through the log files to search and extract the client IP addresses into a DynamoDB table.","correct":false},{"id":"0fcaa257260dc2e705852935fcc43979","text":"Modify the application code to pull the client IP into the X-Forwarded-For header so the web servers can parse the information.","correct":true},{"id":"db95fed268eaf12b5b9c069f8256be2f","text":"Enable CloudTrail on your ELB and push the logs to an S3 bucket. Search the logs using Athena or download them as a CSV to identify the IP addresses of your customers.","correct":false}]},{"id":"1de9eb98-4b61-4178-b30f-68d5d6422439","domain":"mon-rep","question":"You need to monitor application-specific events every 10 seconds. How can you configure this?","explanation":"you need to configure a custom metric to handle application specific events and if you want to monitor at 10 second intervals, you need to use high-resolution metrics. Detailed monitoring reports metrics at 1 minute intervals.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html","title":"CloudWatch Custom Metrics"}],"answers":[{"id":"f3e15ffbefd8415dda26321a2912dca1","text":"Select detailed monitoring in CloudWatch","correct":false},{"id":"da902bf148db5983868bf3383162183a","text":"Select high-resolution metrics in CloudWatch","correct":false},{"id":"8625460160031630c52a466b7a91f16b","text":"configure a high-resolution custom metric in CloudWatch","correct":true},{"id":"886f04b8880657a2d07a12c6355639a7","text":"Configure the application to send notifications using SNS every 10 seconds","correct":false}]},{"id":"f58e7b6a-5516-478d-a844-e4608b1f806f","domain":"data-man","question":"A new employee has accidentally deleted an important file from S3. What's the best way to recover from accidental deletions like this in the future?","explanation":"Enabling versioning is the simplest way. Versioning provides the ability to recover from both unintended user actions and application failures. You can use versioning to preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket. Deleting a file from a versioning-enabled bucket simply sets a delete marker which can be removed to recover the file.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/undelete-objects.html","title":"How do I undelete a deleted S3 object?"}],"answers":[{"id":"dc44c1c88bef6b1b4ddafd1f22a12289","text":"Enable cross-region replication on the S3 bucket to backup the objects to a different region.","correct":false},{"id":"253efe32850426ce32c509612536c798","text":"Enable versioning on the bucket.","correct":true},{"id":"d31598f049bfcd9b0c8bd1da569ee7bb","text":"Write a Lambda function that copies the objects periodically to a backup bucket.","correct":false},{"id":"dc2505a1fd1d3de79b0541ff7bc80d43","text":"Write a Lambda function that copies the objects periodically to a backup EBS volume.","correct":false}]},{"id":"374ba54c-c9fb-4438-92d0-b002e0cd8e58","domain":"data-man","question":"An application has an Aurora single-master cluster as its database. As users keep growing, there are more and more read requests to the database and throughput is nearing capacity. You need to increase the read capacity of the database to ensure the user experience is not impacted as user numbers continue to grow. Which of the following options is the most appropriate to address the read capacity issue?","explanation":"There are two ways to scale Aurora MySQL DB instances, instance scaling and read replica scaling. As the read capacities increase, Aurora Replicas should be added. A single-master Aurora DB cluster can have up to 15 Aurora Replicas and they can offload read workloads from the primary DB instance. Unlike DynamoDB, there is no Accelerator feature for Aurora. There is not option to modify a DB instance to be Read optimized, it is either a Primary DB instance or a Read Replica DB instance. CloudFront also does not help as CloudFront distribution cannot configure an Aurora cluster endpoint as its origin.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Managing.Performance.html","title":"Aurora read replica"}],"answers":[{"id":"1b8cb94dc108c58fe7bc5ee63f8ee45a","text":"Configure several Read Replicas in the Aurora cluster to share the read traffic.","correct":true},{"id":"5b235156cd7d71262846409b34661073","text":"Enable Aurora Accelerator for the cluster.","correct":false},{"id":"53a2145209a8955575577b2e91e93aeb","text":"Modify the DB instance class for each DB instance in the DB cluster to be a read optimized one.","correct":false},{"id":"b1780d2940a1e174629e1c00182059ad","text":"Configure a CloudFront distribution with the Aurora cluster endpoint as the origin.","correct":false}]}]}}}}
