{"data":{"createNewExamAttempt":{"attempt":{"id":"cdf641cf-5226-4014-8f20-8563668e8729"},"exam":{"id":"a39a7a1c-8175-4eb5-b276-4d379f30b7c2","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"62d8dc77-c233-45c2-a957-5d33339eab6e","domain":"Performant","question":"When reviewing Auto Scaling events, it is noticed that an application is scaling up and down multiple times per hour. What design change could you make to optimize cost while preserving elasticity?","explanation":"Modifying your scaling threshold is preferable to altering your number of instances manually.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/as-instance-termination.html","title":"Auto-scaling Thresholds"}],"answers":[{"id":"375c182a3d055fd5c0423b9ae48f006a","text":"Add a Provisioned IOPS volume to the instance.","correct":false},{"id":"7ef405f3ad8fb6e5ab62fdb296690514","text":"Change the scale-down CloudWatch metric to a higher threshold.","correct":true},{"id":"efe86514d63b2cddf4fff0701f7625e8","text":"Increase the number of instances in the Auto Scaling group.","correct":false},{"id":"e8210fd4c78d4a3776a601bbefdec9e3","text":"Change the Launch Configuration to use a larger instance type.","correct":false}]},{"id":"126e898c-dd73-4447-b5a7-59701a16a92d","domain":"ResilientDesign","question":"You are reviewing Change Control requests and you note that there is a proposed change designed to reduce errors due to S3 Eventual Consistency by updating the 'DelaySeconds' attribute. What does this mean?","explanation":"Poor timing of SQS processes can significantly impact the cost effectiveness of the solution.","links":[{"url":"http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"464400e5333b3beab1128b1b1f7cedf7","text":"While processing a message, a consumer instance can amend the message visibility counter by a fixed amount.","correct":false},{"id":"4b46d6ad9dd090f0143cc40fecbad7b5","text":"When a new message is added to the SQS queue, it will be hidden from consumer instances for a fixed period.","correct":true},{"id":"6e5b2857717c8cf5b2722dc270183515","text":"While processing a message, a consumer instance can reset the message visibility by restarting the preset timeout counter.","correct":false},{"id":"f170b98804f18cb00b57e135f0a3f116","text":"When the consumer instance polls for new work, the consumer instance will wait a certain time until it has a full workload before closing the connection.","correct":false}]},{"id":"006ec6f2-1540-4cfe-b08c-1ca53ead39b9","domain":"ResilientDesign","question":"An Amazon EC2 instance is part of an Amazon EC2 Auto Scaling group. You want to reboot an instance without Amazon EC2 Auto Scaling terminating it due to a health check failure. What are the suitable options available to reboot an instance in an Auto Scaling group in such circumstances?","explanation":"To Reboot an Instance that is in Auto Scaling group, safely turn the Instance into Standby state so that Auto Scaling will not perform Health Checks. Another option is to detach the instance from the Auto Scaling group, complete the reboot and then reattach to the Auto Scaling Group. Finally, another alternative is to temporarily suspend the health check process. Suspending the health check process affects monitoring of all instances in an Auto Scaling group. Until Auto Scaling is resumed, Amazon EC2 Auto Scaling will not replace any unhealthy instances. Deleting the Auto Scaling Group will set the maximum and minimum value to zero and as a result the instances part of ASG will be terminated.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/reboot-autoscaling-group-instance/","title":"Autoscaling Instance Reboot"}],"answers":[{"id":"c007187e9d7b4fab169929539672954e","text":"Put the instance into the Standby state, reboot the instance and return the instance to service in the Auto Scaling group","correct":true},{"id":"c99d27c2bcca9f203966edc777d1bb1e","text":"Delete the CloudWatch Logs from where the health check status is collected","correct":false},{"id":"d66bf3b7154a0725f08d76e7bd7a6bfe","text":"Delete the Auto Scaling Groups and then restart the instances as they are not part of any Auto Scaling group","correct":false},{"id":"24b084eff4d9b8cf5e41ec744b14984f","text":"Detach the instance from the group, reboot the instance and reattach the instance to the Auto Scaling group","correct":true},{"id":"cd149f119240a36cffc5bf48d82e5d3f","text":"Suspend the health check process temporarily and after reboot resume the suspended process","correct":true}]},{"id":"09223b1a-2169-4791-94b1-9ecf1716c8eb","domain":"Performant","question":"Which of the following AWS services store data as key-value pairs?","explanation":"Both DynamoDB and S3 use key-value pairs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html","title":"Working With S3 Objects"},{"url":"https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs","title":"DynamoDB Data Models"}],"answers":[{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false}]},{"id":"57ee57eb-5b47-45ff-8c95-42b35bb8e719","domain":"ResilientDesign","question":"A Multi-AZ RDS deployment will automatically fail-over as a result of which two of the following?","explanation":"Amazon RDS detects and automatically recovers from the most common failure scenarios for Multi-AZ deployments so that you can resume database operations as quickly as possible without administrative intervention. Amazon RDS automatically performs a failover in the event of any of the following: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, Storage failure on primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"Failover Process for Amazon RDS"}],"answers":[{"id":"7ecc550bc4f7f4c4d01c334d359bb0d9","text":"Loss of availability in standby Availability Zone","correct":false},{"id":"7b75b57dbe879950151e7a40cf0aed41","text":"A region-wide loss of service","correct":false},{"id":"8851c500044adfe0ba4a247acdb86eda","text":"Loss of network connectivity to the Primary","correct":true},{"id":"215b7e6d7f48e4225c06a3c50bf400d2","text":"Loss of availability in primary Availability Zone","correct":true}]},{"id":"793e017d-b2b4-4b0b-a7ed-d3b202410562","domain":"Performant","question":"In the event that you need customers to send you files to go into S3, but want to minimize the time take to upload them.  Which options will help you?","explanation":"It is possible to expedite uploads from the Internet to S3 by writing directly to an Edge Location.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html","title":"S3 Transfer Acceleration via Edge Locations"}],"answers":[{"id":"64ddfa92db48b3459937294e09d15938","text":"Create an S3 bucket in each region and use cross region replication to collate all the objects.","correct":false},{"id":"c344016cabbd89af452f461db9e4b465","text":"Make use of S3 Transfer Acceleration.","correct":true},{"id":"ea475dc430e3465eafb86f308790483f","text":"Make use of Lambda@Edge to intercept the uploads and redirect them via S3 Transfer Acceleration.","correct":false},{"id":"836966f15450f5e37095e8e0bce1f2df","text":"use CloudFormation to create Direct Connect connection with a large dedicated bandwidth pipe.","correct":false}]},{"id":"27f1f472-2ea9-43e0-b75d-6be01c620049","domain":"CostOptimized","question":"You have a website that allows users in third world countries to store their important documents safely and securely online. Internet connectivity in these countries is unreliable, so you implement multipart uploads to improve the success rate of uploading files. Although this approach works well, you notice that when an object is not uploaded successfully, incomplete parts of that object are still being stored in S3 and you are still being charged for those objects. What S3 feature can you implement to delete incomplete multipart uploads?","explanation":"You can create a lifecycle policy that expires incomplete multipart uploads, allowing you to save on costs by limiting the time non-completed multipart uploads are stored.","links":[{"url":"https://aws.amazon.com/blogs/aws/s3-lifecycle-management-update-support-for-multipart-uploads-and-delete-markers/","title":"S3 Lifecycle Management - Incomplete Multipart Uploads"}],"answers":[{"id":"86d93427d74df0b30713341818e3d556","text":"S2 Reduced Redundancy Storage","correct":false},{"id":"ee966c2ebd84a4f7add1d9ceabe082c9","text":"Have S3 trigger DataPipeling Auto-delete.","correct":false},{"id":"5ff7e884d027004938c218aafa63c215","text":"S3 Lifecycle Policies","correct":true},{"id":"bc5e8477b1dde2747a8cb281160b01f7","text":"Have CloudWatch trigger a Lambda function that deletes the S3 data.","correct":false}]},{"id":"7240e60f-f337-4116-be42-8df912212cfd","domain":"Performant","question":"What is the minimum time interval granularity for the data that Amazon CloudWatch receives and aggregates?","explanation":"The minimum time interval for CloudWatch is 1 minute.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch.html","title":"CloudWatch - Detailed Monitoring"}],"answers":[{"id":"4adcc26418f545df76ab44c53fc55702","text":"5 minutes","correct":false},{"id":"3d393dc956fea776f25db075df639cb1","text":"30 seconds","correct":false},{"id":"70abb32fcb0c9e8194526d1eef15eb05","text":"10 minutes","correct":false},{"id":"f77eb9f1b917ba78f6eb2ce8ede0a0e4","text":"1 minute","correct":true}]},{"id":"c232c020-d1d3-4b31-91c9-e8906b3fe973","domain":"Performant","question":"A business productivity service would like to add an online chat platform to their offerings. Their customer base is made up primarily of large multi-national corporations. These corporations will need to be able to include users in multiple countries in real-time chats. Static content for the application will reside on Amazon S3 and chat orchestration will be hosted on Amazon EC2 with Elastic Block Store volumes. Which architecture will provide the best performance efficiency for the chat platform?","explanation":"CloudFront supports WebSockets to establish persistent connections, which provide lower latency for real-time communications. Origin behaviors specify which origin satisfies which type of content request (ex. all .jpg files), not which origin servers to use. Route 53 is not needed, because requests for CloudFront content are automatically routed to the edge location with the lowest latency. Using ElastiCache to cache at the storage level may result in some efficiency, but leveraging CloudFront's Edge locations at the network level will provide the greatest performance gains.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-working-with.websockets.html","title":"Using WebSocket with CloudFront Distributions"}],"answers":[{"id":"06a06760d361cbafcca4c47d8ab93c8e","text":"Have clients use HTTP upgrade semantics to establish WebSockets connections with CloudFront distributions","correct":true},{"id":"3cdc4a0838e007f3a5500a2b555b9a73","text":"Leverage ElastiCache to manage in-progress chat conversations in-memory, and write conversation history to EBS volumes later","correct":false},{"id":"49d904e69d2f386dc05917de19119370","text":"Use a Route 53 latency routing policy to send traffic to the lowest latency CloudFront Edge location","correct":false},{"id":"00539fd580f87a3d665dfe784d08d459","text":"Create a CloudFront distribution with origin behaviors that point to chat servers in the regions where the clients reside","correct":false}]},{"id":"c07cbbaf-7a26-44d9-9e50-86908c1ac754","domain":"ResilientDesign","question":"A football scoreboard app uses an AWS Lambda backend to retrieve game information stored in an Amazon DynamoDB database. An EC2 instance reads multiple Amazon Kinesis streams of scores and stats and writes them to the database. Two app users sitting side-by-side at a restaurant refresh the scoreboard at the same time and get different stats for the same game. What should the app developers do to resolve this?","explanation":"DynamoDB is eventually consistent by default, and may not reflect the results of a recently completed write since data is automatically replicated across three facilities in an AWS region for durability. You can request strongly consistent reads that reflect all previous writes. Consolidating Kinesis streams probably won't help since Kineses producers are generally singular data sources (all stats of a specific type will come from one producer). Replacing Lambda with EC2 will have cost consequences, and in this case will probably result in an undesirable stateful architecture. Timestamp information will not resolve an eventual consistency issue.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadConsistency.html","title":"DynamoDB Read Consistency"}],"answers":[{"id":"a8da8441084c1a5b79e47be3f6f98a0d","text":"Have the Lambda function perform a strongly consistent read from the database","correct":true},{"id":"95bc7fe6a012dc37b025c1cb8fe566e7","text":"Replace Lambda with an EC2 instance that synchronizes reads of the data with database updates","correct":false},{"id":"c606fec0599df4127dba2d5df85a283f","text":"Store score and stat updates timestamps in the database to ensure the most recent information is served by the Lambda backend ","correct":false},{"id":"c151deab4b337fd8377eed0413d50903","text":"Consolidate the Kinesis streams into a single stream to avoid writing different results to the database","correct":false}]},{"id":"79861610-5123-41e0-b0ff-52cee5365540","domain":"SecureSolutions","question":"You are about to encrypt the data in your S3 buckets, and you need a solution to enable the use of a customer master key (CMK) as an added layer of protection against unauthorized access. In addition, this solution must provide you with an audit trail that shows you when and who used the CMK. Which of the following choices denote this type of encryption?","explanation":"Generally speaking, SSE is actually correct. However, the question is asking for a specific type of server-side encryption. SSE-S3 is another possible answer, since it encrypts the objects in the S3 buckets and Amazon S3 manages the encryption keys. However, the CMK and audit trail attributes are missing from this choice. With SSE-KMS, you get the CMK addition for added protection, as well as the audit trail, which is why SSE-KMS is the right answer. SSE-C is not the right choice because you, rather than Amazon, would manage the keys.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting Data Using Server-Side Encryption"},{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html","title":"Server-Side Encryption: Using SSE-KMS"}],"answers":[{"id":"9b7e6d7280803d9f9a6072b4421611fc","text":"Server-Side Encryption with Customer-Provided Keys (SSE-C)","correct":false},{"id":"772996341baeebbfac39d70e8ed5a300","text":"Server-Side Encryption with AWS Key Management Service (SSE-KMS)","correct":true},{"id":"c76bcbd057118544ba0ccb76a8a22e46","text":"Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)","correct":false},{"id":"a8d0fb2ecae10336e81eec65375a4abe","text":"Server-Side Encryption","correct":false}]},{"id":"f3e923a2-2e1a-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You want to track the amount of money you ideally want your company to spend for EC2 data transfers every month. Which of the following actions will accomplish that?","explanation":"AWS Cost Explorer is for providing information that you can use to track and manage costs, but it doesn’t enable the creation of budgets; that’s what AWS Budgets is for. If the question was strictly addressing cost, then creating a Cost budget with AWS Budgets would have been the correct answer. However, your concern is specifically with a usage type, which is EC2 data transfers. In this case, you would need to create a Usage budget with AWS Budgets and receive alerts when your defined threshold is met.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/budgets-managing-costs.html","title":"Managing Your Costs with Budgets"}],"answers":[{"id":"4407cc58412e1c4727ad336bd8b8453f","text":"Create a Reservation budget with AWS Budgets.","correct":false},{"id":"e7f799a3bc73b229cd75d773a9d7f547","text":"Create a Usage budget with AWS Budgets.","correct":true},{"id":"41e006394cc745a90a25e57065b658c2","text":"Create a Cost budget with AWS Budgets.","correct":false},{"id":"8d35bf16b7d263f4ab864e392d023e54","text":"Enable AWS Cost Explorer","correct":false}]},{"id":"ac606721-1133-4438-8a6f-ec7bc24443ed","domain":"SecureSolutions","question":"Your organization has a custom VPC, but you've just discovered that one of your developers has created an RDS instance in the default VPC (in violation of company policy.) You need to re-create this RDS instance inside your custom VPC with as little effort as possible. What should you do?","explanation":"The easiest way would be to take a snapshot of the DB Instance in the Default VPC and restore it to your custom VPC by specifying the DB Subnet Group you want to use.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RestoreFromSnapshot.html","title":"Restoring (or moving) From a Snapshot"}],"answers":[{"id":"7a4d78c86de0e51b5dbc37976fdf85cb","text":"Use the RDS Import/Export Wizard to Migrate the RDS instance across to the custom VPC.","correct":false},{"id":"71ae0650c202e7da315185fadebdec02","text":"Use the command 'aws rds mv dbname < VPC'.","correct":false},{"id":"c04f8f858073c4a62ff00a4eff9386dc","text":"Use AWS Database Migration Service.","correct":false},{"id":"4997ddcea578c38851dfd6681dc85500","text":"Take a snapshot of your DB Instance in the default VPC and restore it to VPC by specifying the DB Subnet Group you want to use in your custom VPC.","correct":true}]},{"id":"c487c002-443f-4d86-bdde-a915adb7924d","domain":"ResilientDesign","question":"You have chosen to use S3 - OneZone-IA with your cloud application. Which limitations have you considered in doing so?","explanation":"In exchange for a significant cost savings, 1Zone-IA has the same Durability as S3, but a lower Availability SLA.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/?nc=sn&loc=3","title":"S3 Storage Classes"}],"answers":[{"id":"a86f1cf2d99a9643587b837f464b5ef8","text":"1Zone-IA offers only 99.50% availability. Therefore you have to design your application to re-create any objects that may be temporally unavailable.","correct":true},{"id":"e0a1c69e07da2a370da0dedf28084491","text":"1Zone-IA offers only 99.50% durability. Therefore you have to design your application to re-create any objects that may be lost.","correct":false},{"id":"3ffe3458e13ccc426e49a1893b78a3f3","text":"1Zone-IA has a 3 - 5 hour data recovery windows.","correct":false},{"id":"4068f35933f215b2818a03234567736a","text":"1Zone-IA requires supplementary Access Control Lists.","correct":false},{"id":"bcddbe2d89ec46d45172296d890040c3","text":"1Zone-IA is available only in the US-STANDARD region.","correct":false}]},{"id":"5c841746-5aea-4a32-8a87-65b78fb0184b","domain":"ResilientDesign","question":"You want to use an AWS service that can monitor your EC2 instances and automatically recover it if it becomes impaired. Which of the following automation tools will enable you to do so?","explanation":"Using a CloudWatch alarm, you can monitor your EC2 instance and automatically recover it if it becomes impaired. Elastic Beanstalk is for deploying and managing web applications, Auto Scaling is for automatically scaling your resources up or down, and Lambda can be set up to automatically execute a function on a regular schedule. None of these tools, however, are used for auto EC2 recovery.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html","title":"Recover Your Instance"}],"answers":[{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":true},{"id":"afd14eb3f151c84e6ef7ab63812b4fbc","text":"Auto Scaling","correct":false},{"id":"bcf6eb183b7da148701bcc059a34675f","text":"AWS Elastic Beanstalk","correct":false},{"id":"dee7ff8f7b10b9d388c7c561e9413b0d","text":"AWS Lambda","correct":false}]},{"id":"62c40f57-a8f9-4280-849b-34440bbcbef9","domain":"SecureSolutions","question":"Which of the following is an invalid VPC peering configuration?","explanation":"Edge-to-edge routing is not allowed through a VPN connection.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html","title":"Invalid VPC Peering Connection Configurations"}],"answers":[{"id":"2fa2fe643e096fd3d938fa5cd569209f","text":"You have a VPC peering connection between VPC A and VPC B. VPC A also has a VPN connection to a corporate network. You use VPC A to extend the peering relationship to exist between VPC B and the corporate network so that traffic from the corporate network can directly access VPC B by using the VPN connection to VPC A.","correct":true},{"id":"63722d8924a7b714eb8a8000961ebf13","text":"VPC A has peering connections to VPCs B and C. All three VPCs are in the same AWS account, and there are no overlapping CIDR blocks.","correct":false},{"id":"808626de978678cbd8fba9cdf7ede572","text":"You have peered three VPCs in a full-mesh configuration. The VPCs are in the same AWS account and do not overlapping CIDR blocks.","correct":false},{"id":"ebd4315b15afc456004798c874243bf9","text":"You have a VPC peering connection between VPCs A and B. They are in the same AWS account, and they do not have overlapping CIDR blocks.","correct":false}]},{"id":"7dd78d8f-4ef3-4d55-941a-c6e865c5ab7c","domain":"Performant","question":"Using the AWS Server Migration Service, what's the maximum number of volumes that can be attached to a VMs during a SMS migration job?","explanation":"At this writing, a VM can only have 22 virtual volumes during the SMS replication job.","links":[{"url":"https://aws.amazon.com/server-migration-service/faqs/","title":"AWS Server Migration Service - FAQ"},{"url":"https://docs.aws.amazon.com/server-migration-service/latest/userguide/prereqs.html","title":"AWS Server Migration Service - limits"}],"answers":[{"id":"0cae09dcea866a75f21e4e0d07a2ebc5","text":"only limited by the OS","correct":false},{"id":"b6d767d2f8ed5d21a44b0e5886680cb9","text":"22","correct":true},{"id":"6364d3f0f495b6ab9dcf8d3b5c6e0b01","text":"32","correct":false},{"id":"c74d97b01eae257e44aa9d5bade97baf","text":"16","correct":false}]},{"id":"da14a91d-ff38-4ee2-976e-87ab89ed2b57","domain":"Performant","question":"You are attempting to move data from one EBS volume to a duplicate volume in a separate region. Which of the following methods will do this best?","explanation":"After you've created a snapshot and it has finished copying to Amazon S3, you can copy it from one AWS region to another, or within the same region.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-copy-snapshot.html","title":"Copying an EBS Snapshot"}],"answers":[{"id":"2d58342b23166c9f5556bbe76440bd28","text":"Move the data to S3 and enable cross-region replication.","correct":false},{"id":"cf0d4fd3cb2d1497b6e5699ec4ee8ed5","text":"Take a snapshot of the EBS volume and copy it to the desired region.","correct":true},{"id":"f1ce9b0c80209553a22ede320d2ce91f","text":"Use a Linux tool like rsync to sync the volume to the other region.","correct":false},{"id":"7ed5cf49719e006c801d0e6fe0f4cf7e","text":"Allow a VPC peering connection to pull the data over.","correct":false}]},{"id":"ae6654da-753e-498d-a2ea-b1e21e295fa7","domain":"Performant","question":"You are considering moving an on-premise SQL Server cluster into AWS, using EC2 instances rather than RDS.  You need to recommend the most suitable EBS volume type for the cluster to use, but also pair it with a suitable EC2 instance type.  You know that the throughput must be good, but the most important thing is to maintain a consistent level of IOPS under normal load which can increase to a much higher level at busy times.  Choose the best option from the following EC2 and EBS pairings.","explanation":"The question states that you require consistent IOPS which means the io1 Provisioned IOPS type is the best choice of the two EBS types available, and therefore the correct answer must have io1 as an option.  Of the remaining two answers, either EC2 families would work.  We know from experience that databases do utilise as much memory as is available, so choosing an r5 family is plausible, however we need to use our extended knowledge of EC2 families to know that X1e was specifically created to run high performance databases and the final answer will therefore contain an io1 EBS volume and the X1e EC2 option.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"Amazon EC2 Instance Types"},{"url":"https://aws.amazon.com/ebs/features/","title":"Amazon EBS features"},{"url":"https://aws.amazon.com/blogs/database/new-memory-optimized-amazon-ec2-instance-types-drive-database-workloads/","title":"New, Memory-Optimized Amazon EC2 Instance Types Drive Database Workloads"}],"answers":[{"id":"78c33d688d1822c44c657b33bb0e5080","text":"Throughout Optimised (st1) EBS volumes with c5 EC2 instances","correct":false},{"id":"27e1d3ca80c5e8a728f7916a73f98ec4","text":"Provisioned IOPS (io1) EBS volumes with X1e EC2 instances","correct":true},{"id":"7b472a990561e6ad0996ca48c955594b","text":"Provisioned IOPS (io1) EBS volumes with r5 EC2 instances","correct":false},{"id":"b28dd6770d9036a2f719c5f4cfc7cecc","text":"Throughout Optimised (st1) EBS volumes with X1e EC2 instances","correct":false}]},{"id":"60257524-46b9-4fd3-9de7-a7febd7b0199","domain":"SecureSolutions","question":"With SAML-enabled single sign-on, ________.","explanation":"To see the process by which federated users are granted access to the AWS console, please follow the link, below.","links":[{"url":"http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_enable-console-saml.html","title":"Federated User Access to the AWS Console"}],"answers":[{"id":"78e79272b9f462f911e8226704695628","text":"After the client browser posts the SAML assertion, AWS sends the sign-in URL as a redirect, and the client browser is redirected to the Console.","correct":true},{"id":"2687603c9611a7e796998f6cbe63e321","text":"The client browser is immediately directed to the AWS Console.","correct":false},{"id":"3c951c75981deee0dc3b3d1d6f75a03b","text":"The portal first verifies the user's identity in your organization, then generates a SAML authentication response.","correct":true},{"id":"3a567201818696fafbfc66b46325647b","text":"The portal acknowledges a SAML authentication response, then verifies the user's identity in your organization.","correct":false}]},{"id":"cbcc2938-15ec-4a2f-bb94-1fefe41f3efe","domain":"Performant","question":"You have an RDS database that has high performance OLTP workloads. Which storage medium would be best to accommodate these requirements?","explanation":"Amazon RDS Provisioned IOPS (SSD) Storage would be the most suitable.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS","title":"RDS Provisioned IOPS for OLTP Workloads"}],"answers":[{"id":"e774a96af9adfaa2402148c9828271e7","text":"Amazon RDS Magnetic Storage","correct":false},{"id":"4d548ff7278077c929b63c67f768cc97","text":"Amazon RDS Provisioned IOPS (SSD) Storage","correct":true},{"id":"0db6de47eed9671e44098c2117fe8916","text":"Amazon RDS Cold Storage","correct":false},{"id":"a257df0abf37db5da9b921f8222eab2a","text":"Amazon RDS General Purpose (SSD) Storage","correct":false}]},{"id":"8c8d1581-f004-4d00-a8a0-503b69a1f4d7","domain":"Performant","question":"You've migrated a legacy workflow application that is written in Java 1.4 from an on-prem server to a single M5 EC2 instance configured in an auto scaling group with a max-size of 1 across multiple AZs in the Asia Pacific (Sydney) region. It periodically checks a database for new and updated records and sends out email notifications. In the logs, you see frequent timeout errors. What could be a possible cause and how can you fix this?","explanation":"Amazon EC2 throttles traffic on port 25 of all EC2 instances by default, but you can request for this throttle to be removed or change to another port. In this example, you are not using SES and therefore, its endpoints or sending limits are irrelevant.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-port-25-throttle/","title":"How do I remove the throttle on port 25 from my EC2 instance?"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-connect.html","title":"Connecting to the Amazon SES SMTP Endpoint"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/regions.html","title":"Regions and Amazon SES"},{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-issues.html","title":"Amazon SES SMTP Issues"}],"answers":[{"id":"385f853c6ca8754ad8dc4289fd42413e","text":"The app uses the standard JavaMail API on port 25. Amazon EC2 throttles traffic on that port of all EC2 instances by default, but you can request for this throttle to be removed.","correct":true},{"id":"3d9ae95c23fe7b09220f12c62ff95f17","text":"Amazon SES Endpoints are only available in the US East (N. Virginia), US West (Oregon) and EU (Ireland) regions. You cannot migrate your legacy app until SES becomes available in Australia.","correct":false},{"id":"8a122c9945f5b1a081e098fdeadc94fe","text":"You might have reached your Amazon email sending limits. To increase that, open a Sending Limit case in the AWS Support Center.","correct":false},{"id":"cdf61badb6564eb5121bb15b0dba57d6","text":"You change an application properties file and update the currently used port from 25 to 2587, build a new AMI with that new version and configure your launch configuration to use that.","correct":true}]},{"id":"24984439-79ad-4ddd-874e-0cf8800affa0","domain":"Performant","question":"You are running a Cassandra database that requires access to tens of thousands of low-latency IOPS. Which of the following EC2 instance families would best suit your needs?","explanation":"High I/O instances use SSD-based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require tens of thousands of IOPS.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/#highio-instances","title":"High I/O Instances"}],"answers":[{"id":"00ce754caeddc3589b864a8e5d665fe7","text":"High I/O instances","correct":true},{"id":"750fc21187d18139777ca329bb74df13","text":"Memory Optimized Instances","correct":false},{"id":"5a09e6d2f372cf15511772f8f380afc0","text":"Dense Storage Instances","correct":false},{"id":"5cd383d698034a613d2efaeb78ade93d","text":"Cluster GPU Instances","correct":false}]},{"id":"326ac44a-0b23-4dd1-81ac-621dbb971905","domain":"Performant","question":"Your company is using S3 as their data layer. There are many requests which include read/write and updates in a bucket. Users complain that sometimes updates to an object are not being reflected. Which of the following could be the cause for this?","explanation":"Updates to a single key are atomic. For example, if you PUT to an existing key, a subsequent read might return the old data or the updated data, but it will never return corrupted or partial data.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html#ConsistencyModel","title":"S3 Data Consistency Model"}],"answers":[{"id":"7852138aa2d80b36ebd5034989991e05","text":"Updates are being made to the same key for the object.","correct":true},{"id":"f76f97e992466b0cabc5c5fccf0e2d9d","text":"Versioning is disabled, so the newer version does not reflect the changes.","correct":false},{"id":"51a0b779ee243096d09f03dccad3347b","text":"The metadata for the S3 bucket is configured incorrectly.","correct":false},{"id":"451122675986310201ea8c2585c6dd41","text":"Encryption is enabled, making it take longer for the updates to be processed.","correct":false}]},{"id":"bccba3fe-36b1-4122-a4d9-dbdaced2250a","domain":"Performant","question":"Your supervisor wants you to specifically record the configuration changes of all the EC2 instances in the environment. Which of the following AWS services will do that?","explanation":"It can be easy to confuse Config and CloudTrail, since both are AWS management-and-governance tools. However, they operate differently. While CloudTrail provides event history of your AWS account activity, Config specifically focuses on listing the resources in your AWS account and presenting their configuration change history.","links":[{"url":"https://aws.amazon.com/config/","title":"AWS Config"}],"answers":[{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":false},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":false},{"id":"621f4719cc9f27432c4c095f76df474e","text":"Amazon GuardDuty","correct":false}]},{"id":"2e18aaa7-7622-4c21-bf16-6b98fe813f7b","domain":"ResilientDesign","question":"You want to receive notifications of when an endpoint fails an Amazon Route 53 health check of your domain. Which of the following services can you combine to make that possible?","explanation":"You can set up a Route 53 health check to monitor the health of your AWS resources, such as a web server, by entering the domain name. You can configure the health check to trigger a CloudWatch alarm when Route 53 detects that the endpoint is unhealthy. CloudWatch then uses SNS to notify users. Although SQS is a messaging service just like SNS, it is for queueing messages","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html","title":"How Amazon Route 53 Checks the Health of Your Resources"}],"answers":[{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":true},{"id":"f7be29c9a4de2fe0c3ced5ca83552403","text":"Amazon Simple Notification Service (SNS)","correct":true},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":false},{"id":"64fdb9de34f1179f1b0a667717e6fba3","text":"Amazon Simple Queue Service (SQS)","correct":false}]},{"id":"70c6a808-0d5d-40d3-9b62-aa2fd031a543","domain":"CostOptimized","question":"You have three AWS payer accounts consolidated under an AWS Organization . Which of the below statements is TRUE for purposes of volume discounts?","explanation":"If you have multiple accounts, your charges will decrease because AWS combines usage from all accounts in the organization to qualify you for volume pricing discounts.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html","title":"Consolidated Billing for Organizations"}],"answers":[{"id":"4fb1af36b069dca73268eedbfab53e7b","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled at the Organisation level","correct":false},{"id":"a6cd99e8b1bbcfc82e184acc9f28eede","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled in each account","correct":false},{"id":"98e718508cd32b9ffb27d8648e9129d0","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to","correct":true},{"id":"c9c2416d95c8112070b7a5b032629fdf","text":"Usage in each account will be evaluated individually to determine the volume discount it is individually entitled to","correct":false}]},{"id":"45e476bb-914a-494b-a3ed-6a57d68834cc","domain":"Performant","question":"Which of the following statements are not true?","explanation":"The only true statement is, 'EBS Volumes cannot be attached to an EC2 instance in another AZ.'' The rest are false.","links":[{"url":"https://aws.amazon.com/ebs/faqs/","title":"Amazon EBS FAQs"}],"answers":[{"id":"0f5ef7da503dad208ed5566a512c9dff","text":"EBS Volumes cannot be attached to an EC2 instance in another AZ.","correct":false},{"id":"7d8d06380f34e4060b3476b81305d7c4","text":"EBS Volumes can be attached to an EC2 instance in another AZ","correct":true},{"id":"2230ea44df7ed2404367921661c19f87","text":"EBS st1 Volumes can be attached to multiple instance simultaneously.","correct":true},{"id":"d7ba5007ee3ffff8826902a82cc7f083","text":"EBS Volumes are ephemeral.","correct":true}]},{"id":"1ae7d81d-4a88-4b2c-8a24-0d23a0b398ca","domain":"Performant","question":"Your company provides an online image recognition service that uses SQS to decouple system components. Your application polls the image queue as often as possible to maximize end-to-end throughput. However, you notice that polling in tight loops is burning CPU cycles and increasing costs with empty responses. How can you reduce the number of empty responses?","explanation":"Long polling will reduce the number of CPU cycles and empty responses, saving you money.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-long-polling.html","title":"SQS Long Polling"}],"answers":[{"id":"fb3af9891cf5d5aceb09ff3b42d07fc9","text":"Enable long polling by setting the ReceiveMessageWaitTimeSeconds to a number > 0","correct":true},{"id":"36d85400100c2ac53783d07f58a9f76d","text":"Enable short polling by setting ReceiveMessageWaitTime = 0.","correct":false},{"id":"aa392ba36a0e879990027e26535b999d","text":"Use AutoScaling to increase the number of instances polling the queue.","correct":false},{"id":"e9986a49c81acbbab4e10ed024c85a46","text":"Enable short polling by setting ReceiveMessageWaitTime > 0.","correct":false}]},{"id":"7589448c-e00c-4c64-9d5f-04e10ac556e4","domain":"CostOptimized","question":"An enterprise is planning to move its on-premise application to AWS cloud. The enterprise planned to build the non-production applications first as a proof of concept, and the governance team has provided approval for downtime for a brief period if cost can be compensated. You recommend spot instances as this satisfies the scenario explained above. Do vCPU limits apply when requesting a spot instance?","explanation":"Amazon EC2 is transitioning on-demand instance limits from the current instance count-based limits to vCPU-based limits to simplify the limit management experience for AWS customers. Beginning September 24, 2019, customers can opt in to vCPU-based instance limits. Count-based instance limits will not be available or supported after November 8, 2019. The vCPU-based limits only apply to running on-demand instances and does not apply when purchasing reserved or spot instances.","links":[{"url":"https://aws.amazon.com/ec2/faqs/","title":"Amazon EC2 compute service features"}],"answers":[{"id":"9bfb4cfa201ec7e2242c7df2c0d39906","text":"vCPU limits apply to spot instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false},{"id":"1fe04947ca4403eb3588fb87310de29e","text":"vCPU limits apply to reserved instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false},{"id":"34394b797e4a477511982b1ac4a38d19","text":"vCPU limits apply only to on-demand instances and do not apply for spot instances.","correct":true},{"id":"a4fb94942aaa43d251b18a4126ce6d18","text":"In AWS, only instance count based limits exist and there is no concept of vCPU limits.","correct":false}]},{"id":"922ca882-d73b-4685-acf4-7c0827021c2b","domain":"ResilientDesign","question":"The customer service organization at your company just told you that a client purchase from your website was processed twice. Your order process involves EC2 instances processing messages from an SQS queue. What changes might you make to ensure this does not happen again?","explanation":"An SWF workflow ensures that actions are executed only once.","links":[{"url":"https://aws.amazon.com/documentation/swf/","title":"SWF Documentation"}],"answers":[{"id":"ae73003f30fc75b349d6c7e1407060ca","text":"Switch to long-polling.","correct":false},{"id":"da3af33124cb0627efe41ca5c7617ddf","text":"Increase the visibility timeout on the SQS queue.","correct":false},{"id":"bacf185330f80f745f66f02bab85053a","text":"Manually delete the order after processing.","correct":false},{"id":"24e1d12f9d1b3de53719bbd5341fbdf1","text":"Rewrite the order-processing workflow to use SWF, rather than SQS.","correct":true}]},{"id":"a5ddd74e-3d62-4d40-a3f0-a23812c15053","domain":"SecureSolutions","question":"You must encrypt all incoming and outgoing traffic between your AWS environment and your customers. Your fleet of EC2 instances lives inside a public subnet and behind an elastic load balancer. Your application is very CPU intensive, and you want to minimize the processing load these EC2 instances must bear. What should you do?","explanation":"The best answer would be to offload your SSL decryption to an Elastic Load Balancer.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/introduction.html#classic-load-balancer-overview","title":" SSL on Classic Load Balancers"},{"url":"https://aws.amazon.com/blogs/aws/new-application-load-balancer-sni/","title":"SSL on Application Load Balancers"}],"answers":[{"id":"3555c67311aafdc06664adfe2aeb2bd1","text":"Use API Gateway to offload the SSL certificate, reducing the amount of load on both your ELB and EC2 instances.","correct":false},{"id":"40d910c6e8118f8cf78ae1cfa0fe7f7f","text":"Install the SSL certificates on each EC2 instance and allow them to do the encryption/decryption with your customers.","correct":false},{"id":"7586d736b703b1462d09b4f190a26f6f","text":"Install the SSL certificates on your ELBs so that there is less load on the EC2 instances.","correct":true},{"id":"59b594b61e296360b3b9eafcbfc28437","text":"Configure a NAT and install the EC2 instance on that NAT so that you offload SSL termination to a third party EC2 instance and not your production environment.","correct":false}]},{"id":"1024766e-2157-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"When setting up the properties of an S3 bucket, which of the following options should you select to track storage cost?","explanation":"You need to label your S3 buckets with tags to track their storage costs. AWS will use the tags to organize costs in a cost allocation report. Object-level logging is for using AWS CloudTrail to record object-level API activity, server access logging is for logging requests for access to the bucket, and versioning is for keeping all versions of an object in the same bucket - not for tracking costs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/CostAllocTagging.html","title":"Using Cost Allocation S3 Bucket Tags"}],"answers":[{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false},{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":false},{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":true},{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":false}]},{"id":"2ad5b0b6-36ed-43f0-9464-2c438e5d3e76","domain":"ResilientDesign","question":"Over the past month the production environment made up of Classic Load Balances and an autoscaling web farm has failed to scale up resulting in massive disruption during the early morning peak load. Your engineering team do not want to be alerted about every change but agree that they should receive relevant SNS alerts for customer impacting problems. Which of the following are appropriate autoscaling SNS alerts to send?","explanation":"AWS are completely transparent about he fact that systems will fail and you need to design for failures. there are four standard SNS alerts of which the LAUNCH_ERROR is the is the most important for being aware of impending customer impacting problems. The offered ELB Errors are CloudWatch metrics not built in SNS notifications.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html","title":"Auto Scaling Groups"},{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/ASGettingNotifications.html","title":"Autoscaling SNS notifications."},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-cloudwatch-metrics.html","title":"CloudWatch Metrics for Your Classic Load Balancer"}],"answers":[{"id":"965b81ae140ff5103117c17a9f69e13b","text":"autoscaling:EC2_INSTANCE_LAUNCH_ERROR","correct":true},{"id":"aac32c743fd98355a24d9989737e40b5","text":"autoscaling:EC2_INSTANCE_LAUNCH","correct":false},{"id":"abc6e1c7ee610d21427d2f9354cf3a94","text":"autoscaling:EC2_INSTANCE_TERMINATE","correct":false},{"id":"d04f697bc72c89bc10704e46aa085b2a","text":"autoscaling:ELB_SPILL_OVER_COUNT_ERROR","correct":false},{"id":"89a683aa5c68153ea037ac7daf704a13","text":"autoscaling:EC2_INSTANCE_TERMINATE_ERROR","correct":false},{"id":"99c3fbb9dd68cd0e89c066e4489c56d6","text":"autoscaling:ELB_SURGE_QUEUE_LENGTH_ERROR","correct":false}]},{"id":"3dc35381-00ad-4390-a31b-23a8340f4d57","domain":"SecureSolutions","question":"A co-employee approaches you with the need to access DynamoDB tables consisting of raw web analytics data to complete a required document on your company’s Data Warehouse processes. This is the only time in which the employee needs to access this information, and he needs such access for this day alone. What is the most appropriate course of action?","explanation":"Documenting your company’s Data Warehouse processes is a required task, so you simply can’t refuse access to the DynamoDB tables. However, it must be done in a way that does not risk the access of data by unauthorized users. That definitely rules out giving the employee your user credentials. And while you can simply create an IAM user, this action is for people who need continued and constant access; this employee only needs information from the database within a one-day window. Ultimately, the best course of action is to assign the appropriate IAM role to the employee to access the tables for this day, then remove the role assignment.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/authentication-and-access-control.html","title":"Identity and Access Management in Amazon DynamoDB"}],"answers":[{"id":"dd83c17dcfcf3b3acbb7200de7c2b473","text":"Give the employee your user credentials.","correct":false},{"id":"890c7f1c8bb33b06433d48f55f6a49d5","text":"Assign the appropriate IAM role to the employee to access the tables.","correct":true},{"id":"2b88f12405ab69024649b137e9e3ff74","text":"Refuse access to the tables.","correct":false},{"id":"5cf22da28e8e107eaa66dc1f724a6e34","text":"Create an IAM user for the employee to access the tables.","correct":false}]},{"id":"6a9be830-9658-4f9f-a5ea-518038423adb","domain":"ResilientDesign","question":"You're running an application that needs to be highly available in eu-west-1. In order for this application to function correctly,  9 related EC2 instances must running at all times. Which of the following deployments provides the ability to meet the requirements should an AZ go down and is the most cost optimized solution?","explanation":"Should an AZ go down, only the answers of 5,5,5 or 6,6,6 or 9,9,0 would meet the requirement of having 9 EC2 instances up, with the most cost optimized being the answer with 15 total EC2 instances.","links":[{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Cost-Optimization-Pillar.pdf","title":"Cost Optimization Pillar - AWS Well-Architected Framework"},{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Reliability-Pillar.pdf","title":"Reliability Pillar - AWS Well-Architected Framework"}],"answers":[{"id":"6d68ff6a6b53ca045964ee07faeeab96","text":"5 EC2 instances in eu-west-1a, 5 EC2 instances in eu-west-1b, and 5 EC2 instances in eu-west-1c.","correct":true},{"id":"640aac80e904b262d7fadd12c44a5802","text":"9 EC2 instances in eu-west-1a, 9 EC2 instances in eu-west-1b, and no EC2 instances in eu-west-1c.","correct":false},{"id":"23ed0726519369cf6068f29abb57e8e7","text":"3 EC2 instances in eu-west-1a, 3 EC2 instances in eu-west-1b, and 3 EC2 instances in eu-west-1c.","correct":false},{"id":"3c730af5a3243511e706f8068c1afc8c","text":"6 EC2 instances in eu-west-1a, 6 EC2 instances in eu-west-1b, and 6 EC2 instances in eu-west-1c.","correct":false}]},{"id":"e44a6772-240a-4c67-af0a-1119285833f9","domain":"ResilientDesign","question":"The large manufacturing company you work for is interested in moving their production estate to AWS. They run a Joomla store which utilizes MySQL on the back end. Currently, they also use clustered MySQL databases in an active/passive configuration at a single site. In moving to AWS, they want an active/passive configuration across 2 geographically distinct locations, with automatic failover between the two. As their solutions architect, which of the following RDS options should you recommend?","explanation":"To automatically failover from one geographic location to another you should use Multi-AZ for RDS.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/#Failover_conditions","title":"RDS Failover Conditions"}],"answers":[{"id":"b1e142eeffe2e60520001a47e8ea488d","text":"RDS with Cross Region Failover","correct":false},{"id":"955edcbe47cfada50233bc45752305b7","text":"RDS with Cross Region Replication","correct":false},{"id":"c1d3dc1d00857a4c8a41667c4089187c","text":"RDS Read Replicas","correct":false},{"id":"57513d6064870e41de997c1e161825c7","text":"RDS Multi-AZ","correct":true}]},{"id":"1f0f9717-876a-4bb8-954b-aaf22341de42","domain":"SecureSolutions","question":"You need to enable SSH remote connectivity to an EC2 instance in your AWS environment from a remote PC with IP 130.194.52.28. The EC2 instance is in a public subnet with an assigned public IP and the NACL rules already enable SSH connectivity. Which of the following is the most secure way to configure the instance’s Security Group?","explanation":"As security groups are stateful, to enable connectivity to the EC2 instance from a remote PC you only need to define an INBOUND rule. Once the Inbound connection is established, outbound connectivity is allowed, therefore answers with outbound rules are incorrect. The most secure configuration is to allow only the specific remote PCs IP address IN on port 22. It is NOT advisable to allow inbound Port 22 from any device.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups for Your VPC"}],"answers":[{"id":"cc24113553ebdfe466a6f9cebcca2ae3","text":"Inbound: Allow SSH (Port 22) from 0.0.0.0/0 \\n Outbound: Allow ALL Ports To 0.0.0.0/0","correct":false},{"id":"7ff22bed410d419cce536fba059b1c8f","text":"Inbound: Allow ALL Ports from 130.194.52.28/32 \\n Outbound: Allow ALL Ports to 130.194.52.28/32","correct":false},{"id":"d037560d28a612a64cc8779c242342af","text":"Inbound: Allow SSH (Port 22) from 130.194.52.28/32","correct":true},{"id":"e8db63151589b254c79e001cda4a9c5c","text":"Inbound: Allow SSH (Port 22) from 0.0.0.0/0","correct":false},{"id":"ce4ef70d7e0a6c5e9eb256dd2b9f74f0","text":"Inbound: Allow SSH (Port 22) from 130.194.52.28/32 \\n Outbound: Allow SSH (Port 22) to 130.194.52.28/32","correct":false}]},{"id":"00be4bb5-a556-48d8-a95c-cac6852e76ba","domain":"CostOptimized","question":"You are operating a popular TV Show news website using a static site generator (SSG) with the resulting HTML pages being served from S3. The vast majority of pages are less than 85 KB in size. After 60 days, new episode page access drops off significantly. Which of the following statements are true?","explanation":"Similar to the STANDARD storage class, STANDARD_IA objects are available for millisecond access.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html","title":"Storage Classes"}],"answers":[{"id":"a32b993ff0fa61fd0da4533f7fc8f1be","text":"Using the STANDARD_IA storage class, Amazon S3 charges you for 128 KB per object if it is less than 128 KB in size.","correct":true},{"id":"b84620799ba94f53d53c1aa19f69bb8a","text":"While objects in the STANDARD storage class are available for millisecond access, accessing STANDARD_IA objects is slightly slower.","correct":false},{"id":"ff55b529dbaaea1355acdc097ad29298","text":"The ONEZONE_IA storage class is as durable as STANDARD_IA, but it is less available and less resilient.","correct":true},{"id":"0c8d66b9d1503b991d171f09f8943ee1","text":"Using the STANDARD_IA storage class, these older pages are stored redundantly across 3 or more geographically separated facilities.","correct":true}]},{"id":"7dafc126-8f93-4ac8-97ba-01818de79dc1","domain":"SecureSolutions","question":"As a junior Cloud Engineer, you receive a CloudWatch alarm indicating that there might be a layer 7 attack of your environment. You recall that your company has an AWS Shield Advanced subscription. Which of the following options is the best response?","explanation":"You *can* investigate and mitigate the DDoS attack on your own, so that is a potentially correct answer. Similarly, requesting internal assistance is another possible answer because of your tech lead’s expertise. However, the best course of action is to take advantage of your AWS Shield Advanced subscription, which routes you to true DDoS experts. In this case the *most correct* answer is to work with AWS Support. Doing nothing should never be considered as an answer.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-responding.html","title":"Responding to DDoS Attacks"}],"answers":[{"id":"e13ab7a7dcc291aa8a8f5e4e1c3a8646","text":"Do nothing; it is an AWS issue that will resolve itself.","correct":false},{"id":"0b9ac6496fca4f50d60b7665f91d9209","text":"Investigate and mitigate the attack on your own.","correct":false},{"id":"43d522d2e9a722af4df45616e09e2ff4","text":"Contact AWS Support Center.","correct":true},{"id":"b62d821db1c6397935c957ddd8214d47","text":"Request assistance from tech lead.","correct":false}]},{"id":"3b0354a2-8cf6-47da-9653-d39e9a2b6777","domain":"ResilientDesign","question":"The company you work for has been acquired and you have been tasked with the redirection of all its website traffic to the new company's website. The old one is hosted on S3 as a static website while the target is a self-hosted website. Which of the following options describes the best approach to achieve that as quickly as possible?","explanation":"Although other listed options are feasible, the quickest way to achieve the desired outcome is to set up a redirect at the S3 bucket level.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/how-to-page-redirect.html","title":"(Optional) Configuring a Webpage Redirect"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"Hosting a Static Website on Amazon S3"}],"answers":[{"id":"26160870cff1bf371f535d8988240c46","text":"In the Amazon S3 console, configure a redirect to the new domain in the 'Redirect requests: Target bucket or domain' box within the 'Static website hosting' section under the Properties tab of the relevant bucket.","correct":true},{"id":"bf5117b1a38008012872c692deb1b8cc","text":"In the Amazon S3 console, set the website redirect location in the metadata of each object in the relevant public bucket. You can do so by specifying the new domain as the value of the 'Website-Redirect-Location' key within the 'Metadata' section under the Properties tab.","correct":false},{"id":"62281fa5145f01f72a905dbfbb919615","text":"Amazon S3 static website hosting supports only redirects to other AWS S3 buckets but not to external URLs. Therefore, you should set up a redirect to a new bucket with a single HTML file in it that uses client-side scripting (window.location.ref and a 'refresh' http-equiv meta tag) for the redirect to the new domain.","correct":false},{"id":"a0baa3a3691b6288e36546a1b852accc","text":"Amazon S3 does not support website redirects. You will need to contact your domain registrar and ask them to update the target URL to point to the self-hosted website.","correct":false}]},{"id":"1679cf82-e083-4fb5-99d2-70a94c74d087","domain":"SecureSolutions","question":"You are using a key pair named EC2-Web-Access to gain access to your EC2 instances in the US-EAST-1 region, and are about to create some instances in the US-EAST-2 for the first time. You want to keep using the same key pair to access these new instances - what do you need to do to accomplish this?","explanation":"Key pairs are stored per-region, therefore the key pair will not exist in the US-EAST-2 region. You cannot automatically \"share\" keys between regions through the console so this is not a valid option. Similarly, uploading the private key is not relevant. This leaves importing the public key for use in the new region as the only valid option.","links":[{"url":"https://aws.amazon.com/blogs/aws/new-amazon-ec2-feature-bring-your-own-keypair/","title":"New Amazon EC2 Feature: Bring Your Own Keypair"}],"answers":[{"id":"8e22081522129e8f7956f5d4b8608b0c","text":"Share the key pair with US-EAST-2 and select it during instance creation","correct":false},{"id":"c57307d0446130e85696bdd0056385ef","text":"Import the public key into US-EAST-2 and select it during instance creation","correct":true},{"id":"9de651ff2567fff8e414c2ec78d3ba42","text":"Upload the private key during the EC2 Instance Creation wizard","correct":false},{"id":"3378ef2641344654b55143259b8ce045","text":"Select EC2-Web-Access as the key pair during instance creation","correct":false}]},{"id":"c2e05533-6321-46fa-a778-47c27ca274d5","domain":"CostOptimized","question":"Your co-worker is about to create a new EC2 instance, and would like to know from what point your company will be billed for it. You tell them that it will be billed from: ","explanation":"In EC2, Instance-hours are  billed only for time your instance is in the \"Running\" state.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-instance-hour-billing/","title":"Instance-Hour Billing"}],"answers":[{"id":"c40f2931153694959f22d5efc95b2a45","text":"When it is in the \"Running\" state","correct":true},{"id":"61b5406c1efb94f47d6a875a56ac05c4","text":"When it is in the \"Stopped\" state","correct":false},{"id":"92f171915935cf43d7367038a0ceb076","text":"When it is in the \"Pending\" state","correct":false},{"id":"6672e2e78662b895923af9d5f73207be","text":"When it is in the \"Provisioned\" state","correct":false}]},{"id":"f26af436-9d46-43c4-bc90-7102c73af3c5","domain":"SecureSolutions","question":"You are creating a new website where users will be able to login using their facebook, google and amazon.com credentials. You need to deploy this website as quickly as possible and you are looking for an AWS service that will enable you to deploy the authentication quickly. Which AWS service should you use?","explanation":"Cognito is a service that can authenticate users via federated Identity Providers, and assign them manage access to AWS resources based on your policies.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/external-identity-providers.html","title":"Identity Pools (Federated Identities)"}],"answers":[{"id":"a095c741ced0e0849b29ce2600af29b0","text":"Cognito with Identity Pools (Federated Identities) External Identity Providers","correct":true},{"id":"8a1c4d12f4eb4126267c40d270d264c4","text":"IAM with Microsoft Active Directory Authentication","correct":false},{"id":"5de42305de3cd44564a54719deb43a37","text":"Amazon Authentication Zero","correct":false},{"id":"e402520d8999ab859a1625c0012ecb4a","text":"Identity Access Management with Open Connect","correct":false}]},{"id":"40bd28c9-dee5-42d8-bc1b-1822db4e5243","domain":"ResilientDesign","question":"An enterprise has a large customer base and sends marketing emails (such as special offers and discounts), transactional orders (such as order confirmations) and correspondence emails (such as newsletters) to all customers. They engaged you to set up an email platform that provides an easy and cost-effective way to send and receive emails using their own email address and domains, and also wanted to set email auto-responders and email unsubscribe systems. Which AWS service below best matches the requirement?","explanation":"Amazon Simple Email Service (Amazon SES) is a highly scalable and cost-effective service for sending and receiving email. Amazon SES eliminates the complexity and expense of building an in-house email solution or licensing, installing, and operating a third-party email solution. Amazon WorkMail is a suite of office tools which help manage daily email workflow. With WorkMail, it is not possible to send transaction email or email newsletters. Amazon WorkMail uses Amazon SES to send and receive mail.","links":[{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/sending-email.html","title":"Setting up Simple Email Service"}],"answers":[{"id":"09e915452f715da52789fa62d9dd5291","text":"Amazon Simple Email Service","correct":true},{"id":"224510290621b43664ba1741744d7c57","text":"Amazon Active Directory Email Service","correct":false},{"id":"ca50f9e142e8d3e5e8fa73cf07d1a437","text":"Amazon Integrated Email solution","correct":false},{"id":"f25bb6e1bd825ac7b88a0340c5d8f4ec","text":"Amazon WorkMail","correct":false}]},{"id":"d5462fb3-227a-4285-8a77-8672c8558693","domain":"CostOptimized","question":"Your AWS environment in us-east-1 contains several EC2 instances with associated RIs dedicated to a project that has just been canceled. You need to recoup the cost of these reserved instances, and you need to preserve the data for future use. What can you do to minimize charges for these instances?","explanation":"You should preserve the data by taking snapshots of the EBS volumes backing your instances and sell the RIs on the Reserved Instance Marketplace.  Remember the Reserved Instances is both a Capacity reserve, and a Billing discount.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"About EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html","title":"Selling on the Reserved Instance Marketplace"}],"answers":[{"id":"8cf9e85628c02261b9bbc22141dba658","text":"Stop the instances and retain them for future use.","correct":false},{"id":"8a56365b62c17d312312ea07efd07dc1","text":"Contact AWS and ask them to release you from your Reserved Instance purchase.","correct":false},{"id":"9dda53fcc86762b17e493dad51eb121a","text":"Take snapshots of the EBS volumes and terminate the instances.","correct":true},{"id":"79ac46c5a0e1356d35f90962f478b6cb","text":"Sell the unused reservations on the AWS Reserved Instance Marketplace.","correct":true}]},{"id":"096baab8-06c7-4b07-8e86-ba304b41102f","domain":"CostOptimized","question":"After migrating an application architecture from on-premise to AWS, you will not be responsible for the ongoing maintenance of which two of the following services.","explanation":"DynamoDB and Amazon RDS are managed services. As such, AWS handles the ongoing maintenance.","links":[{"url":"https://aws.amazon.com/rds/details/","title":"About RDS"},{"url":"https://aws.amazon.com/dynamodb/details/","title":"About DynamoDB"}],"answers":[{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true}]},{"id":"bdfff765-ad59-45a9-9e3c-605a3d2ad9d7","domain":"ResilientDesign","question":"You have been asked to set up an EFS storage solution for a project team.  Which of the following tasks do you need to complete ?","explanation":"It is necessary to set up the bi-directional network permissions, normally with Security Groups. You will connect the EFS Target to your EC2 instance with a 'mount' statement. You do not need to stipulate the size or format the volume. AWS provide a nominally unlimited file system ready for you to use.  As normal under the shared security model AWS will ensure that the EFS system is secure, but you are responsible for the access control security inside the EFS file space provided to you.","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html","title":"EFS - How It Works"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/limits.html","title":"EFS limits"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/security-considerations.html","title":"EFS Security"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/accessing-fs-create-security-groups.html","title":"EFS Security Groups"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/wt1-getting-started.html","title":"Mounting and EFS target"}],"answers":[{"id":"9a0eabcd19e62a99932848808a473c0f","text":"mount EFS vol to your EC2 instance using 'mount -t nfs -o xxxx '.","correct":true},{"id":"30f2e62c04d187f6e6f58e730e462680","text":"Configure a Security Group to allow admin traffic on port 22 to connect to the EFS system.","correct":false},{"id":"8388b16ddec8dec25d6caba4dbe7f8cb","text":"specify and provision disk capacity on the EFS system using 'fdisk' and 'mkfs -t xfs'.","correct":false},{"id":"9bc552892ca2c2c5be9e7c352fc0cdc8","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EC2 server.","correct":true},{"id":"417164507c199eb8b0fb1daa3bae285c","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EFS target","correct":true},{"id":"7f41c759c946659e0ef49f87f6684503","text":"Set Linux file system permissions on the presented EFS volume using 'chmod' and 'chown'.","correct":true}]},{"id":"e62d3927-3172-4d89-a2f2-b70a62da50d7","domain":"CostOptimized","question":"What are the key instance attribute variables that determine reserved instance price?","explanation":"Reserved instances provide significant savings on Amazon EC2 costs compared to on-demand instance pricing. Reserved instances are not physical instances, but rather a billing discount applied to the use of on-demand instances in your account. These on-demand instances must match certain attributes, such as instance type and region, in order to benefit from the billing discount. A reserved instance has four instance attributes that determine its price. They are Instance Type, Scope, Tenancy, Platform. The attributes also determine how the reserved instance is applied to a running instance in your account.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","title":"Reserved Instance Attribute"}],"answers":[{"id":"8f1f69be4b7932f83f66e28cfee82568","text":"Instance Type, Scope, Tenancy, Network","correct":false},{"id":"f7925fb10a7a695858fd864c7a5ba10b","text":"Instance Type, Usage/Load, Tenancy, Network","correct":false},{"id":"e5a48e08950e10c8e11c7de25d41b2ae","text":"Instance Type, Scope, Tenancy, Platform","correct":true},{"id":"6650ae9522d5793a5a4f0818eba78ed6","text":"Instance Type, Usage/Load, Tenancy, Platform","correct":false}]},{"id":"9fc041cf-1305-46e0-9851-bbf11b320f3c","domain":"Performant","question":"You need to develop an infrastructure that can be replicated and deployed in another AWS Region in a matter of minutes. Which AWS service might you use to build a reproducible, version-controlled infrastructure?","explanation":"AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"About CloudFormation"}],"answers":[{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"c0f075697e6a50da6356e4718f5a1de0","text":"CloudWatch Template","correct":false},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"d8d0959d6dfc410044ed02441ee86c96","text":"EC2 AMIs with EBS snapshots","correct":false}]},{"id":"1131af07-2a70-4e76-9964-1c8c8ff48627","domain":"ResilientDesign","question":"You've been tasked with setting up an S3 solution to store large amounts of critical data. With high availability and fault-tolerance in mind, what further safeguards should you implement to protect your data in the event that an entire AZ became unusable?","explanation":"S3 is designed to be regionally redundant through replication between data centres (for most classes). The exception is the  S3-OneZone-IA class which is NOT replicated and therefore would be at risk if a whole AZ became unavailable.","links":[{"url":"https://aws.amazon.com/s3/","title":"About S3"},{"url":"https://aws.amazon.com/s3/storage-classes/","title":"About S3 , S3 One Zone-IA"}],"answers":[{"id":"20de218abe483588a9454b83bc8ef9ac","text":"Use One Zone-IA class to take advantage of it's unique replication configuration.","correct":false},{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"77dabb1c3a140e4601e6911ff822ebd3","text":"Deploy a gateway-stored AWS Storage Gateway.","correct":false},{"id":"222cdf6bec04850773a7236508610daf","text":"Nothing if you use the correct storage class.","correct":true},{"id":"01126a45eebb74981a7a80fc3dabf48d","text":"Use lifecycle policies to copy the data to Glacier.","correct":false}]},{"id":"232e5218-23ae-49a3-b865-c44f4aa3c430","domain":"SecureSolutions","question":"You have just created a new IAM role called US-S3-Access using the GUI at \"https://console.aws.amazon.com/iam/home?region=us-east-1#/roles\". This role grants access to the a bucket called ec2-temp-storage254 which was created in the us-east-1 region. One of your colleagues wants their EC2 instance in us-east-2 region to access this bucket - how can this be accomplished","explanation":"IAM is a global service, and therefore objects created in one region are available in all regions. Although S3 buckets are created and stored in a specific region, they are accessible globally - therefore the correct answer is to attach the existing role to the instance - this will grant the instance access to the bucket. There is no need to create a new role, and there is no such setting as multi-region access on roles.","links":[{"url":"https://aws.amazon.com/iam/faqs/","title":"IAM FAQ"}],"answers":[{"id":"dedf1276f190146139ebc76212f15edb","text":"Enable multi-region use for the role, attach it to the instance","correct":false},{"id":"057599d3b676dc5e3f4a5284f641c5ca","text":"Create a new role in the us-east-2 region that grants access to the bucket, and attach it to the instance","correct":false},{"id":"1a108ea83cc5a71b33fe8e2455e7fd37","text":"Attach the existing role to the EC2 instance","correct":true},{"id":"320c9d5e32dfe1dce4ea215892e1d7fe","text":"This cannot be done as the EC2 instance and S3 bucket are in different regions","correct":false}]},{"id":"b6275c5c-1ac1-4382-9ee0-540d5b7e499a","domain":"SecureSolutions","question":"A contract management application stores its content in Amazon Simple Storage Service. The documents are encrypted with AWS Key Management Service keys. A security engineer imports a new Customer Master Key, manually rotates the keys, and deletes the previous key. The IT service center begins to receive calls that those trying to retrieve older contracts are receiving 'data inaccessible' errors. What needs to be done to resolve the issue?","explanation":"KMS supports keeping older versions of imported keys available, but in this case, the security team neglected to do so. Unfortunately, the contract documents need to be re-encrypted. AWS does not offer a KMS Sync operation or a KMS Restore capability. KMS won't be able to tie a re-imported key back to the older documents.","links":[{"url":"https://aws.amazon.com/kms/","title":"AWS Key Management Service (KMS)"},{"url":"https://aws.amazon.com/kms/faqs/","title":"AWS Key Management Service FAQs"}],"answers":[{"id":"ebe28348d4f30f69bfa81ccded9bae95","text":"Re-encrypt the contract documents with the new Customer Master Key","correct":true},{"id":"ab06ac4163b2759feeed0c0255c614fc","text":"Perform a KMS Sync operation to align all of the documents with the new Customer Master Key","correct":false},{"id":"cd5e0e6c549884e3e0c9aa1630412b3c","text":"Re-import the previous key into KMS and rotate the keys again","correct":false},{"id":"ce9a8e2d9aba9a5b8e82432d3220852e","text":"Perform a KMS Restore to re-establish the relationship between older contract documents and the previous key","correct":false}]},{"id":"fb005f63-f7ec-4219-a509-0be9a1c6177a","domain":"ResilientDesign","question":"You are migrating a production website to AWS. The site will be using EC2, Application Load Balancers and RDS Multi-AZ across 3 AZs. You need a minimum of 6 EC2 instances at any given time and your site must be able to tolerate the loss of 1 Availability Zone. What is the most cost effective way of meeting these requirements?","explanation":"S3 Sta xxxxxxxxxxxxx.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html","title":"Benefits of Auto Scaling"},{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html","title":"Autoscaling with Multi-AZ ELB"}],"answers":[{"id":"59e343895f33803418aeb6c89a533c09","text":"2 instances in 2 Availability Zones each.","correct":false},{"id":"23c83f5eec11b24316a37be4ab4fcd44","text":"3 instances in 2 Availability Zones each.","correct":false},{"id":"90b873045418d59670454ca34ccb08c6","text":"6 instances in 3 Availability Zones each.","correct":false},{"id":"2cdc460773914fca2de6ff43f23e52f7","text":"3 instances in 3 Availability Zones each.","correct":true}]},{"id":"55eaf278-bf1a-404e-8263-42f36c83fbf3","domain":"Performant","question":"As a Cloud Engineer, you have been tasked to create many EC2 instances in three availability zones to deploy software that indexes web content. This software program does so with integrated crawlers to significantly improve search performance. Your Team Lead has strongly recommended choosing an EC2 instance type that provides low latency, incredibly high random I/O performance, and high sequential read throughput. Which of the following instance types is best suited for this application?","explanation":"IOPS, latency, and throughput are essential metrics for measuring storage performance. Therefore a storage-optimized EC2 instance is what you would need. The i3.2xlarge type is storage-optimized, with the root volume configured to 1 TB.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types"}],"answers":[{"id":"c39169d62a23aac2e5896f19e2e31505","text":"p3.2xlarge","correct":false},{"id":"05c25e549fbb3f158f12a9945bff38ee","text":"t3.medium","correct":false},{"id":"d6c756c3ad88241444ff9f5d58543014","text":"c5.large","correct":false},{"id":"1d4f2c610dbeb44e7ba09fed19564c76","text":"t2.micro","correct":false},{"id":"dfec39bedb7ca4d2ecc77b437fba1fe9","text":"i3.2xlarge","correct":true}]},{"id":"8b4f4f4a-0f1e-420a-9115-3ddde644cecc","domain":"Performant","question":"Your application's has a rapid upscale and usage peaks at 90% during the hours of 9 AM and 10 AM everyday. All other hours require only 10% of the peak resources. What is the best way to scale your application so you're only paying for max resources during peak hours?","explanation":"Proactive cyclic scaling is scaling that occurs at a fixed interval (daily, weekly, monthly, quarterly. The proactive approach can be very effective when the upscale is large and rapid and you cannot wait for the delays of a sequence of auto-scaling steps.)","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/schedule_time.html","title":"Scheduled Scaling"}],"answers":[{"id":"6acf192ec915189144dfc5769ea5905a","text":"Reactive event-based scaling","correct":false},{"id":"d08473e23d73d31785239196c7ef5064","text":"Proactive cyclic scaling","correct":true},{"id":"1c8add13dc251f42618a5622a1a04714","text":"Reactive cyclic scaling","correct":false},{"id":"00464894fd00bf415d119e5a89bd61a4","text":"Proactive event-based scaling","correct":false}]},{"id":"37bacf63-a62f-4f99-a0b0-6bf9bf5a5210","domain":"CostOptimized","question":"You have a series of websites hosted in AWS. You need to ensure that users from Europe are directed to www.my-gdpr-site.com for regulatory purposes. What could help accomplish this?","explanation":"Geolocation routing lets you choose the resources that serve your traffic based on the geographic location of your users, meaning the location that DNS queries originate from. For example, you might want all queries from Europe to be routed to an ELB load balancer in the Frankfurt region.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"adba6b9b5a5387ec8af8d012d272715b","text":"Using the AWS Config service.","correct":false},{"id":"2b840caf003f35a0ca6a82ea4d66b8a8","text":"Using the Elastic Load Balancer service.","correct":false},{"id":"3efbfae41092bb136dee3c26de7750f1","text":"Using the Route 53 service.","correct":true},{"id":"4b3ecb216d2654061f67ae382d891333","text":"Using the Autoscaling service.","correct":false}]},{"id":"ed20f2cf-7759-41d0-9463-48c3624e7bf8","domain":"CostOptimized","question":"When deploying a NAT gateway, which of the following will you be billed for?","explanation":"With NAT Gateways, you are billed a flat fee for every hour that the gateway is active, plus an amount per GB processed by the gateway no matter the source or destination. Note that you will also have to pay the standard bandwidth charges for the traffic once it has passed through the gateway, in addition to the gateway costs.","links":[{"url":"https://aws.amazon.com/vpc/pricing/","title":"AWS VPC Pricing"}],"answers":[{"id":"064634bdc8ac6c8fa5b308fdd665e1f3","text":"A cost per hour that the NAT Gateway is active","correct":true},{"id":"cf784879b0aed688d70b47aebb1551b4","text":"All traffic processed, regardless of it's direction","correct":true},{"id":"28ab52fb3a68950991911ff132f533e6","text":"Only inbound traffic","correct":false},{"id":"a89c265a0491dbc3c90fcda91959c002","text":"Only outbound traffic","correct":false},{"id":"774e2089dd85e418697003baa7c7cf2e","text":"The instance that the NAT Gateway is running on","correct":false}]},{"id":"dfc3f2ec-3161-4e55-8132-ac8c4e1a3c81","domain":"ResilientDesign","question":"Which of the following is true with regard to Elastic IP addresses?","explanation":"Elastic IP address is a static IPv4 address and can be associated with a public address for dynamic cloud computing. When Elastic IP is associated with an instance, the existing Public IPv4 address is released back to the Amazon pool. Elastic IP addresses are region specific. Elastic IPs may be recovered if released, only if the IP is not associated with another account. Elastic IPs can be recovered using EC2 API or CLI tool only. In EC2-Classic, an Elastic IP is disassociated from the instance when you stop it.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html","title":"Elastic IP Addressing"}],"answers":[{"id":"9980200da917f7d405e7f6a765bf4586","text":"An Elastic IP address will remain associated with the EC2-Classic instance when the EC2-Classic instance is stopped.","correct":false},{"id":"0cfca15b9f0c8a1563edbf0e6a36171a","text":"When an Elastic IP address is associated with an instance, the instance's Public IPv4 address is released back to the Amazon pool and cannot be reused. The public DNS hostname of the instance changes to match the Elastic IP address.","correct":false},{"id":"4aaf488833f9d54d0834959007c03d78","text":"An Elastic IP address can be recovered using the Amazon EC2 API or a command line tool only.","correct":true},{"id":"933828eae3a2cae2240b99074d71d62a","text":"An Elastic IP address is for a specific region only.","correct":true},{"id":"41fceb47b8c47422341f02c0a017394b","text":"If released, an Elastic IP address can be recovered if it is not associated with another AWS account.","correct":true},{"id":"a2cdfe942dc44e6af7dc620c6625b1d5","text":"An Elastic IP address is for a specific Availability Zone only.","correct":false}]},{"id":"b8cb8890-c16a-4609-904f-2cd52cfeba0e","domain":"CostOptimized","question":"What is the minimum billable object size for S3 - IA?","explanation":"The minimum object size is 0 bytes, however you will be billed for 128 KB.  Objects smaller that 128 can still be stored, but will be billed as if they are 128KB. ","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Standard - IA Object Size (table)"},{"url":"https://aws.amazon.com/s3/faqs/?nc=sn&loc=6","title":"S3 Standard - IA minimums"}],"answers":[{"id":"bf361755334066f22d019854dd2be686","text":"1 KB","correct":false},{"id":"fdd68bff35708140c14d3cd3a3b0759d","text":"0 Bytes","correct":false},{"id":"05a402af63179f5ea4189bcb6a7e8bc5","text":"1 Byte","correct":false},{"id":"5de6c8bb0062d1883700e0bd14152d0d","text":"128 KB","correct":true}]},{"id":"2edec957-8dde-4a46-a4af-5c65142d38c3","domain":"ResilientDesign","question":"Which of the following Route 53 policies allow you to a) route data to a second resource if the first is unhealthy, and b) route data to resources that have better performance?","explanation":"Failover Routing and Latency-based Routing are the only two correct options, as they consider routing data based on whether the resource is healthy or whether one set of resources is more performant than another.  Any answer containing location based routing (Geoproximity and Geolocation) cannot be correct in this case, as these types only consider where the client or resources are located before routing the data.  They do not take into account whether a resource is online or slow.  Simple Routing can also be discounted as it does not take into account the state of the resources.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"6cc2be97f86de8b660b1fbafb18a890f","text":"Failover Routing and Latency-based Routing","correct":true},{"id":"6036d720543b35a606bc0c2a682b27cf","text":"Geoproximity Routing and Geolocation Routing","correct":false},{"id":"f44dc584b393fd984b1646d677520fb0","text":"Failover Routing and Simple Routing","correct":false},{"id":"d1333c4521b08ff7084ea38f02e7fd41","text":"Geolocation Routing and Latency-based Routing","correct":false}]},{"id":"33082520-edb1-41d0-8b6e-fa2f43c3a6a2","domain":"ResilientDesign","question":"You have been tasked with the creation of a highly available website that serves static content from EC2 instances. Which of the following is not a requirement to accomplish this goal?","explanation":"While an SQS queue can be an important part of a decoupled web application, it is not required when hosting a highly available static website on EC2. An auto scaling group configured to deploy EC2 instances in multiple subnets located in multiple availability zones allows an application to remain online despite an instance or AZ failure.","links":[{"url":"https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf","title":"Fault Tolerance and High Availability"}],"answers":[{"id":"4a7bf4c9871ab5d9a4cdcf72a1b29de9","text":"Multiple subnets","correct":false},{"id":"3b92e08f936523bf2c3b0abb698f73ba","text":"An SQS queue","correct":true},{"id":"4bf22bd2ec00ce8656941ab4941f1bab","text":"An auto-scaling group","correct":false},{"id":"b30e76c0e28a8979554e0da16b91238f","text":"A multi-AZ deployment","correct":false}]},{"id":"800d5598-41b8-45b0-8ed1-282e298da6d1","domain":"SecureSolutions","question":"Your company hosts a popular web application that connects to an Amazon RDS MySQL DB instances running in a private subnet created with the default ACL settings. Your security department has identified a DoS attack originating from a suspicious IP address. How can you protect the subnets from this attack?","explanation":"A network access control list (ACL) is another layer of security for your VPC that acts as a firewall for controlling traffic in and out of one or more subnets. Network ACLs and security groups apply different types of filtering and can be used together.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"8dcd632682257a9e6db8658fd01c07f9","text":"Change the Outbound Security Groups to deny access from the suspicious IP address.","correct":false},{"id":"4f16db81b73ca177c79c3244e13c35a2","text":"Change the Inbound Security Groups to deny access from the suspicious IP address.","correct":false},{"id":"6ca751c9ece11db6ef98b0c5a39d0694","text":"Change the Outbound NACL to deny access from the suspicious IP address.","correct":false},{"id":"ba87fc8ccb2ecf3a22e7ec386b502f39","text":"Change the Inbound NACL to deny access from the suspicious IP address.","correct":true}]},{"id":"0e7948c3-c7b8-48bb-b746-69af9470c6e6","domain":"SecureSolutions","question":"Which of the following statements illustrate the difference between inbound rules and outbound rules in security groups?","explanation":"Security groups use inbound rules to control web traffic that’s coming in and outbound rules to control web traffic that’s going out. In addition, that control is applied at the traffic’s source for inbound and destinations for outbound. So, 'Inbound rules control the web traffic leaving an instance' is wrong because it is the opposite of what inbound and outbound rules are supposed to do. Rules concern web traffic control, not resource input and output.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules","title":"Security Group Rules"}],"answers":[{"id":"c6451c3b0d042f27e66c2e374ac1d440","text":"Inbound rules control the incoming web traffic allowed to reach an instance; outbound rules control the outgoing web traffic allowed to leave the instance.","correct":true},{"id":"d1ca51f4c422914ee7d02e892c179621","text":"Inbound rules control the resources put into a VPC; outbound rules control the resources allowed to be removed from a VPC.","correct":false},{"id":"f0a9a7849b47e74650564106403565cd","text":"Inbound rules control the web traffic leaving an instance; outbound rules control the web traffic reaching the instance.","correct":false},{"id":"f41a017dfcebbacabef27c3fda2d04bf","text":"Inbound rules control the source of the web traffic; outbound rules control the destination for the web traffic.","correct":true}]},{"id":"7337c116-fab1-4400-b398-1315ca924cc4","domain":"SecureSolutions","question":"You are about to delete the second snapshot of an EBS volume which had 10 GiB of data at the time when the very first snapshot was taken. 6 GiB of that data has changed before the second snapshot was created. An additional 2 GiB of data have been added before the third and final snapshot was taken. Which of the following statements about that is correct?","explanation":"When you delete a snapshot, only the data unique to that snapshot is removed. Each snapshot contains or references all of the information needed to restore your data (from the moment when the snapshot was taken) to a new EBS volume.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"Amazon EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-snapshot.html","title":"Deleting an Amazon EBS Snapshot"}],"answers":[{"id":"6e2b9212876d0db9a9e41869a7e9ade1","text":"After deletion, the total storage required for the two remaining snapshots is 12 GiB; 10 GiB for the first and 2 GiB for the last snapshot.","correct":false},{"id":"80af6d01abbcd4194141d891cb0d666f","text":"Each EBS volume snapshot is a full backup of the complete data and independent of other snapshots. You can go ahead and delete the second snapshot to save costs. After that, you are charged for only 22 GiB of data for the two remaining snapshots.","correct":false},{"id":"63e57b6a1c92e6f3be354afc213938f4","text":"Before deletion, the total storage required for the three snapshots was 18 GiB of which the second one had 6 GiB of data. After the deletion of that second snapshot, you are still charged for storing 18 GiB of data - 10 GiB from the very first snapshot and 8 GiB (6 + 2) of data from the last snapshot.","correct":true},{"id":"d740c4bcb406d23f82b101e434a867d6","text":"Snapshots are incremental backups, which means that only the blocks on the device that have changed after your most recent snapshot are saved. Therefore, you can only delete them in reverse chronological order, i.e. starting with the third snapshot and then the second one.","correct":false}]}]}}}}
