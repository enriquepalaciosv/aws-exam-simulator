{"data":{"createNewExamAttempt":{"attempt":{"id":"e925418c-cc59-4644-b93e-12a447c999ba"},"exam":{"id":"ca725e04-4bd0-47fd-b80b-d9f5524ad74e","title":"AWS Certified Developer - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"e516825d-bec2-463c-9a64-63be7bc91509","domain":"refactoring","question":"You are developing a serverless application which runs on Lambda, DynamoDB and API Gateway. The application needs to support an average of 5,000 requests per second. During testing, the Test Team want to test for peaks of 2.5 x the average load (12,500 requests per second). Shortly after testing begins, your application crashes with API Gateway generating a 429 error code. What could be the reason for this?","explanation":"By default, API Gateway limits the steady-state request rate to 10,000 requests per second. The 429 error means that the application is generating too many requests and is being throttled.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html","title":"API Request Throttling"}],"answers":[{"id":"c44bbd8c68bc540a9f4ec1eb6aef1f14","text":"Your Lambda function has run out of memory, you need to increase CPU capacity in order to increase memory capacity","correct":false},{"id":"998c50932ec426f49890c7568b789ab0","text":"Your tests have caused the application to hit the default limit of 10,000 requests per second for API Gateway","correct":true},{"id":"e33a82eb6c47467dbddcc3cebfdd8dae","text":"Your tests have caused the application to hit the default limit of 10,000 requests per second for Lambda","correct":false},{"id":"71cfc755a5cb85f74a6c94a83c5a102b","text":"Your Lambda function has run out of CPU, you need to increase the memory allocation in order to increase CPU capacity","correct":false}]},{"id":"ece363fd-ee54-4d01-9e79-4ea34bf9b04a","domain":"mon-trb","question":"Your application is using SQS to send and receive messages. On average, it takes your application between 20 and 40 seconds to process a message and you have noticed that quite frequently, multiple application servers are attempting to process the same message which is causing issues within the application. What can you do to help prevent this from happening?","explanation":"Default message visibility timeout is 30 seconds. Your application is not always able to process a message within that time which means that after 30 seconds, the message is becomes visible on the queue again and is available for other consumers. Increasing the Visibility Timeout will give your application servers more time to processing and delete the message from the queue.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html#changing-message-visibility-timeout","title":"SQS Visibility Timeout"}],"answers":[{"id":"33e24a8e438593d0ed4994ce9ea68ccd","text":"Enable Long Polling","correct":false},{"id":"9ef993bf7e61fa02b5f6ac0fc8da6b18","text":"Enable Short Polling","correct":false},{"id":"ece10cb74c921cec6162012cfe67d416","text":"Increase the message visibility timeout","correct":true},{"id":"b2228b2fb368662ba42277270a2d0545","text":"Lower the message visibility timeout","correct":false}]},{"id":"76e6d618-2134-4a73-94dc-dc1c3af9eac3","domain":"development","question":"Which of the following are supported ways to upload and deploy your Lambda code?","explanation":"You can paste code or upload a zip file directly to the console, upload your code to S3 or use a CloudFormation template. Elastic Beanstalk is not a supported method of deploying Lambda.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html","title":"Lambda Deployment Packages"},{"url":"https://docs.aws.amazon.com/toolkit-for-eclipse/v1/user-guide/lambda-tutorial.html#lambda-tutorial-upload-code","title":"Uploading Lambda Code"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-lambda-function.html","title":"CloudFormation and Lambda"}],"answers":[{"id":"5c0aaa802c93c303836e0babb6d7e99c","text":"Zip your code into a zip file, upload it to an S3 bucket and have Lambda download it from S3","correct":true},{"id":"a1d81e8594c3bbc120a7270f2475c2b1","text":"Zip your code into a zip file and upload it via the Lambda console","correct":true},{"id":"9a700b9b08c4e3228582eae88ca49df0","text":"Write a CloudFormation template that will deploy your environment including your code.","correct":true},{"id":"185133cc98a2cbb85e317fd8493e7a26","text":"Copy and paste your code in to the integrated development environment (IDE) inside Lambda","correct":true},{"id":"cf448e03c3d4d06aae12f839f0b9c6ec","text":"Zip your code into a zip file, upload it to Elastic Beanstalk, then deploy your environment using Elastic Beanstalk","correct":false}]},{"id":"f6676496-9451-49c5-b9a0-d9f6db7a2b42","domain":"development","question":"Which of the following Elastic Beanstalk deployment approaches allow you to maintain full capacity while performing an update?","explanation":"Rolling with Additional Batch and Immutable both involve provisioning new servers to ensure capacity is not reduced. All At Once means the application will be offline for the duration of the update. Performing a Rolling Update without an additional batch of servers means a reduction in capacity.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.deploy-existing-version.html","title":"Elastic Beanstalk Deployments"}],"answers":[{"id":"11efd9ae6f76e706e3f1b34d97584ebc","text":"Immutable","correct":true},{"id":"caf75ce833223dcb2c5cfbbcad2ec02a","text":"All At Once","correct":false},{"id":"f4920797afb92022a9c6608efcd86317","text":"Rolling","correct":false},{"id":"431fffe43dba24b87f7ce578ca6f418c","text":"Rolling With Additional Batch","correct":true}]},{"id":"313867da-7161-4083-9745-77950b6208dd","domain":"development","question":"You are using CodeBuild to create a Docker image and add the image to your Elastic Container Registry. Which of the following commands should you include in the buildspec.yml?","explanation":"Use the docker push command to add your image to your Elastic Container Registry","links":[{"url":"https://aws.amazon.com/blogs/devops/build-a-continuous-delivery-pipeline-for-your-container-images-with-amazon-ecr-as-source/","title":"Build a Continuous Delivery Pipeline for Your Container Images with Amazon ECR as Source"}],"answers":[{"id":"d2d39a1ed4490154f045931eee5d18e4","text":"aws ecr push $REPOSITORY_URI:latest","correct":false},{"id":"ec1f85b16af01c1d7ec994f6ba6efa32","text":"docker push $REPOSITORY_URI:latest","correct":true},{"id":"c1520af238ed7b988b389f732c0d6287","text":"docker build -t $REPOSITORY_URI:latest .","correct":true},{"id":"585a787c56d351517a27b9d64d3db8ae","text":"docker add $REPOSITORY_URI:latest","correct":false},{"id":"87c7975f8fe350f6f133c1f3d3b6b9f2","text":"aws codebuild docker -t $REPOSITORY_URI:latest .","correct":false}]},{"id":"870dde60-9a99-4f30-8d55-38e1210b0d43","domain":"security","question":"You are trying to use CodeDeploy to deploy the latest version of your application which is stored in S3. You are trying to deploy the code to a new EC2 instance for the very first time. However the deployment keeps failing with an IAM_ROLE_PERMISSIONS error. Other team members have been able to successfully run the deployment to other EC2 instances and you suspect that your instance may not have permission to access the code in the S3 bucket. Which of the following can you use to test whether the instance role allows your EC2 instance to get the code from S3?","explanation":"With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies attached to IAM users, groups, or roles in your AWS account. You can test which actions are allowed or denied by the selected policies for specific resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html","title":"Testing IAM Policies with the IAM Policy Simulator"}],"answers":[{"id":"062324ad112d3df43caf83238dda051b","text":"Check the IAM logs to see whether the instance role allows access","correct":false},{"id":"45e2014a81f5345a25e46e1cadc42450","text":"Use the IAM Policy Simulator test whether the instance role allows access","correct":true},{"id":"5895d9b1a65074025b856fa95f5df0a5","text":"Use Trusted Advisor to check whether the instance role allows access","correct":false},{"id":"b165b6ec45a2a25d8d218f6f03383a30","text":"Use the console to check the public access permission on the S3 bucket and enable it if is set to false","correct":false}]},{"id":"a4afc791-647b-40b6-8f2a-29feb6142a0d","domain":"development","question":"ABC corp runs a web application that uses API Gateway to provide their developer customers with access to data. To reduce load on their upstream systems, the ABC corp have enabled API Gateway caching. A small number of developer customers still need access to results directly from the integration endpoint. To prevent all developer customers from bypassing the cache, ABC corp has also enabled the requirement for cache invalidation to require authorization.\n\nWhat must a developer customer do to return a result that is not cached from the API Gateway?","explanation":"Setting a Cache-Control: max-age=0 HTTP header as part of the request tells API Gateway that you want a response directly from the integration endpoint, rather than a cached response. This header can be interpreted as the client stating the maximum age a cached result can be is 0 seconds - equivalent to saying it cannot be cached at all.\n\nAs the cache is configured to require authorization to be invalidated, the request must be signed with a user or role that allows the execute-api:InvalidateCache action to be performed on the API Gateway resource. An example of this policy is found in the documentation for API Gateway Caching. We have also included a link to how to sign a request using AWS Signature Version 4.\n\nIt is recommended that you require authorization to invalidate a cached response; otherwise, if a significant number of requests perform an invalidation, the cache is no longer helping reduce load on upstream systems.\n\nCalling flush-stage-cache is incorrect because this would delete all data in the entire API cache, rather than just for the response the client has requested. Called often, this will likely result in the cache not having sufficient data to be effective.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html","title":"API Gateway Cache developer guide"},{"url":"https://docs.aws.amazon.com/apigateway/api-reference/signing-requests/","title":"Signing API Gateway requests"}],"answers":[{"id":"54f0ac8f9360a2dfe63f22a0a503ae7e","text":"Call the /execute-api-invalidate-cache API Gateway endpoint before sending their request.","correct":false},{"id":"cb28453003b461189ca4aec138e2d1bf","text":"Sign their request with a user or role that has the required execute-api:InvalidateCache permissions to invalidate the cache.","correct":true},{"id":"3dd3c69d480989554365826eaef7be2f","text":"Include a ?execute-api-invalidate-cache query string in their request.","correct":false},{"id":"4f0d8679da16e6c12618e0c2b85739be","text":"Include a Cache-Control: max-age=0 HTTP header in their request.","correct":true},{"id":"0f148da68f4442eace5c89fe939ba9ac","text":"Call the flush-stage-cache command before making the request.","correct":false}]},{"id":"d8b8e087-28cf-41f5-b882-7c4d8e237e4b","domain":"refactoring","question":"You are working on a project to migrate an on-premises website to AWS, your CTO has mandated that wherever possible, Serverless technologies should be used. Which of the following services would you consider for this project?","explanation":"S3, Lambda and DynamoDB are all serverless technologies that could be used to build a website. EC2 and RDS are not considered to be serverless because they are backed by a virtual server.","links":[{"url":"https://aws.amazon.com/serverless/","title":"What is Serverless?"}],"answers":[{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true}]},{"id":"5d9b4539-7320-47c6-82c5-4552d4b3bf29","domain":"development","question":"You are developing an application using multiple AWS services. You need to find a solution to decouple the application components, so that they can fail independently of one another. Which of the following AWS services will enable this?","explanation":"SQS is a fully managed message queuing service that enables you to decouple and scale micro-services, distributed systems, and serverless applications. SQS eliminates the complexity and overhead associated with managing and operating message-oriented middleware, and empowers developers to focus on differentiating work.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html","title":"SQS Developer Guide"}],"answers":[{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":false},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"ef4ba2f338cdf4b615ed280ff0b2777d","text":"SQS","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false}]},{"id":"777f1a0d-0acd-4907-be1f-ceb4266d3170","domain":"development","question":"You are developing a Lambda function which takes an average of 20 seconds to execute. During performance testing, you are trying to simulate peak loads, however soon after the testing begins, you notice that requests are failing with a throttling error. What could be the problem?","explanation":"When requests come in faster than your function can scale, or when your function is at maximum concurrency, additional requests fail with a throttling error (429 status code).","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/limits.html","title":"Lambda Limits"},{"url":"https://aws.amazon.com/about-aws/whats-new/2017/05/aws-lambda-raises-default-concurrent-execution-limit/","title":"Default Concurrent Execution Limit"}],"answers":[{"id":"67713e6254fbdabc3504f77f455cf500","text":"The deployment package is too large","correct":false},{"id":"396cb0f44930bc3d21771b4f8c6e7afd","text":"You have reached the limit of concurrent executions for Lambda","correct":true},{"id":"f33d22d5ee65a1e9f86c1631c889d199","text":"The Lambda function is taking too long to execute","correct":false},{"id":"5f877189f6b1d52e35220d6fac989254","text":"Your application does not have permission to invoke the Lambda function","correct":false},{"id":"e7f379a6b188c5064bd7c1bf17994433","text":"You haven't allocated enough memory to your function","correct":false}]},{"id":"f71363df-7941-4a84-93e1-7a5ed2ef1c08","domain":"security","question":"You have some sensitive data that you would like to encrypt. You want to be sure that once the data is encrypted, nobody but you will be able to use the encryption key to decrypt your files. Your head of security has asked you to make sure that the key used to encrypt your files is itself encrypted under another key. Which AWS technology enables this?","explanation":"When you encrypt your data, your data is protected, but you have to protect your encryption key. One strategy is to encrypt it. Envelope encryption is the practice of encrypting plaintext data with a data key, and then encrypting the data key under another key.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#enveloping","title":"Envelope Encryption"}],"answers":[{"id":"c5c0340c8e4f6673916050e3cbc5e2b2","text":"Store the encryption key in an encrypted S3 bucket","correct":false},{"id":"fdf5291377e4e56d4ee76f0328313232","text":"Use envelope encryption to encrypt the data key with another key","correct":true},{"id":"8afab6f0bb19c0796620267f6a74644b","text":"Encrypt the master key with the data key","correct":false},{"id":"834369e6ea722aa59f60696c106ba827","text":"Re-encrypt the data key with the master key","correct":false},{"id":"bd2c15ddb6cb6e3fee2adc749979e1e1","text":"Store the encryption keys in CloudHSM","correct":false}]},{"id":"6e7680bf-f045-4583-b38b-b2ca3ae466ed","domain":"security","question":"An IT Auditor has started in your Security Team, they will need access to read files in S3 and DynamoDB as well as the ability to describe EC2 instances. You want to ensure that only the Auditor is granted this access and that the IAM policy you create cannot mistakenly be attached to any other user. Which IAM policy type should you use?","explanation":"When you use an inline policy, the permissions in the policy cannot be inadvertently attached to the wrong principal entity","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html","title":"Managed Policies and Inline Policies"}],"answers":[{"id":"05aaffc9a37013fcae1b36c4baffceff","text":"AWS Managed Policy","correct":false},{"id":"ab18cb3ee046b7e5466057043f273700","text":"Custom Policy","correct":false},{"id":"60a6d5742e8f4d09d2d0edb9b15fa80d","text":"Customer Managed Policy","correct":false},{"id":"449ff67db14fb547ec64ef11c4d33c40","text":"Inline Policy","correct":true}]},{"id":"3f74aa43-386f-49e4-bc1d-3e32a1282397","domain":"development","question":"An application uses DynamoDB table as its backend data store. Each item has size of 10KB.  The application needs to perform 100 eventually consistent read operations per second, and 50 write operations per second.  What is the provisioned WCU value required to meet these requirements?","explanation":"One write capacity unit is equivalent to one write per second for an item up to 1 KB in size.  Thus, the required WCU in this scenario is 10KB item size x 50 write operations per second = 500 WCU.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.ProvisionedThroughput.Manual","title":"Provisioned Mode"}],"answers":[{"id":"6c9882bbac1c7093bd25041881277658","text":"250","correct":false},{"id":"cee631121c2ec9232f3a2f028ad5c89b","text":"500","correct":true},{"id":"7ef605fc8dba5425d6965fbd4c8fbe1f","text":"150","correct":false},{"id":"a9b7ba70783b617e9998dc4dd82eb3c5","text":"1000","correct":false}]},{"id":"88bcdf37-e9ac-4a5a-9561-a0b40b3d5942","domain":"deployment","question":"You have deployed your application on EC2 using Elastic Beanstalk. You would like to configure your application to send data to X-Ray. Where should you install the X-Ray daemon?","explanation":"To relay trace data from your application to AWS X-Ray, you can run the X-Ray daemon on your Elastic Beanstalk environment's Amazon EC2 instances. Elastic Beanstalk platforms provide a configuration option that you can set to run the daemon automatically. You can enable the daemon in a configuration file in your source code or by choosing an option in the Elastic Beanstalk console. When you enable the configuration option, the daemon is installed on the instance and runs as a service.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-beanstalk.html","title":"Running the X-Ray daemon on AWS Elastic Beanstalk"}],"answers":[{"id":"020611c7739a39c03183a066978fdad7","text":"Install the X-Ray daemon on the EC2 instances located in your own data center","correct":false},{"id":"b869cc613e5695b1535e3509f2226824","text":"Install the X-Ray daemon on the EC2 instances inside your Elastic Beanstalk environment.","correct":true},{"id":"2e3b28f6b658014b7006069d657a21b0","text":"Manually provision a new EC2 instance and install the X-Ray daemon on the new instance","correct":false},{"id":"815e2ca172c43e652a7d680047998174","text":"Install the X-Ray daemon on a Docker container running on your EC2 instance","correct":false}]},{"id":"868cb94f-ce60-4590-bfd2-60e8295cc413","domain":"security","question":"You are developing a online-banking website which will be accessed by a global customer base. You are planning to use CloudFront to ensure users experience good performance regardless of their location. The Security Architect working on the project asks you to ensure that all requests to CloudFront are encrypted using HTTPS. How can you configure this?","explanation":"Viewer Protocol Policy defines the protocols which can be used to access CloudFront content","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.html","title":"Requiring HTTPS for Communication Between Viewers and CloudFront"}],"answers":[{"id":"052066815497ced9f9852e55d66c6782","text":"Set the Request Protocol Policy to redirect HTTP to HTTPS","correct":false},{"id":"659099387a57b1f316abf3c6afac459d","text":"Set the Session Protocol Policy to redirect HTTP to HTTPS","correct":false},{"id":"ae41866f6b2df14a344847e9629076db","text":"Set the User Protocol Policy to redirect HTTP to HTTPS","correct":false},{"id":"c40022183e6d5dd97e4c778332064ed2","text":"Set the Viewer Protocol Policy to redirect HTTP to HTTPS","correct":true}]},{"id":"0d9472d0-587b-4961-9457-e37e75979b7c","domain":"development","question":"You are working on a Serverless application written in Python and running in Lambda. You have uploaded multiple versions of your code to Lambda, but would like to make sure your test environment always utilizes the latest version. How can you configure this?","explanation":"When you create a Lambda function, there is only one version: $LATEST. You can refer to the function using its Amazon Resource Name (ARN). There are two ARNs associated with this initial version, the qualified ARN which is the function ARN plus a version suffix e.g. $LATEST. Or the unqualified ARN which is the function ARN without the version suffix. The function version for an unqualified function always maps to $LATEST, so you can access the latest version using either the qualified ARN with $LATEST, or the unqualified function ARN. Lambda also supports creating aliases for each of your Lambda function versions. An alias is a pointer to a specific Lambda function version, aliases will not be updated automatically when a new version of the function becomes available.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-intro.html","title":"Introduction To Lambda Function Versioning"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda Function Versioning and Aliases"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/how-to-manage-versioning.html","title":"Lambda Versioning"}],"answers":[{"id":"0311fc386b14ce5afd0843ecf4a6ff16","text":"Create another function to automatically update your function alias to point to the latest version of the code every time it is updated","correct":false},{"id":"d483464867986a2d830ac23858944891","text":"Create an alias to point to the correct version of your code","correct":false},{"id":"07c1095b47175c42406ba59e91205281","text":"Reference the function using an unqualified ARN","correct":true},{"id":"cc67dedc36d230ab3574dc07b41b7443","text":"Configure the alias to automatically update to point to the latest version of the code every time it is updated","correct":false},{"id":"02f663ae252fea90c711171a5572d211","text":"Reference the function using a qualified ARN and the $LATEST suffix","correct":true}]},{"id":"bfec04c8-32f9-42df-b7de-1ba954709dff","domain":"refactoring","question":"Using the AWS console, you are trying to Scale DynamoDB past its pre-configured maximums. Which service can you increase by raising a ticket to AWS support?","explanation":"Provisioned throughput limits","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html#default-limits-capacity-units-provisioned-throughput","title":"Capacity Units and Provisioned Throughput"}],"answers":[{"id":"1ed115474e3650b86e2a64fa03839943","text":"Global Secondary Indexes","correct":false},{"id":"657289d6192c6cf5d405aa8b4596bd21","text":"Provisioned throughput limits","correct":true},{"id":"eb1167f3583beb42c4f2e414033c5ae6","text":"Local Secondary Indexes","correct":false},{"id":"3c11d73c8083e3aae0a758891afe3a0a","text":"Item Sizes","correct":false}]},{"id":"e466b1d0-1858-40d8-aeca-e48e5e44ae2d","domain":"deployment","question":"Your application is using Kinesis to ingest data from a number of environmental sensors which continuously monitor for pollution within a 1 mile radius of a local primary school. An EC2 instance consumes the data from the stream using the Kinesis Client Library. You have recently increased the number of shards in your stream to 6 and your project manager is now suggesting that you need to add at least 6 additional EC2 instances to cope with the new shards. What do you recommend?","explanation":"Re-sharding enables you to increase or decrease the number of shards in a stream in order to adapt to changes in the rate of data flowing through the stream. You should ensure that the number of instances does not exceed the number of shards (except for failure standby purposes). Each shard is processed by exactly one KCL worker and has exactly one corresponding record processor, so you never need multiple instances to process one shard. However, one worker can process any number of shards, so it's fine if the number of shards exceeds the number of instances. When re-sharding increases the number of shards in the stream, the corresponding increase in the number of record processors increases the load on the EC2 instances that are hosting them. If the instances are part of an Auto Scaling group, and the load increases sufficiently, the Auto Scaling group adds more instances to handle the increased load.","links":[{"url":"https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html","title":"Kinesis Data Streams Terminology"},{"url":"https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html","title":"Resharding, Scaling, and Parallel Processing"}],"answers":[{"id":"6c565b117fa64cb3b8ddaf38c670efed","text":"You should increase the number of instances to match the number of shards","correct":false},{"id":"1c8f531c39885147b4935b0e64880b97","text":"The number of instances should be greater than number of shards","correct":false},{"id":"7561e4f93183899bc8757da9db13ae60","text":"One worker can process any number of shards, so it's fine if the number of shards exceeds the number of instances","correct":true},{"id":"c11271a6921d20363c624ddde1790781","text":"You should decrease the number of shards to match the number of consumer instances","correct":false}]},{"id":"943289f7-db1b-4439-b4c2-915168f617f9","domain":"development","question":"You work for a company which facilitates and organizes technical conferences. You ran a large number of events this year with many high profile speakers and would like to enable your customers to access videos of the most popular presentations. You have stored all your content in S3, but you would like to restrict access so that people can only access the videos after logging into your website. How should you configure this?","explanation":"All objects by default are private. Only the object owner has permission to access these objects. However, the object owner can optionally share objects with others by creating a pre-signed URL, using their own security credentials, to grant time-limited permission to download the objects. Anyone who receives the pre-signed URL can then access the object. For example, if you have a video in your bucket and both the bucket and the object are private, you can share the video with others by generating a pre-signed URL.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html","title":"Serving Private Content"},{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-signed-urls.html","title":"CloudFront and Signed URLs"}],"answers":[{"id":"ccfccd796a677ec7b7686f3d8c21a602","text":"Remove public read access from the S3 bucket where the videos are stored","correct":true},{"id":"9d3d0a72e06711a3345d6dd192885795","text":"Use SSE-S3 to generate a signed URL","correct":false},{"id":"90d89af9eb0c2a7b8b70ca4a300d9920","text":"Share the videos by creating a pre-signed URL","correct":true},{"id":"1925533bcb7e305a66391f083dd879d9","text":"Use CloudFront with HTTPS to enable secure access to the videos","correct":false},{"id":"07b930b04afb83395edadd40528e8336","text":"Use web identity federation with temporary credentials allowing access to the videos","correct":false}]},{"id":"6a4ef89c-dbe0-491d-88d4-11b09f0a272a","domain":"development","question":"What is NOT the best practice when deploying production applications using Elastic Beanstalk?","explanation":"It is a good practice to decouple an Amazon RDS instance from an Elastic Beanstalk environment, especially in production environment.  Launching an RDS database as part of an Elastic Beanstalk environment may be suitable for development or PoC environments. However, in general, it isn’t ideal as this means that termination of the Elastic Beanstalk environment will result in termination of the database as well. To protect important data from potential data loss, Amazon RDS database should be launched outside of the Elastic Beanstalk environment. With this approach, we decouple the life-cycle of the database from the life-cycle of the Elastic Beanstalk environment. This method also allows us to connect multiple environments to the same RDS instance. This may be useful for performing advanced deployment scenarios such as blue-green deployments. Storing RDS connection string in an encrypted, secured, and controlled S3 bucket and using Elastic Beanstalk configuration files is a valid method that can be used to securely store this data outside of the application code. Protecting the RDS databases from accidental deletion by enabling Delete Protection is always a good practice.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.RDS.html","title":"Using Elastic Beanstalk with Amazon RDS"},{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/decouple-rds-from-beanstalk/","title":"How do I decouple an Amazon RDS instance from an Elastic Beanstalk environment without downtime, database sync issues, or data loss?"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/rds-external-credentials.html","title":"Storing the connection string in Amazon S3"}],"answers":[{"id":"f8ac7ea397ed3bf0d0dcf3a3d5123521","text":"Amazon RDS databases should be included in the Elastic Beanstalk environment as that maintains the same life cycle for all components of the environment.","correct":true},{"id":"24e8e8250f45def68ec55670ac2390e7","text":"Amazon RDS Delete Protection should be enabled.","correct":false},{"id":"9e19947230060c5fdc4610175989a39e","text":"Amazon RDS Connection String should be stored in a controlled S3 bucket.","correct":false},{"id":"1a265bcccdb4ad642b0a09989c931196","text":"Amazon RDS database should be launched outside of the Elastic Beanstalk environment as that provides more flexibility.","correct":false}]},{"id":"322048b9-4d49-4c64-8aca-c7479619982a","domain":"mon-trb","question":"Your company is reaching the end of the financial year and the Finance team are running a lot of large database queries and scans against your DynamoDB tables. The database queries and scans are taking much longer to complete than expected, how can you make them more efficient?","explanation":"Reducing page size for queries and running scans in parallel are both recommended approaches for making DynamoDB operations more efficient. DynamoDB uses eventually consistent reads by default and filtering the results will not improve efficiency","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Best Practices for Querying and Scanning Data"}],"answers":[{"id":"867b7b3ff3ddfb076ff319ce80e543c5","text":"Run parallel scans","correct":true},{"id":"c6c36956db297a402f3fef1bf83c4c7e","text":"Filter your results based on the Primary Key and Sort Key","correct":false},{"id":"60e26c5aacc3bba5083560f51b354c87","text":"Reduce the page size to return fewer items per results page","correct":true},{"id":"e131078f81b76b76be2718610cc739a9","text":"Set your queries to be eventually consistent","correct":false}]},{"id":"52bc2a05-9de5-46cb-ab80-feb67dadc6d9","domain":"deployment","question":"What is the maximum size of an S3 object?","explanation":"The minimum size of an object is 0 bytes (empty or 'touched' files are permitted) and the maximum size of an object is 5TB.","links":[{"url":"https://aws.amazon.com/s3/faqs/#general","title":"How Much Data Can I Store?"}],"answers":[{"id":"6aaa2ffc817cac34a806a149bee36350","text":"50 GB","correct":false},{"id":"47a5e6e39f64ff5d5dfb25da1aa3f3f2","text":"500 GB","correct":false},{"id":"951b67b6006b1e714e7d8b65b90d56b5","text":"50 TB","correct":false},{"id":"b3dd42c7956751be5d38b5c0cb2e09c0","text":"5 TB","correct":true}]},{"id":"779acf8c-3df3-43fe-9714-3ebaf8e40ef2","domain":"refactoring","question":"You are working for an investment bank and have been asked to help the application support team with their annual Disaster Recovery testing. The main production PostgreSQL database is hosted in RDS Multi-AZ deployment, with multiple applications running on a combination of EC2 and Lambda. You have been asked to help the team to demonstrate the impact that a failed Availability Zone will have on the database. Which of the following do you suggest?","explanation":"If the Amazon RDS instance is configured for Multi-AZ, you can perform the reboot with a failover. An Amazon RDS event is created when the reboot is completed. If your DB instance is a Multi-AZ deployment, you can force a failover from one Availability Zone (AZ) to another when you reboot. When you force a failover of your DB instance, Amazon RDS automatically switches to a standby replica in another Availability Zone, and updates the DNS record for the DB instance to point to the standby DB instance. As a result, you need to clean up and re-establish any existing connections to your DB instance. Rebooting with failover is beneficial when you want to simulate a failure of a DB instance for testing, or restore operations to the original AZ after a failover occurs.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RebootInstance.html","title":"RDS - Rebooting a DB Instance"}],"answers":[{"id":"428c5da3acc9c6986847b2511e6129f5","text":"Simulate an AZ failure by rebooting the underlying EC2 instance which is running the database","correct":false},{"id":"4496cfe7afc55864d488f038430be2b5","text":"Simulate an AZ failure by disconnecting your RDS instance from the network","correct":false},{"id":"e8d6fb964d48234750126a73a5fa41f4","text":"Simulate an AZ failure by performing a reboot with forced failover on the RDS instance","correct":true},{"id":"222811da7a574ef8ec4e058ece75fe23","text":"Simulate an AZ failure by deleting the primary RDS instance","correct":false},{"id":"1db313c348c46e6cefc8bf25ce3e0d15","text":"Simulate an AZ failure by moving your RDS instance to a different subnet","correct":false}]},{"id":"bd3b8069-4ee1-480b-8738-d0683a3de962","domain":"security","question":"A company security team wants to implement a solution for securely storing RDS database credentials.  The solution should provide automatic rotation of database credentials.  What AWS service can the team use to meet these requirements?","explanation":"AWS Secrets Manager is an AWS service that can be used to securely store, retrieve, and automatically rotate database credentials. AWS Secrets Manager has built-in integration for RDS databases. Applications use Secrets Manager API's to retrieve database credentials, enabling secure storage of sensitive information outside of the application code. Systems Manager Parameter Store provides secure storage of sensitive information. However, it does not provide automatic credentials rotation capability specified as a requirement in the question scenario. Key Management Service (KMS) is used for management of cryptographic encryption keys, not for storage of sensitive information. Resource Access Manager is not applicable here as it is used for managing access to AWS resources between multiple accounts.","links":[{"url":"https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html","title":"What Is AWS Secrets Manager?"}],"answers":[{"id":"7898cb92c418aeed6974ede9cb146462","text":"AWS Secrets Manager","correct":true},{"id":"fcba7bd474eb1fdf49705827bbb6f28c","text":"AWS Key Management Service","correct":false},{"id":"b77e6ac1dd339ec1c0d94107e6c9d3d2","text":"AWS Systems Manager Parameter Store","correct":false},{"id":"7c09430feea9bf5bdf657bd178ce574c","text":"AWS Resource Access Manager","correct":false}]},{"id":"a45d7c37-eb4b-4a39-9fb2-d5298cb40491","domain":"security","question":"You work for a large I.T. recruitment company that are launching a mobile application which will allow job seekers to apply for jobs online and attach their résumé to their application. Users will be able to log in to their account using Facebook and the application stores their contact and profile details in a DynamoDB table. Which of the following approaches would you recommend for enabling the users to gain access to view and update their data?","explanation":"With Web Identity Federation, you don't need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well-known external identity provider (IdP), such as Login with Amazon, Facebook, Google. For most Web Identity Federation scenarios, we recommend that you use Amazon Cognito because it acts as an identity broker and does much of the federation work for you.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_oidc.html","title":"Web Identity Federation"}],"answers":[{"id":"e0bc3be9eb85e3ef437aac25d15f5be4","text":"Allow customers to embed user credentials in settings of the mobile app","correct":false},{"id":"3b5209dda18fcdea46a196b06d17c586","text":"Configure Web Identity Federation with Cognito","correct":true},{"id":"f11ad00f139ee7fd7ecde821e3769c1a","text":"Configure cross-account access between the mobile app and DynamoDB ","correct":false},{"id":"ff1fd8b56d2c836edd2795619fa9b681","text":"Configure Web Identity Federation with ADFS","correct":false}]},{"id":"aadb1fdb-d919-4989-ab28-6bd8ffcd7c7a","domain":"security","question":"You are developing a healthy-eating application which tracks nutrition and water intake on a daily basis. Your users mainly access the application using a mobile device like a cell phone or tablet. You are planning to run a promotion to attract new users by providing a free trial period and you would like to make it easy for guest users to trial your application. Which of the following can you use to configure access for guest users?","explanation":"With a Cognito identity pool, your users can obtain temporary AWS credentials to access AWS services, such as Amazon S3 and DynamoDB. Identity pools support anonymous guest users, as well as federation through third-party IdPs.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-scenarios.html","title":"Common Cognito Scenarios"}],"answers":[{"id":"8102630f0a77efc6d438d44b1badd712","text":"IAM User Pools","correct":false},{"id":"12ffa121095c5fb3ad9fa1f1ed509e46","text":"Identity Federation with SAML","correct":false},{"id":"1c3430e7715f141606c52e6ff2c15c05","text":"Identity Federation with AWS","correct":false},{"id":"22d4851cfa5c3b7d3fa506d938aeb081","text":"Cognito Identity Pools","correct":true}]},{"id":"af4efcf0-4c08-4c5c-ade1-6e8196c9f0b7","domain":"deployment","question":"Your application needs to process large numbers of job requests and you need to ensure that they are processed in order, and that each request is processed only once. How would you deploy SQS to achieve this end?","explanation":"FIFO queues offer FIFO (First-In-First-Out) delivery and exactly-once processing: The order in which messages are sent and received is strictly preserved and a message is delivered once and remains available until a consumer processes and deletes it; duplicates are not introduced into the queue.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html","title":"SQS FIFO Queues"}],"answers":[{"id":"54bf18f30fcf900dcdce5a9bcd553058","text":"Use an SQS FIFO queue to process the jobs.","correct":true},{"id":"31ea3ce575bc576b9ed1b36ce7cccbbc","text":"Configure FIFO delivery in a standard SQS queue.","correct":false},{"id":"78f49aed62525e2d821207ac91af1b24","text":"Use the SetOrder attribute ensure sequential job processing.","correct":false},{"id":"bbd8881e023d2e48310f360e90cc7582","text":"Convert your standard queue to a FIFO queue by renaming your standard queue with the .fifo suffix.","correct":false}]},{"id":"c1fc5f56-f74e-405f-a974-d9bb2e2c57e6","domain":"deployment","question":"You have deployed a new version of your Lambda function, however during testing, you notice that  your application is not behaving as expected. How can you roll back to the previous version of your code?","explanation":"Remapping the PROD alias to the previous version will allow you to quickly roll back","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda versioning and Aliases"}],"answers":[{"id":"1ba636d1ad4c4e2a9239fc75d17ffc41","text":"Update the $LATEST alias to point to the previous version of your function","correct":false},{"id":"28ab809ddc3a2aee352db2592bca020a","text":"Remap the PROD alias to point to the previous version of your function","correct":true},{"id":"aa97bfdc9437ce44352de51699501c4d","text":"Make a new version of your function using the original Lambda code","correct":false},{"id":"60682da7d7f6df421c71e7e42cf4b227","text":"Redeploy your original code to $LATEST","correct":false}]},{"id":"8ee26b88-194a-4069-85a1-e28a48bcca27","domain":"security","question":"An organization has mandated that all data within its DynamoDB tables must be encrypted at rest using an AWS owned key. What must a developer do to ensure this?","explanation":"All DynamoDB tables are encrypted at rest using an AWS owned CMK by default. Non-encrypted DynamoDB tables are no longer supported in AWS. You have the option to pick an alternative AWS or Customer Managed KMS key if required.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EncryptionAtRest.html","title":"DynamoDB Encryption at Rest"}],"answers":[{"id":"2a13575a2661e32db0bdf9ad7b95ffee","text":"This cannot be done; DynamoDB does not support encryption at rest.","correct":false},{"id":"5744856c94411674b105aff56f20a6a3","text":"There's no need to do anything; all DynamoDB tables are encrypted at rest with an AWS owned key by default.","correct":true},{"id":"852abdb4878eba09a03ca6e37eb1dd16","text":"Enable DynamoDB encryption and select AWS managed CMK.","correct":false},{"id":"92c03c315e7b990388532214f2a73c62","text":"Enable DynamoDB encryption and select AWS owned CMK.","correct":false}]},{"id":"a911b79a-68c9-41f0-af02-0f57c3ccdc66","domain":"mon-trb","question":"A company's services are protected by AWS WAF. The development team would like to enable logging on the WAF to get detailed information about traffic that is analyzed by the web ACLs in order to enhance their troubleshooting efforts. Which service can the team use to collect AWS WAF logs?","explanation":"In order to enable and configure AWS WAF logs, a Kinesis Data Firehose is required for delivery of the logs to the destination.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/logging.html","title":"Logging Web ACL Traffic Information"}],"answers":[{"id":"72e5e39b79c3d4d99d9c68a6a5e4d9f0","text":"Kinesis Data Firehose","correct":true},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"33eb5c1f2566526637e791c925c4c505","text":"VPS Flow Logs","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false}]},{"id":"616a7b1c-bc17-42a4-b361-74af9a86607f","domain":"development","question":"A financial services company is implementing a payments processing application utilizing DynamoDB tables for its data store. To process payments, the application needs to perform a write operation on a sequence of items, and roll back and reverse all operations in case of any one faulty operation.  What is the best method to accomplish this requirement?","explanation":"DynamoDB transactions feature provides ability to group multiple items into a single atomic transaction and perform all-or-nothing coordinated operations.  This can be done programmatically using the TransactWriteItems operation. The BatchWriteItem operation does not meet the question requirements as it does not guarantee that the actions will be performed on all items as a single atomic coordinated operation. It is possible that only some of the actions in the batch succeed while the others do not. Updating the payments application is not the ideal solution.  It requires application code change and tracking all connected operations and reversing them as required is not trivial to implement.  Using the native transaction ability provided by DynamoDB is a better option.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html","title":"Amazon DynamoDB Transactions: How It Works"}],"answers":[{"id":"aa5647f8e2c8e7147097b79d2b2a5555","text":"Use the BatchWriteItem operation.","correct":false},{"id":"cb748237c6e223d0f4506cff55c6b259","text":"Use the TransactWriteItems operation.","correct":true},{"id":"758e6d47da6512d38526cfcfa39bb5c1","text":"Update the application to manage and perform roll-back operations.","correct":false},{"id":"3b08e25699a7082805a9be123c9acbbb","text":"DynamoDB does not support atomic transactions.  Use relational database (such as RDS) that supports atomic transactions.","correct":false}]},{"id":"daa8b2ee-b810-4e35-947d-9ad26196189d","domain":"mon-trb","question":"You can use X-Ray with applications running on which platforms? ","explanation":"X-Ray works with Lambda, EC2, API Gateway, Elastic Beanstalk and ECS","links":[{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"}],"answers":[{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":true},{"id":"c8f63ecaff5e983a2441126a241c4cfa","text":"ECS","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":false},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true}]},{"id":"6641f65a-c837-49a2-bbeb-11af158d44e0","domain":"mon-trb","question":"What is the maximum execution duration for a Lambda request?","explanation":"As of Oct 2018 the maximum execution duration has been increased from 300 seconds to 900 seconds (15 minutes)","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/limits.html","title":"Lambda Limits"},{"url":"https://aws.amazon.com/about-aws/whats-new/2018/10/aws-lambda-supports-functions-that-can-run-up-to-15-minutes/","title":"Update notice- Oct 2018"}],"answers":[{"id":"7ed53d277129b356be62369ec930e3b8","text":"500 seconds","correct":false},{"id":"4234838a99b7912e550babb083c205c4","text":"60 seconds","correct":false},{"id":"a51534ea662db3ce23238035e25859e2","text":"900 seconds","correct":true},{"id":"533f546e5ddb63fb2c810f7cca06678f","text":"300 seconds","correct":false},{"id":"8d15ed7d27d83ed6229a66b1f44b7696","text":"3 minutes","correct":false}]},{"id":"33d838eb-6e2a-499f-b1a0-0d385c20732a","domain":"deployment","question":"You have deployed an application using Elastic Beanstalk and your code is running in a Docker container. What is the process for upgrading this application?","explanation":"When you use the Elastic Beanstalk console to deploy a new application or an application version, you'll need to upload a source bundle. Your source bundle must consist of a single ZIP file or WAR file which does not exceed 512 MB. By using Docker with Elastic Beanstalk, you have an infrastructure that automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html","title":"Create an Application Source Bundle"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html","title":"Deploying Elastic Beanstalk Applications from Docker Containers"}],"answers":[{"id":"9142b51f935ad294eb31a909cbe9336e","text":"Upload a zip file containing the new version of your code using the \"Upload and Deploy\" button in the ElasticBeanstalk console","correct":true},{"id":"c9bd7c34b6482e6240a3a8a6404e5d09","text":"Upload your code to Elastic Container Registry and select the \"Deploy Now\" option in Elastic Container Service console","correct":false},{"id":"f65c3a605a6af1f8f362fab1debc50b2","text":"Upload your code to CodeCommit and select the \"Deploy Now\" option in Elastic Container Service console","correct":false},{"id":"50ca13bdc867153ec83d6d066d4950b3","text":"Use CodeBuild to deploy the new code to the docker container","correct":false}]},{"id":"f5072793-928c-4fc3-8ce0-bd18571b6765","domain":"deployment","question":"You are developing a gaming website which scores all players scores in a DynamoDB table. You are using a Partition key of user_ID and a Sort Key of game_ID as well as storing the user_score which is the user's highest score for the game and also a timestamp. You need to find a way get the top scorers for each game, who have scored over 50,000 points. Which of the following will allow to to find this information in the most efficient way?","explanation":"A scan operation would be less efficient than a query, so that is definitely not the most efficient way. The Query operation described won't help you find the top scorers for each game. A local secondary index is an index that has the same partition key as the base table, but a different sort key. A global secondary index is an index with a partition key and a sort key that can be different from those on the base table.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Queries and Scans"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-indexes-general.html","title":"DynamoDB Indexes"}],"answers":[{"id":"7b9684c68079e7ca02fe44efb81fa0eb","text":"Query the table using a partition key of user_ID and sort by game_ID","correct":false},{"id":"eae4d20326b1ecd862aed8669ad068ca","text":"Use a global secondary index with a partition key of game_ID and a sort key of user_ID","correct":false},{"id":"1e267d3212493fc534c9b2e9de826341","text":"Use a local secondary index with a partition key of user_ID and a sort key of user_score","correct":true},{"id":"efcb11f92c2fff3dca6935cb74653ad7","text":"Scan the table and order by score","correct":false}]},{"id":"5953c122-dbdd-4d25-a8fe-3e1fd23a6c8f","domain":"mon-trb","question":"An application developer finds that performing a scan operation on a large DynamoDB table is taking a long time to execute.  What can be used to improve the performance and decrease the execution time of the scan operation?","explanation":"Parallel scans can be used by multiple worker threads in an application to perform a scan of a DynamoDB table much faster. Filter expression in a scan operation only filters the results.  Scan operation still performs the same amount of read operations. Projection expression is used to limit the attributes returned by the scan operation.  It reduces the size of the payload of the scan operation, but it does not affect the speed of the scan operation. Pagination can be used to divide the result set into multiple pages, but does not increase the performance of the scan operation.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html#Scan.ParallelScan","title":"Parallel Scan"}],"answers":[{"id":"e262b00e3caa1a25ec14571777714e9c","text":"Use of projection expression.","correct":false},{"id":"b68d0e7d10bb7958f9b4b5fa43f06ac3","text":"Use of parallel scans.","correct":true},{"id":"62fef50451cb13a49660c69ae13e7932","text":"Use of filter expression.","correct":false},{"id":"7eeca829a717872bbf53c3ff8a69e41a","text":"Use of pagination.","correct":false}]},{"id":"331062f4-325b-4205-8f7b-0d7af956d7d2","domain":"development","question":"How does API Gateway handle SOAP?","explanation":"API Gateway supports the legacy SOAP protocol, which returns results in xml format rather than JSON, in pass-through mode.","links":[{"url":"https://www.rubix.nl/blogs/how-configure-amazon-api-gateway-soap-webservice-passthrough-minutes","title":"Configuring SOAP Web Service Pass-Through with API Gateway"}],"answers":[{"id":"9421a86b8ea1ce095c60a8551f33914c","text":"SOAP is deprecated and not supported","correct":false},{"id":"59028be6a7a6ca137dfcc0ef0c6b7415","text":"The API gateway converts the xml response received by the SOAP API to JSON","correct":false},{"id":"1deb9d05d2561d899fbf9b7ddc218dcd","text":"The API Gateway converts the SOAP API to a RESTful API","correct":false},{"id":"2ea57db3530b67b7c9d0a760772338e8","text":"SOAP is handled as web service pass-through","correct":true}]},{"id":"7b9da250-0466-4f74-a5f4-a48611e4ad52","domain":"deployment","question":"Which of the following could you NOT achieve using the Amazon SQS Extended Client Library for Java?","explanation":"You can use Amazon S3 and the Amazon SQS Extended Client Library for Java to manage Amazon SQS messages stored in S3. This includes specifying when messages should be stored in S3, referencing message objects stored in S3, getting them, and deleting them.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"c864c8d423d9f1ff9520db533d3c55f0","text":"Create a new S3 bucket and move a batch of SQS messages into the bucket","correct":true},{"id":"0c34c3d6deafa4117735272f76eb3ab8","text":"Delete a message object from an Amazon S3 bucket","correct":false},{"id":"d6cda81adfce3f5709327b9e75258e8a","text":"Manage large SQS Messages stored on S3","correct":false},{"id":"d807fc120f6730850ff6425f9e3c48a0","text":"Specify whether messages are always stored in Amazon S3 or only when the size of a message exceeds 256 KB","correct":false},{"id":"b236aa2fd73c138dd311cd5ab9732edb","text":"Get a message object from an S3 bucket","correct":false}]},{"id":"235fa5cd-42b5-4017-af9a-e62d0503651a","domain":"security","question":"You are working on a Lambda function which needs to access data in RDS, which of the below are valid approaches for securely storing the encrypted database connection strings and other secrets which your function needs to use?","explanation":"Parameter Store provides secure storage for configuration data, connection strings, passwords and secrets management. None of the other options are secure.","links":[{"url":"https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html","title":"AWS Systems Manager Parameter Store"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/tutorial-env_console.html","title":"Create a Lambda Function Using Environment Variables To Store Sensitive Information"}],"answers":[{"id":"ca7c47bd30833fb42e5bc78f6c7583be","text":"Use Lambda Environment Variables","correct":true},{"id":"913d4a9f910c7f6b836d623b39131480","text":"Use Systems Manager Parameter Store","correct":true},{"id":"53708b71a9f9d0c3994b3bd1d470b254","text":"Use DynamoDB to store the encrypted connection string and secrets","correct":false},{"id":"f2523ec5429fa4e1be124d650a69a0f5","text":"Store the encrypted connection string and other secrets in S3","correct":false}]},{"id":"2204af3d-2ed7-41c4-9182-2df403ce77df","domain":"security","question":"An organization receives documents from its users, which must be put into a SQS queue, ready for processing. The documents range in size from 3 MB to 20 MB, and must always be encrypted at rest.\n\nWhat is the best was to queue these documents?","explanation":"SQS has a maximum message size of 256 KB, and DynamoDB has a maximum Item size of 400 KB; therefore, neither of these would be suitable for storing such large documents.\n\nGlacier would not be suitable as its use-case is for long term document archiving, not short term document processing.\n\nAll options listed provide encryption at rest.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-limits.html","title":"SQS Limits"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"f9c2efbd72c96aab06a14e4f3be9b830","text":"Store the document in DynamoDB. Include a reference to the item in a SQS message.","correct":false},{"id":"23a28d35794f1802b4590c8433d5f0be","text":"Store the document in S3. Include a reference to the object in a SQS message.","correct":true},{"id":"19455cef763d19eace0135946b6c4a0b","text":"Store the document in Glacier. Include a reference to the object in a SQS message.","correct":false},{"id":"e0d9c5dbccbb6899d85b6efde57b2929","text":"Base64 encode the document, then attached it to the SQS message as a Message Attribute. ","correct":false}]},{"id":"064a1ca2-3ce2-483d-9e44-f0381416aa53","domain":"development","question":"You are developing a CloudFormation template and need to retrieve a string value containing the DNS name of the load balancer from an earlier section of the template. How would to refer to this string value in the most efficient and automated fashion?","explanation":"The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. This is the best choice per documentation and eliminates the need to hardcode values to be able to automate future renditions of the template rather than having to manually change every hard-coded value. The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. The intrinsic function Fn::FindInMap returns the value corresponding to keys in a two-level map that is declared in the Mappings section.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getatt.html","title":"Fn::GetAtt"}],"answers":[{"id":"a458b06d7d68a0755776d692742aebe5","text":"Hardcode the string value by checking the DNS name number ELBs in the Console and insert the value in the template.","correct":false},{"id":"d07c84be22b2e436b377f48b647e144a","text":"Use the condition function Fn::FindInMap to return the value corresponding to the key.","correct":false},{"id":"597e06174b5664dffc6d5fa8752fc74b","text":"Use the condition function Fn::Select to return the value of the string.","correct":false},{"id":"f9121262138f8b6c85cca08c00b4b4f5","text":"Use the condition function Fn::GetAtt to return the value of the attribute","correct":true}]},{"id":"22556a45-7db0-48f9-85cf-654ac74d729f","domain":"security","question":"When using the AWS REST API to upload an object to S3, which of the following request headers will ensure that your data must be encrypted using SSE?","explanation":"To request server-side encryption using the object creation REST APIs, provide the x-amz-server-side-encryption request header.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html","title":"Protecting Data Using Server-Side Encryption"}],"answers":[{"id":"6d1f5944b9a6aada7e00dc385d5373bd","text":"x-s3-server-side-encryption","correct":false},{"id":"6d38512683c3cf8052e7e47d9d12a9f6","text":"x-amz-server-side-encryption","correct":true},{"id":"f041d978ebb9256a023c1f9d263316ac","text":"amz-s3-server-side-encryption","correct":false},{"id":"63e1961675193e5c234f582f08632a28","text":"s3-amz-server-side-encryption","correct":false}]},{"id":"fb5e139f-6556-4841-94ce-b9801f9b88e4","domain":"refactoring","question":"You are migrating a restaurant booking application from your own data center to AWS. The application currently runs on a number of virtual machines running web and application servers as well as a shared database server. The applications need to access a large number of shared images and documents containing drinks and food menus. Which of the following could you use as a shared storage solution for this application so that the application servers can still access the shared files?","explanation":"ElastiCache is a temporary in memory data store, and is not for persisting shared files. DynamoDB is a noSQL database and not a suitable place to store images and text documents. SQS is a messaging system and not a data store. S3 is a storage solution suitable for images, documents and other files or objects which can be accessed by multiple users and services. The recommended way to enable EC2 instances to access S3 is by using an Instance Role.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html","title":"Using an IAM Role to Grant Permissions to Applications Running on Amazon EC2 Instances"}],"answers":[{"id":"7b5afb2448ce66d49ccd20687b03fb3d","text":"Store the files in DynamoDB","correct":false},{"id":"1c032bc585b67b0da68ac7711f6903dc","text":"Store the files in SQS","correct":false},{"id":"cfef61a88093b57cdfb2b8f688437a31","text":"Store the files in S3","correct":true},{"id":"c82a0db1b2bb65a785fb8195491de836","text":"Store the files in ElastiCache","correct":false},{"id":"31ad78ce89dc92d90e742d7ddf764a6d","text":"Embed IAM credentials in the EC2 instance metadata","correct":false},{"id":"1da781de965981ece00cf74ff1369c3e","text":"Generate a pre-signed URL to grant access","correct":false},{"id":"2412dfdf36b33ac6269617fc20e8cc04","text":"Use an IAM instance role to grant access","correct":true}]},{"id":"24137be2-c9b8-4be2-a4f0-0a5476fc15f9","domain":"development","question":"A developer has been tasked with migrating a large legacy web application, written in C++, to AWS. The developer wants to benefit from using Elastic Beanstalk to simplify the management of the infrastructure.\n\nWhich of the following methods would allow the developer to migrate the application with the least amount of work?\n","explanation":"Elastic Beanstalk supports Docker containers and custom AMIs via Packer. Both would allow the legacy application to be wrapped in a layer of abstraction such that Elastic Beanstalk itself would not need to support the specific language of the legacy application.\n\nThe Go platform only supports applications written in Go.\n\nThe application could be re-written in Node.js, but as it's a large application, a full rewrite is unlikely to require the least amount of work.\n\nElastic Beanstalk cannot be used to manage Lambda functions.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/create_deploy_docker.html","title":"Docker on Elastic Beanstalk"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/custom-platforms.html","title":"Packer with Elastic Beanstalk"}],"answers":[{"id":"680517836f5d3fd52719bcc51f4f57e9","text":"Use the Go platform, which can support any compiled language such as C++.","correct":false},{"id":"8711e00909d504f51f9e7cc0aea8ed4d","text":"Use Packer to generate a custom AMI that contains the application, which can then be deployed via Elastic Beanstalk.","correct":true},{"id":"37d73c08ebaf765061f6ad4fe756430a","text":"Create a custom Lambda layer with a C++ runtime, which can be called from within Elastic Beanstalk.","correct":false},{"id":"ea130ff77bca2e340acf49c464cdd620","text":"Rewrite the application in Node.js, which can then run natively via Elastic Beanstalk.","correct":false},{"id":"dadd577f7c15163f58854c17403e2a6d","text":"Use Docker to containerize the application, which can then be deployed via Elastic Beanstalk.","correct":true}]},{"id":"cd7c8d61-2ce7-401a-956f-c01c33305ae2","domain":"deployment","question":"Which of the following statements is correct?","explanation":"EBS-backed instances can be stopped and restarted without losing the data on the volume.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/instance-store-vs-ebs/","title":"Differences between EBS and Instance Store"}],"answers":[{"id":"36e118d467e9fcf94627a5fa1bc11446","text":"Instance-store backed instances can be stopped and restarted.","correct":false},{"id":"91fff5146ee33778a9158bd16a8ba469","text":"An Amazon VPC requires that instances be backed with EBS.","correct":false},{"id":"18eb677e835b4b7214b432d085e121fb","text":"An EBS backed instance can be stopped and restarted.","correct":true},{"id":"b335920b9f6cd5d6425a787a6183b378","text":"If you want to use auto-scaling, you must use an EBS-backed instance.","correct":false}]},{"id":"8caa9788-5c49-413f-b0c0-6f515af3fe5f","domain":"security","question":"An organization has mandated that all files stored in their newly created S3 bucket, 'top-secret-documents', must be encrypted using a Customer Master Key stored in KMS.\n\nWhat is the best way to enforce this requirement?","explanation":"To ensure objects are stored using a specific type of server-side encryption, you must use a bucket policy. In this case, the bucket policy must ensure the encryption type matches SSE-KMS.\n\nSetting a default encryption type on the bucket is not sufficient, as the default only applies to uploaded objects that do not specify any encryption type. For example, if the default encryption is set to AWS-KMS, but an object is uploaded with the header `x-amz-server-side-encryption: AES256`, the resulting object is encrypted using SSE-S3, not SSE-KMS.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html","title":"Protecting S3 Data Using Server-Side Encryption"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html","title":"Example bucket policy for enforcing SSE"}],"answers":[{"id":"62e28c6b06e8b3895db973aa3d03c4fd","text":"Add a bucket policy that denies PUT operations that don't contain the HTTP header `x-amz-server-side-encryption: AES256`","correct":false},{"id":"7910fc40ce77db47b28825a906611f8d","text":"Enable S3 Default encryption and select AWS-KMS","correct":false},{"id":"21b68cac2d99a4c11c51d224971ee62f","text":"Add a bucket policy that denies PUT operations that don't contain the HTTP header `x-amz-server-side-encryption: aws:kms`","correct":true},{"id":"8be8b17570d837c0301070a5b8fde1cb","text":"Add a bucket policy that denies PUT operations that don't contain the HTTP header `x-amz-server-side-encryption: SSE:C`","correct":false}]},{"id":"52d02968-6d43-434e-8d41-eaa3d8e69b68","domain":"mon-trb","question":"You are trying to diagnose a performance problem with your serverless application, which uses Lambda, API Gateway, S3 and DynamoDB. Your DynamoDB table is performing well and you suspect that your Lambda function is taking too long to execute. Which of the following could you use to investigate the source of the issue?","explanation":"AWS X-Ray can be used to display a histogram showing the latency of your Lambda function. Latency is the amount of time between when a request starts and when it completes. API Gateway Integration Latency in the time between when API Gateway relays a request to the backend and when it receives a response from the backend. API Gateway Latency is the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Lambda Invocations Sum measures the number of times a function is invoked in response to an event or invocation API call.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html","title":"API Gateway CloudWatch Metrics"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-metrics.html","title":"Lambda CloudWatch Metrics"},{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"},{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-histograms.html","title":"Using Latency Histograms in the AWS X-Ray Console"}],"answers":[{"id":"c464cce256f4ab986973ddae5e8fdf34","text":"Lambda Invocations Sum metric in CloudWatch","correct":false},{"id":"a8d172dc1d7797b755f243837a74be36","text":"API Gateway Latency metric in CloudWatch","correct":false},{"id":"90099b94810e3f14b68c4739eb4c456c","text":"API Gateway Integration Latency metric in CloudWatch","correct":true},{"id":"3dc993924bceb799c7009d281aa91408","text":"AWS X-Ray","correct":true}]},{"id":"08e64f1f-bcb0-40f6-843c-3457d9588552","domain":"refactoring","question":"A mobile social network application uses AWS SQS to distribute user's friends' profile updates. As the application grows in popularity, the required updates are reaching the 256KB message limit of SQS. What is a suitable solution to this problem?","explanation":"Using compression to reduce the size of the message payload is a possible approach to solving this issue. However, this would only be a temporary solution. As the number of members increased, the payload size would increase and would start to exceed the SQS message limit again. A more flexible approach is to store the update data in S3. This ensures that the data is stored reliably without any concerns regarding the data size. The SQS message payload would then contain a reference to the S3 blob. If the application is written in Java, the AWS SDK for Java supports this functionality out of the box. SNS has the same message payload limit as SQS, so this is not a suitable option. AWS AppSync is a service for enabling development of GraphQL based applications.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"520228b4da343e55c373c25f4d422e6e","text":"Use AWS AppSync to synchronize data to mobile app.","correct":false},{"id":"8face15b61dcc69017b29352cd7dc288","text":"Create an SNS Topic. Use SNS to send updates instead of SQS.","correct":false},{"id":"a2b93e7b257a6da054c32b0dd043384e","text":"Use compression to store the update data in a smaller SQS message.","correct":false},{"id":"0f7d51f145a99e3a18dbed75b79df613","text":"Store update data in S3 bucket. Send the reference to the S3 blob in the SQS message.","correct":true}]},{"id":"b1a8a6e6-0eb1-4c01-8d8b-4baebf067f88","domain":"development","question":"An application uses DynamoDB table as its backend data store. Each item has size of 10KB.  The application needs to perform 100 eventually consistent read operations per second, and 50 write operations per second.  What is the provisioned RCU value required to meet these requirements?","explanation":"1 RCU is equivalent to two eventually consistent reads per second of an item up to 4KB in size.  Thus, to calculate the required RCU in this scenario we need to: 1) Round up the item size to the nearest 4KB (12KB). 2) Divide by 4KB to calculate number of read units (12/4 = 3). 3) Divide by 2 to calculate the number of eventually consistent read units per item (3/2 = 1.5). 4) Multiple by operations per second to get the total RCU required (1.5*100 = 150 RCU).","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.ProvisionedThroughput.Manual","title":"Provisioned Mode"}],"answers":[{"id":"cee631121c2ec9232f3a2f028ad5c89b","text":"500","correct":false},{"id":"94f6d7e04a4d452035300f18b984988c","text":"300","correct":false},{"id":"a9b7ba70783b617e9998dc4dd82eb3c5","text":"1000","correct":false},{"id":"7ef605fc8dba5425d6965fbd4c8fbe1f","text":"150","correct":true}]},{"id":"f70f0615-b415-485e-93d5-2286bc2c25cc","domain":"development","question":"What is the maximum size of an item in a DynamoDB table?","explanation":"The maximum item size in DynamoDB is 400 KB.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html","title":"Limits in Amazon DynamoDB"}],"answers":[{"id":"5bdde53de5ac658c8aeeacac334b0152","text":"40 MB","correct":false},{"id":"3c0512af07779a4b40b2b3d95dd1375b","text":"40 KB","correct":false},{"id":"462e2e8040f8c2b03228a91524dd8953","text":"400 MB","correct":false},{"id":"1310fc461ca5af7082d588ba9c2a795b","text":"400 KB","correct":true}]},{"id":"bc3ffcc3-4225-4da3-8819-17ae2ee5c3dc","domain":"security","question":"A VPC has four subnets: 1) Subnet1 has a route table entry with destination: 0.0.0.0/0 and target: VPC Internet Gateway ID; 2) Subnet2 has a route table entry with destination 0.0.0.0/0 and target: NAT Gateway ID; 3) Subnet3 has a EC2 instance that serves as a bastion host 4) Subnet4 has an NSG Inbound Rule with Source: 0.0.0.0/0; Protocol: TCP; and Port Range: 1433. What would be the recommended subnet for hosting an RDS database instance?","explanation":"Security best practice would state that RDS Database instances should be deployed to a private subnet. A private subnet would only have private IP's with no direct access to the public internet. Outbound connectivity would be provided via a NAT gateway. Thus, Subnet2 is a suitable choice for deploying RDS instances as it is characterized as a private subnet. Subnet1 has direct connectivity to the public internet via the Internet gateway. Thus, it is characterized as a public subnet and would not be recommended location for deploying databases. Bastion hosts allow direct inbound connections from public internet. This means that Subnet3 would not be a good choice to host databases. Lastly, Subnet4 contains NSG rule that allows inbound connectivity from the public internet on the database port (1433). This makes it a poor candidate to host databases.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html","title":"VPC with Public and Private Subnets (NAT)"}],"answers":[{"id":"5fb3d14ca24c9ce9e6eecb5a650bf8c9","text":"Subnet2","correct":true},{"id":"58726f362b0b49454806dac56cdef893","text":"Subnet4","correct":false},{"id":"6415a7d7642468e623d92a6df2333f86","text":"Subnet1","correct":false},{"id":"5cf0f214c90cf601b2f5f3bb0c6ec507","text":"Subnet3","correct":false}]},{"id":"e4d5998a-073a-4507-991c-ac138ac609c5","domain":"mon-trb","question":"Your application reads data from an SQS queue. The reads are then forwarded to Lambda downstream for processing critical customer information including purchasing and inventory data. It is critical that this data is not lost. How would you accommodate failed Lambda captures of the data?","explanation":"A dead letter queue would allow you to prevent data loss. After a message is taken from the queue and returned for the maximum number of retries, it is automatically sent to a dead letter queue, if one has been configured. It stays there until you retrieve it for forensic purposes. To prevent other consumers from processing the message again, Amazon SQS sets a visibility timeout, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. The default visibility timeout for a message is 30 seconds. DelaySeconds for individual messages are similar to visibility timeouts because both features make messages unavailable to consumers for a specific period of time. The difference between the two is that, for delay queues, a message is hidden when it is first added to queue, whereas for visibility timeouts a message is hidden only after it is consumed from the queue. A FIFO queue guarantees first-in-first-out.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html","title":"Amazon SQS Dead-Letter Queues"}],"answers":[{"id":"b431614eebc36d55520274500ed9ba2d","text":"Create a FIFO queue and set DelaySeconds to 3.","correct":false},{"id":"5d63d8895abd795fa4b98f12304185dc","text":"Create a dead letter queue and set the Maximum Receives to 3.","correct":true},{"id":"7e66715cc7d52627f1372ab97dbd2350","text":"Requeue the message with DelaySeconds to 3.","correct":false},{"id":"029cff5be66415e342452d104b4e2e57","text":"Requeue the message with a VisibilityTimeout of 30 seconds.","correct":false}]},{"id":"47e074a7-e675-4918-92bf-d9a34b82803c","domain":"security","question":"Your application needs to access content located in an S3 bucket which is residing in a different AWS account, which of the following API calls should be used to gain access?","explanation":"The STS AssumeRole API call returns a set of temporary security credentials which can be used to access AWS resources, including those in a different account","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html","title":"Providing temporary access to AWS resources"}],"answers":[{"id":"5854d57d52033e05be8f9fda06330abd","text":"STS:AttachRole","correct":false},{"id":"c2599de6f471b00ab3948981939f8315","text":"STS:GetFederationToken","correct":false},{"id":"818a55892aa657e5ef8dae6d12ee9273","text":"IAM:AddRoleToInstanceProfile","correct":false},{"id":"100979100796827d7bcafe4666e4984f","text":"STS:AssumeRole","correct":true}]},{"id":"55ffe5c3-b16f-42d6-9b3e-5f4d77890f49","domain":"mon-trb","question":"You are troubleshooting a major incident which has resulted in data loss in your application. Your manager asks if you can provide a time-ordered sequence of any modifications which happened to the items in your DynamoDB table over the past 24 hours so that you can work out what happened. Which service could you use to most effectively provide this?","explanation":"DynamoDB Streams captures a time-ordered sequence of item-level modifications in a DynamoDB table and durably stores the information for up to 24 hours.","links":[{"url":"https://aws.amazon.com/blogs/database/dynamodb-streams-use-cases-and-design-patterns/","title":"DynamoDB Streams Use Cases"}],"answers":[{"id":"1f60690ba7c488a02416a7bf195f900b","text":"DynamoDB Streams","correct":true},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"48d30a1b2a41bc37892197dc4df30262","text":"Kinesis Streams","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false}]},{"id":"b41da940-4b4e-11ea-b77f-2e728ce88125","domain":"mon-trb","question":"You created a CloudFormation template that launched a web application in us-west-1. However, you are experiencing a problem creating a development stack in us-east-1 to serve clients in another geographical location. What should you do to solve the problem?","explanation":"An Amazon Machine Image, or AMI, is used to launch an EC2 instance in a specified region. So, to use it in another region, you will have to copy it to the region of your choice. Recreating the resources is unnecessary since you only need to copy the AMI. And the IAM role is irrelevant to the question, since IAM roles are valid across the entire AWS account.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"e3bebd36eb37842d75a71b0a69c37abe","text":"Copy the AMI in the template from us-west-1 to us-east-1.","correct":true},{"id":"b5a9be3c7b03258224fb637458459b99","text":"Recreate the AWS resources used for the application in us-west-1.","correct":false},{"id":"6971fa728cde2ee82b21faac08aeb60a","text":"Copy your IAM role to us-east-1 region so that you have permissions to deploy CloudFormation stacks in that region.","correct":false},{"id":"e72b5dc8983df71bdc1fa0c5b4985e4f","text":"Copy the AMI in the template from us-east-1 to us-west-1.","correct":false}]},{"id":"72b0a4e6-82a6-4355-aa09-cf28563f00ed","domain":"development","question":"You are developing an online gaming application which needs to synchronize user profile data, preferences and game state across multiple mobile devices. Which of the following Cognito features enables you to do this?","explanation":"Amazon Cognito Sync is an AWS service and client library that enable cross-device syncing of application-related user data. You can use it to synchronize user profile data across mobile devices and web applications. The client libraries cache data locally so your app can read and write data regardless of device connectivity status. When the device is online, you can synchronize data, and if you set up push sync, notify other devices immediately that an update is available.","links":[{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-sync.html","title":"Amazon Cognito Sync"},{"url":"https://docs.aws.amazon.com/cognito/latest/developerguide/getting-started-with-cognito-sync.html","title":"Getting Started with Amazon Cognito Sync"}],"answers":[{"id":"9a09b38e27134b81a45f7f2ed3939edc","text":"Cognito User Pools","correct":false},{"id":"0b422b4e655adc456bd9363c2dba938a","text":"Cognito Events","correct":true},{"id":"67cb5d76e7fadc7e245c0cce89ad6dbf","text":"Cognito Sync","correct":true},{"id":"31aa670fdceaaf4289c74a1425e69d5b","text":"Cognito Streams","correct":false}]},{"id":"dbc263cc-9e31-4671-b11a-674870a5dcd3","domain":"deployment","question":"You have been asked to use Elastic Beanstalk to build a number of web servers to use in your development environment, which of the following services can you use?","explanation":"Except for Lambda, all of the services listed can be used to create a web server farm. AWS Lambda automatically runs your code without requiring you to provision or manage servers. Lambda is generally used for stateless, short-running tasks and is not suitable for long-running tasks like running a web server.","links":[{"url":"https://aws.amazon.com/lambda/","title":"What Is Lambda?"},{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html","title":"What Is AWS Elastic Beanstalk?"}],"answers":[{"id":"e95e5a2a3cc8625bca3d71b817367e2d","text":"Elastic Load Balancer","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"b578e821ab9be9669c17208a583b5899","text":"Auto Scaling Group","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true}]},{"id":"b6e02165-99c1-465f-b270-e95ed7b282c6","domain":"deployment","question":"Your distributed application sends and receives a number of large SQS messages, each of which can be up to 2GB in size. You are finding that the messages in one particular queue are getting processed a few seconds faster than expected which is causing problems in your application. The application architect has asked you to introduce a sleep period of 5 seconds which should apply to all the messages in the queue and you have also been asked to avoid storing large amounts of data in SQS. Which of the following changes do you recommend?","explanation":"Delay queues let you postpone the delivery of new messages to a queue for a number of seconds. If you create a delay queue, any messages that you send to the queue remain invisible to consumers for the duration of the delay period. You can use Amazon S3 and the Amazon SQS Extended Client Library for Java to manage Amazon SQS messages. This is especially useful for storing and consuming messages up to 2 GB in size. Unless your application requires repeatedly creating queues and leaving them inactive or storing large amounts of data in your queue, consider using Amazon S3 for storing your data.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"afb12b79c99a2eeace3a062cd3ad4cd6","text":"Use a FIFO queue to postpone the delivery of SQS messages by 5 seconds","correct":false},{"id":"a41630268ea2c21362c11173dd3e5ff1","text":"Store the large messages in DynamoDB","correct":false},{"id":"1f11b5e76705a7428ff631dfaae81308","text":"Store the large messages on S3","correct":true},{"id":"3b29dadac2fdd775f1294d12bdccec11","text":"Store the large messages in a separate queue","correct":false},{"id":"64c850e3b6d5e1a54696ff59341cffc2","text":"Use an SQS delay queue to let you postpone the delivery of SQS messages by 5 seconds","correct":true}]},{"id":"c9035bad-12fc-4afa-805c-a9faa8f1078f","domain":"development","question":"Your application accesses data stored in an S3 bucket. The S3 bucket hosts human resources data and the application produces a summary of key metrics with the human resources data via dashboard. The data is also inserted into an RDS table for another downstream process. Given this environment, which operation could return temporarily inconsistent results?","explanation":"Amazon S3 provides read-after-write consistency for PUTS of new objects in your S3 bucket in all Regions with one caveat. The caveat is that if you make a HEAD or GET request to a key name before the object is created, then create the object shortly after that, a subsequent GET might not return the object due to eventual consistency. Amazon S3 offers eventual consistency for overwrite PUTS and DELETES in all Regions. Strict read-after-write consistency is available on the main DB Instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Introduction to Amazon S3"}],"answers":[{"id":"d78b72603892e5cf166cd79f125685df","text":"Downloading employee data from S3 after it was created.","correct":false},{"id":"88b5992e95f695a0d9a8f5bc66376a6e","text":"Running a SELECT statement in RDS after new employee data was inserted.","correct":false},{"id":"b5bc268aa60bf81ed5116d16a002db71","text":"Reading employee data on the dashboard after the employee was deleted from the S3 bucket from termination.","correct":true},{"id":"d0cc2f897bd189b1c38cb5df31dd166d","text":"Running a SELECT statement in RDS after employee data was removed due to termination.","correct":false}]},{"id":"8b887631-86bd-436d-adee-4e2ba3b02111","domain":"security","question":"You have an application running on multiple EC2 instances, however every time an instance fails, your users complain that they lose their session. What can you do to prevent this from happening?","explanation":"There are various ways to manage user sessions including storing those sessions locally to the node responding to the HTTP request or designating a layer in your architecture which can store those sessions in a scalable and robust manner. Common approaches used include utilizing Sticky sessions or using a Distributed Cache for your session management. In order to address scalability and to provide a shared data storage for sessions that can be accessed from any individual web server, you can abstract the HTTP sessions from the web servers themselves. A common solution for this is to leverage an In-Memory Key/Value store such as ElastiCache.","links":[{"url":"https://aws.amazon.com/caching/session-management/","title":"Session management in AWS"}],"answers":[{"id":"b225818943ba4680b8e7dc9d9c376359","text":"Store session state in RDS","correct":false},{"id":"89230492f141a4f85234c624287bb96a","text":"Store session state in ElastiCache","correct":true},{"id":"ef4fd36fa55c3c499f3fffa82a0c95e8","text":"Store session state in on the Elastic Load Balancer","correct":false},{"id":"b193b1caff1bda86125cc326ca1058ac","text":"Store session state on a dedicated EC2 instance","correct":false},{"id":"76fc6bddee6b0f8d088ea5cbe4e57160","text":"Store session state in S3","correct":false}]},{"id":"f83e6c6c-f206-4918-8457-d6bef8d4a555","domain":"deployment","question":"You have deployed a new version of your Lambda function, however the Application Support team have reported a number of issues with the new code. What is the easiest way to fix this?","explanation":"You can map an alias to different versions of the same function, allowing for easy roll back to a previous version","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda Versions"}],"answers":[{"id":"80718f268b030c98e8cb509f28eebee4","text":"Roll back by restoring the original function from an EBS snapshot","correct":false},{"id":"8ab78c3f557d33ed014a6819ff45cf93","text":"Troubleshoot the issue using X-Ray, then redeploy an updated version of the function","correct":false},{"id":"1275e2de1d5df0a79ed92417584f94e9","text":"Delete the CloudFormation stack and redeploy using the previous version","correct":false},{"id":"bb979a7d188850e77ff0bc3293db2877","text":"Roll back to a previous version by updating your PROD alias to point to the previous version of the function","correct":true}]},{"id":"339adcf9-1e4b-4680-89d7-c123c6b2c310","domain":"deployment","question":"Which DynamoDB feature allows you to set an expiry on table items so that they can automatically be deleted to reduce storage costs?","explanation":"Time To Live (TTL) for DynamoDB allows you to define when items in a table expire so that they can be automatically deleted from the database. TTL is provided at no extra cost as a way to reduce storage usage and reduce the cost of storing irrelevant data without using provisioned throughput. With TTL enabled on a table, you can set a timestamp for deletion on a per-item basis, allowing you to limit storage usage to only those records that are relevant.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html","title":"DynamoDB TTL"}],"answers":[{"id":"52d5592ad24a2cda379ce38e9c218d65","text":"DynamoDB TTL","correct":true},{"id":"1f60690ba7c488a02416a7bf195f900b","text":"DynamoDB Streams","correct":false},{"id":"23b12446c9410404041f4de88841a9c3","text":"DynamoDB Provisioned Throughput","correct":false},{"id":"61cc6306baa4c0f3c5fe422a835c2455","text":"DynamoDB AutoDelete","correct":false}]},{"id":"422c80de-8e21-4706-ab03-ce11c4cfa083","domain":"deployment","question":"You are developing a completely serverless application using Lambda and API Gateway. You need a place to persist data as key-value pairs and your application will need low latency access to the data. Which of the following is the best option for storing this data?","explanation":"DynamoDB is a key-value and document database that delivers single-digit millisecond performance at any scale. RDS does not store data as key-value pairs, a JSON document in S3 is not an efficient way to store the data and using an EC2 instance would not be serverless and would not be scalable.","links":[{"url":"https://aws.amazon.com/dynamodb/","title":"DynamoDB Overview"}],"answers":[{"id":"243a3f875904542a9e0117f28650b59f","text":"Store the data in an RDS database","correct":false},{"id":"866706615c3cfcbd5b3dfc3bbd116f85","text":"Store the data in JSON format in an S3 bucket","correct":false},{"id":"5d9c9d9ca04e432986c67415ccfdb791","text":"Store the data in JSON format on an EC2 instance","correct":false},{"id":"023289eeb117bb428a4288ca492fd5e8","text":"Store the data in a DynamoDB table","correct":true}]},{"id":"c11f4354-0409-46a1-a058-1e377939c655","domain":"development","question":"You are in a development team working on a popular serverless web application which allows users to book late availability flights and hotels at a significant discount. You occasionally receive complaints that the website is running slowly. After some investigation, you notice that at the time of the complaints, DynamoDB reported a ProvisionedThroughputExceeded error. Which of the following approaches is a recommended way to handle this error?","explanation":"Increasing Lambda capacity will not fix the issue because the problem is with DynamoDB. As the error only appears occasionally, the first thing to do is to ensure that the application is using Exponential Backoff to improve flow control. Increasing the capacity on the DynamoDB table could be considered but only if the problem persists.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff","title":"DynamoDB Error Handling"}],"answers":[{"id":"7f6f787080ee787e0f7554f770e0c693","text":"Ensure your application is using Exponential Backoff","correct":true},{"id":"528fd1044e587b850c48dc8d209cfe11","text":"Increase the read/write capacity of the DynamoDB table","correct":false},{"id":"cbf47ddd16d15ef42c8c335fe895c69f","text":"Increase the CPU capacity of the Lambda function","correct":false},{"id":"e7668448048601413de55468a4091b5d","text":"Increase the RAM capacity of the Lambda function","correct":false}]},{"id":"2d2bf934-5970-454e-846b-eaec6bf8d227","domain":"security","question":"A financial services organization is using Amazon S3 service to store highly sensitive data. What is the correct IAM Policy that must be applied to ensure that all objects uploaded to the S3 bucket are encrypted?","explanation":"In IAM Policy, the optional condition block enables specification of conditions for when a policy is in effect. In the Condition block, condition operators (such as equal, less than, etc.), the condition keys, and values can be combined into an expression to be evaluated. The IAM policy is applied when the condition expression is true. Condition key s3:x-amz-server-side-encryption must be used to validate that the object being uploaded is encrypted. Resource S3 ARN must include /* at the end of the S3 bucket name to be a valid ARN.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/amazon-s3-policy-keys.html","title":"Specifying Conditions in a Policy"}],"answers":[{"id":"6d70f3311566d7a45c1ee462595ab321","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:x-amz-server-side-encryption\":\"AES256\"\n                   }\n                }\n             }\n          ]\n       }\n       ","correct":false},{"id":"1cf9545900a32abf21ee1166aa1f7d3d","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket/*\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:sse-encryption-cipher\":\"AES256\"\n                   }\n                }\n             }\n          ]\n       }\n       ","correct":false},{"id":"38189a723781ee6f9148edfaeaf7f44b","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket/*\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:x-amz-server-side-encryption\":\"AES256\"\n                   }\n                }\n             }\n       ","correct":true},{"id":"ca109710bb536d634e22f18fabf99d28","text":"{\n          \"Version\":\"2012-10-17\",\n          \"Id\":\"PutObjPolicy\",\n          \"Statement\":[{\n                \"Sid\":\"DenyUnEncryptedObjectUploads\",\n                \"Effect\":\"Deny\",\n                \"Principal\":\"*\",\n                \"Action\":\"s3:PutObject\",\n                \"Resource\":\"arn:aws:s3:::SensitiveDataBucket\",\n                \"Condition\":{\n                   \"StringNotEquals\":{\n                      \"s3:sse-encryption-cipher\":\"AES256\"\n                   }\n                }\n             }\n          ]\n       }\n       ","correct":false}]}]}}}}
