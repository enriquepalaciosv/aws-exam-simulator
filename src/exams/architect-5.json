{"data":{"createNewExamAttempt":{"attempt":{"id":"d1a75224-e48f-48c7-839f-61c64afcf17a"},"exam":{"id":"b17e6980-b2b8-45a7-ab1f-9d91eb42eebe","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"a037e5e2-59b3-4163-8260-8e6ce3054ec7","domain":"CostOptimized","question":"A consumer electronics manufacturer has recently migrated their applications to AWS. They receive their first monthly invoice which results in many questions about their AWS usage. The finance team attempts to answer inquiries using Cost Explorer, but some of the requests regard specialized accounting for their business which Cost Explorer doesn't address. Which solution will give them the ability to search, analyze, and visualize their costs in a granular way for their specific requirements?","explanation":"The AWS Cost and Usage Report contains line items for each unique combination of AWS product, usage type, and operation that your AWS account uses. Deploying a Kibana dashboard with Elasticsearch provides the capability to create custom visualizations. Leveraging the Kibana offering inside Amazon Elasticsearch provides a fully managed service that doesn't need to be managed as it would be on EC2. Since we're only looking to search a single cost usage table with a huge number of rows, and don't need to perform table joins, an RDS MySQL or RedShift solution would not be required and would be more costly. The AWS Detailed Billing Reports will be unavailable at a later date, and AWS recommends using the Cost and Usage Report instead.","links":[{"url":"https://aws.amazon.com/aws-cost-management/aws-cost-and-usage-reporting/","title":"AWS Cost and Usage Report"},{"url":"https://aws.amazon.com/elasticsearch-service/","title":"Amazon Elasticsearch Service"},{"url":"https://aws.amazon.com/solutions/cost-optimization-monitor/?did=sl_card&trk=sl_card","title":"Cost Optimization Monitor"}],"answers":[{"id":"701c3c7e248d12e2b08cc6fb88e5789d","text":"Implement scripts on an EC2 instance that pull AWS Detailed Billing Reports from S3 and load the data into an Amazon Elasticsearch Service domain. Deploy Kibana on that same EC2 instance and create the custom visualizations required","correct":false},{"id":"b61314c9a3e461d11598a04472234a0c","text":"Deploy AWS Database Migration Service to read AWS Cost and Usage Reports from S3 and load the data into an Amazon RDS MySQL database. Create an Amazon QuickSight dashboard with the custom visualizations required","correct":false},{"id":"bbf8436d8501e9bd4d59b9d3d378d28c","text":"Create scripts on an EC2 instance that pull AWS Cost and Usage Reports from S3 and load the data into an Amazon Elasticsearch Service domain. Configure Kibana dashboards in Amazon Elasticsearch for the custom visualizations required","correct":true},{"id":"8608d849f91c63eea5519d1fdd9e2143","text":"Configure AWS Glue to read AWS Detailed Billing Reports from S3 and load the data into Amazon Redshift. Create an Amazon QuickSight dashboard with the custom visualizations required","correct":false}]},{"id":"c4ce254d-d835-4beb-b096-153d84bada07","domain":"SecureSolutions","question":"Which of the following services allows you to access the service's underlying operating system?","explanation":"Access to the underlying operating system is granted for Elastic Map Reduce and Elastic Beanstalk. The others are managed services.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html","title":"About Elastic Beanstalk"},{"url":"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html","title":"About EMR"}],"answers":[{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":true},{"id":"8d4c0b2cef256d21ab680366c8b1c6bf","text":"EMR","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false}]},{"id":"60422bef-b086-4439-aea9-d69bec189aeb","domain":"ResilientDesign","question":"Your company is planning on moving to AWS. One of your applications will be launched on a set of EC2 instances. You will need to ensure that the architecture is fault tolerant and highly available. Which of the following would be considered during the design process?","explanation":"Most of the higher-level services, such as Amazon Simple Storage Service (S3), Amazon SimpleDB, Amazon Simple Queue Service (SQS), and Amazon Elastic Load Balancing (ELB), have been built with fault tolerance and high availability in mind. Services that provide basic infrastructure, such as Amazon Elastic Compute Cloud (EC2) and Amazon Elastic Block Store (EBS), provide specific features, such as availability zones, elastic IP addresses, and snapshots, that a fault-tolerant and highly available system must take advantage of and use correctly. Just moving a system into the cloud doesn’t make it fault-tolerant or highly available.","links":[{"url":"https://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_ftha_04.pdf","title":"Fault Tolerance and High Availability"}],"answers":[{"id":"700492f3858af873a95f4dba00498eb1","text":"Ensure that the EC2 instances are spread across a single Availability Zone for better maintenance.","correct":false},{"id":"a5d1a542762ddd14a1eab199dd696866","text":"Enable Multi-AZ for the databases.","correct":false},{"id":"8452a57471394c1fe0eb301c134cd186","text":"Ensure that the EC2 instances are spread across multiple Availability Zones.","correct":true},{"id":"2147d9d417ff1f29977b7ba5eb1a98b0","text":"Use a load balancer in front of the EC2 instances.","correct":true}]},{"id":"b21cf2a7-0cf1-47d4-a0c2-60403bb9cf37","domain":"CostOptimized","question":"To stay within the AWS Free Tier using Amazon EC2 for the first 12 months of having an AWS account, which of the following instance types should you use?","explanation":"One of the EC2 requirements for staying within the AWS Free Tier is using EC2 micro instances only. That makes t2.micro and t3.micro the correct responses.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc","title":"AWS Free Tier"}],"answers":[{"id":"1d4f2c610dbeb44e7ba09fed19564c76","text":"t2.micro","correct":true},{"id":"affa6cb0576af5aa6e603780fe7b203c","text":"t3a.small","correct":false},{"id":"ab61127647912c159c3fc08e9a102efc","text":"t2.small","correct":false},{"id":"7d3869f3c790e32d408d21d331095b0b","text":"t3.micro","correct":true}]},{"id":"8da7e23d-5ac6-44bf-b3e0-366162b92047","domain":"Performant","question":"Your employer, a publishing company, wants the images of its various websites to be resized so that they can be optimally viewed on any electronic device. Which of the following AWS services will be most suitable for this type of processing?","explanation":"Although Amazon S3 is used to store the image files, it is an AWS Lambda function that would be used to resize them for optimal viewing on any device, such as a desktop computer, tablet, or smartphone. CloudTrail is used for captured AWS API calls and RDS is a Database service, so neither would be suitable for this application.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/with-s3-example.html","title":"Tutorial - Using AWS Lambda with Amazon S3"}],"answers":[{"id":"35686630aa3baddc18c904374e570233","text":"Amazon RDS","correct":false},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":false},{"id":"dee7ff8f7b10b9d388c7c561e9413b0d","text":"AWS Lambda","correct":true},{"id":"270fcb785810d0206945029bb05f4e97","text":"Amazon S3","correct":false}]},{"id":"65db44a4-e11e-495a-9524-5bc708945f8d","domain":"Performant","question":"Which of the following services allows you to have root-level access to the underlying operating system","explanation":"You can use SSH to access the underlying operating systems of EMR and EC2.","links":[{"url":"https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-connect-master-node-ssh.html","title":"Connecting to the EMR Master Node"}],"answers":[{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"8d4c0b2cef256d21ab680366c8b1c6bf","text":"EMR","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false}]},{"id":"9c17aa9c-1337-4d5c-9e2b-c9c8c518d11c","domain":"ResilientDesign","question":"You work for a games development company who are re-architecting their production environment. They have decided to make all web servers stateless. Which of the following the AWS services will help your company achieve this goal?","explanation":"An Elastic Load Balancer can help you deliver stateful services, but not stateless. Elastic Map Reduce is a data-analysis service and is not related to servicing web traffic.","links":[{"url":"https://d0.awsstatic.com/whitepapers/managing-your-aws-infrastructure-at-scale.pdf","title":"Managing your Infrastructure at Scale"}],"answers":[{"id":"1e96c51293fadd6f988e139c54e7b754","text":"ELB","correct":false},{"id":"8d4c0b2cef256d21ab680366c8b1c6bf","text":"EMR","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":true}]},{"id":"8b4f4f4a-0f1e-420a-9115-3ddde644cecc","domain":"Performant","question":"Your application's has a rapid upscale and usage peaks at 90% during the hours of 9 AM and 10 AM everyday. All other hours require only 10% of the peak resources. What is the best way to scale your application so you're only paying for max resources during peak hours?","explanation":"Proactive cyclic scaling is scaling that occurs at a fixed interval (daily, weekly, monthly, quarterly. The proactive approach can be very effective when the upscale is large and rapid and you cannot wait for the delays of a sequence of auto-scaling steps.)","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/schedule_time.html","title":"Scheduled Scaling"}],"answers":[{"id":"6acf192ec915189144dfc5769ea5905a","text":"Reactive event-based scaling","correct":false},{"id":"d08473e23d73d31785239196c7ef5064","text":"Proactive cyclic scaling","correct":true},{"id":"1c8add13dc251f42618a5622a1a04714","text":"Reactive cyclic scaling","correct":false},{"id":"00464894fd00bf415d119e5a89bd61a4","text":"Proactive event-based scaling","correct":false}]},{"id":"3dc35381-00ad-4390-a31b-23a8340f4d57","domain":"SecureSolutions","question":"A co-employee approaches you with the need to access DynamoDB tables consisting of raw web analytics data to complete a required document on your company’s Data Warehouse processes. This is the only time in which the employee needs to access this information, and he needs such access for this day alone. What is the most appropriate course of action?","explanation":"Documenting your company’s Data Warehouse processes is a required task, so you simply can’t refuse access to the DynamoDB tables. However, it must be done in a way that does not risk the access of data by unauthorized users. That definitely rules out giving the employee your user credentials. And while you can simply create an IAM user, this action is for people who need continued and constant access; this employee only needs information from the database within a one-day window. Ultimately, the best course of action is to assign the appropriate IAM role to the employee to access the tables for this day, then remove the role assignment.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/authentication-and-access-control.html","title":"Identity and Access Management in Amazon DynamoDB"}],"answers":[{"id":"890c7f1c8bb33b06433d48f55f6a49d5","text":"Assign the appropriate IAM role to the employee to access the tables.","correct":true},{"id":"2b88f12405ab69024649b137e9e3ff74","text":"Refuse access to the tables.","correct":false},{"id":"5cf22da28e8e107eaa66dc1f724a6e34","text":"Create an IAM user for the employee to access the tables.","correct":false},{"id":"dd83c17dcfcf3b3acbb7200de7c2b473","text":"Give the employee your user credentials.","correct":false}]},{"id":"700ce3f4-c46f-458d-8091-8479bbd91a0f","domain":"ResilientDesign","question":"A three-tier application is hosted on Amazon EC2 instances inside a VPC. User-facing web application servers are hosted in a public subnet. Backend application servers and database servers are hosted in private subnets. Backend applications must communicate with third party service providers for software updates. Which option follows best practice for enabling communication with third party service providers?","explanation":"A network address translation (NAT) gateway is used to enable instances in a private subnet to connect to the internet, but prevent the internet from initiating a connection with those instances. NAT Gateway is a highly-available and redundant service managed by AWS and optimized for handling NAT traffic. On the other hand, high-availability, redundancy, maintenance, and performance optimization must all be managed by the client for NAT instances. For this reason, a NAT Gateway is the preferred solution. Bastion hosts are used to provide inbound traffic from the internet to servers inside a private subnet. Internet Gateway is a VPC component that enables communication between EC2 instances inside a VPC and the internet.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html","title":"NAT Gateways"}],"answers":[{"id":"6d055f2d1cd38f65e273e810495a0262","text":"Create an Internet Gateway in the public subnet.","correct":false},{"id":"01f72d8ddec0b1ad2b072ea6bf2dc573","text":"Create a NAT Gateway in the public subnet.","correct":true},{"id":"34eba009b3f3688edc57beccaedb02e5","text":"Create a NAT instance in the public subnet.","correct":false},{"id":"92280e9e404f0e94fd6dfbae89030a55","text":"Create a Bastion instance in the public subnet.","correct":false}]},{"id":"27dde6ff-a04e-4241-ba67-ebe458140bc8","domain":"SecureSolutions","question":"Which of the following EC2 operating systems is NOT supported by CloudWatch?","explanation":"All EC2 operating systems are supported by CloudWatch.","links":[{"url":"https://aws.amazon.com/cloudwatch/details/#amazon-ec2-monitoring","title":"CloudWatch and EC2"}],"answers":[{"id":"3d945423f8e9496c429a5d8c65b4604f","text":"Ubuntu","correct":false},{"id":"6fe8b98c53e8d099686936732785d471","text":"Debian","correct":false},{"id":"989c778ad92edeea91902330359e214d","text":"None of these. All EC2 instance types and operating systems are supported by CloudWatch.","correct":true},{"id":"0916f479fafc28dd10d3cee381041c01","text":"Amazon Linux","correct":false}]},{"id":"424b1344-ed2d-45df-8705-ccc54d235d1e","domain":"ResilientDesign","question":"You've been storing social media post information about your company's products for a little over two years. Most of the information is frequently used by the marketing department. The raw posts and some metadata are stored in an Amazon Aurora database. One day, the query application begins returning error messages. Marketing department users tell you they need the application available immediately for work on a campaign that's launching next week. Upon investigation you find that database storage has grown to the 64 TB limit for Aurora. What will be the most expeditious way to solve this issue?","explanation":"You can use AWS Database Migration Service (DMS) to migrate data from Aurora to S3 in CSV format, which can then be queried by Amazon Athena if needed. Creating a case with AWS Support won't resolve this issue since the Aurora storage limit is not an adjustable quota. Using the Aurora Global Database feature will not increase the maximum storage limit for a single database. While an EMR cluster may be a better solution for this use case, there is not time to perform such a migration in the time frame required by the marketing department","links":[{"url":"https://aws.amazon.com/rds/aurora/","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/dms/","title":"Amazon Database Migration Service"},{"url":"https://aws.amazon.com/blogs/database/archiving-data-from-relational-databases-to-amazon-glacier-via-aws-dms/","title":"How to archive data from relational databases to Amazon Glacier using AWS DMS"}],"answers":[{"id":"98787ed0461b156ab50abac0b75e22c4","text":"Use AWS Database Migration Service to move the least accessed data to Amazon S3","correct":true},{"id":"e9351ebb109e6e0e2d29eaa03a931116","text":"Open a case with the AWS Support Center to increase the Aurora database's storage quota","correct":false},{"id":"deb5ee8cd76c99a18d1c712fa2fe45a5","text":"Migrate the database to an Amazon EMR cluster and use data mining tools for analyses going forward","correct":false},{"id":"40f74ae9c39738abdadc3558462e1b39","text":"Turn on the Aurora Global Database feature and distribute part of the data to another AWS Region","correct":false}]},{"id":"6360570c-c801-4b78-a0ba-7860817cb309","domain":"ResilientDesign","question":"You have a busy media website that runs on a fleet of EC2 instances behind an application load balancer. You have a number of different target groups for different purposes. One of these target groups is a fleet of EC2 instances which contains the images for your website. When ever a user visits www.yoursite.com/images/ you need your application load balancer to direct the request to the images target group. How do you configure this rule on your application load balancer?","explanation":"One of the major benefits of teh ALB is that it supports 'path-based' routing which allows you to direct the traffic based on the content of the URL path.  In this case /images/ can be directed to a specific target group.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-update-rules.html","title":"ALB Listener Rules"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html","title":"What Is an Application Load Balancer?"}],"answers":[{"id":"002f909cd633d40a7e860e8793272fe4","text":"Using Cross Zone Load Balancing.","correct":false},{"id":"86e943f32a460169646a1a9a54de8934","text":"Using Sticky Sessions.","correct":false},{"id":"4d15809e9acf1ee9617c2e118157323e","text":"Using Query String Parameters.","correct":false},{"id":"5a3ddbcafc8cd528ecdb152c181daba6","text":"Using Path Patterns.","correct":true}]},{"id":"4eb40e8a-8251-44ca-a55f-7a2d2e39a78c","domain":"CostOptimized","question":"A large company is running multiple Amazon EC2 and Amazon RDS services across several AWS Regions. You are an AWS consultant and the company approaches you to provide recommendations on how to reduce operational cost without any major changes. The company confirms that certain instances are required to be run only during business hours from 8AM to 6PM on weekdays and can be shutdown on weekends and non-business hours. Which of the following automated solutions best matches the requirements?","explanation":"AWS offers infrastructure on demand so that customers can control their resource capacity and pay only for what they consume. One simple method to reduce costs is to stop resources that are not in use, and then start those resources again when their capacity is needed. The AWS Instance Scheduler is a simple AWS-provided solution that enables customers to easily configure custom start and stop schedules for their Amazon EC2 and Amazon RDS instances. The solution is easy to deploy and can help reduce operational costs for both development and production environments. Customers who use this solution to run instances during regular business hours can save up to 70% compared to running those instances 24 hours a day. AWS Auto Scaling is not a correct solution as auto-scaling groups can contain Amazon EC2 instances from multiple Availability Zones within the same Region and cannot contain instances from multiple regions. As the company confirms that the instances are required to be run during Business hours, Spot Instance is not a good choice as spot instances may be terminated if the spot price is higher than the bid price. Also, moving AWS Instances to lesser configurations is neither an automated solution nor guarantees saving operational cost if run 24 hours.","links":[{"url":"https://docs.aws.amazon.com/solutions/latest/instance-scheduler/overview.html","title":"AWS Instance Scheduler"}],"answers":[{"id":"c9eccc5399c22049703ce9be447d23d7","text":"AWS Instance Scheduler","correct":true},{"id":"f4bf61a51bd424cab4d9129fd4f2ef6a","text":"Move Instances to Spot Instances","correct":false},{"id":"f657bd5509ffc79a6cb033747ff52f50","text":"Move AWS instances to lesser configuration Instance Type","correct":false},{"id":"2f766b7c3ac605171e839f447d7e239c","text":"AWS Auto Scaling","correct":false}]},{"id":"8a4cd8a8-183f-11ea-8d71-362b9e155667","domain":"CostOptimized","question":"Your company recently expressed interest in upgrading to an AWS Support plan that provides infrastructure event management and incident response for the launch of a business-critical application. Which of the following support plans will satisfy your company's requirements?","explanation":"Each AWS account comes with Basic Support, so Basic is not the answer. Either the Business or the Enterprise plan grants access to AWS Infrastructure Event Management, the program your company needs for assistance with launching the application. The Enterprise plan, however, provides up to a 15-minute response time if the business-critical application goes down; the Business plan does not offer this option. In addition, the Busines Plan does not include Infrastructure Event Management - you need to pay an additional fee for this. Therefore the Enterprise plan is the only option that provides the appropriate level of incident response and infrastructure event management required.","links":[{"url":"https://console.aws.amazon.com/support/plans/home?#/","title":"AWS Support Plans"},{"url":"https://aws.amazon.com/premiumsupport/programs/iem/","title":"AWS Infrastructure Event Management"}],"answers":[{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":false},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false}]},{"id":"b492e9e4-864d-4ff2-9702-262996b05c46","domain":"Performant","question":"How does AWS deliver high durability for DynamoDB?","explanation":"Amazon DynamoDB is highly available, with automatic and synchronous data replication across three facilities within a Region. This helps protect your data against individual machine, or even facility level failures.","links":[{"url":"https://aws.amazon.com/dynamodb/details/#High_Availability","title":"DynamoDB High Availability"}],"answers":[{"id":"b0991ddf7a0ec7d6b52ed6e7bfc4c119","text":"DynamoDB data is automatically replicated across multiple AZs.","correct":true},{"id":"d617d277b2fd6ec82cdccb131e3676a4","text":"AWS maintains a schedule of incremental backups and log shipping.","correct":false},{"id":"9cb98abf406dd2e8a688aeb9c3ffdbcd","text":"DynamoDB supports user Snapshots to S3.","correct":false},{"id":"e8d0300d557f883b2150d8e9c16a64f9","text":"Like S3, DynamoDB is a global service -- data is automatically replicated across multiple AWS Regions.","correct":false}]},{"id":"2e18aaa7-7622-4c21-bf16-6b98fe813f7b","domain":"ResilientDesign","question":"You want to receive notifications of when an endpoint fails an Amazon Route 53 health check of your domain. Which of the following services can you combine to make that possible?","explanation":"You can set up a Route 53 health check to monitor the health of your AWS resources, such as a web server, by entering the domain name. You can configure the health check to trigger a CloudWatch alarm when Route 53 detects that the endpoint is unhealthy. CloudWatch then uses SNS to notify users. Although SQS is a messaging service just like SNS, it is for queueing messages","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html","title":"How Amazon Route 53 Checks the Health of Your Resources"}],"answers":[{"id":"f7be29c9a4de2fe0c3ced5ca83552403","text":"Amazon Simple Notification Service (SNS)","correct":true},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":false},{"id":"64fdb9de34f1179f1b0a667717e6fba3","text":"Amazon Simple Queue Service (SQS)","correct":false},{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":true}]},{"id":"d5d30bcd-fdb1-44d2-88ab-5f84a76d7054","domain":"CostOptimized","question":"Comma-delimited files with information about how customers navigate your company website arrive from a third party on a nightly basis. The data is pre-sorted by the third party for concurrent access by multiple compute instances running in the AWS cloud. Which storage service will provide the highest cost optimization for the solution?","explanation":"Since the data is pre-sorted by the third-party, a relational database is unnecessary. Amazon Elastic File System provides a more cost-effective solution. Amazon Elastic Block Store storage cannot be shared across multiple instances, and Amazon ElastiCache will be a higher cost solution.","links":[{"url":"https://aws.amazon.com/efs/","title":"Amazon Elastic File System"}],"answers":[{"id":"4b6ccd94421822eaaf7bd027992018af","text":"Amazon Elastic Block Store","correct":false},{"id":"02f85544eeded6ef1b6c40d62bcadddd","text":"Amazon Elastic File System","correct":true},{"id":"6b039cd7fadc9d6a3d6a936b729c3900","text":"Amazon RDS for SQL Server","correct":false},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false}]},{"id":"a5ddd74e-3d62-4d40-a3f0-a23812c15053","domain":"SecureSolutions","question":"You must encrypt all incoming and outgoing traffic between your AWS environment and your customers. Your fleet of EC2 instances lives inside a public subnet and behind an elastic load balancer. Your application is very CPU intensive, and you want to minimize the processing load these EC2 instances must bear. What should you do?","explanation":"The best answer would be to offload your SSL decryption to an Elastic Load Balancer.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/introduction.html#classic-load-balancer-overview","title":" SSL on Classic Load Balancers"},{"url":"https://aws.amazon.com/blogs/aws/new-application-load-balancer-sni/","title":"SSL on Application Load Balancers"}],"answers":[{"id":"3555c67311aafdc06664adfe2aeb2bd1","text":"Use API Gateway to offload the SSL certificate, reducing the amount of load on both your ELB and EC2 instances.","correct":false},{"id":"7586d736b703b1462d09b4f190a26f6f","text":"Install the SSL certificates on your ELBs so that there is less load on the EC2 instances.","correct":true},{"id":"40d910c6e8118f8cf78ae1cfa0fe7f7f","text":"Install the SSL certificates on each EC2 instance and allow them to do the encryption/decryption with your customers.","correct":false},{"id":"59b594b61e296360b3b9eafcbfc28437","text":"Configure a NAT and install the EC2 instance on that NAT so that you offload SSL termination to a third party EC2 instance and not your production environment.","correct":false}]},{"id":"b8cb8890-c16a-4609-904f-2cd52cfeba0e","domain":"CostOptimized","question":"What is the minimum billable object size for S3 - IA?","explanation":"The minimum object size is 0 bytes, however you will be billed for 128 KB.  Objects smaller that 128 can still be stored, but will be billed as if they are 128KB. ","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Standard - IA Object Size (table)"},{"url":"https://aws.amazon.com/s3/faqs/?nc=sn&loc=6","title":"S3 Standard - IA minimums"}],"answers":[{"id":"bf361755334066f22d019854dd2be686","text":"1 KB","correct":false},{"id":"5de6c8bb0062d1883700e0bd14152d0d","text":"128 KB","correct":true},{"id":"05a402af63179f5ea4189bcb6a7e8bc5","text":"1 Byte","correct":false},{"id":"fdd68bff35708140c14d3cd3a3b0759d","text":"0 Bytes","correct":false}]},{"id":"47c3aa9c-215f-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"Even though your company is migrating to Amazon EC2, it wants to continue using its Oracle 12c software license to comply with the contract requirements of one of its clients. Which of the following pricing models accommodates this goal?","explanation":"Consisting of an actual physical EC2 server, the Dedicated Hosts plan will allow the company to use its eligible software license from Oracle on Amazon EC2. The other choices will not work because they don’t include a physical server to address corporate compliance requirements.","links":[{"url":"https://aws.amazon.com/ec2/dedicated-hosts/","title":"Amazon EC2 Dedicated Hosts"}],"answers":[{"id":"942d4e37dd5607ab68e54755540d4a47","text":"Reserved","correct":false},{"id":"244492cdce9dce0555c52ebe1182e0a3","text":"On Demand","correct":false},{"id":"6c9d6b8aea6f3d16847bdebe05878a2d","text":"Spot","correct":false},{"id":"acbe4e201e8e2ac67830983f9c8d7970","text":"Dedicated Hosts","correct":true}]},{"id":"bdfff765-ad59-45a9-9e3c-605a3d2ad9d7","domain":"ResilientDesign","question":"You have been asked to set up an EFS storage solution for a project team.  Which of the following tasks do you need to complete ?","explanation":"It is necessary to set up the bi-directional network permissions, normally with Security Groups. You will connect the EFS Target to your EC2 instance with a 'mount' statement. You do not need to stipulate the size or format the volume. AWS provide a nominally unlimited file system ready for you to use.  As normal under the shared security model AWS will ensure that the EFS system is secure, but you are responsible for the access control security inside the EFS file space provided to you.","links":[{"url":"https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html","title":"EFS - How It Works"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/limits.html","title":"EFS limits"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/security-considerations.html","title":"EFS Security"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/accessing-fs-create-security-groups.html","title":"EFS Security Groups"},{"url":"https://docs.aws.amazon.com/efs/latest/ug/wt1-getting-started.html","title":"Mounting and EFS target"}],"answers":[{"id":"417164507c199eb8b0fb1daa3bae285c","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EFS target","correct":true},{"id":"30f2e62c04d187f6e6f58e730e462680","text":"Configure a Security Group to allow admin traffic on port 22 to connect to the EFS system.","correct":false},{"id":"8388b16ddec8dec25d6caba4dbe7f8cb","text":"specify and provision disk capacity on the EFS system using 'fdisk' and 'mkfs -t xfs'.","correct":false},{"id":"9a0eabcd19e62a99932848808a473c0f","text":"mount EFS vol to your EC2 instance using 'mount -t nfs -o xxxx '.","correct":true},{"id":"9bc552892ca2c2c5be9e7c352fc0cdc8","text":"Configure a Security Group to allow data traffic on port 2049 to connect to the EC2 server.","correct":true},{"id":"7f41c759c946659e0ef49f87f6684503","text":"Set Linux file system permissions on the presented EFS volume using 'chmod' and 'chown'.","correct":true}]},{"id":"e7ba33b8-6d4c-428b-a57a-dcfbf9fcf616","domain":"ResilientDesign","question":"When considering the SQS Standard queues. Which of these describe the design concern or limit that you need to manage in your application design?","explanation":"With Standard Queues, each message will be delivered at least once, this ensures that no message is lost, but leaves you t manage duplicates. SQS standard queues will process messages in a loosely sequential order, due to the number of SQS nodes and that some may be restarting or load splitting the order is not guaranteed.  You should recognize that all the others are related FiFo queues.","links":[{"url":"https://aws.amazon.com/sqs/details/","title":"SQS Product Details"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-how-it-works.html","title":"How SQS works"},{"url":"https://aws.amazon.com/blogs/developer/how-the-amazon-sqs-fifo-api-works/","title":"How SQS FiFo works (blog)"}],"answers":[{"id":"a0792aa56343575141024087ca38fb6a","text":"If a log contains identical log entries 'ContentBasedDeduplication' will see duplicate messages and prevent messages other than the 1st being processed until the index expires.","correct":false},{"id":"23f8f465ecf2aae88fc210a3d7bf5181","text":"If a message creating system restarts a queue or reprocesses a log, duplicate messages may be generated, sent to SQS and processed.","correct":true},{"id":"7c287e3e01eabc58b4984f14b0fe6683","text":"The order that messages are processed is loosely sequential, but this cannot be relied on ","correct":true},{"id":"6568af366d80b8c8c4df81e76cd92948","text":"The product design indicates that you will need be between 30,000 and 100,000 inflight messages at any one time.","correct":false},{"id":"74cf0b557de0daa58606a28a96003a22","text":"You need to process more than 300 messages per second, per action and cannot use Batching","correct":false},{"id":"4db8fff01bf1b1d61c2df74ac7c2c9a2","text":" If multiple threads in a message creating process generates messages with the same 'message group ID' at the same time the order of processing may be uncertain.","correct":false}]},{"id":"b66725f5-c28a-40e3-a66f-ab440f24f05d","domain":"SecureSolutions","question":"You work for a construction company that has their production environment in AWS. The production environment consists of 3 identical web servers that are launched from a standard Amazon Linux AMI using Auto Scaling. The web servers are launched in to the same public subnet and belong to the same security group. They also sit behind the same ELB. You decide to do some testing: you launch a 4th EC2 instance into the same subnet and same security group. Annoyingly, your 4th instance does not appear to have internet connectivity. What could be the cause of this?","explanation":"Of these choices, the absence of the Elastic IP is the only one that could prevent internet access.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Internet_Gateway.html","title":"Enabling Internet Access"}],"answers":[{"id":"dbfb29d2865a1da80068dc82bdf11f7f","text":"You have not configured a NAT in the public subnet.","correct":false},{"id":"3de8a51a1f321c3839a3ac9442da1f72","text":"You have not assigned an elastic IP address to this instance.","correct":true},{"id":"3645b812b5554461edf969a5a7b19083","text":"You need to update your route table so as to provide a route out for this instance.","correct":false},{"id":"1b5e2f314ee9201857bbf929863476b9","text":"You have not configured a routable IP address in the host OS of the fourth instance.","correct":false}]},{"id":"fa1bda16-305f-4828-b6ad-7283e0871b17","domain":"ResilientDesign","question":"You manage a Ruby on Rails application that lives on a cluster of EC2 instances. Your website occasionally experiences brief, strong, and entirely unpredictable spikes in traffic that overwhelm your EC2 instance resources and freeze the application. As a result, you're losing recently submitted requests from end users. You use Auto Scaling to deploy additional resources to handle the load during spikes, but the new instances don't spin-up fast enough to prevent the existing application servers from freezing. Which of the following will provide the most cost-effective solution in preventing the loss of recently submitted requests?","explanation":"Neither increasing the size of your EC2 instances nor maintaining additional EC2 instances is cost-effective, and pre-warming an ELB signifies that these spikes in traffic are predictable. The cost-effective solution to the unpredictable spike in traffic is to use SQS to decouple the application components.","links":[{"url":"https://aws.amazon.com/sqs/details/","title":"About SQS"}],"answers":[{"id":"6db3854f95cc6b24174021466671b1ac","text":"Ask AWS support to pre-warm the Elastic Load Balancer.","correct":false},{"id":"8369c6dde55e9f75a78d9cf464140a27","text":"Keep a large EC2 instance on standby.","correct":false},{"id":"c0b360995bf53c751147bc20838b7649","text":"Increase the size of your existing EC2 instances.","correct":false},{"id":"3e72cba47f2e1a3f598502fa537cd4fd","text":"Use Amazon SQS to decouple the application components and keep the requests in queue until the extra Auto-Scaling instances are available.","correct":true}]},{"id":"9217f221-d436-4a41-a625-280ddc5dc210","domain":"SecureSolutions","question":"You have just created two EC2 instances in your VPC and have allocated them IPs on the same subnet (10.0.1.0/24). A default security group has been created, and you have added both instances to it. The two instances need to communicate with each other. What else do you need to do to allow this to happen?","explanation":"Since both instances are in the same subnet and connectivity is within the subnet, NACL rules do not apply to traffic between the two instances. Only Security Group settings are required to support the required connectivity between the instances and the default settings enable this.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html","title":"Security Groups for Your VPC"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-network-acls.html","title":"Network ACLs"}],"answers":[{"id":"351b5d48765db8ce844bc356643d3f1b","text":"NACL rules will need to be added to allow for the required Inbound and Outbound traffic, security group rules are not needed since they share the same Security Group.","correct":false},{"id":"4fb4682a32431d9fb34f70e83161654c","text":"NACL rules will need to be added to allow the required Inbound and Outbound traffic, security group entries are also required to allow the required inbound and outbound traffic.","correct":false},{"id":"e7cca5653481d2b3786aec2bdede2165","text":"Since both instances are in the same subnet and have the same security group, connectivity will be enabled by default, so nothing extra is required.","correct":true},{"id":"1cb99d8ab36453c1d339711c8cf27808","text":"Since both instances are in the same Subnet, additional security group rules are needed to allow the required inbound and outbound traffic.","correct":false}]},{"id":"9fc041cf-1305-46e0-9851-bbf11b320f3c","domain":"Performant","question":"You need to develop an infrastructure that can be replicated and deployed in another AWS Region in a matter of minutes. Which AWS service might you use to build a reproducible, version-controlled infrastructure?","explanation":"AWS CloudFormation gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html","title":"About CloudFormation"}],"answers":[{"id":"d8d0959d6dfc410044ed02441ee86c96","text":"EC2 AMIs with EBS snapshots","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"c0f075697e6a50da6356e4718f5a1de0","text":"CloudWatch Template","correct":false}]},{"id":"89f330aa-397e-49a6-99c1-59a911318d03","domain":"SecureSolutions","question":"To protect S3 data from accidental overwrites and deletes, which of the following should you do first?","explanation":"The first thing you should do is enable versioning.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html","title":"S3 Object Versioning"}],"answers":[{"id":"9fb0a6abf0e1bda745fab85832252ee0","text":"Use a bucket policy to disable deletes from S3","correct":false},{"id":"f85fb671c749e7fcc0f440124d0879d7","text":"Access S3 only from signed URLs.","correct":false},{"id":"253efe32850426ce32c509612536c798","text":"Enable versioning on the bucket.","correct":true},{"id":"d5ea3592264e2a8848ca043466fd5c46","text":"Allow only MFA access","correct":false}]},{"id":"3044519c-b0ea-41bf-a1ab-832c95a8343e","domain":"ResilientDesign","question":"Your three AWS accounts (A, B and C) share data. In an attempt to maximize performance between the accounts, you place all the instances for these accounts in 'eu-west-1b'. During testing, you find almost no transfer latency between accounts A and B, but significant latency between accounts B and C, and accounts C and A. Which of the following possibilities is the most likely explanation of the problem?","explanation":"The Availability Zone names presented are unique per account and do not represent a specific set of physical resources.","links":[{"url":"https://aws.amazon.com/about-aws/global-infrastructure/","title":"AWS Regions and Availability Zones"}],"answers":[{"id":"90fe72b25f4890a77a480f704373c65f","text":"You have incorrectly configured the cross-account authentication policies in account C, which contributes to the latency between those instances.","correct":false},{"id":"09f51ccd7846588cb204fc7d0ceeac44","text":"Account C has been allocated to an older section of the data center with slower networking.","correct":false},{"id":"11dc5d08c98ffd7b540d0982b7d307ad","text":"Availability Zones consist of one or more discrete data centers; as such, 'eu-west-1b' is not necessarily the same physical location for all three accounts. This explains the latency.","correct":true},{"id":"af1ce7d8b9e63a18ed9096c0d1f9e90b","text":"The instances for account C are on an overloaded host. Stop all the Account C instances and then start them together so that they run an a new host.","correct":false}]},{"id":"70c6a808-0d5d-40d3-9b62-aa2fd031a543","domain":"CostOptimized","question":"You have three AWS payer accounts consolidated under an AWS Organization . Which of the below statements is TRUE for purposes of volume discounts?","explanation":"If you have multiple accounts, your charges will decrease because AWS combines usage from all accounts in the organization to qualify you for volume pricing discounts.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/consolidated-billing.html","title":"Consolidated Billing for Organizations"}],"answers":[{"id":"c9c2416d95c8112070b7a5b032629fdf","text":"Usage in each account will be evaluated individually to determine the volume discount it is individually entitled to","correct":false},{"id":"4fb1af36b069dca73268eedbfab53e7b","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled at the Organisation level","correct":false},{"id":"98e718508cd32b9ffb27d8648e9129d0","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to","correct":true},{"id":"a6cd99e8b1bbcfc82e184acc9f28eede","text":"Usage across the three accounts will be aggregated in determining the volume discount your Organization is entitled to only if Consolidated Billing is enabled in each account","correct":false}]},{"id":"09223b1a-2169-4791-94b1-9ecf1716c8eb","domain":"Performant","question":"Which of the following AWS services store data as key-value pairs?","explanation":"Both DynamoDB and S3 use key-value pairs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingObjects.html","title":"Working With S3 Objects"},{"url":"https://aws.amazon.com/dynamodb/faqs/#Data_Models_and_APIs","title":"DynamoDB Data Models"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true}]},{"id":"067a4664-2e5b-11ea-978f-2e728ce88125","domain":"Performant","question":"As a Solutions Architect employed at a niche clothing and accessories company, you are assigned the task of figuring out how to record requests made to S3 buckets that contain the images. The Director of Marketing Strategy needs that information to help her understand the company’s customer base and help her shape her marketing strategy in the coming months. Which of the following features should be enabled to record this information?","explanation":"Server access logging is what you should enable to record and get information on the requests made to the company’s S3 buckets. You choose object-level logging for recording object-level API activity using AWS CloudTrail, which comes with a cost. Enabling versioning would keep all versions of an object in the same bucket, and tags are for tracking project costs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerLogs.html","title":"Amazon S3 Server Access Logging"}],"answers":[{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":false},{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":true},{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":false},{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false}]},{"id":"d5733ca8-59ad-4f5d-b36f-b9ab95f39669","domain":"SecureSolutions","question":"A company has begun building applications in AWS. They have come to you for some guidance around security.  Occasionally they need to SSH into their application and web servers, which are hosted in a public subnet.  What recommendations would you make to the company in order to improve the security of their workload?","explanation":"Deploying workloads into public subnets is generally an unnecessary risk, so moving them from public to private subnets is a good idea. AWS load balancers can sit in your public subnets in front of your EC2 instances which are protected in private subnets.  In order to SSH to those instances from the Internet you can also deploy Bastion Hosts in the public subnets.  AWS Security Manager is not a service providing monitoring of malicious activity (the service would be provided by AWS Guard Duty.)  Similarly, the CloudWatch agent does not analyse the behaviour of applications, that is an offering of the AWS Inspector service and agent.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/public-load-balancer-private-ec2/","title":"How do I connect a public-facing load balancer to EC2 instances that have private IP addresses?"},{"url":"https://aws.amazon.com/blogs/security/securely-connect-to-linux-instances-running-in-a-private-amazon-vpc/","title":"Securely Connect to Linux Instances Running in a Private Amazon VPC"},{"url":"https://aws.amazon.com/blogs/security/controlling-network-access-to-ec2-instances-using-a-bastion-server/","title":"Controlling Network Access to (Windows) EC2 Instances Using a Bastion Server"}],"answers":[{"id":"48a2dae1ec2dd4ef4ac0ce35564240ac","text":"Use Network and Elastic Load Balancers in front of any application or web servers to serve traffic","correct":true},{"id":"6ec4bcc6e53670dd38e466f86448b64a","text":"Install the CloudWatch agent on the servers to analyze the behavior of the applications and identify potential security issues","correct":false},{"id":"7f7d3f30def404b95583fc1925c5ac58","text":"Use Bastion Hosts to SSH from the Internet and then connect to application and web servers","correct":true},{"id":"0cac7b74e61a7847a4f70d6683c3b45c","text":"Move the application and web servers to private subnets to restrict access","correct":true},{"id":"4766a3554e4aca8517eb72b2422912e8","text":"Enable AWS Security Manager to continuously monitors for malicious activity and unauthorized behavior","correct":false}]},{"id":"737e3562-19f3-11ea-978f-2e728ce88125","domain":"Performant","question":"Which of the following AWS services enables on-premises applications to use AWS Cloud storage?","explanation":"Although all four responses are similar in that they are AWS storage services, it is Storage Gateway that enables on-premises applications to use cloud-based storage. EFS is for simple, scalable file storage, EBS serves as a virtual disk for virtual servers launched with EC2, and S3 is for object-based storage.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/WhatIsStorageGateway.html","title":"What Is AWS Storage Gateway?"}],"answers":[{"id":"9155453f43b8a6472df0b8ffa5b5a028","text":"Amazon Elastic Block Storage (EBS)","correct":false},{"id":"d2a6652ddeb631da029d1f2806e11fdc","text":"Amazon Elastic File System (EFS)","correct":false},{"id":"df346128c45efa43efc29607224fc716","text":"Amazon Simple Storage Service (S3)","correct":false},{"id":"5ba49687f2f5ade4cd1c756a7e9024e3","text":"AWS Storage Gateway","correct":true}]},{"id":"e8d097c8-1789-4684-a73f-f00c261d1c55","domain":"ResilientDesign","question":"You need to find both the Public and Private IP addresses of an instance. Which of the following URLs should you query?","explanation":"Be careful on the exam to read the numbers and not assume what they are. The octet 254 is transposed into 524 in two of the answers, and two are user-data and two are meta-data. ","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html#instancedata-data-retrieval","title":"Retrieving Instance Meta-Data"}],"answers":[{"id":"60d4c7e460aafc0be725859f467e2178","text":"http://169.254.169.524/latest/user-data/","correct":false},{"id":"2ac0e8450882e7026fe16254736b901f","text":"http://169.254.169.254/latest/meta-data/","correct":true},{"id":"a8a9e51abf5c6064eb3d890d974f3e21","text":"http://169.254.169.524/latest/meta-data/","correct":false},{"id":"2e987eca0f9afee62ad0f6deb9d1f59e","text":"http://169.254.169.254/latest/user-data/","correct":false}]},{"id":"f85240a5-118e-4367-b2ed-0c442a60bec4","domain":"ResilientDesign","question":"You currently have a web application that uses two EC2 instances and you want 75% of the web traffic to go to one server and the other 25% to go to the other. Which of the following routing policies should you choose?","explanation":"You need a weighted routing policy because you want to be able to set the proportions traffic routed to your servers. A simple routing policy would have been ideal if you had a single server. Although failover and geolocation routing policies are for routing traffic to more than one resource, the former is ideal for configuring active-passive failover, and the latter is for specifying location rather than traffic proportions.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"323d4eb70b252acb4a04eaf9e0882597","text":"Geolocation","correct":false},{"id":"582368ac8232617ead14ac74ccc40ea9","text":"Weighted","correct":true},{"id":"1fbb1e3943c2c6c560247ac8f9289780","text":"Simple","correct":false},{"id":"7388404ef116c3ff812bfd290b094d9e","text":"Failover","correct":false}]},{"id":"7d17894a-afd7-44cf-8ef0-0b4698e75902","domain":"Performant","question":"You need to upgrade your RDS database to a larger instance class and you must minimize the amount of disruption to your business as much as possible. What should you do.","explanation":"When upgrading an RDS instance class your database will be temporarily unavailable while the DB Instance Class is modified. This period of unavailability typically lasts only a few minutes, and will occur during the maintenance window for your DB Instance, unless you specify that the modification should be applied immediately.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ModifyInstance.MySQL.html","title":"Modifying an RDS Instance"}],"answers":[{"id":"9645ca2d23347fd27cb00e4048158900","text":"Do the upgrade using the AWS console and ensure the 'do not reboot' option is checked when upgrading.","correct":false},{"id":"64c0cf5fc5de497475145808fffcff77","text":"You do not need to worry: when upgrading an instance class, your database will not go off line.","correct":false},{"id":"088f69f13b003fa224256412f3a2e237","text":"Do the upgrade using the AWS CLI using the option --NOREBOOT","correct":false},{"id":"9e621f1fb2263ab1552a7d3086c500a7","text":"Schedule the upgrade for a maintenance window during a time when you have the fewest possible customers. The production database should only be unavailable for a couple of minutes.","correct":true}]},{"id":"7ff46f0c-2e05-11ea-8a91-2e728ce88125","domain":"Performant","question":"You wish to exclusively use AWS services to buy a domain name and create a static website. Which of the following combinations will enable you to do so?","explanation":"You use Route 53 to register your domain and configure it so that Internet traffic is routed to your designated target. The target can be Amazon S3, where you can create a bucket, upload the HTML file that will function as the static website, configure the permissions for everyone to see the content, and configure the bucket for website hosting. Route 53 is missing from the other three choices; this omission makes these responses wrong.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html#root-domain-walkthrough-update-ns-record","title":"Setting Up a Static Website Using a Custom Domain"}],"answers":[{"id":"28968cd50e98048b344f0d7bd4fd54e6","text":"Amazon Virtual Private Cloud (VPC) and Relational Database Service (RDS)","correct":false},{"id":"8399383b83ea44cd15f0f7f7f8d1fe6b","text":"Amazon API Gateway and Elastic Compute Cloud (EC2)","correct":false},{"id":"a119836cf024ddc24285f609454cf7bf","text":"Amazon Route 53 and Simple Storage Service (S3)","correct":true},{"id":"c3794257c21696f8d06348f26e2b81a9","text":"Amazon Lambda and Elastic File Service (EFS)","correct":false}]},{"id":"516c16a0-3100-45f1-9b36-fe2cef037119","domain":"SecureSolutions","question":"You have an EC2 instance with a Security Group attached. This security group is configured to only allow traffic to/from 10.0.0.0/16. A colleague has also configured a NACL on the private subnet that the instance resides on, and this NACL is configured to block all traffic, except where the destination is in 10.0.1.0/24. What will happen when the instance attempts to access IP 192.168.0.12 on port 80?","explanation":"With outbound traffic, Security Groups are evaluated first, then NACLs. The security group is configured to only allow traffic where the destination is 10.0.0.0/16, and as 192.168.0.12 does not fall within this range it will be blocked by the security group before it reaches the NACL.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"c885215eb76a3baac02ca8ea6da9a7b4","text":"The NACL will block the traffic before it is evaluated by the security group","correct":false},{"id":"5298f0866dac220c6bbad6d2da2163d8","text":"The traffic will be allowed as it is still within a private range","correct":false},{"id":"eb5d4be456a62dd4f884a4b47c45fd46","text":"The traffic will be blocked simultaneously by the Security Group and NACL","correct":false},{"id":"d3d7c67e2cf8c1d1cb89971fd90c2b72","text":"The security group will block the traffic before it is evaluated by the NACL","correct":true}]},{"id":"99b3a227-a362-456e-8474-dba3e0b3f6ff","domain":"Performant","question":"You are developing a video conferencing service that translates spoken language to sign language in near real time using AWS Lambda. One of your functions does the heavy video/audio lifting by using common utilities including FFmpeg, Sound eXchange (SoX) and ImageMagick - each provided as a separate layer. Your function is also connected to nltk, the Python Natural Language Toolkit library and your own custom archive with some shared code - both provided as additional layers. You encounter a problem after you've updated your function's configuration to change to the latest version of your code. What are possible reasons for that and how can you resolve that issue?","explanation":"You can specify up to 5 layers in your function's configuration, during or after function creation.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html","title":"AWS Lambda Layers"}],"answers":[{"id":"dbc5c5e38dfb1c3c8d8f6d0a1d1ca917","text":"Layers are extracted to the /opt directory in the function execution environment and applied in the order that's specified, merging any folders with the same name. If the same file appears in multiple layers, the version in the last applied layer is used. Rename the conflicting file in your archive.","correct":true},{"id":"4a90d094e62078f6c53fa5c71052b723","text":"You reached the 50MB zipped deployment package size limit for direct uploads. Refactor your function and move some code into a new layer.","correct":false},{"id":"00133f9caaca04cea058c5ceb62d5a8a","text":"You have gone over the 250MB unzipped deployment package size limit. Remove some unused libraries from your own archive.","correct":true},{"id":"14a4dc8ed5178c4185b29595e49de3df","text":"When you added the last layer to your function, the previous list was overwritten by the new one. Include all layers every time you update the layer configuration.","correct":true}]},{"id":"eb7c5d7d-09d6-4dee-bf55-d97a53af72f2","domain":"SecureSolutions","question":"Your organisation is about to deploy a new website into their AWS environment that will publish news articles created by your content team, which will reside on the URL “www.cloud-news.com”. This website makes use of two EC2 austoscaling groups to serve content - one is for publicly accessible content and one for members-only content. An in-house developed authentication mechanism redirects users to “members.cloud-news.com” to access the members-only content. Which load balancer configuration is most appropriate for this architecture?","explanation":"The load balancer needs to be able to look at the hostname of the request and redirect it to the appropriate EC2 Autoscaling group - this requires the ability to do host-based routing, which is a feature of ALBs and is not available in NLBs. As we are routing to a different hostname, the path is irrelevant - only host-based will work, and the condition for this on an ALB is \"host-header\"","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/ ","title":"Load Balancing Features"}],"answers":[{"id":"1d8d6c68ab28d0288ad4747f3e53f1e4","text":"Use a Network Load Balancer in a public subnet, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the \"path-pattern\" condition on each listener rule to redirect users to the appropriate target group.","correct":false},{"id":"9748d8cbee76d8e5ee49130319e6dabc","text":"Use an Application Load Balancer, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the “path-pattern” condition on each listener rule to redirect users to the appropriate target group.","correct":false},{"id":"512616e676f1cc76a267567948528f9e","text":"Use an Application Load Balancer, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the \"host-header\" condition on each listener rule to redirect users to the appropriate target group.","correct":true},{"id":"c6e704e1b985b6cd50ffe0d7750681ff","text":"Use a Network Load Balancer in a public subnet, with a target group for each Autoscaling group.  Configure 2 listeners - one for each content type. Use the \"host-header\" condition on each listener rule to redirect users to the appropriate target group.","correct":false}]},{"id":"15c91139-c33f-4583-8864-dba8207c73a0","domain":"Performant","question":"Your organisation is running a business critical application with a backend MySQL DB that has been experiencing performance issues due to an increase in customers hitting the website. Management are concerned that the existing solution will not handle the anticipated customer growth over the next 12 months and any outages could lead to a loss in potential revenue.\\n You’ve been asked to develop a suitable AWS cloud based solution that will best meet the requirements of the organisation and require minimal operational overhead. Which AWS DB service will be most suitable for your organisation?","explanation":"Aurora natively maintains 2 copies of your data in each availability zone (3 AZs x 2 = 6 copies) within a region providing the highly available solution needed for this scenario. It also supports storage autoscaling and CPU and Memory scaling. Aurora also provides up to 5 times improved performance over a traditional DB installation.  MySQL and PostgreSQL support multi-AZ deployments and read replicas, but this requires additional configuration. CPU, memory and storage scaling is not automated and requires additional configuration and design consideration. Redshift does not support Multi-AZ deployments.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/","title":"Amazon Aurora FAQs"}],"answers":[{"id":"f52a9d91766886fb3a524dd06d1581cb","text":"Redshift","correct":false},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false},{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":true},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false}]},{"id":"54f49b19-525b-42bc-956a-c02a709ea575","domain":"Performant","question":"A political consulting group wants to monitor Twitter tweets from all candidates in an election to assess campaign statements and positions on current issues. They'll implement calls to the Twitter API from a Python script on an EC2 instance to get the tweets, and they'll use Amazon QuickSight to visualize the data. They anticipate that as the election approaches, tweet volume will increase dramatically. Which architecture will provide the scalability they need in the most cost effective way?","explanation":"Using Kinesis Streams to batch the tweets for the Lambda consumer function helps orchestrate the process of invoking Comprehend on a specific set of tweets. If the data is written directly to S3 via Kinesis Firehose PutRecord calls without some batching of the tweets, Comprehend will scan the same data multiple times. Comprehend currently does not support DynamoDB as a data source. Comprehend is a natural language processing service and doesn't require the data to be pre-formatted.","links":[{"url":"https://aws.amazon.com/kinesis/","title":"Amazon Kinesis"},{"url":"https://aws.amazon.com/comprehend/","title":"Amazon Comprehend"},{"url":"https://github.com/aws-samples/lambda-refarch-streamprocessing","title":"Serverless Reference Architecture: Real-time Stream Processing"}],"answers":[{"id":"60a15003c784ca46eb2291738f62038a","text":"Have the Python script write the tweets to an Amazon Kinesis Streams stream. Configure a Lambda function as the consumer of the stream. Have the Lambda function write the data to Amazon DynamoDB. Invoke Amazon Comprehend from the Lambda function to assess sentiment in the tweets and write the results back to DynamoDB","correct":false},{"id":"29db045869ea4a45b00a8df4819dc756","text":"Have the Python script write the tweets to an Amazon Kinesis Streams stream. Configure a Lambda function as the consumer of the stream which receives tweets in batches. Have the Lambda function write the data to Amazon S3. Have the Lambda function also invoke Amazon Comprehend to assess sentiment in the batch and write the results back to S3","correct":true},{"id":"4e077d33575cabb8babd3a56c3f77d32","text":"Have the Python script write the tweets to an Amazon Kinesis Firehose stream with PutRecordBatch API calls. Configure the stream to write the data to Amazon S3. Trigger a Lambda function to put the data into a standard format, and then invoke Amazon Comprehend to assess sentiment in the tweets. Write the results back to S3","correct":false},{"id":"2447562bf64c3157516a40a083254449","text":"Have the Python script write the tweets to an Amazon Kinesis Firehose stream with PutRecord API calls. Configure the stream to write the data to Amazon S3. Trigger a Lambda function to invoke Amazon Comprehend to assess sentiment in the tweets and write the results back to S3","correct":false}]},{"id":"f289e7cc-2d51-11ea-978f-2e728ce88125","domain":"Performant","question":"You are currently tasked with creating a table in Amazon DynamoDB. Which of the following choices will enable you to do so?","explanation":"To create a DynamoDB table, you can either start the process by either entering the 'aws dynamodb create-table' command in the CLI or clicking the blue 'Create table' button in the DynamoDB dashboard of the AWS Management Console. Entering the 'create-table' command in the CLI is not enough; you need to specify the AWS database service you are using. Building an application to add a DynamoDB table using an AWS programming toolkit is not a valid option.","links":[{"url":" https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/getting-started-step-1.html","title":"Amazon DynamoDB – Create a Table"}],"answers":[{"id":"3a62b314d239d0b2d75fefee9e84425e","text":"Enter the 'aws dynamodb create-table' command in the AWS Command Line Interface (CLI).","correct":true},{"id":"18511f701a7ad2abc2b90948d1b57b17","text":" Enter the 'create-table' command in the AWS Command Line Interface (CLI).","correct":false},{"id":"906505a11abce1d46233801349bcd80e","text":"Build an application to add a DynamoDB table using an AWS programming toolkit.","correct":false},{"id":"668f280aab8a436e55f13dae23642214","text":"Click the blue 'Create table' button in the DynamoDB dashboard of the AWS Management Console.","correct":true}]},{"id":"c67d3b2b-2a42-4093-af94-3336110e8c4e","domain":"SecureSolutions","question":"A human resources consulting company has recently implemented Amazon Redshift to perform analytics on customer engagements. A number of departments have been given the ability to query the data. The operations team needs to be able to monitor and terminate queries as needed, but they should not have the ability to modify or delete any other Redshift resources. Which approach will provide the operations team with the access they require?","explanation":"A policy with the redshift:Describe*, redshift:CancelQuerySession, and redshift:ViewQueriesInConsole actions will provide an IAM user with the ability to select a Redshift cluster, list all running queries, and terminate a query if needed. The redshift:DeleteQueries action does not exist. The AmazonRedshiftOperations and AmazonRedshiftQueryAdministrator managed policies do not exist.","links":[{"url":"https://docs.aws.amazon.com/redshift/latest/mgmt/redshift-iam-access-control-identity-based.html","title":"Using Identity-Based Policies (IAM Policies) for Amazon Redshift"},{"url":"https://aws.amazon.com/blogs/big-data/granting-fine-grained-access-to-the-amazon-redshift-management-console/","title":"Grant fine-grained access to the Amazon Redshift Management Console"}],"answers":[{"id":"1c9dea7ba839156d4a9974ba5fb8b5eb","text":"Assign the AmazonRedshiftOperations managed policy to the users on the operations team.","correct":false},{"id":"b69684debc1d2f03125faa0a3a2c466c","text":"Assign the AmazonRedshiftReadOnlyAccess and AmazonRedshiftQueryAdministrator managed policies to the users on the operations team.","correct":false},{"id":"13679882b475c07d8adca4e6fa29df4f","text":"Create a custom IAM policy that includes the redshift:Describe*, redshift:CancelQuerySession, and redshift:ViewQueriesInConsole actions. Assign the policy to the users on the operations team.","correct":true},{"id":"313e53fee44351534143a5526b03f8b1","text":"Create a custom IAM policy that includes the redshift:Describe*, redshift:View* and redshift:DeleteQueries actions. Assign the policy to the users on the operations team.","correct":false}]},{"id":"9cfdc945-a7e0-479c-9bcc-973f9ebfd7dc","domain":"CostOptimized","question":"You want to set up 2 CloudWatch alarms in addition to the 6 you already have to monitor your cloud environment. It has been 13 months since you created your AWS account, and you want to avoid being charged for creating the alarms. What should you do?","explanation":"Upon signing up for an AWS account, you will get a range of service usage that will never cost you anything. Such offers include 10 alarms with CloudWatch. That’s why creating the alarms is the correct answer. Contacting support is wrong because it’s not necessary to request a service increase limit. Avoiding creating new alarms is also wrong because there’s no term limits on the CloudWatch alarm offer; it’s always free. Creating more alarms in this case is still free of charge because the free offer is limited to 10 CloudWatch alarms.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsm.page-all-free-tier=1","title":"AWS Free Tier"}],"answers":[{"id":"3e9a7ae3a0c82f4aaf031d7400a3774f","text":"Do not create the alarms; you will be charged, since you get a maximum of 10 alarms with CloudWatch for the first 12 months after your account sign-up.","correct":false},{"id":"a336fb6001d622e126c7d02da7ab218f","text":"Go ahead and create the alarms; CloudWatch alarms are always free of charge, regardless of number.","correct":false},{"id":"d8991b206aa9d731ab999eddedf26d6e","text":"Go ahead and create the alarms; you can have up to 10 CloudWatch alarms without being charged.","correct":true},{"id":"222fcbee1f68dae67b4406597659a622","text":"Contact AWS Support for a service increase limit.","correct":false}]},{"id":"2f1ce543-076b-448b-8b72-e8f8791474a3","domain":"SecureSolutions","question":"You have an EC2 instance with a Security Group attached. This security group is configured to only allow traffic to/from 10.0.0.0/16. A collegue has also configured a NACL on the private subnet that the instance resides on, and this NACL is configured to block all traffic, except where the destination is in 10.0.1.0/24. What will happen when the instance attempts to access IP 192.168.0.12 on port 80?","explanation":"With outbound traffic, Security Groups are evaluated first, then NACLs. The security group is configured to only allow traffic where the destination is 10.0.0.0/16, and as 192.168.0.12 does not fall within this range it will be blocked by the security group before it reaches the NACL.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"c885215eb76a3baac02ca8ea6da9a7b4","text":"The NACL will block the traffic before it is evaluated by the security group","correct":false},{"id":"eb5d4be456a62dd4f884a4b47c45fd46","text":"The traffic will be blocked simultaneously by the Security Group and NACL","correct":false},{"id":"d3d7c67e2cf8c1d1cb89971fd90c2b72","text":"The security group will block the traffic before it is evaluated by the NACL","correct":true},{"id":"5298f0866dac220c6bbad6d2da2163d8","text":"The traffic will be allowed as it is still within a private range","correct":false}]},{"id":"37bacf63-a62f-4f99-a0b0-6bf9bf5a5210","domain":"CostOptimized","question":"You have a series of websites hosted in AWS. You need to ensure that users from Europe are directed to www.my-gdpr-site.com for regulatory purposes. What could help accomplish this?","explanation":"Geolocation routing lets you choose the resources that serve your traffic based on the geographic location of your users, meaning the location that DNS queries originate from. For example, you might want all queries from Europe to be routed to an ELB load balancer in the Frankfurt region.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"4b3ecb216d2654061f67ae382d891333","text":"Using the Autoscaling service.","correct":false},{"id":"adba6b9b5a5387ec8af8d012d272715b","text":"Using the AWS Config service.","correct":false},{"id":"3efbfae41092bb136dee3c26de7750f1","text":"Using the Route 53 service.","correct":true},{"id":"2b840caf003f35a0ca6a82ea4d66b8a8","text":"Using the Elastic Load Balancer service.","correct":false}]},{"id":"33481ccb-46de-434a-ad35-cfcd2b9a960f","domain":"SecureSolutions","question":"Which of the following AWS services can you use to protect data within your VPC?","explanation":"For data protection, AWS recommends tools like IAM, CloudTrail, and Macie. IAM is for safeguarding account credentials and granting users only the necessary permissions to perform their job duties. CloudTrail is for tracking user activity and API usage. And Macie is an advanced security service that uses machine learning to automatically discover, classify, and protect data. CloudFront is the only odd one out; it is AWS’s content delivery service, rather than a security or management and governance tool.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/data-protection.html","title":"Data Protection in Amazon Virtual Private Cloud"}],"answers":[{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":true},{"id":"a86087964fb00f6ae81475d2c8c3c40c","text":"AWS Identity and Access Management (IAM)","correct":true},{"id":"1f7efb5a61d1162575c83917dd086ad7","text":"Amazon Macie","correct":true},{"id":"dfdfd742376f1e718ab36a8a1ee9143e","text":"Amazon CloudFront","correct":false}]},{"id":"5b52d388-382c-4f3c-9d9d-0e15d2c4dccd","domain":"CostOptimized","question":"You have a static HTML website that requires inexpensive, highly available hosting solution that scales automatically to meet traffic demands. Which AWS service would best suit this requirement?","explanation":"S3 Static Website Hosting offers the best solution here: it is highly-available, scales automatically, and is cost-effective.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Static Website Hosting"}],"answers":[{"id":"b0bca3ada773197571a3697e029cdfc4","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 1 instance","correct":false},{"id":"a98f92c3d9a3073bdf1d35f748a53342","text":"S3 - Static Website Hosting","correct":true},{"id":"b812d3912dbd32666e0d2865e0ee9d19","text":"EC2 with CloudFront","correct":false},{"id":"7e247cebfa4700e9281d3e30ac07ac70","text":"EC2 with EBS behind and Autoscaling Group with a minimum configuration of 2 instances","correct":false}]},{"id":"e19d68d3-a39e-4056-bef8-7fb2d19df5b9","domain":"SecureSolutions","question":"Which of the following areas of Security in the Cloud involves the identification of potential threats or incidents?","explanation":"Detective controls, such as conducting an inventory of assets or carrying out internal auditing, are employed to look out for anything that poses a threat to the security of a cloud environment. There are five areas of Security in the Cloud: IAM, Detective Controls, Infrastructure Protection, Data Protection, and Incident Response.","links":[{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Security-Pillar.pdf","title":"AWS Security Pillar"}],"answers":[{"id":"7e7397a7b79323762c61941fc0e6b5f9","text":"Data protection","correct":false},{"id":"caa28027e00cbf3f30f66fe8846f2bb0","text":"Detective controls","correct":true},{"id":"5fe5bde89ae88d436f1f8ba2d3a64130","text":"Identity and Access Management (IAM)","correct":false},{"id":"7fb1ca7b0dfce3a9a7eaedc329cecc27","text":"Incident response","correct":false},{"id":"cd978e0acae323979bd0c7a15fdffb2c","text":"Infrastructural protection","correct":false}]},{"id":"f1eea1a4-0b1e-4702-bb51-0937708005a3","domain":"ResilientDesign","question":"In the future, you will need to preserve, restore, and retrieve every version of every file that you have stored in AWS. Which service should you use?","explanation":"Versioning allows you to preserve, retrieve, and restore every version of every object stored in an Amazon S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"Using Versioning with S3"}],"answers":[{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false},{"id":"e9a5105fa288ef2b71c037e42d665d91","text":"S3 - OneZone-IA","correct":false},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"8eeeb63c58948c56dc93f4dd229fc796","text":"S3 with Versioning enabled.","correct":true}]},{"id":"3a6323db-58c8-4ddf-a758-288887c972ed","domain":"CostOptimized","question":"You are a small business startup and wanted to host a website for your business. You purchased a Reserved EC2 instance with all upfront payment with one year commitment. Because of difficulties, the website hosting is given to a third party provider to host the website. As the reserved EC2 instance is not required anymore, what are the options available?","explanation":"Reserved instances provide significant savings on Amazon EC2 costs compared to on-demand instance pricing. Reserved instances are not physical instances, but rather a billing discount applied to the use of on-demand instances in AWS account. The Reserved instance applies to a single instance type, platform, scope, and tenancy over a term. Reserved instances once purchased cannot be cancelled. But the unused reserved instances can be sold in the Reserved Instance Marketplace if the eligibility criteria are met. The Reserved Instance Marketplace is a platform that supports the sale of third-party and AWS customers' unused Standard Reserved Instances, which vary in term lengths and pricing options.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html","title":"Reserved Instance Marketplace"}],"answers":[{"id":"fe819908a4d33b8ae37ab227c535e0f7","text":"The reserved instance purchase can be cancelled so that AWS will refund the EC2 instance cost for the remaining tenure.","correct":false},{"id":"cd9f297f2ab1b919d62d05c2aaa09984","text":"The reserved instance can be transferred to another account owned by your friend for a cheaper rate.","correct":false},{"id":"df56e478b94b7cf467346bbdd6b7fb2b","text":"Terminate the EC2 instance so that there will not be any running cost. Submit a request to AWS to refund the cost for remaining tenure.","correct":false},{"id":"86529fdb220411c4056281091b93c2eb","text":"Reserved instance purchases cannot be cancelled. But if the business need changes, these reserved instances may be sold in the Reserved Instance Marketplace.","correct":true}]},{"id":"c232c020-d1d3-4b31-91c9-e8906b3fe973","domain":"Performant","question":"A business productivity service would like to add an online chat platform to their offerings. Their customer base is made up primarily of large multi-national corporations. These corporations will need to be able to include users in multiple countries in real-time chats. Static content for the application will reside on Amazon S3 and chat orchestration will be hosted on Amazon EC2 with Elastic Block Store volumes. Which architecture will provide the best performance efficiency for the chat platform?","explanation":"CloudFront supports WebSockets to establish persistent connections, which provide lower latency for real-time communications. Origin behaviors specify which origin satisfies which type of content request (ex. all .jpg files), not which origin servers to use. Route 53 is not needed, because requests for CloudFront content are automatically routed to the edge location with the lowest latency. Using ElastiCache to cache at the storage level may result in some efficiency, but leveraging CloudFront's Edge locations at the network level will provide the greatest performance gains.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-working-with.websockets.html","title":"Using WebSocket with CloudFront Distributions"}],"answers":[{"id":"49d904e69d2f386dc05917de19119370","text":"Use a Route 53 latency routing policy to send traffic to the lowest latency CloudFront Edge location","correct":false},{"id":"3cdc4a0838e007f3a5500a2b555b9a73","text":"Leverage ElastiCache to manage in-progress chat conversations in-memory, and write conversation history to EBS volumes later","correct":false},{"id":"00539fd580f87a3d665dfe784d08d459","text":"Create a CloudFront distribution with origin behaviors that point to chat servers in the regions where the clients reside","correct":false},{"id":"06a06760d361cbafcca4c47d8ab93c8e","text":"Have clients use HTTP upgrade semantics to establish WebSockets connections with CloudFront distributions","correct":true}]},{"id":"b09415bc-dd01-42c0-a7f8-f3603cd59468","domain":"CostOptimized","question":"You need to automatically migrate objects from one S3 storage class to another based on the age of the data. Which S3 service can you use to achieve this?","explanation":"S3 Lifecycle management provides the ability to define the lifecycle of your object with a predefined policy and reduce your cost of storage. You can set lifecycle transition policy to automatically migrate Amazon S3 objects to Standard - Infrequent Access (Standard - IA) and/or Amazon Glacier based on the age of the data.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html","title":"S3 Object Lifecycle Management"}],"answers":[{"id":"5b6019950a69fdc69d23187a8254c7b4","text":"Reduced Redundancy","correct":false},{"id":"fa532045e834ec2fac1200964a189516","text":"Lifecycle Management","correct":true},{"id":"b1926a8ac417114ef193a282594538c7","text":"Infrequent Access","correct":false},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false}]},{"id":"05751b9c-f43e-4d4d-baa5-e9351b502b6b","domain":"Performant","question":"You are currently designing a low-latency interactive app that requires an Amazon EBS volume that can support up to 16,000 IOPS. Your Project Manager didn’t mention any consideration to cost; he is only concerned with volume performance. Which of the following EBS volume types could be used to meet the requirements?","explanation":"SSD-backed EBS volumes are much faster than HDD-backed ones, so that automatically rules out the Throughput Optimized HDD and Cold HDD responses. General Purpose SSD is right on the mark with a maximum IOPS of 16,000. If the PM requested that you pick the most cost-effective volume, then General Purpose SSD would be the only answer. Otherwise, you can also go for the Provisioned IOPS SSD, which is the highest-performing EBS volume available with a maximum IOPS of 64,000. Either one of the SSD-backed EBS volumes will do.","links":[{"url":"https://aws.amazon.com/ebs/features/","title":"Amazon EBS Features"}],"answers":[{"id":"21a9eab81bfbbe0ba71336bf88d5feea","text":"Cold HDD","correct":false},{"id":"c01eb4fc3413d489e9258ff97066ee1d","text":"General Purpose SSD","correct":true},{"id":"acdd848c4ecdd949a1afa61eeb675655","text":"Throughput Optimized HDD","correct":false},{"id":"43fd7af2adc3101adebb61366bf16df2","text":"Provisioned IOPS SSD","correct":true}]},{"id":"f11b087b-c82c-479f-aae3-d8937d5b3dee","domain":"ResilientDesign","question":"Following an acquisition, a company on-boarded a large number of IAM users into their account. What service will allow the account administrator to check if the company is approaching allowed IAM user service limit?","explanation":"AWS Trusted Advisor provides a service limits recommendation category that performs checks for service usage limits. Number of IAM users is one of the service limit checks performed by AWS Trusted Advisor.","links":[{"url":"https://aws.amazon.com/premiumsupport/technology/trusted-advisor/best-practice-checklist/","title":"AWS Trusted Advisor Best Practice Checks"}],"answers":[{"id":"526775c1622cd0e7b703eb8d4a83d657","text":"AWS Service Catalog","correct":false},{"id":"85c0418befdeed397590cda97cf6d876","text":"AWS Managed Services","correct":false},{"id":"d189bb1b260dc3da48b6e6f5e1ec6879","text":"AWS Personal Health Dashboard","correct":false},{"id":"113b1ad9ce6cdc3a37ad8475bc9bb2b2","text":"AWS Systems Manager","correct":false},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":true}]},{"id":"126e898c-dd73-4447-b5a7-59701a16a92d","domain":"ResilientDesign","question":"You are reviewing Change Control requests and you note that there is a proposed change designed to reduce errors due to S3 Eventual Consistency by updating the 'DelaySeconds' attribute. What does this mean?","explanation":"Poor timing of SQS processes can significantly impact the cost effectiveness of the solution.","links":[{"url":"http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"4b46d6ad9dd090f0143cc40fecbad7b5","text":"When a new message is added to the SQS queue, it will be hidden from consumer instances for a fixed period.","correct":true},{"id":"464400e5333b3beab1128b1b1f7cedf7","text":"While processing a message, a consumer instance can amend the message visibility counter by a fixed amount.","correct":false},{"id":"f170b98804f18cb00b57e135f0a3f116","text":"When the consumer instance polls for new work, the consumer instance will wait a certain time until it has a full workload before closing the connection.","correct":false},{"id":"6e5b2857717c8cf5b2722dc270183515","text":"While processing a message, a consumer instance can reset the message visibility by restarting the preset timeout counter.","correct":false}]},{"id":"f3d178d0-2157-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"Which of the following AWS Support elements provide the assessment of how ready your AWS environment is for your application prior to launch?","explanation":"If you need an assessment of your AWS environment to help identify and mitigate risks that can affect your application prior to launch, you need an AWS Support plan that includes Infrastructure Event Management. The other elements mentioned here are not event or launch focused; Technical Account Managers handle more technical issues. The Support Concierge is a team of enterprise account specialists dedicated to billing and account issues, and Trusted Advisor is all about helping you reduce cost, increasing performance, and improving security.","links":[{"url":"https://aws.amazon.com/premiumsupport/programs/iem/","title":"AWS Infrastructure Event Management"},{"url":"https://aws.amazon.com/premiumsupport/plans/enterprise/","title":"AWS Enterprise Support"}],"answers":[{"id":"af8f25ab81f04f0feba2075a09b65389","text":"Infrastructure Event Management","correct":true},{"id":"3d582ac943b9ba9113651d26bdee7a79","text":"Technical Account Managers","correct":false},{"id":"33b19f092c13caec1202c108b57d2bc1","text":"Support Concierge","correct":false},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false}]},{"id":"64f67680-5d1e-4338-9872-4851f3575ff2","domain":"ResilientDesign","question":"You are designing an application made up of EC2 instances residing in a VPC, RDS for data storage, DynamoDB for user session data and S3 for object storage. This application needs to be to be highly available - it must be able to withstand an Availability Zone outage in AWS's infrastructure. For which of the components will you need to design redundancy into your solution?","explanation":"S3 and DynamoDB are availability-zone redundant by default - so there is no need for any extra redundancy to be designed in. However, EC2 and RDS both need to be designed in a redundant way, such as Multi-AZ configurations for RDS and having EC2 instances across multiple zones","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-increase-availability.html","title":"Tutorial: Increase the Availability of Your Application on Amazon EC2"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"High Availability (Multi-AZ) for Amazon RDS"}],"answers":[{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":false}]},{"id":"c9b8d0e7-d31d-4641-a11c-28681f078732","domain":"SecureSolutions","question":"A new team member hasn't used AWS before and is interested in learning more about its global infrastructure and related concepts. Select all valid and correct statements.","explanation":"No VPC peering is required for S3 cross-region replication. Since July 2017, Amazon Virtual Private Cloud allows customers to create a new default VPC directly from the console or by using the CLI.  Osaka is a special Region that has only one AZ available for consumer use.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2017/07/create-a-new-default-vpc-using-aws-console-or-cli/","title":"Create a New Default VPC using AWS Console or CLI"},{"url":"https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html","title":"What is VPC Peering?"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"Cross-Region Replication"},{"url":"https://aws.amazon.com/about-aws/global-infrastructure/","title":"AWS Global Infrastructure"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-regions-availability-zones","title":"Region and Availability Zone Concepts"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html","title":"Regions and Availability Zones"},{"url":"https://aws.amazon.com/vpc/faqs/","title":"Amazon VPC FAQs"}],"answers":[{"id":"5d9924102f5bb35d22225ddaead7bb7b","text":"An Availability Zone (AZ) is an isolated location within a region. While AWS operates some with only one EC2 Availability Zone, other regions have between two and six AZs.","correct":true},{"id":"f8e30527ccced5256b677cdda7901c9c","text":"After creating a VPC, you can add one or more subnets in each Availability Zone. Each subnet must reside entirely within one Availability Zone and cannot span zones.","correct":true},{"id":"fd6d1a12cbfa90d38b2d701360224d21","text":"For cross-region replication to work, you must set up a peering connection between the two relevant VPCs in each region","correct":false},{"id":"f0007b62472d187cfae568a97cfdfd27","text":"It is not possible to create a new default VPC directly from the console if the default VPC in a region has been deleted. Instead, you need to contact AWS support and raise a ticket for that.","correct":false}]},{"id":"2f18032b-ba16-4cf1-a9f4-0ee458e316bb","domain":"ResilientDesign","question":"Your development team have created a cloud specific application which is decoupled from other services.  You have been tasked with choosing an AWS service to use as message queue in this service.  The developers have specified that the chosen service must cope with at least 5000 transactions per second, guarantee delivery of each message but allows for the message being sent a number of times.","explanation":"The Standard SQS Queue meets all of the goals listed in the question, each message will be delivered at least once, but may be sent more than once. It can also cope with almost unlimited number of transactions per second. The FIFO queue can guarantee to deliver messages at least once, but can only handle 300 transactions per second.  Amazon MQ is specifically developed to move existing applications to the cloud without changing your code and it may work in this context, but it is not recommended.  SNS is a notification service not a messaging queue.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"Amazon SQS FAQs"},{"url":"https://aws.amazon.com/sqs/features/","title":"Amazon SQS features"}],"answers":[{"id":"6d0cf8e6998da0736797ae76fc1b5071","text":"SQS FIFO","correct":false},{"id":"0a4adfe9c9d87e31e94e1e13e2f44441","text":"SQS Standard","correct":true},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":false}]},{"id":"bce7cb5d-687e-4e77-a516-1cde22e6f4e8","domain":"Performant","question":"How quickly can objects be restored from Glacier?","explanation":"You can expect most restore jobs initiated via the Amazon S3 APIs or Management Console to complete in 3-5 hours. Expedited restore is available at a price. ","links":[{"url":"https://aws.amazon.com/glacier/faqs/#dataretrievals","title":"Retrieving Data From Glacier"}],"answers":[{"id":"0d714869027c4e08ea9b2943d9bd704e","text":"30 minutes","correct":false},{"id":"6619a70f8ab8877e4131643fb8ded723","text":"2 hours","correct":false},{"id":"72ab9d0304d3e84c6aa2dd15eda282f2","text":"1 hour","correct":false},{"id":"99d888e6893ac480abd21ecb8a18e060","text":"3-5 hours","correct":true}]},{"id":"1a0b1d3a-8954-4a09-8952-177296aa74d9","domain":"CostOptimized","question":"A financial services company is located in New York, while their development and testing is performed in San Francisco. The development team lead wants to ensure that the data stored in their test account Amazon S3 bucket is a current copy of the data in their production account Amazon S3 bucket. What steps implement the solution in the most effective way?","explanation":"S3 Cross-Region Replication is S3 capability that can be configured on an S3 bucket to automatically replicate objects to another bucket in a different region. S3 bucket versioning is a requirement to enable S3 cross-region replication. S3 lifecycle policies are not related to replication of S3 data between accounts or regions. S3 lifecycle policies can be used to transition S3 objects to another Amazon S3 storage class (e.g. Glacier). Using S3 bucket event notifications for implementing object replication is not the optimal solution as it does not use S3 native capabilities. Implementing a Lambda function to replicate S3 objects to another bucket is not the optimal solution as it requires custom code development and testing.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html","title":"Amazon S3 Replication"}],"answers":[{"id":"d685fd084e72386d91439741e993fa1a","text":"Configure S3 Bucket Lifecycle Policy.","correct":false},{"id":"a0ebcbd1b7f09f700a7220e87af23e93","text":"Configure S3 Bucket Versioning.","correct":true},{"id":"797931651fc0ec6480675746a061a614","text":"Configure S3 Bucket Event Notification.","correct":false},{"id":"08bc138542a70d8db6cf01c61ecbe9c2","text":"Configure Cross-Region Replication.","correct":true},{"id":"3dc5e668dc968f6dfd1f7b9df09f4182","text":"Configure an AWS Lambda function to replicate S3 objects.","correct":false}]},{"id":"263940e4-1502-11ea-8d71-362b9e155667","domain":"Performant","question":"You work for a digital media company and have been tasked with designing a solution for storing all CloudWatch logs. Which of the following solutions would you recommended when applying best practices?","explanation":"CloudWatch log data consists of files, which means that S3 is the most suitable storage service for this application. RDS, on the other hand, is a database service; and Amazon Elasticsearch Service is used for streaming CloudWatch log data instead of storing it. Although you can use an existing bucket to export the log data to S3, it is an AWS best practice to create a dedicated S3 bucket specifically for storing your CloudWatch Logs.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/S3ExportTasksConsole.html","title":"Export Log Data to Amazon S3 Using the Console"}],"answers":[{"id":"f4b568c1cb1ddb17fdb76089fa04ad8d","text":"Use Elasticsearch Service for the CloudWatch log data.","correct":false},{"id":"ca8178d77067bfd4c1e2feeb95937a6e","text":"Create an S3 bucket specifically for exporting the CloudWatch log data.","correct":true},{"id":"818a59284d05a35c0f93dcef80e55fe1","text":"Store CloudWatch log data in an RDS instance.","correct":false},{"id":"fb77a37699b9da358561f0841ee07b2d","text":"Use an existing bucket to export the CloudWatch log data to S3.","correct":false}]}]}}}}
