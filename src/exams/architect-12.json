{"data":{"createNewExamAttempt":{"attempt":{"id":"d3bdb86a-18ba-4cca-8c2e-8786081abc1d"},"exam":{"id":"ff6989c0-3faa-41a1-b25f-052062e4e414","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"089e8631-f537-4929-b785-87c88ccbd55f","domain":"Performant","question":"Which of the following are AWS compute services?","explanation":"EC2, ECS, and Lambda are AWS compute services.","links":[{"url":"https://aws.amazon.com/products/compute/#Cloud_Compute_Details","title":"AWS Compute Services"}],"answers":[{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"f332127ba5ee3389e4c5cff45ac9a518","text":"EFS","correct":false},{"id":"c8f63ecaff5e983a2441126a241c4cfa","text":"ECS","correct":true},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true}]},{"id":"f85240a5-118e-4367-b2ed-0c442a60bec4","domain":"ResilientDesign","question":"You currently have a web application that uses two EC2 instances and you want 75% of the web traffic to go to one server and the other 25% to go to the other. Which of the following routing policies should you choose?","explanation":"You need a weighted routing policy because you want to be able to set the proportions traffic routed to your servers. A simple routing policy would have been ideal if you had a single server. Although failover and geolocation routing policies are for routing traffic to more than one resource, the former is ideal for configuring active-passive failover, and the latter is for specifying location rather than traffic proportions.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Choosing a Routing Policy"}],"answers":[{"id":"323d4eb70b252acb4a04eaf9e0882597","text":"Geolocation","correct":false},{"id":"7388404ef116c3ff812bfd290b094d9e","text":"Failover","correct":false},{"id":"1fbb1e3943c2c6c560247ac8f9289780","text":"Simple","correct":false},{"id":"582368ac8232617ead14ac74ccc40ea9","text":"Weighted","correct":true}]},{"id":"43bbab14-2b64-442d-98c0-632324c887f8","domain":"CostOptimized","question":"Your company has been running its core application on a fleet of r4.xlarge EC2 instances for a year.  You are confident that you understand the application steady-state performance and now you have been asked to purchase Reserved Instances (RIs) for a further 2 years to cover the existing EC2 instances, with the option of moving to other Memory or Compute optimised instance families when they are introduced. Which of the following options meet the above criteria whilst offering the greatest flexibility and maintaining the best value for money.","explanation":"When answering this question, it's important to exclude those options which are not relevant, first.  The question states that the RI should allow for moving between instance families and this immediately rules out Standard and Scheduled RIs as only Convertible RIs can do this.  Of the 2 Convertible RI options, the first can be ruled out as it suggests selling unused RI capacity on the Reserved Instance Marketplace, but this is not available for Convertible RIs and therefore that only leaves one answer as being correct.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/reserved-instances-types.html","title":"Types of Reserved Instances (Offering Classes)"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-reserved-instances.html","title":"Reserved Instances"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html","title":"Scheduled Reserved Instances"}],"answers":[{"id":"188dc576a2e69c4182330092ab7f3786","text":"Purchase a Scheduled RI for 3 years, then sell the unused RI on the Reserved Instance Marketplace","correct":false},{"id":"41620e7974f0d2cca7f57d1972e30387","text":"Purchase a Convertible RI for 3 years, then sell the unused RI on the Reserved Instance Marketplace","correct":false},{"id":"b46dcc09115bb8c1683455addbc4fa46","text":"Purchase a 1 year Convertible RI for each EC2 instance, for 2 consecutive years running","correct":true},{"id":"89987ea3ddc88d352336561f25d83387","text":"Purchase a 1 year Standard Zonal RI for 3 years, then sell the unused RI on the Reserved Instance Marketplace","correct":false}]},{"id":"f50eca72-215c-11ea-978f-2e728ce88125","domain":"Performant","question":"EC2 includes instances like i3.xlarge, which are designed to provide high sequential read and write access to very large data sets on local storage. Which of the following EC2 instance types does i3.xlarge fall under?","explanation":"An EC2 instance like i3.xlarge delivers high sequential read and write access, a characteristic that is ideal for large data sets. Data is stored in the instance’s solid-state drive, a type of storage renowned for quick access time and low latency. As a result, i3.xlarge is classified as a storage optimized instance.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"Amazon EC2 Instance Types"}],"answers":[{"id":"fb152ac1edfe96da5fe255e395003b0d","text":"Memory Optimized","correct":false},{"id":"b26f852f8cf53bd055d76deddcadf155","text":"Compute Optimized","correct":false},{"id":"ea999a66bf3ccfec4616d5be49348665","text":"Storage Optimized","correct":true},{"id":"94a1a3953054d8ece597f4f69bb343d4","text":"General Purpose","correct":false},{"id":"2f925ef0b67b13f124d684b4e0ca9682","text":"Accelerated Computing","correct":false}]},{"id":"b8be7547-0f55-4f09-addd-11907477196e","domain":"CostOptimized","question":"You have a one-year contract with a client to create and maintain its cloud environment with an AWS account, with the awareness that each AWS service and resource used has a 12-month free usage term. When that 12-month term expires, which of the following happens?","explanation":"After the 12-month free usage term expires for an AWS service, you will start paying the standard, pay-as-you-go service rates. There are no reduced rates, extensions from AWS Support, or automatic renewals of the 12-month term.","links":[{"url":"https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc","title":"AWS Free Tier"}],"answers":[{"id":"674c02a2df56483f7902847e2dbb8cd8","text":"The free usage term will be automatically renewed for another 12 months.","correct":false},{"id":"cb548d5d972e20059df43a3c680b32b5","text":"AWS Support will extend the free usage term to another 12 months upon request.","correct":false},{"id":"a0cdfc4210cbbb0f723b10fafa2c6120","text":"You will pay a fee that is reduced from the full pricing.","correct":false},{"id":"233245ebe184276bbec368b4fd80f067","text":"You will pay standard, pay-as-you-go service rates.","correct":true}]},{"id":"176bd1a3-b3e8-4c3c-9921-28d83bdada07","domain":"ResilientDesign","question":"Which of the following statements are true?","explanation":"Be clear about the meaning of the terms Availability, Durability & Resilient.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"},{"url":"https://aws.amazon.com/s3/reduced-redundancy/","title":"S3 Reduced Redundancy Storage"}],"answers":[{"id":"da8bfe5d95dde1d95483782050e21075","text":"S3-Standard is designed for 11-nines availability","correct":false},{"id":"bd3cdbd6cb4f1c07310bfd9a4b19ff32","text":"S3-OneZone-IA carries the risk that the destruction of a Datacentre will result in data loss.","correct":true},{"id":"f06957dc3a39f41ed53e9dacbed9ea14","text":"S3-Standard provides 99.99% availability.","correct":true},{"id":"012e8dcc5fad05d9c1c912d6445392af","text":"S3-RRS provides 99.99% durability","correct":true},{"id":"496a94c1faa1463c556c49c59561c7aa","text":"S3-Standard is designed for 11-nines durability.","correct":true}]},{"id":"15e27dc3-562b-420f-9c0b-a23760418ac9","domain":"SecureSolutions","question":"Your company is concerned about accidental deletion of files in S3 buckets. Which of the following steps can be taken to help prevent this?","explanation":"The Multi-Factor Authentication (MFA) Delete capability of S3 Versioning can be used to provide an additional layer of security. By default, all requests to your Amazon S3 bucket require your AWS account credentials. If you enable Versioning with MFA Delete on your Amazon S3 bucket, two forms of authentication are required to permanently delete a version of an object: your AWS account credentials and a valid six-digit code and serial number from an authentication device in your physical possession.","links":[{"url":"https://aws.amazon.com/s3/faqs/#Durability_.26_Data_Protection","title":"S3 FAQ - Durability & Data Protection"}],"answers":[{"id":"3c4f445265007c269794ba9a9252cd55","text":"Enable MFA Delete on the bucket.","correct":true},{"id":"d2a53118e334bf22b7cddab8d4ec51e4","text":"Only work on S3 files while someone is reviewing your work.","correct":false},{"id":"f8083509762323539199cd4c55986e6c","text":"Enable encryption on the bucket.","correct":false},{"id":"253efe32850426ce32c509612536c798","text":"Enable versioning on the bucket.","correct":true}]},{"id":"89f330aa-397e-49a6-99c1-59a911318d03","domain":"SecureSolutions","question":"To protect S3 data from accidental overwrites and deletes, which of the following should you do first?","explanation":"The first thing you should do is enable versioning.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html","title":"S3 Object Versioning"}],"answers":[{"id":"f85fb671c749e7fcc0f440124d0879d7","text":"Access S3 only from signed URLs.","correct":false},{"id":"d5ea3592264e2a8848ca043466fd5c46","text":"Allow only MFA access","correct":false},{"id":"9fb0a6abf0e1bda745fab85832252ee0","text":"Use a bucket policy to disable deletes from S3","correct":false},{"id":"253efe32850426ce32c509612536c798","text":"Enable versioning on the bucket.","correct":true}]},{"id":"f1715a54-ef4a-4912-9093-e8e36698b0c9","domain":"CostOptimized","question":"Your company needs to run several monthly workloads that will each take several hours to complete. Although critical, these workloads can be stopped and restarted without adversely affecting the outcome of the job. Which pricing model would you use to deliver the most economical solution?","explanation":"Spot instances are a cost-effective choice if you can be flexible about when your applications run and if your applications can be interrupted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html","title":"About Spot Instances"}],"answers":[{"id":"026db7f2265667575c05772f32778b8a","text":"Spot Instances","correct":true},{"id":"c658c72ec41cc513ad91a3f3e6d2c060","text":"On-demand Instances","correct":false},{"id":"de53d38fe38e0fce729f15c292a59891","text":"Free-Tier Instances","correct":false},{"id":"29068f6044e3fedf44165e646a2d2bb1","text":"Reserved Instances","correct":false}]},{"id":"08233176-e11b-410e-98eb-25ca6e2eebcb","domain":"ResilientDesign","question":"A large enterprise has a distributed application in its own data center and relies on message brokers to connect and co-ordinate different systems. Message Brokers serve as the backbone for their IT environment and ultimately their business services. The enterprise has started to move some of its applications to the cloud and is looking for a cloud message broker solution so that the on-premise applications can interact with cloud-based application components. Which of the following services best suit the customer requirements?","explanation":"Amazon MQ is recommended for messaging between on-premises and cloud application components. It also supports industry-standard APIs and protocols such as JMS, AMQP and MQTT. Amazon SQS is best utilized as a messaging solution between components entirely on AWS. Amazon Step Functions is a fully managed service which makes it easy to co-ordinate components of distributed applications using visual workflows. Amazon SNS is a managed publish/subscribe service which reliably delivers messages to all valid AWS endpoints.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-activemq-in-a-hybrid-cloud-environment-with-amazon-mq/","title":"AWS Application Integration Services"}],"answers":[{"id":"55daa020bacdf7e4ae1a33c9f14c45b3","text":"Amazon SNS","correct":false},{"id":"860f0e709d06a1c1529c01a39cdfd798","text":"Amazon Step Functions","correct":false},{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true}]},{"id":"05830be4-2d87-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"When configuring an Internet-facing load balancer for IPv4 traffic, you choose the two desired Availability Zones, only to get a message saying that you need an Internet gateway attached to their subnets. However, you already have an Internet gateway attached to the VPC where the subnets reside. Which of the following choices will solve the issue?","explanation":"Each route in a table specifies a destination and a target. To enable the subnets to access the Internet through the Internet gateway, you will have to go to the route table associated with the VPC and add a destination CIDR of 0.0.0.0/0 to represent all IPv4 traffic. In addition, set the target to the Internet gateway. The destination CIDR of : :/0 is for IPv6 traffic, which is why Response D is not the answer to the question. Neither Response A nor Response C are valid options, since you cannot attach Internet gateways to subnets; they are attached to VPCs.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html","title":"Route Tables"}],"answers":[{"id":"9f7fae07aa20499b2d47232ac7ee1359","text":"Update the route table applied to the VPC to include a route with a destination CIDR of : :/0 and the target set to the Internet gateway.","correct":false},{"id":"270b3bd868c19217f93445afd33afdb7","text":"Create an Internet gateway and attach them to both subnets.","correct":false},{"id":"429880699dd7f62a46b148db907548ef","text":"Update the route table applied to the VPC to include a route with a destination CIDR of 0.0.0.0/0 and the target set to the Internet gateway.","correct":true},{"id":"9ba5219b7133b2e35f31fff7e7a24b58","text":"Create two Internet gateways and attach them to the two subnets.","correct":false}]},{"id":"f3d178d0-2157-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"Which of the following AWS Support elements provide the assessment of how ready your AWS environment is for your application prior to launch?","explanation":"If you need an assessment of your AWS environment to help identify and mitigate risks that can affect your application prior to launch, you need an AWS Support plan that includes Infrastructure Event Management. The other elements mentioned here are not event or launch focused; Technical Account Managers handle more technical issues. The Support Concierge is a team of enterprise account specialists dedicated to billing and account issues, and Trusted Advisor is all about helping you reduce cost, increasing performance, and improving security.","links":[{"url":"https://aws.amazon.com/premiumsupport/programs/iem/","title":"AWS Infrastructure Event Management"},{"url":"https://aws.amazon.com/premiumsupport/plans/enterprise/","title":"AWS Enterprise Support"}],"answers":[{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"3d582ac943b9ba9113651d26bdee7a79","text":"Technical Account Managers","correct":false},{"id":"33b19f092c13caec1202c108b57d2bc1","text":"Support Concierge","correct":false},{"id":"af8f25ab81f04f0feba2075a09b65389","text":"Infrastructure Event Management","correct":true}]},{"id":"181cab5b-23af-4947-8821-51ed16f55a7d","domain":"ResilientDesign","question":"A large jewelry distributor has installed their new inventory application in a development environment on AWS. After completing their testing, they're ready to deploy the application into its production environment. They've been using VPN connections for the development phase, but they need to upgrade to a higher resiliency network connection scheme to communicate back and forth from other on-premises business applications that are mirrored across two data centers. Testing results indicate that some transactions may require more than a 1.25 Gbps connection to ensure a quality customer experience. Which network architecture will provide the appropriate resiliency for this inventory application?","explanation":"For critical production workloads like an inventory application that require high resiliency, it is recommended to have one connection at multiple locations. Such a topology ensures resilience to connectivity failure due to a fiber cut or a device failure as well as a complete location failure. Use of a Direct Connect Gateway will provide access to any AWS Region from any Direct Connect location. Installing separate connections terminating on separate devices in more than one location gives another layer of resiliency, but that configuration, along with its added costs, is not necessary for this use case. Creating separate connections to only a single Direct Connect location from a single data center does not mitigate the risk of full facility outages. AWS doesn't recommend using a VPN as a backup for connections that require speeds greater than 1 Gbps.","links":[{"url":"https://aws.amazon.com/directconnect/","title":"AWS Direct Connect"},{"url":"https://aws.amazon.com/directconnect/resiliency-recommendation/","title":"AWS Direct Connect Resiliency Recommendations"}],"answers":[{"id":"8a967bd089e29673bac3c13fd00105ca","text":"Implement an AWS Direct Connect connection from one data center to an AWS Direct Connect location. Establish a VPN connection from the other data center as a backup.","correct":false},{"id":"a4c6c0827f35637ae33dfd03b1b3e0f6","text":"Configure two AWS Direct Connect connections to an AWS Direct Connect location from two different network devices in one data center.","correct":false},{"id":"508aa0084ed6faa994e17273231899f1","text":"Create an AWS Direct Connect connection from one data center to an AWS Direct Connect location. Install another AWS Direct Connect connection from the other data center to a different AWS Direct Connect location.","correct":true},{"id":"6dd9941a3ca38128754b0fb66f8642cb","text":"Install two AWS Direct Connect connections to an AWS Direct Connect location from two different network devices in one data center. Create another two AWS Direct Connect connections to a different AWS Direct Connect location from two different network devices in the other data center.","correct":false}]},{"id":"62ce46dc-9858-4179-b84a-49f85cddb413","domain":"Performant","question":"You maintain an application which needs to store files in a file system which has the ability to be mounted on various Linux EC2 Instances. Which of the following would be an ideal storage solution?","explanation":"Amazon EFS provides scalable file storage for use with Amazon EC2. You can create an EFS file system and configure your instances to mount the file system. You can use an EFS file system as a common data source for workloads and applications running on multiple instances.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEFS.html","title":"Amazon Elastic Files System (Amazon EFS)"}],"answers":[{"id":"a0d5b037004b9bef739343edbcb14326","text":"Amazon EC2 Instance store","correct":false},{"id":"f7b96044a16becafecad63df1725e9c8","text":"Amazon EFS","correct":true},{"id":"270fcb785810d0206945029bb05f4e97","text":"Amazon S3","correct":false},{"id":"516729a7c0562425406a22cfe6a2c163","text":"Amazon EBS","correct":false}]},{"id":"6853a0e8-ce9d-4d37-a7af-b235c0d5fc05","domain":"SecureSolutions","question":"To establish a successful site-to-site VPN connection from your on-premise network to an AWS Virtual Private Cloud, which of the following must be configured?","explanation":"You must have a VPC with Hardware VPN Access, an on-premise Customer Gateway, and a Virtual Private Gateway to make the VPN connection work.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/NetworkAdminGuide/Introduction.html#Summary","title":"Setting Up a VPN Connection"}],"answers":[{"id":"3d989f6e836bff71e5a2d4a288d70000","text":"An on-premise Customer Gateway","correct":true},{"id":"ade419f8f6139a9769e4b0131d39f641","text":"A Virtual Private Gateway","correct":true},{"id":"d776301586e8b5388ed61cd90c180467","text":"A NAT instance","correct":false},{"id":"de8b5ba929b3369272eb1146eb6f3f64","text":"A VPC with Hardware VPN Access","correct":true},{"id":"e04ddd768294b403207504bfa9eb006c","text":"A private subnet in your VPC","correct":false}]},{"id":"7ad502a4-1c97-11ea-978f-2e728ce88125","domain":"ResilientDesign","question":"A Fortune 500 company is currently migrating to AWS. The organization has determined that it needs an AWS Support plan that can mitigate failure or disruption of processes essential to its operation. Which of the following plans is most suitable for this purpose?","explanation":"Basic Support is included with each AWS account, so that automatically rules it out as the correct answer. Based on the description of the company’s needs and size, Enterprise Support is strongly recommended. This plan is ideally designed for organizations that have business or mission-critical workloads in AWS. Developer is geared towards those who experiment or test in AWS, and Business is ideal for production workloads. Neither of them is as robust as the Enterprise offering.","links":[{"url":"https://aws.amazon.com/premiumsupport/plans/","title":"Compare AWS Support Plans"}],"answers":[{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":false},{"id":"972e73b7a882d0802a4e3a16946a2f94","text":"Basic","correct":false},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":false}]},{"id":"74da1953-0d65-427a-bbba-a17f2cf81ddd","domain":"SecureSolutions","question":"You need to implement a new web application that allows users to store family photos online in such a way that only invited guests will be able to view the images. Which type of S3 encryption should you choose to maintain full end-to-end control of the encryption/decryption of objects and assure that only encrypted objects are transmitted over the Internet to Amazon S3.","explanation":"","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html","title":"Using a Client-Side Master Key"}],"answers":[{"id":"e17194408dc439e1658a544965724d44","text":"SSE-KMS","correct":false},{"id":"5e146922b28cce8eae49ecb39eef972d","text":"Provide a client-side master key to the Amazon S3 Encryption Client","correct":true},{"id":"1562bb9d2d9567740605dcb1ccab5c80","text":"SSE-S3","correct":false},{"id":"472035b16201f5505380c16ec3eb8518","text":"SSE-C","correct":false}]},{"id":"53543ab6-d7b3-4a4f-a3ba-fde0ca70ed9b","domain":"Performant","question":"Six years ago you launched a new app and had the forethought to design the environment to use ELBs and simple robust autoscaling groups.  This has served well however recently you are seeing that the demand is coming on very steeply as people check the services 1st thing in the morning.  Your dashboard is now showing that customer connections are being delayed and at time rejected.  This is impacting your previously five-star customer satisfaction rating.  Why is your design failing?","explanation":"Auto scaling is not really intended to respond to instantaneous spikes in traffic.  Even in the Cloud commissioning a server takes real time.  The bigger and more complicated the server the longer it takes.  There are ways to deal with this from redesign to use more agile compute like containers and Serverless, step and overlapping autoscaling policies to more rapidly respond, or scheduled scaling for predictable loads. AMIs may be 'legacy', but there is no limit as implied in the answer.  Scaling policies can block each other, but it would not result in a 'per hour' limitation.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html","title":"Dynamic Scaling for Amazon EC2 Auto Scaling"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-cloudwatch-metrics.html","title":"CloudWatch Metrics for Your Application Load Balancer"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-cloudwatch-metrics.html","title":"CloudWatch Metrics for Your Classic Load Balancer"},{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/Cooldown.html","title":"autoScaling cooldown"}],"answers":[{"id":"62cb96bc5208881af5c2e6ae7304b484","text":"The launch configuration is using legacy AMIs which are in short supply resulting in a delay in scaling response.","correct":false},{"id":"5c7b8ce4a67af83307447d9fe679a66c","text":"Simple autoscaling is better suited for slow uptake than rapid or steep uptake in demand.","correct":true},{"id":"27a7809b77e13496ba126da27107c680","text":"Your down scaling policy is wrong resulting in a limit to how many new instances can be launched per hour.","correct":false},{"id":"612acf301ab3c0f2bca86d2056ddaa0d","text":"Using multiple autoscaling groups can confuse the scaling algorithm causing delays in initiating new instances.","correct":false}]},{"id":"15c0f4d7-ac13-40b0-98fb-2d8fd8b077ee","domain":"Performant","question":"You have been asked to advise on a scaling concern.  The client has an elegant solution that works well.  As the information base grows they use CloudFormation to spin up another stack made up of an S3 bucket and supporting compute instances.  The trigger for creating a new stack is when the PUT rate approaches 100 PUTs per second.  the problem is that as the business grows that number of buckets is growing into the hundreds and will soon be in the thousands.  You have been asked what can be done to reduce the number of buckets without changing the basic architecture.","explanation":"Until 2018 there was a hard limit on S3 puts of 100 PUTs per second.  To achieve this care needed to be taken with the structure of the name Key to ensure parallel processing.  As of July 2018 the limit was raised to 3500 and the need for the Key design was basically eliminated. Disk IOPS is not the issue with the problem. The account limit is not the issue with the problem.","links":[{"url":"https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/","title":"S3 Request rates - Whats new"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/request-rate-perf-considerations.html","title":"S3 Request rates documentation"},{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage classes"}],"answers":[{"id":"0196ee21bff2d4c35c191d0973220d3c","text":"Upgrade all buckets to S3 provisioned IOPS to achieve better performance.","correct":false},{"id":"906c60dd95d60014479c321de23c5a4c","text":"Refine the key hashing to randomise the name Key to achieve the potential of 300 PUTs per second.","correct":false},{"id":"c1ee6963e6cab066324cc7e832d9ea3d","text":"Change the trigger level to around 3000 as S3 can now accommodate much higher PUT and GET levels.","correct":true},{"id":"b183896b9af1543c0b43e9540b244954","text":"Set up multiple accounts so that the per account hard limit on S3 buckets is avoided.","correct":false}]},{"id":"f83080c3-ee9d-4ca9-ada5-f94b6642d2f2","domain":"CostOptimized","question":"Your company is running an older version of Windows on employees' desktops/laptops which will be going off of mainstream support in the near future. The most current version of Windows will require a large capital investment to purchase more powerful hardware to run it. All desktops/laptops require access to the Internet as well as access to multiple business applications running on Amazon EC2 web servers in the AWS cloud. Your manager has tasked you with determining how to move the company's desktops/laptops to the most current version of Windows. Which architecture will provide the most cost effective solution?","explanation":"Amazon Workspaces provides the capability to serve virtual cloud-based desktop sessions to your desktop/laptop users (either Windows or Linux). It eliminates the need for powerful hardware, and it removes the burden of individual desktop/laptop software maintenance. AppStream is not needed to access the Internet, nor is it needed to serve the EC2 applications in this use case since a browser can be used from WorkSpaces to access the web servers. A NAT Gateway is preferred to an Internet Gateway since all traffic is initiated from the desktop/laptop, instead of from out on the Internet. WorkSpaces provides for creating an authentication directory, so creating one separately is not needed. WorkSpaces also creates an ENI for each session inherently.","links":[{"url":"https://docs.aws.amazon.com/workspaces/latest/adminguide/amazon-workspaces.html","title":"What is Amazon WorkSpaces?"},{"url":"https://aws.amazon.com/blogs/desktop-and-application-streaming/why-customers-are-moving-their-windows-desktops-to-the-cloud-with-aws/","title":"Why Customers Are Moving Their Windows Desktops to the Cloud with Amazon WorkSpaces"}],"answers":[{"id":"7c8f5d29af4240a4ec8c68eaa488e933","text":"Use Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use an Internet Gateway in the same VPC to provide access to the Internet. Provision an AWS Managed Microsoft AD instance and link it to your on-premises Active Directory for user authentication.","correct":false},{"id":"58e179301471d5f030ad1b404a5c527f","text":"Deploy Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use a NAT Gateway in the same VPC to provide access to the Internet.","correct":true},{"id":"e33c2a9e2b05853b6c1f1bc548357068","text":"Implement Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use Amazon AppStream to provide access to the Internet and to serve the EC2 applications to the desktops/laptops.","correct":false},{"id":"7c9f90a44ccdb77a69453cc39d1fdba7","text":"Implement Amazon WorkSpaces with the most current version of Windows to provide Desktop-as-a-Service capability. Use an Internet Gateway in the same VPC to provide access to the Internet. Provision Elastic Network Interfaces in the same VPC to connect the desktops/laptops to the EC2 applications.","correct":false}]},{"id":"d5462fb3-227a-4285-8a77-8672c8558693","domain":"CostOptimized","question":"Your AWS environment in us-east-1 contains several EC2 instances with associated RIs dedicated to a project that has just been canceled. You need to recoup the cost of these reserved instances, and you need to preserve the data for future use. What can you do to minimize charges for these instances?","explanation":"You should preserve the data by taking snapshots of the EBS volumes backing your instances and sell the RIs on the Reserved Instance Marketplace.  Remember the Reserved Instances is both a Capacity reserve, and a Billing discount.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html","title":"About EBS Snapshots"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html","title":"Selling on the Reserved Instance Marketplace"}],"answers":[{"id":"9dda53fcc86762b17e493dad51eb121a","text":"Take snapshots of the EBS volumes and terminate the instances.","correct":true},{"id":"8a56365b62c17d312312ea07efd07dc1","text":"Contact AWS and ask them to release you from your Reserved Instance purchase.","correct":false},{"id":"8cf9e85628c02261b9bbc22141dba658","text":"Stop the instances and retain them for future use.","correct":false},{"id":"79ac46c5a0e1356d35f90962f478b6cb","text":"Sell the unused reservations on the AWS Reserved Instance Marketplace.","correct":true}]},{"id":"adbe2585-a484-493a-bec9-ed54d0ff4672","domain":"SecureSolutions","question":"You have a website that contains public content and member-only content. These are being served from 2 different auto-scaling EC2 instance groups, one for members and one for non-members. Once a member logs in, they are re-directed to a \"members.myawesomesite.com\" URL. You would like to put a single load balancer in front of both groups to direct users as appropriate - how would you design this?","explanation":"Both the network load balancer and classic load balancer do not support layer-7, and therefore cannot help route based on the hostname. Although having 2 load balancers and using R53 would work, the scenario asks for 1 if possible - and this is possible using an application load balancer as these operate at Level 7","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/features/","title":"Elastic Load Balancing features"}],"answers":[{"id":"8ab4d2b861c5ab884c9ef4cbdebe221a","text":"It is not possible to have multiple auto-scaling groups attached to one load balancer, so 2 load balancers will we required, then use R53 to point to the appropriate load balancer based on URL.","correct":false},{"id":"18e6dd30c5604d6a1b97f7f9fd9b21f3","text":"Use an application load balancer with host-based routing configured","correct":true},{"id":"bae789245cb0d3f5b010dd39d2af14bb","text":"Use a classic load balancer with URL based routing configured","correct":false},{"id":"f3551559eb91b2d8b762d7c8fd38a725","text":"Use a network load balancer with domain-based routing enabled","correct":false}]},{"id":"b5dbb10f-bfe9-4798-94bf-1058f0e38858","domain":"SecureSolutions","question":"One of your web servers runs in an EC2 Linux instance in the us-west-2 region. You need to SSH into the instance to make some configuration changes. Your AWS Management Console currently points to the us-east-1 region. You enter the connect string from your desktop, but the command hangs for a period of time and then returns an “Operation timed out” message. What is most likely the cause of the connection failure?","explanation":"When you attempt to SSH into an EC2 Linux instance without a Security Group inbound rule that allows access the requesting IP address, you will get an 'Operation timed out' message. If you include the wrong key pair file in your connect string, you will immediately receive a 'Permission denied' error message. You don't need to have your Management Console pointed to the region you are trying to SSH to. In fact you don't even need to be logged in to the Management Console. Route Table targets only apply to outbound traffic.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html","title":"Amazon EC2 Security Groups for Linux Instances"}],"answers":[{"id":"7d2ee468760d828148d74bdf16458a9d","text":"The Security Group for the EC2 instance is blocking your access","correct":true},{"id":"7bd21fc3a95d9ab8bc81887f0eabe6e2","text":"You’ve specified the wrong key pair file in the connect string from your desktop","correct":false},{"id":"5a59d873dee868ebc4a43c10c1a954c5","text":"The Route Table for the subnet where the EC2 instance resides is missing an Internet Gateway target","correct":false},{"id":"15f0fad365a5009122f37d5693f5ca56","text":"Your AWS Management Console needs to point to the region where the EC2 instance resides","correct":false}]},{"id":"331294bf-39e7-425e-9bac-d8b0d7f3c5b9","domain":"Performant","question":"You have a data warehouse on AWS utilizing Amazon Redshift of 50 Tb. Your data warehouse is located in us-east-1 however you are opening a new office in London where you will be employing some data scientists. You will need a copy of this Redshift cluster in eu-west-2 for performance and latency considerations. What is the easiest way to manage this migration?","explanation":"Where AWS provides a service, it is wise to use it rather than trying to create a bespoke service.  The AWS service will have been designed and tested to ensure robust and secure transfer taking into account key management and validation.","links":[{"url":"https://docs.aws.amazon.com/redshift/latest/mgmt/managing-snapshots-console.html#xregioncopy-kms-encrypted-snapshot","title":"Cross-Region Snapshot Copy"}],"answers":[{"id":"391581e947946e86d8de1e84eaadaf1e","text":"Create a new redshift cluster in eu-west-2. Once provisioned use AWS data pipeline to export the data from us-east-1 to eu-west-2.","correct":false},{"id":"ebe9254e3a4f7de6dbfc80c13f29082d","text":"In the AWS console go in to Redshift and choose Backup, and then choose Configure Cross-Region Snapshots. Select Copy Snapshot and then choose the eu-west-2 region. Once successfully copied use the snapshot in the new region to create a new Redshift cluster from the snapshot.","correct":true},{"id":"b3e2fd4ff81f2e4fff2f071064c717b0","text":"Order an AWS Snowball. Export the Redshift data to the Snowball and then ship the snowball from us-east-1 to eu-west-2. Load the data into Redshift in London.","correct":false},{"id":"fcdde9340024a4e534cb48d9980a5511","text":"Export the data to S3 using Data Pipeline and configure Cross Region Replication to an S3 bucket based in London. Use AWS lambda to import the data back to Redshift.","correct":false}]},{"id":"5a47c265-e7a8-455e-9a59-35c26843fc4c","domain":"ResilientDesign","question":"You have a website that uses the HTTP and HTTPS protocols and consists of two web servers and an RDS database server. Which of the following choices would be the most suitable load balancer for distributing incoming web traffic?","explanation":"As of now, AWS offers three types of load balancers, which are Application Load Balancers, Network Load Balancers, and Classic Load Balancers. All three types are elastic load balancers, which means that they automatically distribute incoming traffic and scale resources to meet traffic demands. So 'Elastic Load Balancer' is incorrect.  Going with an application load balancer is the best choice because it makes routing decisions at the application layer, which is HTTP and HTTPS. If the question was addressing routing decisions at the transport layer—which includes protocols like TCP, UDP, and TLS—then Network Load Balancer would have been the correct answer. Classic Load Balancers is no longer the recommended load balancer for the majority of users in AWS; it is now only recommended for use when running in EC2 Classic mode.","links":[{"url":"https://aws.amazon.com/elasticloadbalancing/","title":"Elastic Load Balancing"}],"answers":[{"id":"b3b5475001f327d331389c6f07ff7c3a","text":"Application Load Balancer","correct":true},{"id":"e0f10b949b1cbe40263bfe87c11a2f5d","text":"Network Load Balancer","correct":false},{"id":"b4ec634f996fd486030f44e2c5fab630","text":"Classic Load Balancer","correct":false},{"id":"e95e5a2a3cc8625bca3d71b817367e2d","text":"Elastic Load Balancer","correct":false}]},{"id":"e1d6c1bd-4d28-44dd-8c24-f71fe1f7fd56","domain":"CostOptimized","question":"An intern comes to you with a problem. To save time, they had stored some data on an unused data volume of an EC2 instance and stopped the instance for the weekend. When they returned on Monday and restarted the instance, they discovered that the data was gone and what to understand why. What would you suggest? ","explanation":"The most likely answer is that the unused volume on the EC2 instance was an instance-store volume. Instance-store volumes are ephemeral, meaning that they cease to exist if powered off.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html","title":"About Instance Store"}],"answers":[{"id":"31d0851f98c4c0e8a3f49f0559d0b47b","text":"The data volume used was not standard EBS storage.","correct":true},{"id":"88de86ec665e01de2e878cfb4d2ebf45","text":"The instance failed to connect to the volume on Monday.","correct":false},{"id":"18466b20b58938619a41bb378cca740e","text":"The EBS volume was not large enough to store the data.","correct":false},{"id":"3f6c001d39e433b32fe99dcce1515a2e","text":"The EBS volume failed over the weekend.","correct":false}]},{"id":"19b5d27c-16ad-11ea-8d71-362b9e155667","domain":"Performant","question":"You set up a static website for a client using S3. However, upon clicking the website endpoint, you realize that you can’t access the website. What do you have to do to enable access without affecting other buckets and objects in the AWS account?","explanation":"Denied access to S3 object is not a technical problem, so there’s no need to notify AWS Support. Right-clicking the object will not get you on the path to enable website access, and the 'Block public access' setting is not valid in a Bucket Policy. And while you can edit public access through the 'Block public access (account settings)' option, it will affect not just the object you want to access; it will apply to all buckets and objects in the account. Ultimately, you will need to click the S3 object serving the client’s website content, click the Permissions tab, click Edit under 'Block public access', uncheck 'Block all public access', and click Save, so that you can access the website endpoint.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html","title":"Example - Setting Up a Static Website Using a Custom Domain"}],"answers":[{"id":"0d1a711860d50694ee751e52b1c419d4","text":"Click 'Block public access (account settings)', click Permissions in the menu, click Edit, uncheck 'Block all public access' if necessary, and click Save Changes.","correct":false},{"id":"70009581d58fa2c9030c0bf7c14fc4d7","text":"Contact AWS Support by creating a case explaining the problem.","correct":false},{"id":"59bd8c47f35dc26b0f3226441682ff62","text":"Click the S3 object serving the website content, click the Permissions tab, click Edit under 'Block public access', uncheck 'Block all public access', and click Save.","correct":true},{"id":"b32a8996f05ca1f442f0c79df948d47f","text":"Right-click the S3 object serving the website content, click Bucket Policy in the menu, click Edit, ensure 'Block public access' is set to 'false', and click Save.","correct":false}]},{"id":"6cead0b9-9173-420b-bf8b-654f29866336","domain":"ResilientDesign","question":"You host a website running on EC2 instances behind an Application Load Balancer. The instances are in an AutoScaling Group in multiple Availability Zones and deliver many large image files stored on an EFS filesystem. Your company wants to improve the user experience by not serving the files from EC2 instances each time they are requested.  Which of following would help accomplishing this?","explanation":"Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you're serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html","title":"What is Amazon CloudFront?"}],"answers":[{"id":"8acd8869e4a5b95482224171bbd3a519","text":"Resize the files so they are smaller.","correct":false},{"id":"83265438081640b65cfcaf2dad505d41","text":"Move the files to S3 Glacier.","correct":false},{"id":"06fa28fb7c08848c8aa0e87d08fc6597","text":"Cache static content using CloudFront.","correct":true},{"id":"f1d4912f618c2ded05231140b98376d8","text":"Use Reserved EC2 Instances.","correct":false}]},{"id":"e9205ab6-d7ce-4708-b92d-e6814f79c6d4","domain":"ResilientDesign","question":"The dashboard application for multiple company contact centers requires fast update response times for a large number of concurrent users. Call center metric data is stored in an Oracle version 11 database. Which architecture will provide high-availability and the low response times needed for this mission-critical data?","explanation":"Since the dashboard updates are needed across multiple contact centers, leveraging read-only replicated databases will provide fast response times. Amazon RDS doesn’t support read replicas for Oracle version 11, so hosting the database on EC2 and replicating the data with Oracle Data Guard is the only viable solution. AWS Database Replication Service is not an offered service, and using EBS snapshots won't provide real-time replication.","links":[{"url":"https://docs.aws.amazon.com/quickstart/latest/oracle-database/overview.html","title":"Oracle Database on AWS"}],"answers":[{"id":"5ee29b50026caa8c20c9e469f93b5a2a","text":"Oracle hosted on Amazon EC2 in Multiple Availability Zones with EBS snapshots","correct":false},{"id":"de5ad68debdabd478d7d4f66542b9ca8","text":"An Amazon RDS Oracle Instance with AWS Database Replication Service","correct":false},{"id":"c1e824f46134bc6696eba635f30df032","text":"An Amazon RDS Oracle instance with Multi-AZ and Read Replicas","correct":false},{"id":"0129ed97e5c2ec017bdc05d836f10049","text":"Oracle hosted on Amazon EC2 in multiple Availability Zones with Oracle Data Guard replication","correct":true}]},{"id":"05751b9c-f43e-4d4d-baa5-e9351b502b6b","domain":"Performant","question":"You are currently designing a low-latency interactive app that requires an Amazon EBS volume that can support up to 16,000 IOPS. Your Project Manager didn’t mention any consideration to cost; he is only concerned with volume performance. Which of the following EBS volume types could be used to meet the requirements?","explanation":"SSD-backed EBS volumes are much faster than HDD-backed ones, so that automatically rules out the Throughput Optimized HDD and Cold HDD responses. General Purpose SSD is right on the mark with a maximum IOPS of 16,000. If the PM requested that you pick the most cost-effective volume, then General Purpose SSD would be the only answer. Otherwise, you can also go for the Provisioned IOPS SSD, which is the highest-performing EBS volume available with a maximum IOPS of 64,000. Either one of the SSD-backed EBS volumes will do.","links":[{"url":"https://aws.amazon.com/ebs/features/","title":"Amazon EBS Features"}],"answers":[{"id":"c01eb4fc3413d489e9258ff97066ee1d","text":"General Purpose SSD","correct":true},{"id":"43fd7af2adc3101adebb61366bf16df2","text":"Provisioned IOPS SSD","correct":true},{"id":"acdd848c4ecdd949a1afa61eeb675655","text":"Throughput Optimized HDD","correct":false},{"id":"21a9eab81bfbbe0ba71336bf88d5feea","text":"Cold HDD","correct":false}]},{"id":"8c9f0c40-1d4b-4d37-a24a-9996d90c99c9","domain":"Performant","question":"You want to contact AWS Technical Support regarding ensuring enough capacity to autoscale for busy periods.  You remember that you have a Basic Support plan. Which of the following case types can you open with this support plan?","explanation":"There are three types of AWS Support cases you can open; they are Account and Billing Support, Service Limit Increase, and Technical Support. Customer Service does not exist as a case type, which eliminates 'Customer Service'. With the Basic plan, you can open either an Account and Billing Support or a Service Limit Increase case. To open a Technical Support case, you will need to get a Developer, Business, or Enterprise plan. So, 'Technical Support' is the wrong response; 'Account and Billing Support' and 'Service Limit Increase' are correct.","links":[{"url":"https://docs.aws.amazon.com/awssupport/latest/user/getting-started.html","title":"Features of AWS Support Plans"}],"answers":[{"id":"d5552e0564007d93ff5937a9cb3bc491","text":"Customer Service","correct":false},{"id":"fec5f90e9985e1f7b8cc6752739ce9b1","text":"Technical Support","correct":false},{"id":"d073dd2e04eae29e3dd076f213f01fe3","text":"Service Limit Increase","correct":true},{"id":"88d14dddd26c18290989cf3ac6ef6141","text":"Account and Billing Support","correct":true}]},{"id":"fd83d649-3eea-46c9-8062-e4b4eb388a43","domain":"Performant","question":"You are auditing your company's RDS estate, and you discover a database that is in a single Availability Zone which is a violation of company policy. You decide to convert this to a multi-AZ deployment. Which of the following things will happen?","explanation":"For the RDS MySQL, MariaDB, PostgreSQL and Oracle database engines, when you elect to convert your RDS instance from Single-AZ to Multi-AZ, the following happens: A snapshot of your primary instance is taken, A new standby instance is created in a different Availability Zone, from the snapshot, synchronous replication is configured between primary and standby instances.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Migrating","title":"Modifying a DB Instance to be a Multi-AZ Deployment"}],"answers":[{"id":"c9a788a92b58e73582c15e80b4d7dee2","text":"A snapshot of your primary instance is taken","correct":true},{"id":"ff1b29c6f313c53b2104c91355b0287d","text":"Asynchronous replication is configured between primary and standby instances","correct":false},{"id":"9d354995cee95598703a43813f67e277","text":"Synchronous replication is configured between primary and standby instances","correct":true},{"id":"193d090a761f5aa3057dc7b001d51fc9","text":"A new standby instance is created in a different Availability Zone, from the snapshot","correct":true}]},{"id":"1024766e-2157-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"When setting up the properties of an S3 bucket, which of the following options should you select to track storage cost?","explanation":"You need to label your S3 buckets with tags to track their storage costs. AWS will use the tags to organize costs in a cost allocation report. Object-level logging is for using AWS CloudTrail to record object-level API activity, server access logging is for logging requests for access to the bucket, and versioning is for keeping all versions of an object in the same bucket - not for tracking costs.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/CostAllocTagging.html","title":"Using Cost Allocation S3 Bucket Tags"}],"answers":[{"id":"189f63f277cd73395561651753563065","text":"Tags","correct":true},{"id":"f87d839acefa86eff3c90b1b44be4aba","text":"Object-level logging","correct":false},{"id":"30054ccc9b587d53668a89942396874c","text":"Server access logging","correct":false},{"id":"198a30920479d1d8e2509b9b59f3d700","text":"Versioning","correct":false}]},{"id":"c3fd126e-3f97-443d-8aa6-30c582c8f4f0","domain":"Performant","question":"Amazon RDS supports which of the following databases?","explanation":"Amazon RDS currently supports MySQL, MariaDB, PostgreSQL, Oracle, Microsoft SQL Server, and Amazon Aurora database engines.","links":[{"url":"https://aws.amazon.com/rds/","title":"RDS: Supported Engines"}],"answers":[{"id":"7f9733e208088b1ce6df3d4be1765396","text":"MariaDB","correct":true},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":true},{"id":"4e6ac8e997ca8f5896cbc28cad3ede24","text":"Sybase","correct":false},{"id":"c890515f1055143925ae4fb85b86ec70","text":"DB2","correct":false}]},{"id":"c6a3e070-265a-11ea-978f-2e728ce88125","domain":"Performant","question":"An SEO company collects data based on disparate search engine optimization metrics and stores it in a DynamoDB database. The company wants to create an extra copy of the database tables as a form of disaster recovery. Which of the following AWS services can do that?","explanation":"True to its naming, AWS Backup is the service that you can use to back up the DynamoDB database tables. It also works for RDS databases.","links":[{"url":"https://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html","title":"What Is AWS Backup?"}],"answers":[{"id":"ce52d2cff6e50f2e74505e0c70d072b3","text":"AWS Backup","correct":true},{"id":"ce1a41ee0352cee512475ef6a6233963","text":"Amazon Elastic Compute Cloud (EC2)","correct":false},{"id":"df346128c45efa43efc29607224fc716","text":"Amazon Simple Storage Service (S3)","correct":false},{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":false}]},{"id":"8d478f70-2e57-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"Your company wants the on-premises network of its nearby branch office to securely connect with the instances launched into the Amazon virtual private cloud (VPC) environment of its headquarters. Which of the following proposed solutions is the correct one?","explanation":"To establish a secure connection between the company’s branch office and the Amazon VPC of its headquarters, you will need to create a site-to-site VPN. This process includes creating a customer gateway for the branch office and a virtual private gateway for the headquarters, so responses A and C only provide part of the answer. Although you can establish a connection with AWS Direct Connect, the connection depends on the headquarters being a Direct Connect location for it to work.","links":[{"url":"https://docs.aws.amazon.com/vpn/latest/s2svpn/how_it_works.html","title":"What is AWS Site-to-Site VPN?"}],"answers":[{"id":"db905221240144105178d58376e68624","text":"Create a virtual private gateway and attach it to the headquarters VPC.","correct":false},{"id":"1c83b0f1e61bd1a6e279dfd7f53aa406","text":"Create an AWS site-to-site VPN connection","correct":true},{"id":"6fc0482bf91e864524eeb8b99b8b1df9","text":"Create a virtual private gateway and a customer gateway and attach them to the headquarters VPC and the branch office on-premises network, respectively.","correct":false},{"id":"572a700c620a728ee9f12b0d7d4601fc","text":"Use AWS Direct Connect to create a connection.","correct":false}]},{"id":"bce7cb5d-687e-4e77-a516-1cde22e6f4e8","domain":"Performant","question":"How quickly can objects be restored from Glacier?","explanation":"You can expect most restore jobs initiated via the Amazon S3 APIs or Management Console to complete in 3-5 hours. Expedited restore is available at a price. ","links":[{"url":"https://aws.amazon.com/glacier/faqs/#dataretrievals","title":"Retrieving Data From Glacier"}],"answers":[{"id":"0d714869027c4e08ea9b2943d9bd704e","text":"30 minutes","correct":false},{"id":"99d888e6893ac480abd21ecb8a18e060","text":"3-5 hours","correct":true},{"id":"72ab9d0304d3e84c6aa2dd15eda282f2","text":"1 hour","correct":false},{"id":"6619a70f8ab8877e4131643fb8ded723","text":"2 hours","correct":false}]},{"id":"3252d84d-08d9-4bde-a8e7-d716502d1855","domain":"Performant","question":"You have a very heavily-trafficked WordPress blog that has approximately 95% read traffic and 5% write traffic. You notice that the blog is getting slower and slower. You discover that the bottleneck is in your RDS instance. Which of the following answers can improve your WordPress blog's performance?","explanation":"You should use a combination of Read Replicas and ElastiCache to help offload the traffic.","links":[{"url":"https://aws.amazon.com/elasticache/","title":"About ElastiCache"}],"answers":[{"id":"1af32ee0c62b109e45b92828dbc33f2d","text":"Create a secondary Multi-AZ database and run the queries off the secondary Multi-AZ database.","correct":false},{"id":"e94a05a7348f87c7b9c4f7036d632a9c","text":"Use ElastiCache to cache the most commonly read posts of your WordPress blog.","correct":true},{"id":"fdc556bb3ab9b5da3b290c181aaefb3c","text":"Create a number of read replicas and update the connection string on your EC2 instances so that traffic is evenly shared amongst these new RDS instances.","correct":true},{"id":"1c551a09129057627b3b75fb70e6f527","text":"Export the database to DynamoDB which has push button scalability.","correct":false}]},{"id":"18196faa-35f6-4a0b-b91b-c62326bbd9bf","domain":"CostOptimized","question":"A team is designing the architecture for a new application with full CI/CD testing.  They want to implement feature branch testing based on pull requests to master.  A Pull Request should cause a full deployment to be run on that feature branch being pulled so that a tester can run through functional tests.  What would you recommend the team does to automate this process at the lowest cost?","explanation":"CloudFormation allows AWS to automatically deploy the infrastructure required to deploy the application for testing.  The infrastructure code can be stored alongside application code to allow the application to be deployed in a fully-isolated infrastructure which can be destroyed once integration testing is complete.  CloudWatch Events (and not CloudTrail) enables pull request events to trigger a deployment.  Finally Amazon EC2 Spot Fleet allow us to deploy a set of EC2 instances at the lowest cost. Reserved Instances are better-suited to pre-purchasing compute capacity which you will use for a fixed period of time - it is not cost-effective to pre-purchase EC2 capacity just to perform integration testing.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html","title":"How Spot Fleet Works"},{"url":"https://ec2spotworkshops.com/amazon-ec2-spot-cicd-workshop.html","title":"CI/CD and Test Workloads with EC2 Spot Instances"}],"answers":[{"id":"254cbe0fa6a5e0b25dd7841402f05e7e","text":"Use Amazon EC2 Spot Fleet and Amazon CloudFormation to deploy an integration testing environment at lowest cost","correct":true},{"id":"cb82b20f57a6882ec563593d14dfb01b","text":"Configure AWS CloudTrail to log pull request events and trigger a deployment","correct":false},{"id":"e4f3730b2899903ad8a6c27eb2693ff2","text":"Configure CloudWatch Events to trigger a deployment based on pull requests","correct":true},{"id":"9d9cce9ec8f58e568222274098cf9b08","text":"Use Amazon EC2 Reserved Instance and Amazon CloudFormation to deploy a testing environment at lowest cost","correct":false}]},{"id":"2403cf92-cd58-4ade-8a82-52be2b2a6b5b","domain":"SecureSolutions","question":"Your Security team is concerned about a recent spate of large-scale DDoS attacks on other providers in your industry. You have a number of internet-exposed services in your business, and any potential outage has significant financial impact. The security team wants to be informed of any attack as it happens, and would like some assistance from AWS to help mitigate an attack should one happen. You currently have WAF deployed, and an Enterprise support agreement in place, but which of the below extra steps would you recommend","explanation":"AWS Shield Standard does not include notification of any attacks detected, therefore can be eliminated straight away. Although WAF can be used during a DDoS attack to help mitigate the attack with custom block rules, there are no in-built DDoS protections with WAF as these are provided by Shield. AWS has a dedicated DDoS Response Team (DRT) to assist during any DDoS attacks - however in order to access them, you need to be on an Enterprise or Business support agreement, and relevant to this scenario, have purchased Shield Advanced. This combined with the alerting of attacks that is available with Shield Advanced make purchasing Shield Advanced the most appropriate choice. ","links":[{"url":"https://aws.amazon.com/shield/getting-started/","title":"Getting Started with AWS Shield"},{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-overview.html#ddos-drt","title":"How AWS Shield Works"}],"answers":[{"id":"b8ede9969b12d6122fcef9029ff00b52","text":"By default all AWS services are automatically protected against DDoS attacks by AWS Shield - nothing extra needs to be done. During an attack lodge a support request using your Enterprise support agreement for assistance","correct":false},{"id":"6afd0c59a36c013760fbb187d8bbb415","text":"Purchase AWS Shield Advanced, and during an attack lodge a support request asking for assistance from AWS","correct":true},{"id":"191789dacb98c2ed977f4a62437a00af","text":"Enable the inbuilt AWS WAF DDoS protections, use SNS to notify when an attack is detected. During an attack lodge a support request using your Enterprise support agreement for assistance","correct":false},{"id":"b41f4d516374b164d0a2c054a39dfe3f","text":"Enable rate limiting on your load balancers, and during an attack lodge a support request using your Enterprise support agreement for assistance","correct":false}]},{"id":"ccdbbdf9-e9b6-4255-bed7-4e5f65b8c940","domain":"SecureSolutions","question":"You are deploying an application on to EC2 instances. The application must make AWS API calls. What is the most secure method to pass credentials to the application?","explanation":"You can use roles to delegate access to users, applications, or services that don't normally have access to your AWS resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html","title":"IAM Roles"}],"answers":[{"id":"59bdef2986f5b1db72e3113469a3f6d6","text":"Store the API credentials as an object in S3.","correct":false},{"id":"98e2209690b12719fd4018b9176c77a9","text":"Assign an IAM role to the EC2 instances.","correct":true},{"id":"431d737549954a94c084b6c8532b8670","text":"Embed the API credentials in the application.","correct":false},{"id":"4fe6cac2e87dc307c93a2b029e6ae5dc","text":"Pass API credentials to the instance using userdata.","correct":false}]},{"id":"7dafc126-8f93-4ac8-97ba-01818de79dc1","domain":"SecureSolutions","question":"As a junior Cloud Engineer, you receive a CloudWatch alarm indicating that there might be a layer 7 attack of your environment. You recall that your company has an AWS Shield Advanced subscription. Which of the following options is the best response?","explanation":"You *can* investigate and mitigate the DDoS attack on your own, so that is a potentially correct answer. Similarly, requesting internal assistance is another possible answer because of your tech lead’s expertise. However, the best course of action is to take advantage of your AWS Shield Advanced subscription, which routes you to true DDoS experts. In this case the *most correct* answer is to work with AWS Support. Doing nothing should never be considered as an answer.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-responding.html","title":"Responding to DDoS Attacks"}],"answers":[{"id":"43d522d2e9a722af4df45616e09e2ff4","text":"Contact AWS Support Center.","correct":true},{"id":"b62d821db1c6397935c957ddd8214d47","text":"Request assistance from tech lead.","correct":false},{"id":"e13ab7a7dcc291aa8a8f5e4e1c3a8646","text":"Do nothing; it is an AWS issue that will resolve itself.","correct":false},{"id":"0b9ac6496fca4f50d60b7665f91d9209","text":"Investigate and mitigate the attack on your own.","correct":false}]},{"id":"4dbb13ea-c707-4846-9f49-584095a20625","domain":"ResilientDesign","question":"You are investigating a performance issue on a MYSQL RDS database and discover that there is only a single DB instance in a single Availability Zone for this database. This goes against your organisation's availability requirements, which specify that the application must automatically remain available during AZ outages and with minimal interruption. This needs to be addressed, along with the performance issue. How would you go about resolving this, while keeping cost to a minimum?","explanation":"When in a Multi-AZ configuration, the secondary database instance is not \"active\" and cannot be read from or written to by clients. This rules out using the secondary instance to address the performance issue. Putting a read replica in a different AZ can help with redundancy, however the read replica will need to be promoted manually in case of a disaster, resulting downtime while this takes place. As this scenario requires that there is minimal interruption to service in case of a AZ outage, any answer using the Read Replica for availability can be discounted. This leaves using a Multi-AZ configuration with a Read Replica as the only valid option.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"Amazon RDS Multi-AZ Deployments"},{"url":"https://aws.amazon.com/blogs/aws/amazon-rds-for-mysql-promote-read-replica/","title":"Amazon RDS for MySQL – Promote Read Replica"}],"answers":[{"id":"43a8b1df93731fc791a9c59882df77b7","text":"Modify the database to be Multi-AZ to address the availability requirement. This will also address the performance issue as there will now be 2 instances for reads and writes.","correct":false},{"id":"9a2f983568edc620fc3719d40f9ea028","text":"Modify the database to be Multi-AZ to address the availability requirement, and deploy a read replica to improve performance","correct":true},{"id":"92df2c8707d1018172156f0e95fd5b26","text":"Deploy a Read Replica for the database into a different AZ to address the availability requirement. Create another read replica in primary zone to improve performance.","correct":false},{"id":"ebda44f0999233da222783fb1a8079dc","text":"Deploy a Read Replica for the database into a different AZ. This will address the performance issue, and can be used in case of a AZ outage","correct":false}]},{"id":"15025340-2278-430c-befc-70d80f9a2544","domain":"ResilientDesign","question":"Your company stores confidential data in S3. To comply with regulations, the data needs to be made available in a different geographical location. What steps would you take to be within compliance?","explanation":"This is a specific use case for S3 Cross-Region Replication. Comply with compliance requirements—Although Amazon S3 stores your data across multiple geographically distant Availability Zones by default, compliance requirements might dictate that you store data at even greater distances. Cross-region replication allows you to replicate data between distant AWS Regions to satisfy these requirements.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html#crr-scenario","title":"Cross-Region Replication - When to Use CRR"}],"answers":[{"id":"62515dd9616b3f1afcfdc0686d8a5759","text":"Apply Multi-AZ for the S3 bucket.","correct":false},{"id":"866cffef4a3a5d96498ba8d57616d6f4","text":"Enable Cross-Region Replication for the S3 bucket.","correct":true},{"id":"7ec7b008897371370d957669d36a1956","text":"Create a snapshot of the S3 bucket and copy it to another region.","correct":false},{"id":"26b572d8c2fcaa2928ad8d9c685b0f4e","text":"Copy the data to an EBS volume in another region.","correct":false}]},{"id":"2a2db64e-2e02-11ea-978f-2e728ce88125","domain":"CostOptimized","question":"You wish to set up a WordPress website consisting of 4 webpages for your client, who recently founded a logo creation business. Based on the client’s specifications, you will create one webpage that gives a summary of the company and its services, a second one that provides a brief professional biography of the founder, a third one that showcases the business owner’s portfolio, and a fourth one that serves as the contact information page and simply contains an email and phone number. Three of the four webpages will include images which the client doesn’t expect will change much, if at all. Using the EC2 service to set up the website, which of the following instance types would be the most cost-effective choice?","explanation":"Based on the client’s specifications, it doesn’t seem like this website requires an elevated level of compute, memory, storage, or networking power. So, a general purpose instance would be the most cost-effective choice.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types"}],"answers":[{"id":"b4820282379b9534539d339e1d898f2b","text":"Storage optimized","correct":false},{"id":"4e8e31d149d66214d0c06fd9ee8b877b","text":"Compute optimized","correct":false},{"id":"e65781ecdb4e2c3e7af2864d7b875e57","text":"Accelerated computing","correct":false},{"id":"3da02f3f7a678b5e2c167fb35dcea8f5","text":"General purpose","correct":true},{"id":"a97bdc2a34beb1500a16c5a5f41d3234","text":"Memory optimized","correct":false}]},{"id":"15c91139-c33f-4583-8864-dba8207c73a0","domain":"Performant","question":"Your organisation is running a business critical application with a backend MySQL DB that has been experiencing performance issues due to an increase in customers hitting the website. Management are concerned that the existing solution will not handle the anticipated customer growth over the next 12 months and any outages could lead to a loss in potential revenue.\\n You’ve been asked to develop a suitable AWS cloud based solution that will best meet the requirements of the organisation and require minimal operational overhead. Which AWS DB service will be most suitable for your organisation?","explanation":"Aurora natively maintains 2 copies of your data in each availability zone (3 AZs x 2 = 6 copies) within a region providing the highly available solution needed for this scenario. It also supports storage autoscaling and CPU and Memory scaling. Aurora also provides up to 5 times improved performance over a traditional DB installation.  MySQL and PostgreSQL support multi-AZ deployments and read replicas, but this requires additional configuration. CPU, memory and storage scaling is not automated and requires additional configuration and design consideration. Redshift does not support Multi-AZ deployments.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_AuroraOverview.html","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/","title":"Amazon Aurora FAQs"}],"answers":[{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":false},{"id":"f52a9d91766886fb3a524dd06d1581cb","text":"Redshift","correct":false},{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":true},{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":false}]},{"id":"c2e05533-6321-46fa-a778-47c27ca274d5","domain":"CostOptimized","question":"Your co-worker is about to create a new EC2 instance, and would like to know from what point your company will be billed for it. You tell them that it will be billed from: ","explanation":"In EC2, Instance-hours are  billed only for time your instance is in the \"Running\" state.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-instance-hour-billing/","title":"Instance-Hour Billing"}],"answers":[{"id":"92f171915935cf43d7367038a0ceb076","text":"When it is in the \"Pending\" state","correct":false},{"id":"61b5406c1efb94f47d6a875a56ac05c4","text":"When it is in the \"Stopped\" state","correct":false},{"id":"c40f2931153694959f22d5efc95b2a45","text":"When it is in the \"Running\" state","correct":true},{"id":"6672e2e78662b895923af9d5f73207be","text":"When it is in the \"Provisioned\" state","correct":false}]},{"id":"6360570c-c801-4b78-a0ba-7860817cb309","domain":"ResilientDesign","question":"You have a busy media website that runs on a fleet of EC2 instances behind an application load balancer. You have a number of different target groups for different purposes. One of these target groups is a fleet of EC2 instances which contains the images for your website. When ever a user visits www.yoursite.com/images/ you need your application load balancer to direct the request to the images target group. How do you configure this rule on your application load balancer?","explanation":"One of the major benefits of teh ALB is that it supports 'path-based' routing which allows you to direct the traffic based on the content of the URL path.  In this case /images/ can be directed to a specific target group.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-update-rules.html","title":"ALB Listener Rules"},{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html","title":"What Is an Application Load Balancer?"}],"answers":[{"id":"5a3ddbcafc8cd528ecdb152c181daba6","text":"Using Path Patterns.","correct":true},{"id":"4d15809e9acf1ee9617c2e118157323e","text":"Using Query String Parameters.","correct":false},{"id":"002f909cd633d40a7e860e8793272fe4","text":"Using Cross Zone Load Balancing.","correct":false},{"id":"86e943f32a460169646a1a9a54de8934","text":"Using Sticky Sessions.","correct":false}]},{"id":"536131e1-bbd8-4ef5-b765-4bd089487b28","domain":"Performant","question":"Your on-premise servers are running low on disk storage space, but your company is not yet ready for a complete move to the public cloud. You've been tasked with finding an interim storage solution that also offers backup and archiving capabilities. Which AWS service would you recommend to meet this immediate need?","explanation":"Storage Gateway is a storage solution that provides on-premise capacity while taking advantage of some of the benefits of Cloud Storage.","links":[{"url":"https://docs.aws.amazon.com/storagegateway/latest/userguide/StorageGatewayConcepts.html#storage-gateway-cached-concepts","title":"Gateway-Cached Volumes Architecture"}],"answers":[{"id":"759533f205f8af35f7da47dc76331eee","text":"Storage Gateway with Gateway-Stored Volumes.","correct":false},{"id":"cdd0d04de2b79c78e792aec6263d2d3d","text":"DirectConnect","correct":false},{"id":"c0429b6a658dd488f7262d983c7e02bb","text":"Snowball","correct":false},{"id":"04567b32a7bb8490dda99a0fe4c3323a","text":"Storage Gateway with Gateway-Cached Volumes","correct":true}]},{"id":"ef035801-88e3-43c1-84ee-acc1076f8838","domain":"SecureSolutions","question":"Your company e-commerce website provides the option to store payment information for convenience when a customer returns to the site for future purchases. Your database administrators require that database tables be normalized to reduce data redundancy and dependency. Which architecture will provide the most secure solution for accessing the payment information?","explanation":"Amazon RDS is the database solution of choice due to the requirement for schema normalization. Placing the database in a private subnet is the most secure solution, with access locked down by a Security Group firewall. NAT Gateways do not provide connectivity from public subnets to private subnets. Encrypting the data is good, but a database with sensitive information should not be placed in a public subnet.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Tutorials.WebServerDB.CreateVPC.html","title":"Create an Amazon VPC for use with a DB Instance"}],"answers":[{"id":"4f89232600cf80506db22ffd586a7fb5","text":"Place an Amazon RDS database in a private subnet and use a NAT Gateway to access the data from the e-commerce application in a public subnet","correct":false},{"id":"e5f5364acc546560f891e7154abfd25e","text":"Place an Amazon RDS database in a private subnet and use a Security Group to limit access to the e-commerce application in a public subnet","correct":true},{"id":"8d8c6acff5b1dc2f04216d24bdec299f","text":"Place an Amazon DynamoDB database in a private subnet and use Security Groups to limit access to the e-commerce application in a public subnet","correct":false},{"id":"497d53830d4dafbb63cce38d18876f21","text":"Place an Amazon RDS database in a public subnet and encrypt the data with Transparent Data Encryption","correct":false}]},{"id":"ce84785e-7010-4243-99f8-3a1ab7d43e31","domain":"ResilientDesign","question":"You work for a cosmetic company which has their production website on AWS. The site itself is in a two-tier configuration with web servers in the front end and database servers at the back end. The site uses using Elastic Load Balancing and Auto Scaling. The databases maintain consistency by replicating changes to each other as and when they occur. This requires the databases to have extremely low latency. Your website needs to be highly redundant and must be designed so that if one availability zone goes offline and Auto Scaling cannot launch new instances in the remaining Availability Zones, the site will not go offline. How can the current architecture be enhanced to ensure this?","explanation":"Deploy your site in three different AZs within the same region. Configure the Auto Scaling minimum to handle 50 percent of the peak load per zone. So, if one AZ goes down, the two remaining AZs can each accommodate 50% of your traffic, giving you 100% coverage.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/latest/userguide/as-register-lbs-with-asg.html","title":"How To Set Up a Scaled and Load-Balanced Application"}],"answers":[{"id":"1dd3aa163155f9eafe380ab0c55794fe","text":"Deploy your website in 2 different regions. Configure Route53 with Weighted Routing. Assign a weight of 25% to region 1 and a weight of 75% to region 2.","correct":false},{"id":"0dfa307c14f360c0a222400c5eecda8d","text":"Deploy your website in 2 different regions. Configure Route53 with a failover routing policy, and set up health checks on the primary site.","correct":false},{"id":"311b1d3a4668bfd8843e4d5dac1e52d5","text":"Deploy your site in three different AZs within the same region. Configure the Auto Scaling minimum to handle 33 percent of the peak load per zone.","correct":false},{"id":"89990e4ab47ac0e1aa67ae395fa51530","text":"Deploy your site in three different AZs within the same region. Configure the Auto Scaling minimum to handle 50 percent of the peak load per zone.","correct":true}]},{"id":"8dea5b5e-453e-4dda-883d-e390d14a8c83","domain":"ResilientDesign","question":"You have chosen to use S3-RRS with your cloud application. Which limitations have you considered in doing so?","explanation":"The use of RRS is being phased out. In exchange for a significant cost savings, RRS offers only 99.99% durability.","links":[{"url":"https://aws.amazon.com/s3/reduced-redundancy/","title":"About S3-RRS"}],"answers":[{"id":"83091b498f26985700b51b43e93fb462","text":"RRS requires supplementary Access Control Lists.","correct":false},{"id":"da6d1d0f493d75bccd625f920a3b8b35","text":"RRS offers only 99.99% durability, so you have to design your application to re-create any objects that may be lost.","correct":true},{"id":"7ae25c780e69aeb7ac28e7b25b79873f","text":"RRS is not recommended for new projects in some AWS regions.","correct":true},{"id":"7e2b64603db15867a5b488818ec6d9f3","text":"RRS has a 4-hour data recovery time.","correct":false},{"id":"07f7d94a1360ae1987207ba589182e55","text":"RRS  is available only in the US-STANDARD region.","correct":false}]},{"id":"f11b087b-c82c-479f-aae3-d8937d5b3dee","domain":"ResilientDesign","question":"Following an acquisition, a company on-boarded a large number of IAM users into their account. What service will allow the account administrator to check if the company is approaching allowed IAM user service limit?","explanation":"AWS Trusted Advisor provides a service limits recommendation category that performs checks for service usage limits. Number of IAM users is one of the service limit checks performed by AWS Trusted Advisor.","links":[{"url":"https://aws.amazon.com/premiumsupport/technology/trusted-advisor/best-practice-checklist/","title":"AWS Trusted Advisor Best Practice Checks"}],"answers":[{"id":"85c0418befdeed397590cda97cf6d876","text":"AWS Managed Services","correct":false},{"id":"d189bb1b260dc3da48b6e6f5e1ec6879","text":"AWS Personal Health Dashboard","correct":false},{"id":"113b1ad9ce6cdc3a37ad8475bc9bb2b2","text":"AWS Systems Manager","correct":false},{"id":"526775c1622cd0e7b703eb8d4a83d657","text":"AWS Service Catalog","correct":false},{"id":"05f43441d2d29ae2bb38fc8596ca6ff7","text":"AWS Trusted Advisor","correct":true}]},{"id":"8fb0e794-243d-11ea-978f-2e728ce88125","domain":"Performant","question":"You work as a Cloud Engineer for a healthcare company that would like to archive patients’ records after 30 days. In addition, the company wants the records to be accessible from the archive within 12 hours. Which of the following storage services will fulfill this company’s requirements?","explanation":"Although Response B would have been the correct answer, this question demands the answer to be more specific. S3 Glacier is the S3 storage class that you need to archive the records. Storage Gateway is for connecting an on-premises software appliance with cloud-based storage to the company’s AWS storage infrastructure, which can include S3. And Amazon EFS is ideal for providing simple, scalable file storage – not data archival.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"Amazon S3 Storage Classes"}],"answers":[{"id":"5ba49687f2f5ade4cd1c756a7e9024e3","text":"AWS Storage Gateway","correct":false},{"id":"cb30b70cc5c8955781b75b49f1e20fe0","text":"Amazon Elastic File Service (EFS)","correct":false},{"id":"df346128c45efa43efc29607224fc716","text":"Amazon Simple Storage Service (S3)","correct":false},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":true}]},{"id":"1ea8aa1e-9454-49b0-b4e2-379eadf674e0","domain":"CostOptimized","question":"You are an employee at a communications firm that is in the process of migrating its data to Amazon S3. The data will be stored in buckets and is sent to customers to do as they see fit. However, certain data is frequently changed when customers request revisions, while the rest of the data is rarely changed. You must be able to immediately access certain data while minimizing costs. Which S3 storage class should you choose?","explanation":"While S3 Glacier is a low-cost storage class, it is for data archiving and thus not ideal for frequent access or changes to data. And S3 One Zone-Infrequent Access is also low-cost, but it does not address the frequently changed data. Although S3 Standard is a suitable choice, since it addresses frequent access, it is not the least expensive choice for the less frequently accessed data. If it was hard to determine which data is frequently changed and which isn’t, S3 Standard might have been the most cost-effective choice. But in this case, S3 Intelligent Tiering is. Intelligent Tiering stores data in two access tiers: one tier is optimized for frequently accessed data while the other is a lower-cost tier for infrequent access.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"5605213ade8877d8d601580dbd0a8aa2","text":"S3 One Zone-Infrequent Access","correct":false},{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":true}]},{"id":"5dcee06e-bd95-4dfd-8540-5c54ae7c5fd3","domain":"SecureSolutions","question":"Your application stores your customers' sensitive passport information in S3. You are required by law to encrypt all data at rest. Company policy states that you must maintain control of your encryption keys. For ease of management, however, you do not want to implement or maintain a client-side encryption library. Which S3 encryption option should you use to secure your data at rest?","explanation":"Use SSE-C (C ≈ customer controlled) if you want to maintain your own encryption keys, but don’t want to implement or leverage a client-side encryption library.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html","title":"S3 - SSE-C"}],"answers":[{"id":"472035b16201f5505380c16ec3eb8518","text":"SSE-C","correct":true},{"id":"1562bb9d2d9567740605dcb1ccab5c80","text":"SSE-S3","correct":false},{"id":"e17194408dc439e1658a544965724d44","text":"SSE-KMS","correct":false},{"id":"bac271f02854883c6bc665637d0a5de6","text":"Amazon S3 Encryption Client","correct":false}]},{"id":"6d368e1f-484b-4536-91ec-6055d5916c49","domain":"Performant","question":"You have developed a file-sharing website for a large corporate entity. They require that the site to be protected from a regional failure. Which S3 service should you use to achieve this? ","explanation":"S3 with Cross-Region Replication automatically replicates data across AWS regions. With CRR, every object uploaded to an S3 bucket is automatically replicated to a destination bucket in a different AWS region that you choose.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html","title":"S3 - Cross-Region Replication"},{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr-what-is-isnot-replicated.html","title":"S3 - Replication guidelines"}],"answers":[{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false},{"id":"73d38a622e5878dd1ecfb83678260bd5","text":"S3 - Cross-Region Replication","correct":true},{"id":"5bd8bda263020cb57b990acb7d5d7218","text":"S3 - RRS with Data Pipeline to DynamoDB","correct":false},{"id":"431cc9c5e56b3f9120509ea377024fbc","text":"Configure S3 to trigger a Lambda function, which will take an object uploaded to S3 and automatically replicate it to an EBS volume.","correct":false}]},{"id":"22315d49-9040-4de7-ae4f-ead04e5b4966","domain":"CostOptimized","question":"An application that performs statistical analysis on weather data receives files once a week. It assimilates the data in these files with previously collected data via its algorithms, and publishes a report at the end of each month. At unspecified times during the week, interim results need to be made available to meteorologists within minutes. Which architecture will meet the data availability requirements for the solution at the least cost, and with the simplest application code?","explanation":"Hibernating an EC2 instance provides a warm-start capability. When an EC2 instance is hibernated, RAM contents are saved to the EBS root volume. RAM contents are reloaded when the instance is restarted. AWS doesn't charge for the time that an instance is in the hibernated state. Storing data in Amazon DynamoDB costs more than EBS. EMR clusters cost more than EC2 instances. Stopping an EC2 instance clears RAM and requires the application to reload the data from a storage source when the instance is restarted.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html","title":"Hibernate Your Instance"}],"answers":[{"id":"79010e5d6c3a7a1b4739890ce79939bd","text":"Process the data on EC2 and store temporary results in Amazon DynamoDB","correct":false},{"id":"1270950fb1ac5049d96bd1c8633745fe","text":"Process the data on EC2 and stop the instance until new data files arrive or an interim results request is made","correct":false},{"id":"591c99dbc7dc2331d09abbc9ee1fb721","text":"Process the data on EC2 and hibernate the instance until new data files arrive or an interim results request is made","correct":true},{"id":"e45f5352867fe69bdbc5efaad38e34b2","text":"Process the data on a transient EMR cluster and store temporary results in S3","correct":false}]},{"id":"1d1dbcc0-0758-4d2c-9427-3bf66dd7edd4","domain":"ResilientDesign","question":"What is the minimum size of an S3 object?","explanation":"An empty file (often, a file that has been 'touched') is allowed. As such, the answer is 0 bytes.","links":[{"url":"https://aws.amazon.com/s3/faqs/","title":"How Much Data Can I Store?"}],"answers":[{"id":"bf361755334066f22d019854dd2be686","text":"1 KB","correct":false},{"id":"007d6e976f21cb9b19203ab0a84e7b3d","text":"1 bit","correct":false},{"id":"ca4a3b82feeaa8b9a19da4cc4f508199","text":"0 bytes","correct":true},{"id":"9066c4d254b4c8ab67e107a1b59e925d","text":"1 byte","correct":false}]},{"id":"e74fe976-5239-428f-a289-a171092a22e5","domain":"CostOptimized","question":"The volume of transactions coming into your online trading application fluctuates each day depending on market events. Log analyses indicate that on the heaviest volume days, compute demand comes in triple that of the average volume days. These heavy volume days occur about 15 days per year. You also have some workloads that need to process before close of business to provide input to daily reporting functions. How would you structure your mix of EC2 General Purpose Linux instances to obtain the highest cost efficiency?","explanation":"The most cost effective pricing for EC2 General Purpose Linux instances will usually involve a mix of pricing models. In this scenario, since the number of heavy volume days is limited, using a combination of reserved instances sized for the average volume days, on-demand instances to handle transaction volume increases on the heavy volume days, and spot instances to handle workloads that just need to complete by a certain time is the best option.  Spot instances for reporting workloads will cost less than using reserved instances and capacity doesn't need to be guaranteed. 3-year reserved instances are more cost-effective than one-year-term reserved instances. Over-provisioning for all but the 15 heavy volume days each year by using RI to cover heaviest load leaves a lot of underutilised capacity.","links":[{"url":"https://aws.amazon.com/ec2/pricing/","title":"Amazon EC2 Pricing"}],"answers":[{"id":"03f9a4a0692a0ea73ab4d51403b45abb","text":"1-Year Term Standard Reserved Instances for 100% of the average and heavy volume days, and Spot Instances to handle the reporting workloads","correct":false},{"id":"e1376165009a434d36a5271305c1773a","text":"3-Year Term Standard Reserved Instances for 100% of the average and heavy volume days, and the reporting workloads","correct":false},{"id":"e4422c9ca1969401387bc4262b9cc0a7","text":"3-Year Term Standard Reserved Instances for 100% of the average volume days and the reporting workloads, On-Demand instances to handle the spikes from the heavy volume days","correct":false},{"id":"b9561b6540a0f9ae99dee0f11fb11d69","text":"3-Year Term Standard Reserved Instances for 100% of the average volume days, On-Demand instances to handle the spikes from the heavy volume days, and Spot Instances to handle the reporting workloads","correct":true}]},{"id":"d3a69a14-8fa0-4820-80ed-04f386b437a1","domain":"ResilientDesign","question":"You are reviewing your colleagues' AWS infrastructure design to handle large distributed and replicated workloads - in this case for a Cassandra non-relational database cluster with many nodes spanning multiple AZs in the same region. It specifies the placement of instances into partitions so that these do not share underlying hardware to reduce the likelihood of correlated failures. Which of the following statements about that is incorrect?","explanation":"A cluster placement group can't span multiple Availability Zones, and a spread placement group cannot use dedicated instances or dedicated hosts. (note that you are looking for 'incorrect' answers)","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"Placement Groups"},{"url":"https://aws.amazon.com/about-aws/whats-new/2018/12/amazon-ec2-ntroduces-partition-placement-groups/","title":"AWS - Partition Placement Groups announcement "}],"answers":[{"id":"7f6572c063647af090c784d97c4ee2bc","text":"Because you have more than 7 running instances per Availability Zone per group, you cannot use a spread placement group.","correct":false},{"id":"bb7339e9c120b35a0f218339b10e34dc","text":"The number of instances that you can launch in a partition placement group is limited only by your account limits but also a partition placement group supports a maximum of 7 partitions per Availability Zone.","correct":false},{"id":"3c7b4f245217b06cc9768cf64221e10e","text":"You can best achieve this with a combination of a spread placement group and dedicated hosts.","correct":true},{"id":"2d1c087097dd168b43a0b9dfa2a961c6","text":"A partition placement group with Dedicated Instances can have a maximum of two partitions while partition placement groups for Dedicated Hosts are not supported.","correct":false},{"id":"f6d473e88ac8ee3505d59f8787d8e9f5","text":"You can best achieve this with the use of a cluster placement group.","correct":true}]},{"id":"6ff5a65b-eaf6-440a-b652-a87cda695ee7","domain":"ResilientDesign","question":"Which of the following is NOT a valid EC2 instance type?","explanation":"D2, C4, M3 are all valid EC2 instances.","links":[{"url":"https://aws.amazon.com/ec2/instance-types/","title":"EC2 Instance Types - Overview"}],"answers":[{"id":"c4d62b6dcca08e5caf06c01889282859","text":"D2","correct":false},{"id":"b713e6323a68d3ddabf4855826c50148","text":"C4","correct":false},{"id":"f1c6eb6f4e48eb34ab40b2987d4976a8","text":"M3","correct":false},{"id":"10cabbedf836057c57d03730b32c6fa5","text":"Z2","correct":true}]},{"id":"264e918f-a0f1-4013-8873-1fafcbd2e3c2","domain":"SecureSolutions","question":"Your company’s Technical Writer needs to know all the Internet protocols that Amazon Route 53 uses to perform health checks. Which of the following are the protocols?","explanation":"AWS offers three protocol choices to use to perform Route 53 health checks. They are HTTP and HTTPS, which operate at the application layer; and TCP, which operates at the transport layer. IMAP is an application-layer protocol that is not offered as a choice when configuring the health check.","links":[{"url":" https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/welcome-health-checks.html","title":"How Amazon Route 53 Checks the Health of Your Resources"}],"answers":[{"id":"0b787be1ef17df10d26758673ae24325","text":"IMAP","correct":false},{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":true},{"id":"b136ef5f6a01d816991fe3cf7a6ac763","text":"TCP","correct":true},{"id":"293c9ea246ff9985dc6f62a650f78986","text":"HTTP","correct":true}]},{"id":"bc814aa4-03e8-4a64-aa0e-84f22d812a95","domain":"SecureSolutions","question":"Which of the following DNS record types does Route 53 not support?","explanation":"Route 53 is a scalable and highly available DNS service and it currently supports 13 different DNS record types including; AAAA, CNAME and SPF.  However, Route 53 does not support DNSSEC (other than during domain registration) and therefore any DNSSEC related records, such as DNSKEY, are also not supported.","links":[{"url":"https://aws.amazon.com/route53/faqs/","title":"Amazon Route 53 FAQs"}],"answers":[{"id":"548deb43a9afe4abcde34a605eb44700","text":"DNSKEY","correct":true},{"id":"b4efb35349e5d93905531be07dbacd6d","text":"SPF","correct":false},{"id":"adc4bfdb0829dae99e3699393e3fbaa4","text":"CNAME","correct":false},{"id":"098890dde069e9abad63f19a0d9e1f32","text":"AAAA","correct":false}]},{"id":"126e898c-dd73-4447-b5a7-59701a16a92d","domain":"ResilientDesign","question":"You are reviewing Change Control requests and you note that there is a proposed change designed to reduce errors due to S3 Eventual Consistency by updating the 'DelaySeconds' attribute. What does this mean?","explanation":"Poor timing of SQS processes can significantly impact the cost effectiveness of the solution.","links":[{"url":"http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"}],"answers":[{"id":"464400e5333b3beab1128b1b1f7cedf7","text":"While processing a message, a consumer instance can amend the message visibility counter by a fixed amount.","correct":false},{"id":"4b46d6ad9dd090f0143cc40fecbad7b5","text":"When a new message is added to the SQS queue, it will be hidden from consumer instances for a fixed period.","correct":true},{"id":"f170b98804f18cb00b57e135f0a3f116","text":"When the consumer instance polls for new work, the consumer instance will wait a certain time until it has a full workload before closing the connection.","correct":false},{"id":"6e5b2857717c8cf5b2722dc270183515","text":"While processing a message, a consumer instance can reset the message visibility by restarting the preset timeout counter.","correct":false}]}]}}}}
