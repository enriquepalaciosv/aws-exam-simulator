{"data":{"createNewExamAttempt":{"attempt":{"id":"fb889421-6465-43b6-ae44-83e84c834471"},"exam":{"id":"e22aeaaa-b1a0-462a-981e-d0fa247be251","title":"AWS Certified Solutions Architect – Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"5d2b3bb0-3bb8-41e0-9e90-7fd70629b5f3","domain":"CostOptimized","question":"You’re researching third-party backup solutions to backup 10 TB of data nightly to Amazon S3. File restores won’t be needed often, but when they are, they’ll need to be available in under five minutes. Your analysis shows that you will exceed your budget for backup storage and you need to find a way to reduce the estimated monthly costs. How should you modify the solution to achieve the cost reduction needed?","explanation":"Most third-party backup solutions write data to S3, but not all write directly to Glacier via the API. This is the most direct solution, and you’ll want to choose one that does. Moving data with S3 lifecycle rules probably won’t be recognized by the third-party software, creating an out of sync situation, and Glacier is more cost effective than the S3-Standard-Infrequent Access storage class.","links":[{"url":"https://aws.amazon.com/glacier/","title":"Amazon S3 Glacier"}],"answers":[{"id":"e7a458c861e5ca337fcdc05bf5a06004","text":"Choose a third-party backup solution that writes directly to the Amazon S3 Glacier API","correct":true},{"id":"c883be39f5cb08a918d59df1f92a1bed","text":"Write the data directly to the S3 Standard-Infrequent Access Storage Class","correct":false},{"id":"e4e3dfa7fa011d21f5b7a4182f3c4d4a","text":"Choose a third-party backup solution that leverages AWS Storage Gateway to write data to Amazon S3 Glacier","correct":false},{"id":"61439f45264a1150586115b18980c024","text":"Create an S3 lifecycle rule to move the data immediately to Amazon S3 Glacier","correct":false}]},{"id":"9deb393a-9a4d-46e5-b4d7-42fc4a6ce528","domain":"ResilientDesign","question":"You have been approached about storing some files used several times a month in AWS. These files need to be rapidly available when requested. It is acceptable for these files to be unavailable due to an Availability Zone outage. Which of the following S3 Storage Tiers is best suited for this request?","explanation":"S3 One Zone-IA is for data that is accessed less frequently, but requires rapid access when needed. S3 One Zone-IA is ideal for customers who want a lower-cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/#__","title":"Amazon S3 Storage Classes - One Zone-Infrequent Access"}],"answers":[{"id":"a4172aee8a692bd73f2781afe65fda72","text":"S3 Infrequently Accessed","correct":false},{"id":"0f351a927f8079b4ee16870680ccc746","text":"S3 One Zone IA","correct":true},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false}]},{"id":"40bd28c9-dee5-42d8-bc1b-1822db4e5243","domain":"ResilientDesign","question":"An enterprise has a large customer base and sends marketing emails (such as special offers and discounts), transactional orders (such as order confirmations) and correspondence emails (such as newsletters) to all customers. They engaged you to set up an email platform that provides an easy and cost-effective way to send and receive emails using their own email address and domains, and also wanted to set email auto-responders and email unsubscribe systems. Which AWS service below best matches the requirement?","explanation":"Amazon Simple Email Service (Amazon SES) is a highly scalable and cost-effective service for sending and receiving email. Amazon SES eliminates the complexity and expense of building an in-house email solution or licensing, installing, and operating a third-party email solution. Amazon WorkMail is a suite of office tools which help manage daily email workflow. With WorkMail, it is not possible to send transaction email or email newsletters. Amazon WorkMail uses Amazon SES to send and receive mail.","links":[{"url":"https://docs.aws.amazon.com/ses/latest/DeveloperGuide/sending-email.html","title":"Setting up Simple Email Service"}],"answers":[{"id":"224510290621b43664ba1741744d7c57","text":"Amazon Active Directory Email Service","correct":false},{"id":"09e915452f715da52789fa62d9dd5291","text":"Amazon Simple Email Service","correct":true},{"id":"ca50f9e142e8d3e5e8fa73cf07d1a437","text":"Amazon Integrated Email solution","correct":false},{"id":"f25bb6e1bd825ac7b88a0340c5d8f4ec","text":"Amazon WorkMail","correct":false}]},{"id":"57ee57eb-5b47-45ff-8c95-42b35bb8e719","domain":"ResilientDesign","question":"A Multi-AZ RDS deployment will automatically fail-over as a result of which two of the following?","explanation":"Amazon RDS detects and automatically recovers from the most common failure scenarios for Multi-AZ deployments so that you can resume database operations as quickly as possible without administrative intervention. Amazon RDS automatically performs a failover in the event of any of the following: Loss of availability in primary Availability Zone, Loss of network connectivity to primary, Compute unit failure on primary, Storage failure on primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html#Concepts.MultiAZ.Failover","title":"Failover Process for Amazon RDS"}],"answers":[{"id":"8851c500044adfe0ba4a247acdb86eda","text":"Loss of network connectivity to the Primary","correct":true},{"id":"7ecc550bc4f7f4c4d01c334d359bb0d9","text":"Loss of availability in standby Availability Zone","correct":false},{"id":"7b75b57dbe879950151e7a40cf0aed41","text":"A region-wide loss of service","correct":false},{"id":"215b7e6d7f48e4225c06a3c50bf400d2","text":"Loss of availability in primary Availability Zone","correct":true}]},{"id":"b09415bc-dd01-42c0-a7f8-f3603cd59468","domain":"CostOptimized","question":"You need to automatically migrate objects from one S3 storage class to another based on the age of the data. Which S3 service can you use to achieve this?","explanation":"S3 Lifecycle management provides the ability to define the lifecycle of your object with a predefined policy and reduce your cost of storage. You can set lifecycle transition policy to automatically migrate Amazon S3 objects to Standard - Infrequent Access (Standard - IA) and/or Amazon Glacier based on the age of the data.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html","title":"S3 Object Lifecycle Management"}],"answers":[{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"fa532045e834ec2fac1200964a189516","text":"Lifecycle Management","correct":true},{"id":"b1926a8ac417114ef193a282594538c7","text":"Infrequent Access","correct":false},{"id":"5b6019950a69fdc69d23187a8254c7b4","text":"Reduced Redundancy","correct":false}]},{"id":"c6a3e070-265a-11ea-978f-2e728ce88125","domain":"Performant","question":"An SEO company collects data based on disparate search engine optimization metrics and stores it in a DynamoDB database. The company wants to create an extra copy of the database tables as a form of disaster recovery. Which of the following AWS services can do that?","explanation":"True to its naming, AWS Backup is the service that you can use to back up the DynamoDB database tables. It also works for RDS databases.","links":[{"url":"https://docs.aws.amazon.com/aws-backup/latest/devguide/whatisbackup.html","title":"What Is AWS Backup?"}],"answers":[{"id":"df346128c45efa43efc29607224fc716","text":"Amazon Simple Storage Service (S3)","correct":false},{"id":"ce1a41ee0352cee512475ef6a6233963","text":"Amazon Elastic Compute Cloud (EC2)","correct":false},{"id":"ce52d2cff6e50f2e74505e0c70d072b3","text":"AWS Backup","correct":true},{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":false}]},{"id":"47e2a7bb-8eb1-401d-b350-543af2df7025","domain":"Performant","question":"A company is designing a log event processing application that must process 1000 events per second. Maintaining event ordering is also a requirement. Which service should they use for this messaging platform?","explanation":"Amazon SQS FIFO queues support processing of messages in first-in-first-out order. However, the service has a limit of 300 messages per second. Therefore, it does not meet the 1000 events per second requirement. Kinesis Data Streams support in-order event processing per shard. Each shard supports up to 1000 events per second. Hence, this is the correct option. Amazon MQ is a managed message broker service meant as a migration replacement for Apache ActiveMQ. Therefore, it is not an optimal solution when designing a new AWS cloud native application. SNS is a service for sending notifications and is not a suitable option in this scenario.","links":[{"url":"https://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html","title":"Kinesis Data Streams Limits"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html","title":"Amazon SQS FIFO (First-In-First-Out) Queues"}],"answers":[{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":false},{"id":"656ce3a05cc3f15979b05086924e3ffc","text":"Kinesis Data Streams","correct":true},{"id":"7a16a49dc1812ae9bd4736a497c23736","text":"SQS FIFO Queues","correct":false},{"id":"54afc4697cf03d8e3ec9a05b16380622","text":"SNS","correct":false}]},{"id":"6ccbdcd8-6433-4b7b-b3d1-b24b7af721c2","domain":"SecureSolutions","question":"Your organization currently has 2 VPCs in the same region - VPC A which has been configured with the subnet 10.1.0.0/16 and VPC B which has been configured with the subnet 10.1.250.0/24. A new requirement has come up to allow all resources in VPC A to access all resources in VPC B and vice versa. One of your colleagues has suggested that you peer the two VPCs together to accomplish this - what is your opinion on this?","explanation":"As the two VPCs have overlapping IP Address ranges, peering will not be possible. VPC Endpoints and NAT Instance will be of no use in peering these two VPCs. The \"easiest\" way forward to accomplish this would be to re-IP the resources in VPC B with a non-overlapping subnet, then peering the two","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/peering/invalid-peering-configurations.html","title":"Unsupported VPC Configurations"}],"answers":[{"id":"4821c3cd5186455ae184d652fe71aecc","text":"This will not be possible with the current configuration","correct":true},{"id":"9a8732602a1b58689b73cef108e907c6","text":"You will need to use VPC Endpoint to peer the two VPCs","correct":false},{"id":"92157c082825fd5c1b2be2b1f2d285c7","text":"Peering these two VPCs sounds like a good plan","correct":false},{"id":"d64a7b7792d5193ef75a3b2dd3fbc91a","text":"You will need to deploy an NAT instance before the VPCs can be peered","correct":false}]},{"id":"4529a700-0c98-4d1e-a64a-fe1543c8bcdd","domain":"SecureSolutions","question":"You have a 3-tier application that you want to deploy into AWS - this application is accessed by users around the world over the Internet.  The design calls for an Application Load Balancer, EC2 Instances for the application software and another set of EC2 Instances to run the custom relational database system for the application. Also, periodically you want the instances to be able to download updates from the internet, via an already-deployed NAT gateway & Internet Gateway in the public subnet. Which of the below deployments would you recommend, keeping in mind that you want to keep costs and complexity to a minimum? ","explanation":"Placing the ALB in a private subnet would generally make it inaccessible to users outside your organization, so these two options can be discounted. Of the remaining two options, although both could work in theory, one has you deploying the application servers into the same public subnet as the ALB - this would mean having to attach a public IP to them in order to allow them to download updates, or using some custom routing at the OS which increases complexity. The recommended architecture is to deploy the ALB into the public subnet, and the application & database tiers into different private subnets.","links":[],"answers":[{"id":"f8d132549046a020830a21bd5dad78ee","text":"Place the ALB in a public subnet inside the VPC. Deploy the application EC2 instances into a private subnet, and the EC2 instances required for the database into a different private subnet","correct":true},{"id":"918887f1baa6a0485499321635ed99c9","text":"Place the ALB in a public subnet inside the VPC. Deploy the application EC2 instances into the same public subnet, and the EC2 instances required for the database into a private subnet","correct":false},{"id":"187ce2fdaf78304235d6899a3a1049e7","text":"Place the ALB in a private subnet inside the VPC. Deploy the application EC2 instances into a different private subnet, and the EC2 instances required for the database into a the same subnet as the application instances","correct":false},{"id":"afa56b5db37a4928a03e39cab6650e6e","text":"Place the ALB in a private subnet inside the VPC. Deploy the application EC2 instances into the same private subnet, and the EC2 instances required for the database into a different private subnet","correct":false}]},{"id":"08233176-e11b-410e-98eb-25ca6e2eebcb","domain":"ResilientDesign","question":"A large enterprise has a distributed application in its own data center and relies on message brokers to connect and co-ordinate different systems. Message Brokers serve as the backbone for their IT environment and ultimately their business services. The enterprise has started to move some of its applications to the cloud and is looking for a cloud message broker solution so that the on-premise applications can interact with cloud-based application components. Which of the following services best suit the customer requirements?","explanation":"Amazon MQ is recommended for messaging between on-premises and cloud application components. It also supports industry-standard APIs and protocols such as JMS, AMQP and MQTT. Amazon SQS is best utilized as a messaging solution between components entirely on AWS. Amazon Step Functions is a fully managed service which makes it easy to co-ordinate components of distributed applications using visual workflows. Amazon SNS is a managed publish/subscribe service which reliably delivers messages to all valid AWS endpoints.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-activemq-in-a-hybrid-cloud-environment-with-amazon-mq/","title":"AWS Application Integration Services"}],"answers":[{"id":"860f0e709d06a1c1529c01a39cdfd798","text":"Amazon Step Functions","correct":false},{"id":"7c5d8cfa463c4a8a74627674da6299f4","text":"Amazon MQ","correct":true},{"id":"0505378c4b7a69664dc5c9a5e845fcfd","text":"Amazon SQS","correct":false},{"id":"55daa020bacdf7e4ae1a33c9f14c45b3","text":"Amazon SNS","correct":false}]},{"id":"056f9437-f1cc-46b7-948d-b824e4165927","domain":"CostOptimized","question":"What is a spot block?","explanation":"Spot instances with a specified duration are called spot blocks and are designed not to be interrupted and will run continuously for the desired duration. This is ideal for jobs that take a defined time to complete, such as batch processing, encoding and rendering, modeling and analysis, and continuous integration.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-requests.html","title":"Spot Instance Request"}],"answers":[{"id":"668cf201cc25653157e381211eb4f454","text":"A limit on the number of spot instances per AWS availability zone within an account.","correct":false},{"id":"7845bf17391493566afba67b5887284a","text":"A limit on the number of spot instances per AWS region within an account.","correct":false},{"id":"630182c415a3baf017c6f8feb47653ff","text":"A number of spot instances that are launched to meet the target capacity specified.","correct":false},{"id":"dfc941b3f66764f082aa64b118e967e2","text":"Spot instances that run for the desired duration without interruption.","correct":true}]},{"id":"5dcee06e-bd95-4dfd-8540-5c54ae7c5fd3","domain":"SecureSolutions","question":"Your application stores your customers' sensitive passport information in S3. You are required by law to encrypt all data at rest. Company policy states that you must maintain control of your encryption keys. For ease of management, however, you do not want to implement or maintain a client-side encryption library. Which S3 encryption option should you use to secure your data at rest?","explanation":"Use SSE-C (C ≈ customer controlled) if you want to maintain your own encryption keys, but don’t want to implement or leverage a client-side encryption library.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/ServerSideEncryptionCustomerKeys.html","title":"S3 - SSE-C"}],"answers":[{"id":"1562bb9d2d9567740605dcb1ccab5c80","text":"SSE-S3","correct":false},{"id":"472035b16201f5505380c16ec3eb8518","text":"SSE-C","correct":true},{"id":"e17194408dc439e1658a544965724d44","text":"SSE-KMS","correct":false},{"id":"bac271f02854883c6bc665637d0a5de6","text":"Amazon S3 Encryption Client","correct":false}]},{"id":"c232c020-d1d3-4b31-91c9-e8906b3fe973","domain":"Performant","question":"A business productivity service would like to add an online chat platform to their offerings. Their customer base is made up primarily of large multi-national corporations. These corporations will need to be able to include users in multiple countries in real-time chats. Static content for the application will reside on Amazon S3 and chat orchestration will be hosted on Amazon EC2 with Elastic Block Store volumes. Which architecture will provide the best performance efficiency for the chat platform?","explanation":"CloudFront supports WebSockets to establish persistent connections, which provide lower latency for real-time communications. Origin behaviors specify which origin satisfies which type of content request (ex. all .jpg files), not which origin servers to use. Route 53 is not needed, because requests for CloudFront content are automatically routed to the edge location with the lowest latency. Using ElastiCache to cache at the storage level may result in some efficiency, but leveraging CloudFront's Edge locations at the network level will provide the greatest performance gains.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-working-with.websockets.html","title":"Using WebSocket with CloudFront Distributions"}],"answers":[{"id":"3cdc4a0838e007f3a5500a2b555b9a73","text":"Leverage ElastiCache to manage in-progress chat conversations in-memory, and write conversation history to EBS volumes later","correct":false},{"id":"00539fd580f87a3d665dfe784d08d459","text":"Create a CloudFront distribution with origin behaviors that point to chat servers in the regions where the clients reside","correct":false},{"id":"49d904e69d2f386dc05917de19119370","text":"Use a Route 53 latency routing policy to send traffic to the lowest latency CloudFront Edge location","correct":false},{"id":"06a06760d361cbafcca4c47d8ab93c8e","text":"Have clients use HTTP upgrade semantics to establish WebSockets connections with CloudFront distributions","correct":true}]},{"id":"21f8c7eb-3702-4f91-8512-9cf16a864164","domain":"SecureSolutions","question":"A junior team member asks you about IAM best practices. Which of the following statements are valid recommendations?","explanation":"If you don't already have an access key for your AWS account root user, don't create one unless you absolutely need to. If you do have an access key for your AWS account root user, delete it. If you must keep it, rotate (change) the access key regularly. Roles don't have their own permanent set of credentials the way IAM users do. In the case of Amazon EC2, IAM dynamically provides temporary credentials to the EC2 instance, and these credentials are automatically rotated for you","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html","title":"IAM Best Practices"}],"answers":[{"id":"b07e4dc1c6a4ca0e981d7980363f11f2","text":"Applications that run on an Amazon EC2 instance need credentials in order to access other AWS services. To provide credentials to the application in a secure way, use IAM roles. Roles have their own permanent set of credentials the way IAM users do.","correct":false},{"id":"4e81fb683ffec5c6b14d5fbf8ca23943","text":"Use IAM roles instead of sharing security credentials between accounts to allow users from another AWS account to access resources in your AWS account.","correct":true},{"id":"ed1cc3d72c302de4311e139931f75f13","text":"A user in an IAM group inherits the permissions assigned to the group. Although you can define additional permissions for an individual IAM user, it can be less obvious what set of permissions is applicable to an individual user when you mix these two approaches.","correct":true},{"id":"e64a9fadc174196728442c9e207040c6","text":"It is best practice to use access keys whenever possible. If you don't already have an access key for your AWS account root user, you should create one and use it instead of your account email address and password to sign in to the AWS Management Console. Rotate the access key regularly.","correct":false}]},{"id":"6d5d2303-29b6-4e31-96a7-b4067a191b9e","domain":"Performant","question":"You have an application that requires that 500 messages per second be sent and processed in order. Which service should be used to accomplish this?","explanation":"SQS FIFO queues are designed to enhance messaging between applications when the order of operations and events is critical, or where duplicates can't be tolerated. SQS Standard queues can process the messages, but cannot guarantee order.  SNS is used to send the messages, but does not process them. SES is an email service.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html","title":"Amazon SQS FIFO Queues"}],"answers":[{"id":"74e06b58e00302916a205d2bf24e9837","text":"AWS SNS","correct":false},{"id":"17d68573ef0a017c323182d2cf4e7477","text":"AWS SES","correct":false},{"id":"cdc05958362b09ba911028eaf41c71d5","text":"AWS SQS","correct":false},{"id":"53a5cedcd58452f2752a4cf26d0c79b7","text":"AWS SQS FIFO","correct":true}]},{"id":"655aca00-21a4-11ea-978f-2e728ce88125","domain":"Performant","question":"A wealth intelligence software company currently uses Oracle 12c as its database solution. However, it wants to move its databases to the AWS Cloud. Which of the following services will accommodate the migration?","explanation":"The hint to the answer lies in the company’s current database software. Oracle 12c is a relational database solution, which is what Amazon RDS is. The company can run its Oracle databases using RDS instances. Amazon DynamoDB is a non-relational DB solution and Amazon Redshift is for Big Data and Data Warehouse solutions. Amazon ElastiCache is used to increase DB performance through caching DB data to improve application performance.","links":[{"url":"https://aws.amazon.com/rds/oracle/","title":"Amazon RDS for Oracle"}],"answers":[{"id":"3e8f51149454b27e82ddd26c897a4167","text":"Amazon Relational Database Service (RDS)","correct":true},{"id":"f7415e33f972c03abd4f3fed36748f7a","text":"Amazon Redshift","correct":false},{"id":"770b120ec487568871cc9ab64475af46","text":"Amazon ElastiCache","correct":false},{"id":"ecafbaed9f41dac736e496a7cd234ce4","text":"Amazon DynamoDB","correct":false}]},{"id":"a037e5e2-59b3-4163-8260-8e6ce3054ec7","domain":"CostOptimized","question":"A consumer electronics manufacturer has recently migrated their applications to AWS. They receive their first monthly invoice which results in many questions about their AWS usage. The finance team attempts to answer inquiries using Cost Explorer, but some of the requests regard specialized accounting for their business which Cost Explorer doesn't address. Which solution will give them the ability to search, analyze, and visualize their costs in a granular way for their specific requirements?","explanation":"The AWS Cost and Usage Report contains line items for each unique combination of AWS product, usage type, and operation that your AWS account uses. Deploying a Kibana dashboard with Elasticsearch provides the capability to create custom visualizations. Leveraging the Kibana offering inside Amazon Elasticsearch provides a fully managed service that doesn't need to be managed as it would be on EC2. Since we're only looking to search a single cost usage table with a huge number of rows, and don't need to perform table joins, an RDS MySQL or RedShift solution would not be required and would be more costly. The AWS Detailed Billing Reports will be unavailable at a later date, and AWS recommends using the Cost and Usage Report instead.","links":[{"url":"https://aws.amazon.com/aws-cost-management/aws-cost-and-usage-reporting/","title":"AWS Cost and Usage Report"},{"url":"https://aws.amazon.com/elasticsearch-service/","title":"Amazon Elasticsearch Service"},{"url":"https://aws.amazon.com/solutions/cost-optimization-monitor/?did=sl_card&trk=sl_card","title":"Cost Optimization Monitor"}],"answers":[{"id":"8608d849f91c63eea5519d1fdd9e2143","text":"Configure AWS Glue to read AWS Detailed Billing Reports from S3 and load the data into Amazon Redshift. Create an Amazon QuickSight dashboard with the custom visualizations required","correct":false},{"id":"701c3c7e248d12e2b08cc6fb88e5789d","text":"Implement scripts on an EC2 instance that pull AWS Detailed Billing Reports from S3 and load the data into an Amazon Elasticsearch Service domain. Deploy Kibana on that same EC2 instance and create the custom visualizations required","correct":false},{"id":"b61314c9a3e461d11598a04472234a0c","text":"Deploy AWS Database Migration Service to read AWS Cost and Usage Reports from S3 and load the data into an Amazon RDS MySQL database. Create an Amazon QuickSight dashboard with the custom visualizations required","correct":false},{"id":"bbf8436d8501e9bd4d59b9d3d378d28c","text":"Create scripts on an EC2 instance that pull AWS Cost and Usage Reports from S3 and load the data into an Amazon Elasticsearch Service domain. Configure Kibana dashboards in Amazon Elasticsearch for the custom visualizations required","correct":true}]},{"id":"c69a71a5-d528-482b-9ef5-2f64f2254885","domain":"SecureSolutions","question":"You are trying to establish a VPC peering connection with another VPC, and you discover that there seem to be a lot of limitations and rules when it comes to VPC peering. Which of the following is not a VPC peering limitation or rule?","explanation":"Cluster Placement Groups can span VPCs, but not AZs.  In Jan 2018 AWS introduced inter-Region VPC Peering.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/invalid-peering-configurations.html","title":"Invalid VPC Peering Connection Configurations"},{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"Placement Groups & VPC Peering"},{"url":"https://docs.aws.amazon.com/vpc/latest/peering/vpc-peering-basics.html","title":"VPC Peering Basics"}],"answers":[{"id":"8c6e6421dad18dba855b5e3a330db13a","text":"You cannot have more than one VPC peering connection between the same VPCs at the same time.","correct":false},{"id":"bec3523f7df93984456e0a052b188d49","text":"A cluster placement group cannot span peered VPCs.","correct":true},{"id":"aad59f4740462dc95a91a5dbd4566dae","text":"You cannot create a VPC peering connection between VPCs in different regions.","correct":true},{"id":"d5940d56f69290da66e11ce1d3447839","text":"You cannot create a VPC peering connection between VPCs with matching or overlapping CIDR blocks.","correct":false}]},{"id":"dbb146aa-ae1d-411e-82be-4777bd07c916","domain":"Performant","question":"A financial market dashboard needs to update asset values almost instantaneously for customers across the United States. Updates will be written to the primary application instance which resides in the AWS us-east-1 region. Which database architecture will provide the best performance for consumers of the dashboard's information?","explanation":"With Aurora MySQL you can configure cross-region Aurora Replicas using logical replication to up to five secondary AWS regions. Aurora PostgreSQL currently does not support cross-region replicas. Aurora Replica physical replication can only replicate to one secondary region. Using Aurora over RDS provides multiple read replicas in the deployment region and other benefits automatically without having to configure them.","links":[{"url":"https://aws.amazon.com/rds/aurora/?nc=sn&loc=0","title":"Amazon Aurora"},{"url":"https://aws.amazon.com/rds/aurora/faqs/?nc=sn&loc=6","title":"Amazon Aurora FAQs - High Availability and Replication"}],"answers":[{"id":"91857d4bed60ff0818ab1d95e0314b9c","text":"Deploy Amazon Aurora MySQL with Aurora Replicas using cross-region logical replication. Create the replicas in the AWS us-east-2 and us-west-2 regions.","correct":true},{"id":"a3f216bc2a3134a725e71894673ef3cd","text":"Deploy Amazon Aurora PostgreSQL with Aurora Replicas using cross-region logical replication. Create the replicas in the AWS us-east-2 and us-west-1 regions.","correct":false},{"id":"31441ec91d70f043876be523dca440b3","text":"Use Amazon RDS PostgreSQL with read replicas. Create the replicas in the AWS us-east-1, us-east-2, and us-west-2 regions.","correct":false},{"id":"f95722da1c54e4a7b38d775dec9d3952","text":"Implement Amazon Aurora MySQL with Aurora Replicas using cross-region physical replication. Create the replicas in the AWS us-east-2 and us-west-2 regions.","correct":false}]},{"id":"5c841746-5aea-4a32-8a87-65b78fb0184b","domain":"ResilientDesign","question":"You want to use an AWS service that can monitor your EC2 instances and automatically recover it if it becomes impaired. Which of the following automation tools will enable you to do so?","explanation":"Using a CloudWatch alarm, you can monitor your EC2 instance and automatically recover it if it becomes impaired. Elastic Beanstalk is for deploying and managing web applications, Auto Scaling is for automatically scaling your resources up or down, and Lambda can be set up to automatically execute a function on a regular schedule. None of these tools, however, are used for auto EC2 recovery.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html","title":"Recover Your Instance"}],"answers":[{"id":"4b88d56bd65ef92611ac63064c38369f","text":"Amazon CloudWatch","correct":true},{"id":"bcf6eb183b7da148701bcc059a34675f","text":"AWS Elastic Beanstalk","correct":false},{"id":"afd14eb3f151c84e6ef7ab63812b4fbc","text":"Auto Scaling","correct":false},{"id":"dee7ff8f7b10b9d388c7c561e9413b0d","text":"AWS Lambda","correct":false}]},{"id":"4839a4ad-8c28-42b6-baa4-ef893f842c21","domain":"Performant","question":"Which of the following RDS database types support RDS Read Replicas?","explanation":"Aurora, MySQL, MariaDB, Oracle and PostgreSQL all natively support read replicas in RDS. Although read replicas are available in MS SQL Server, these are not natively available in RDS and must be deployed into EC2 instances to work.","links":[{"url":"https://aws.amazon.com/rds/details/read-replicas/","title":"Amazon RDS Read Replicas"}],"answers":[{"id":"399bd1ee587245ecac6f39beaa99886f","text":"PostgreSQL","correct":true},{"id":"62a004b95946bb97541afa471dcca73a","text":"MySQL","correct":true},{"id":"7f9733e208088b1ce6df3d4be1765396","text":"MariaDB","correct":true},{"id":"30162ed78b6c10f731411f2fc440c24f","text":"Oracle","correct":true},{"id":"509e0895bd82e3315e79018a6ce02181","text":"Aurora","correct":true},{"id":"8797fea4e66df215a8f85b78c1dc9c41","text":"Microsoft SQL","correct":false}]},{"id":"dfc3f2ec-3161-4e55-8132-ac8c4e1a3c81","domain":"ResilientDesign","question":"Which of the following is true with regard to Elastic IP addresses?","explanation":"Elastic IP address is a static IPv4 address and can be associated with a public address for dynamic cloud computing. When Elastic IP is associated with an instance, the existing Public IPv4 address is released back to the Amazon pool. Elastic IP addresses are region specific. Elastic IPs may be recovered if released, only if the IP is not associated with another account. Elastic IPs can be recovered using EC2 API or CLI tool only. In EC2-Classic, an Elastic IP is disassociated from the instance when you stop it.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html","title":"Elastic IP Addressing"}],"answers":[{"id":"4aaf488833f9d54d0834959007c03d78","text":"An Elastic IP address can be recovered using the Amazon EC2 API or a command line tool only.","correct":true},{"id":"933828eae3a2cae2240b99074d71d62a","text":"An Elastic IP address is for a specific region only.","correct":true},{"id":"0cfca15b9f0c8a1563edbf0e6a36171a","text":"When an Elastic IP address is associated with an instance, the instance's Public IPv4 address is released back to the Amazon pool and cannot be reused. The public DNS hostname of the instance changes to match the Elastic IP address.","correct":false},{"id":"41fceb47b8c47422341f02c0a017394b","text":"If released, an Elastic IP address can be recovered if it is not associated with another AWS account.","correct":true},{"id":"a2cdfe942dc44e6af7dc620c6625b1d5","text":"An Elastic IP address is for a specific Availability Zone only.","correct":false},{"id":"9980200da917f7d405e7f6a765bf4586","text":"An Elastic IP address will remain associated with the EC2-Classic instance when the EC2-Classic instance is stopped.","correct":false}]},{"id":"33481ccb-46de-434a-ad35-cfcd2b9a960f","domain":"SecureSolutions","question":"Which of the following AWS services can you use to protect data within your VPC?","explanation":"For data protection, AWS recommends tools like IAM, CloudTrail, and Macie. IAM is for safeguarding account credentials and granting users only the necessary permissions to perform their job duties. CloudTrail is for tracking user activity and API usage. And Macie is an advanced security service that uses machine learning to automatically discover, classify, and protect data. CloudFront is the only odd one out; it is AWS’s content delivery service, rather than a security or management and governance tool.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/data-protection.html","title":"Data Protection in Amazon Virtual Private Cloud"}],"answers":[{"id":"dfdfd742376f1e718ab36a8a1ee9143e","text":"Amazon CloudFront","correct":false},{"id":"a86087964fb00f6ae81475d2c8c3c40c","text":"AWS Identity and Access Management (IAM)","correct":true},{"id":"26ca9b29af36f84c577a85a80a58a381","text":"AWS CloudTrail","correct":true},{"id":"1f7efb5a61d1162575c83917dd086ad7","text":"Amazon Macie","correct":true}]},{"id":"77ab3cbd-1ff6-4911-a1b6-1f01659ee239","domain":"Performant","question":"An organization is looking to re-use an existing unused EC2 instance, load it with required application components and hibernate it, so that an application can be made available quickly whenever required. Can hibernation be enabled on an existing instance?","explanation":"While the EC2 instances can be up and running in a matter of seconds, booting the operating system and the application can take considerable time. Also, caches and other memory-centric application components can take some time (sometimes tens of minutes) to pre-load or warm up. AWS gives you the ability to launch EC2 instances, set them up as desired, hibernate them, and then bring them back to life when you need them. The hibernation process stores the in-memory state of the instance, along with its private and elastic IP addresses, allowing it to pick up exactly where it left off. When an instance is instructed to hibernate, it writes the in-memory state to a file in the root EBS volume and then (in effect) shuts itself down. To hibernate an instance, it must first be enabled for hibernation, which can be enabled while launching the instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html#enabling-hibernation","title":"AWS Instance States"}],"answers":[{"id":"71150f1592f997bed8c810f1a34647b2","text":"Hibernation can be enabled only at instance launch and cannot be enabled on an existing instance (running or stopped)","correct":true},{"id":"7d9d86ad36047738986c27894521f476","text":"A running instance can be made standby by enabling hibernation in the instance details properties pane","correct":false},{"id":"8f2d0a9ae66943db6854c1de51b4a054","text":"The running instance should be stopped before enabling hibernation","correct":false},{"id":"d3ba50a992abb9a181c0fb7f24a57832","text":"Hibernation is part of EC2 auto-scaling and cannot be enabled at instance level","correct":false}]},{"id":"43fc02ed-4b66-416e-affa-8cfa3643bfd6","domain":"SecureSolutions","question":"To simplify your environment configuration how should you manage access from EC2 instances to AWS services?","explanation":"Access keys should *never* be stored on an AMI or in plain text anywhere.  Roles are specifically designed to abstract the Keys away from front line services reducing the risk of exposure, and allowing secure and non-impacting Key management.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html","title":"IAM Best Practices"},{"url":"https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html","title":"BBest Practices for Managing AWS Access Keys"}],"answers":[{"id":"fca203d4e929e309ed060a778ff1f1aa","text":"Create service accounts and embed the Keys for these accounts in the AMIs.","correct":false},{"id":"19543199cf399870f8acf4b311ac0435","text":"Build one or two Roles with high levels of access each, and assign to the EC2 instances according to the team managing them.","correct":false},{"id":"364e7e3be5971c70b948d12c536dafe1","text":"Build multiple Roles with minimal viable access each, and assign them to the EC2 launch configurations according to their function.","correct":true},{"id":"11f52231435fc56bb21e9a4b5a11bd39","text":"Create service accounts and store the Keys in an encrypted S3 and access them programmatically.","correct":false}]},{"id":"a81c4d2c-8cb8-429e-a182-3f586da0e2fb","domain":"SecureSolutions","question":"You need a web access control list (web ACL) that protects the load balancer for your application. Which of the following services will enable you to do that?","explanation":"With WAF, you can create a web ACL that consists of rules to define its protection strategy and apply it to resources such as your load balancer. AWS Shield protects your resources from DDoS attacks, Firewall Manager is for centralizing your WAF and Shield configurations, and GuardDuty is for detecting threats to your network.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/how-aws-waf-works.html","title":"How AWS WAF Works"}],"answers":[{"id":"621f4719cc9f27432c4c095f76df474e","text":"Amazon GuardDuty","correct":false},{"id":"145bdf97ed8968896f4747b4b64867ae","text":"AWS Firewall Manager","correct":false},{"id":"769f2c629067645d4b60e13009500c9f","text":"AWS Web Application Firewall (WAF)","correct":true},{"id":"637d82e8a7206e87344161109cf7112d","text":"AWS Shield","correct":false}]},{"id":"c5cc330a-0f8f-11ea-8d71-362b9e155667","domain":"ResilientDesign","question":"You recently got hired by a sole proprietor specializing in baking and selling oatcakes within the state of Maryland, which is in the East Coast of the United States. The sole proprietor is ready to launch a website to expand her business online and sell on a national scale. She wants assurance that the website is always available to customers throughout the United States. Using Amazon Route 53 and EC2, which of the following is the best course of action?","explanation":"Ideally, you should architect AWS usage to take advantage of multiple Regions and Availability Zones. Based on the client’s demands, you need an active-passive failover configuration within the United States — not between the United States and Singapore, for example.  So, setting up a failover routing policy for the website with both EC2 instances in North American Regions and Availability Zones is the correct option. With Maryland falling within the US East Region, the secondary resources can be deployed in the US West Region for coast-to-coast national coverage. A simple routing policy won’t work, since it distributes web traffic randomly. And while geolocation routing can address the client’s national reach plans, it will not address the website’s resiliency.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html#dns-failover-types-active-passive","title":"Active-Passive Failover"}],"answers":[{"id":"5aa9a31751ffd108c0b6c3dd7bf7a4c2","text":"Set up a geolocation routing policy in Route 53 for the website that directs traffic to the EC2 instance in the us-east 1 Availability Zone as the area where the company is based. It will failover to the EC2 instance in the us-west-1 Availability Zone as the secondary resource when necessary.","correct":false},{"id":"67671c325b8941bda2a15e76be801e2d","text":"Set up a failover routing policy in Route 53 for the website that has an EC2 instance in the us-east-1 Availability Zone as the primary resource and another EC2 instance in the us-west-1 Availability Zone as the secondary resource.","correct":true},{"id":"80fe4ea40ff6dc32a5c8e993ca1f435c","text":"Set up a geolocation routing policy in Route 53 for the website that directs traffic to the EC2 instance in the us-east 1 Availability Zone as the area where the company is based. It will failover to the EC2 instance in the ap-southeast-1 Availability Zone as the secondary resource when necessary.","correct":false},{"id":"00bd2e799600e5dc9ac2ed23e17b593a","text":"Set up a failover routing policy in Route 53 for the website that has an EC2 instance in the us-east-1 Availability Zone as the primary resource and another EC2 instance in the eu-west-2 Availability Zone as the secondary resource.","correct":false},{"id":"eb41eb5a739a5015ab0b9122db69f20a","text":"Set up a simple routing policy in Route 53 for the website that switches between the EC2 instance launched in the us-east 1 Availability Zone and a second EC2 instance launched in the us-west-1 Availability Zone.","correct":false}]},{"id":"cbcc2938-15ec-4a2f-bb94-1fefe41f3efe","domain":"Performant","question":"You have an RDS database that has high performance OLTP workloads. Which storage medium would be best to accommodate these requirements?","explanation":"Amazon RDS Provisioned IOPS (SSD) Storage would be the most suitable.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html#USER_PIOPS","title":"RDS Provisioned IOPS for OLTP Workloads"}],"answers":[{"id":"4d548ff7278077c929b63c67f768cc97","text":"Amazon RDS Provisioned IOPS (SSD) Storage","correct":true},{"id":"0db6de47eed9671e44098c2117fe8916","text":"Amazon RDS Cold Storage","correct":false},{"id":"a257df0abf37db5da9b921f8222eab2a","text":"Amazon RDS General Purpose (SSD) Storage","correct":false},{"id":"e774a96af9adfaa2402148c9828271e7","text":"Amazon RDS Magnetic Storage","correct":false}]},{"id":"e19d68d3-a39e-4056-bef8-7fb2d19df5b9","domain":"SecureSolutions","question":"Which of the following areas of Security in the Cloud involves the identification of potential threats or incidents?","explanation":"Detective controls, such as conducting an inventory of assets or carrying out internal auditing, are employed to look out for anything that poses a threat to the security of a cloud environment. There are five areas of Security in the Cloud: IAM, Detective Controls, Infrastructure Protection, Data Protection, and Incident Response.","links":[{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Security-Pillar.pdf","title":"AWS Security Pillar"}],"answers":[{"id":"7e7397a7b79323762c61941fc0e6b5f9","text":"Data protection","correct":false},{"id":"7fb1ca7b0dfce3a9a7eaedc329cecc27","text":"Incident response","correct":false},{"id":"cd978e0acae323979bd0c7a15fdffb2c","text":"Infrastructural protection","correct":false},{"id":"caa28027e00cbf3f30f66fe8846f2bb0","text":"Detective controls","correct":true},{"id":"5fe5bde89ae88d436f1f8ba2d3a64130","text":"Identity and Access Management (IAM)","correct":false}]},{"id":"54a97315-a053-4325-8561-ee1f495c4daf","domain":"SecureSolutions","question":"A DevOps team has started a new Sprint to create and deploy code on Amazon EC2 Linux instances. Each DevOps team member has an IAM user name in a single AWS account. One team member creates a test EC2 instance, and another member logs in successfully from her desktop using the SSH key. However, when she attempts to deploy code using the CLI, she receives an authentication error message. What is most likely the problem?","explanation":"Failing to include a valid Access Key ID and Secret Access Key in the 'aws configure' command from your CLI client will result in an authentication failure when CLI commands are run. An IAM policy issue will result in an authorization error message. A missing inbound Security Group rule will produce a connection timeout error. SSH keys are not needed for CLI requests.","links":[{"url":"https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html","title":"Configuring the AWS CLI"}],"answers":[{"id":"bb707ca44acf191ea91f0d79b61d7fd3","text":"She has neglected to include the SSH key in her CLI request","correct":false},{"id":"b861e17f8814c3d98bfa05753a8066c0","text":"She doesn't have an IAM policy associated with her user name authorizing her to write to an EC2 instance","correct":false},{"id":"a2ac4e17c4a14e6e069328f0a7316ba7","text":"The Security Group for the EC2 instance doesn't have an inbound rule allowing traffic from her desktop","correct":false},{"id":"8711823a056ce438338116fbd7ac2a44","text":"She has not included her Access Key and Secret Access Key in the CLI configuration","correct":true}]},{"id":"3f2e5bb1-a59e-43b6-b8ae-e259613ea7f0","domain":"Performant","question":"You have an application that allows people in very remote locations to store their files safely and securely. You need to leverage CloudFront's globally distributed Edge Locations, so that as data arrives at an Edge Location the data is routed to your Amazon S3 bucket over an optimized network path. Which of the following services should you use?","explanation":"Amazon S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and your Amazon S3 bucket. Transfer Acceleration leverages Amazon CloudFront's globally distributed AWS Edge Locations.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html","title":"S3 Transfer Acceleration"}],"answers":[{"id":"00a7fea0b5c382041a8f16e4f30edd83","text":"CloudFront Multipart Upload","correct":false},{"id":"ac27af728db591b665d751dc0178ad25","text":"S3 Transfer Acceleration","correct":true},{"id":"1ac055ca7e4a6e0dbbf0b1e7a224ea1f","text":"S3 Multipart Upload","correct":false},{"id":"89dba4392223291ad101e5636df095ea","text":"CloudFront Transfer Acceleration","correct":false}]},{"id":"4dbb13ea-c707-4846-9f49-584095a20625","domain":"ResilientDesign","question":"You are investigating a performance issue on a MYSQL RDS database and discover that there is only a single DB instance in a single Availability Zone for this database. This goes against your organisation's availability requirements, which specify that the application must automatically remain available during AZ outages and with minimal interruption. This needs to be addressed, along with the performance issue. How would you go about resolving this, while keeping cost to a minimum?","explanation":"When in a Multi-AZ configuration, the secondary database instance is not \"active\" and cannot be read from or written to by clients. This rules out using the secondary instance to address the performance issue. Putting a read replica in a different AZ can help with redundancy, however the read replica will need to be promoted manually in case of a disaster, resulting downtime while this takes place. As this scenario requires that there is minimal interruption to service in case of a AZ outage, any answer using the Read Replica for availability can be discounted. This leaves using a Multi-AZ configuration with a Read Replica as the only valid option.","links":[{"url":"https://aws.amazon.com/rds/details/multi-az/","title":"Amazon RDS Multi-AZ Deployments"},{"url":"https://aws.amazon.com/blogs/aws/amazon-rds-for-mysql-promote-read-replica/","title":"Amazon RDS for MySQL – Promote Read Replica"}],"answers":[{"id":"92df2c8707d1018172156f0e95fd5b26","text":"Deploy a Read Replica for the database into a different AZ to address the availability requirement. Create another read replica in primary zone to improve performance.","correct":false},{"id":"ebda44f0999233da222783fb1a8079dc","text":"Deploy a Read Replica for the database into a different AZ. This will address the performance issue, and can be used in case of a AZ outage","correct":false},{"id":"43a8b1df93731fc791a9c59882df77b7","text":"Modify the database to be Multi-AZ to address the availability requirement. This will also address the performance issue as there will now be 2 instances for reads and writes.","correct":false},{"id":"9a2f983568edc620fc3719d40f9ea028","text":"Modify the database to be Multi-AZ to address the availability requirement, and deploy a read replica to improve performance","correct":true}]},{"id":"7589448c-e00c-4c64-9d5f-04e10ac556e4","domain":"CostOptimized","question":"An enterprise is planning to move its on-premise application to AWS cloud. The enterprise planned to build the non-production applications first as a proof of concept, and the governance team has provided approval for downtime for a brief period if cost can be compensated. You recommend spot instances as this satisfies the scenario explained above. Do vCPU limits apply when requesting a spot instance?","explanation":"Amazon EC2 is transitioning on-demand instance limits from the current instance count-based limits to vCPU-based limits to simplify the limit management experience for AWS customers. Beginning September 24, 2019, customers can opt in to vCPU-based instance limits. Count-based instance limits will not be available or supported after November 8, 2019. The vCPU-based limits only apply to running on-demand instances and does not apply when purchasing reserved or spot instances.","links":[{"url":"https://aws.amazon.com/ec2/faqs/","title":"Amazon EC2 compute service features"}],"answers":[{"id":"1fe04947ca4403eb3588fb87310de29e","text":"vCPU limits apply to reserved instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false},{"id":"a4fb94942aaa43d251b18a4126ce6d18","text":"In AWS, only instance count based limits exist and there is no concept of vCPU limits.","correct":false},{"id":"34394b797e4a477511982b1ac4a38d19","text":"vCPU limits apply only to on-demand instances and do not apply for spot instances.","correct":true},{"id":"9bfb4cfa201ec7e2242c7df2c0d39906","text":"vCPU limits apply to spot instances. Spot instance requests are submitted based on vCPU limits not on instances count.","correct":false}]},{"id":"12fb3f72-11e3-4972-8865-f1908bc30711","domain":"ResilientDesign","question":"Which AWS Load Balancer types uses a Round-Robin load distribution strategy?","explanation":"The Classic will use Round-Robin only for TCP.  The ALB will use it for final node selection after parsing the routing rules.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/how-elastic-load-balancing-works.html","title":"Load Balancers"}],"answers":[{"id":"0f6975b500958e951609c73209f53f17","text":"The NLB uses a Round-Robin strategy for all protocols.","correct":false},{"id":"4e1348884902f131e480120c42e16de5","text":"The Classic uses a Round-Robin strategy for all protocols.","correct":false},{"id":"60c392425b2060877c76060fa9948c5d","text":"The ALB 1st selects a target based on the routing rule, then uses a Round-Robin strategy to select a node.","correct":true},{"id":"1220c0c8265522f50a088b4795aae533","text":"The NLB does not uses a Round-Robin strategy.","correct":true},{"id":"1881f07f9b445773ef3dd661956852f7","text":"The ALB uses a Round-Robin strategy 1st to select an ELB node, then selects a target based on the routing rules.","correct":false},{"id":"8b36a2d7f6241479c6bb85c59718f049","text":"The Classic uses a Round-Robin strategy for TCP listeners only.","correct":true},{"id":"08a60d89a0593174086a25573dbfb20c","text":"The Classic uses a Round-Robin strategy for HTTP / HTTPS only.","correct":false}]},{"id":"da14a91d-ff38-4ee2-976e-87ab89ed2b57","domain":"Performant","question":"You are attempting to move data from one EBS volume to a duplicate volume in a separate region. Which of the following methods will do this best?","explanation":"After you've created a snapshot and it has finished copying to Amazon S3, you can copy it from one AWS region to another, or within the same region.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-copy-snapshot.html","title":"Copying an EBS Snapshot"}],"answers":[{"id":"cf0d4fd3cb2d1497b6e5699ec4ee8ed5","text":"Take a snapshot of the EBS volume and copy it to the desired region.","correct":true},{"id":"f1ce9b0c80209553a22ede320d2ce91f","text":"Use a Linux tool like rsync to sync the volume to the other region.","correct":false},{"id":"7ed5cf49719e006c801d0e6fe0f4cf7e","text":"Allow a VPC peering connection to pull the data over.","correct":false},{"id":"2d58342b23166c9f5556bbe76440bd28","text":"Move the data to S3 and enable cross-region replication.","correct":false}]},{"id":"3e4057fc-efb7-49ac-bfc3-f0ad470a75fc","domain":"ResilientDesign","question":"You wonder why a SWF workflow you created has not made any progress in the last three weeks. What is the most likely explanation for the workflow behavior?","explanation":"SWF is a service that supports the integration of out-of-band or human tasks or approvals ","links":[{"url":"https://aws.amazon.com/swf/faqs/","title":"SWF FAQs"}],"answers":[{"id":"f8b5c495060b999d78b6fc7332d913b8","text":"The workflow has exceeded the maximum 90-day lifespan of an SWF workflow.","correct":false},{"id":"dffb3b8e2515a8daf96a878b1d66fe6f","text":"The last task has exceeded SWF's 14-day task execution time.","correct":false},{"id":"6f9d87bd5238a37741012b2d1b2d46d9","text":"SWF does not support tasks located outside of AWS, so you will need to remove those tasks from your on-premise servers.","correct":false},{"id":"f278bacbdf6d989935d4c5333d2dc595","text":"SWF is awaiting human input from a task you assigned to a colleague.","correct":true}]},{"id":"ac606721-1133-4438-8a6f-ec7bc24443ed","domain":"SecureSolutions","question":"Your organization has a custom VPC, but you've just discovered that one of your developers has created an RDS instance in the default VPC (in violation of company policy.) You need to re-create this RDS instance inside your custom VPC with as little effort as possible. What should you do?","explanation":"The easiest way would be to take a snapshot of the DB Instance in the Default VPC and restore it to your custom VPC by specifying the DB Subnet Group you want to use.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_RestoreFromSnapshot.html","title":"Restoring (or moving) From a Snapshot"}],"answers":[{"id":"7a4d78c86de0e51b5dbc37976fdf85cb","text":"Use the RDS Import/Export Wizard to Migrate the RDS instance across to the custom VPC.","correct":false},{"id":"c04f8f858073c4a62ff00a4eff9386dc","text":"Use AWS Database Migration Service.","correct":false},{"id":"71ae0650c202e7da315185fadebdec02","text":"Use the command 'aws rds mv dbname < VPC'.","correct":false},{"id":"4997ddcea578c38851dfd6681dc85500","text":"Take a snapshot of your DB Instance in the default VPC and restore it to VPC by specifying the DB Subnet Group you want to use in your custom VPC.","correct":true}]},{"id":"ed20f2cf-7759-41d0-9463-48c3624e7bf8","domain":"CostOptimized","question":"When deploying a NAT gateway, which of the following will you be billed for?","explanation":"With NAT Gateways, you are billed a flat fee for every hour that the gateway is active, plus an amount per GB processed by the gateway no matter the source or destination. Note that you will also have to pay the standard bandwidth charges for the traffic once it has passed through the gateway, in addition to the gateway costs.","links":[{"url":"https://aws.amazon.com/vpc/pricing/","title":"AWS VPC Pricing"}],"answers":[{"id":"064634bdc8ac6c8fa5b308fdd665e1f3","text":"A cost per hour that the NAT Gateway is active","correct":true},{"id":"774e2089dd85e418697003baa7c7cf2e","text":"The instance that the NAT Gateway is running on","correct":false},{"id":"a89c265a0491dbc3c90fcda91959c002","text":"Only outbound traffic","correct":false},{"id":"cf784879b0aed688d70b47aebb1551b4","text":"All traffic processed, regardless of it's direction","correct":true},{"id":"28ab52fb3a68950991911ff132f533e6","text":"Only inbound traffic","correct":false}]},{"id":"1a0b1d3a-8954-4a09-8952-177296aa74d9","domain":"CostOptimized","question":"A financial services company is located in New York, while their development and testing is performed in San Francisco. The development team lead wants to ensure that the data stored in their test account Amazon S3 bucket is a current copy of the data in their production account Amazon S3 bucket. What steps implement the solution in the most effective way?","explanation":"S3 Cross-Region Replication is S3 capability that can be configured on an S3 bucket to automatically replicate objects to another bucket in a different region. S3 bucket versioning is a requirement to enable S3 cross-region replication. S3 lifecycle policies are not related to replication of S3 data between accounts or regions. S3 lifecycle policies can be used to transition S3 objects to another Amazon S3 storage class (e.g. Glacier). Using S3 bucket event notifications for implementing object replication is not the optimal solution as it does not use S3 native capabilities. Implementing a Lambda function to replicate S3 objects to another bucket is not the optimal solution as it requires custom code development and testing.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html","title":"Amazon S3 Replication"}],"answers":[{"id":"08bc138542a70d8db6cf01c61ecbe9c2","text":"Configure Cross-Region Replication.","correct":true},{"id":"a0ebcbd1b7f09f700a7220e87af23e93","text":"Configure S3 Bucket Versioning.","correct":true},{"id":"d685fd084e72386d91439741e993fa1a","text":"Configure S3 Bucket Lifecycle Policy.","correct":false},{"id":"797931651fc0ec6480675746a061a614","text":"Configure S3 Bucket Event Notification.","correct":false},{"id":"3dc5e668dc968f6dfd1f7b9df09f4182","text":"Configure an AWS Lambda function to replicate S3 objects.","correct":false}]},{"id":"e8d097c8-1789-4684-a73f-f00c261d1c55","domain":"ResilientDesign","question":"You need to find both the Public and Private IP addresses of an instance. Which of the following URLs should you query?","explanation":"Be careful on the exam to read the numbers and not assume what they are. The octet 254 is transposed into 524 in two of the answers, and two are user-data and two are meta-data. ","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html#instancedata-data-retrieval","title":"Retrieving Instance Meta-Data"}],"answers":[{"id":"2e987eca0f9afee62ad0f6deb9d1f59e","text":"http://169.254.169.254/latest/user-data/","correct":false},{"id":"a8a9e51abf5c6064eb3d890d974f3e21","text":"http://169.254.169.524/latest/meta-data/","correct":false},{"id":"2ac0e8450882e7026fe16254736b901f","text":"http://169.254.169.254/latest/meta-data/","correct":true},{"id":"60d4c7e460aafc0be725859f467e2178","text":"http://169.254.169.524/latest/user-data/","correct":false}]},{"id":"2ce2d6e0-2252-424b-a96a-9035a47d0d8d","domain":"ResilientDesign","question":"You have a requirement that all objects stored in a particular bucket be copied to another region. You have enabled Cross Region Replication from the source bucket to the target bucket, but objects are not appearing in the target bucket as expected.  What are some possible reasons this could be happening?","explanation":"S3 doesn't replicate objects retroactively. S3 doesn't chain replications of CRR. S3 can't copy objects with SSE-C.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/crr-what-is-isnot-replicated.html","title":"What Does Amazon S3 Replicate?"}],"answers":[{"id":"51a9e582824a1f789301122142991445","text":"The objects in the source bucket are replicas that were created by another cross-region replication.","correct":true},{"id":"ae8c36cabd222a45126c72828b824823","text":"The objects created with server-side encryption using customer-provided (SSE-C) encryption keys.","correct":true},{"id":"61987ebda14757b2f1b5f4750a70f487","text":"The object tags in the source bucket have not been assigned.","correct":false},{"id":"f41cf0b95c577e75d1f18894d41c387a","text":"The object does not have lifecycle configuration enabled.","correct":false},{"id":"a5e0172eb202b849afb9d7bb30be8539","text":"The objects existed before you added the replication configuration to the source bucket.","correct":true},{"id":"d6b42f1fd5dcafc64053f48b9d85ad6d","text":"The objects in the source bucket for which the bucket owner has permissions to read objects and ACLs.","correct":false}]},{"id":"491201a9-371b-4123-ae89-1419f3804be4","domain":"ResilientDesign","question":"You work for a large insurance company that has issued 10,000 insurance policies. These policies are stored as PDFs. You need these policies to be highly available, and company policy says that the data must be able to survive the simultaneous loss of two facilities. What storage solution should you use?","explanation":"Your best solution would be to use S3, which redundantly stores multiple copies of your data in multiple facilities and on multiple devices within each facility.","links":[{"url":"https://aws.amazon.com/s3/faqs/#Where_is_my_data_stored","title":"S3 - Storage Across Multiple Facilities"}],"answers":[{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"248c1b0bcb74394beb4a08030c4a6847","text":"EBS","correct":false},{"id":"1975c42630e9441aaabe6b700afc92d5","text":"A single EC2 instance with an EBS volume provisioned as a secondary volume.","correct":false},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false}]},{"id":"19b5d27c-16ad-11ea-8d71-362b9e155667","domain":"Performant","question":"You set up a static website for a client using S3. However, upon clicking the website endpoint, you realize that you can’t access the website. What do you have to do to enable access without affecting other buckets and objects in the AWS account?","explanation":"Denied access to S3 object is not a technical problem, so there’s no need to notify AWS Support. Right-clicking the object will not get you on the path to enable website access, and the 'Block public access' setting is not valid in a Bucket Policy. And while you can edit public access through the 'Block public access (account settings)' option, it will affect not just the object you want to access; it will apply to all buckets and objects in the account. Ultimately, you will need to click the S3 object serving the client’s website content, click the Permissions tab, click Edit under 'Block public access', uncheck 'Block all public access', and click Save, so that you can access the website endpoint.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html","title":"Example - Setting Up a Static Website Using a Custom Domain"}],"answers":[{"id":"b32a8996f05ca1f442f0c79df948d47f","text":"Right-click the S3 object serving the website content, click Bucket Policy in the menu, click Edit, ensure 'Block public access' is set to 'false', and click Save.","correct":false},{"id":"59bd8c47f35dc26b0f3226441682ff62","text":"Click the S3 object serving the website content, click the Permissions tab, click Edit under 'Block public access', uncheck 'Block all public access', and click Save.","correct":true},{"id":"70009581d58fa2c9030c0bf7c14fc4d7","text":"Contact AWS Support by creating a case explaining the problem.","correct":false},{"id":"0d1a711860d50694ee751e52b1c419d4","text":"Click 'Block public access (account settings)', click Permissions in the menu, click Edit, uncheck 'Block all public access' if necessary, and click Save Changes.","correct":false}]},{"id":"c7389a3c-56be-4682-8ee3-af150046cc22","domain":"ResilientDesign","question":"A business-critical application requires multi-region deployment in order to meet availability SLA's. What solution is suitable for achieving these requirements?","explanation":"ELB and API Gateway are both regional services and are not able to route traffic to different AWS regions. CNAME DNS records cannot be used to route traffic to multiple endpoints. In order to implement traffic routing across multiple regions, Route53 must be used. For each application endpoint, create an A (or Alias) record. A weighted routing policy can be used where each record has equal weight. In order to support automatic failover, application health-check should be implemented.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html#dns-failover-types-active-active","title":"Active-Active and Active-Passive Failover"}],"answers":[{"id":"d2c21c6f551d5cf92df475bb36f7984e","text":"Route53 with Weighted Routing Policy and application health-check configured.","correct":true},{"id":"3f6dd4980f466bfc756fc9424b447273","text":"ELB with application health-check configured.","correct":false},{"id":"c615b1eb411e5e6b2475753e1742787c","text":"Configure CNAME record for each application endpoint in Route53.","correct":false},{"id":"03f1b0386c6511e6b329683a17ee66cf","text":"API Gateway with application endpoints configured as targets.","correct":false}]},{"id":"2f1ce543-076b-448b-8b72-e8f8791474a3","domain":"SecureSolutions","question":"You have an EC2 instance with a Security Group attached. This security group is configured to only allow traffic to/from 10.0.0.0/16. A collegue has also configured a NACL on the private subnet that the instance resides on, and this NACL is configured to block all traffic, except where the destination is in 10.0.1.0/24. What will happen when the instance attempts to access IP 192.168.0.12 on port 80?","explanation":"With outbound traffic, Security Groups are evaluated first, then NACLs. The security group is configured to only allow traffic where the destination is 10.0.0.0/16, and as 192.168.0.12 does not fall within this range it will be blocked by the security group before it reaches the NACL.","links":[{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Security.html","title":"VPC Security"}],"answers":[{"id":"5298f0866dac220c6bbad6d2da2163d8","text":"The traffic will be allowed as it is still within a private range","correct":false},{"id":"c885215eb76a3baac02ca8ea6da9a7b4","text":"The NACL will block the traffic before it is evaluated by the security group","correct":false},{"id":"eb5d4be456a62dd4f884a4b47c45fd46","text":"The traffic will be blocked simultaneously by the Security Group and NACL","correct":false},{"id":"d3d7c67e2cf8c1d1cb89971fd90c2b72","text":"The security group will block the traffic before it is evaluated by the NACL","correct":true}]},{"id":"40c8ad54-f968-412c-a7e0-9732db1d93ae","domain":"Performant","question":"You have a small database workload with infrequent I/O. Which storage medium would the most cost-effective way to meet these requirements?","explanation":" The question is specific that you are evaluating for RDS. Cold Storage is not a valid option for RDS. of the three valid types for RDS, Magnetic is still the cheapest","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html","title":"RDS Storage Types"},{"url":"https://aws.amazon.com/rds/pricing/","title":"RDS pricing"},{"url":"http://calculator.s3.amazonaws.com/index.html#s=RDS","title":"AWS pricing calculator"}],"answers":[{"id":"4d548ff7278077c929b63c67f768cc97","text":"Amazon RDS Provisioned IOPS (SSD) Storage","correct":false},{"id":"a257df0abf37db5da9b921f8222eab2a","text":"Amazon RDS General Purpose (SSD) Storage","correct":false},{"id":"0db6de47eed9671e44098c2117fe8916","text":"Amazon RDS Cold Storage","correct":false},{"id":"e774a96af9adfaa2402148c9828271e7","text":"Amazon RDS Magnetic Storage","correct":true}]},{"id":"eba390fe-7699-47c0-b51f-f38cbc948112","domain":"CostOptimized","question":"What is the 'first-byte' latency when retrieving data from Glacier?","explanation":"You should expect data retrieval latency of 3-5 hours when retrieving data from Glacier.","links":[{"url":"https://aws.amazon.com/glacier/faqs/#dataretrievalpolicies","title":"Glacier Data Retrieval Policies"}],"answers":[{"id":"b86a4270946442f3b17bd51e3aa226ce","text":"> 5 hours","correct":false},{"id":"72ab9d0304d3e84c6aa2dd15eda282f2","text":"1 hour","correct":false},{"id":"99d888e6893ac480abd21ecb8a18e060","text":"3-5 hours","correct":true},{"id":"6619a70f8ab8877e4131643fb8ded723","text":"2 hours","correct":false}]},{"id":"3252d84d-08d9-4bde-a8e7-d716502d1855","domain":"Performant","question":"You have a very heavily-trafficked WordPress blog that has approximately 95% read traffic and 5% write traffic. You notice that the blog is getting slower and slower. You discover that the bottleneck is in your RDS instance. Which of the following answers can improve your WordPress blog's performance?","explanation":"You should use a combination of Read Replicas and ElastiCache to help offload the traffic.","links":[{"url":"https://aws.amazon.com/elasticache/","title":"About ElastiCache"}],"answers":[{"id":"1af32ee0c62b109e45b92828dbc33f2d","text":"Create a secondary Multi-AZ database and run the queries off the secondary Multi-AZ database.","correct":false},{"id":"e94a05a7348f87c7b9c4f7036d632a9c","text":"Use ElastiCache to cache the most commonly read posts of your WordPress blog.","correct":true},{"id":"fdc556bb3ab9b5da3b290c181aaefb3c","text":"Create a number of read replicas and update the connection string on your EC2 instances so that traffic is evenly shared amongst these new RDS instances.","correct":true},{"id":"1c551a09129057627b3b75fb70e6f527","text":"Export the database to DynamoDB which has push button scalability.","correct":false}]},{"id":"096baab8-06c7-4b07-8e86-ba304b41102f","domain":"CostOptimized","question":"After migrating an application architecture from on-premise to AWS, you will not be responsible for the ongoing maintenance of which two of the following services.","explanation":"DynamoDB and Amazon RDS are managed services. As such, AWS handles the ongoing maintenance.","links":[{"url":"https://aws.amazon.com/rds/details/","title":"About RDS"},{"url":"https://aws.amazon.com/dynamodb/details/","title":"About DynamoDB"}],"answers":[{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true},{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false}]},{"id":"8db02025-839b-4cba-9396-3bf3d30f5c41","domain":"ResilientDesign","question":"You are a system administrator and you need to take a consistent snapshot of your EC2 instance. Your application holds large amounts of data in cache that is not written to disk automatically. What would be the best approach to taking an application consistent snapshot?","explanation":"As you need an application consistent snapshot, your best option would be to shutdown the EC2 instance and detach the EBS volume, then take the snapshot.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-creating-snapshot.html","title":"Creating an EBS Snapshot"}],"answers":[{"id":"8f8e16b428381fb3d36f848931c82fb2","text":"Take a snapshot in real time using the EC2 API.","correct":false},{"id":"f9074c78a685a4482c46191309041432","text":"Take a snapshot using the AWS CLI.","correct":false},{"id":"0ca1045c8304935b9a8a2966f9558b13","text":"Shut down the EC2 instance and detach the EBS volume, then take the snapshot.","correct":true},{"id":"35151eb8d8b2db302878d62b44030835","text":"In the AWS console, take a snapshot and ensure that the 'application consistent' check box is ticked.","correct":false}]},{"id":"389f02f0-27ea-11ea-978f-2e728ce88125","domain":"SecureSolutions","question":"Which of the following layers of DDoS attacks does AWS automatically address?","explanation":"AWS automatically addresses DDoS attacks at the network and transport layers, which are Layer 3 and Layer 4, respectively.","links":[{"url":"https://docs.aws.amazon.com/waf/latest/developerguide/ddos-responding.html","title":"Responding to DDoS Attacks"}],"answers":[{"id":"5ab5764b458bd4674dffe82c5f1cda53","text":"Layer 1","correct":false},{"id":"9041d5d59c0e46d987baf883fd77e227","text":"Layer 3","correct":true},{"id":"73d19b475178ae97c94ed26431e3b138","text":"Layer 4","correct":true},{"id":"537c230a6d35c80a253f85b1c6d607c4","text":"Layer 7","correct":false}]},{"id":"8c9f0c40-1d4b-4d37-a24a-9996d90c99c9","domain":"Performant","question":"You want to contact AWS Technical Support regarding ensuring enough capacity to autoscale for busy periods.  You remember that you have a Basic Support plan. Which of the following case types can you open with this support plan?","explanation":"There are three types of AWS Support cases you can open; they are Account and Billing Support, Service Limit Increase, and Technical Support. Customer Service does not exist as a case type, which eliminates 'Customer Service'. With the Basic plan, you can open either an Account and Billing Support or a Service Limit Increase case. To open a Technical Support case, you will need to get a Developer, Business, or Enterprise plan. So, 'Technical Support' is the wrong response; 'Account and Billing Support' and 'Service Limit Increase' are correct.","links":[{"url":"https://docs.aws.amazon.com/awssupport/latest/user/getting-started.html","title":"Features of AWS Support Plans"}],"answers":[{"id":"88d14dddd26c18290989cf3ac6ef6141","text":"Account and Billing Support","correct":true},{"id":"fec5f90e9985e1f7b8cc6752739ce9b1","text":"Technical Support","correct":false},{"id":"d073dd2e04eae29e3dd076f213f01fe3","text":"Service Limit Increase","correct":true},{"id":"d5552e0564007d93ff5937a9cb3bc491","text":"Customer Service","correct":false}]},{"id":"05ab8679-89d2-4db7-83f2-6cd0a315ae13","domain":"CostOptimized","question":"Amazon Web Services offers 4 different levels of support. Which of the following are valid support levels?","explanation":"The correct answers are Enterprise, Business, Developer. The 4th level is Basic.  Remember that Free Tier is a billing rebate not an account type or support level.","links":[{"url":"https://aws.amazon.com/premiumsupport/compare-plans/","title":"AWS Support Plans"}],"answers":[{"id":"5ef2f1c1df8b6b0fed2186a0abe18f50","text":"Free Tier","correct":false},{"id":"d6e6cb19e3b9c02f89d6cd54cfa7c613","text":"Business","correct":true},{"id":"a0f27638260642afb474516cc918407e","text":"Enterprise","correct":true},{"id":"7effe80425095de4d5b996a01e4f00a3","text":"Corporate","correct":false},{"id":"672caf27f5363dc833bda5099775e891","text":"Developer","correct":true}]},{"id":"1ea8aa1e-9454-49b0-b4e2-379eadf674e0","domain":"CostOptimized","question":"You are an employee at a communications firm that is in the process of migrating its data to Amazon S3. The data will be stored in buckets and is sent to customers to do as they see fit. However, certain data is frequently changed when customers request revisions, while the rest of the data is rarely changed. You must be able to immediately access certain data while minimizing costs. Which S3 storage class should you choose?","explanation":"While S3 Glacier is a low-cost storage class, it is for data archiving and thus not ideal for frequent access or changes to data. And S3 One Zone-Infrequent Access is also low-cost, but it does not address the frequently changed data. Although S3 Standard is a suitable choice, since it addresses frequent access, it is not the least expensive choice for the less frequently accessed data. If it was hard to determine which data is frequently changed and which isn’t, S3 Standard might have been the most cost-effective choice. But in this case, S3 Intelligent Tiering is. Intelligent Tiering stores data in two access tiers: one tier is optimized for frequently accessed data while the other is a lower-cost tier for infrequent access.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"4867860f253fdfd13af73b9154d1199b","text":"S3 Intelligent Tiering","correct":true},{"id":"e1e33699d68fc57a2e226244acd0ff86","text":"S3 Glacier","correct":false},{"id":"5605213ade8877d8d601580dbd0a8aa2","text":"S3 One Zone-Infrequent Access","correct":false},{"id":"bd3a39ea89511889f7971688dceeac97","text":"S3 Standard","correct":false}]},{"id":"58af5529-d965-4ab9-ae2f-a906c0b8c41e","domain":"Performant","question":"You've enabled website hosting on a bucket called 'aspiring-guru' in the us-west-2 Region. Which of the following is the URL that will be assigned to your website?","explanation":"Your bucket name *always* comes first. 's3-website', followed by the Region, *always* comes next.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html","title":"S3 Website Hosting"}],"answers":[{"id":"eff2fbc9e562b82d9381082df00c92d6","text":"s3-website.aspiring-guru-us-west-2.amazonaws.com","correct":false},{"id":"1b924bbbc14b974d21d136baae3e2618","text":"None of these","correct":false},{"id":"b7ac852a2cf809dc4fb801df9b658c8a","text":"aspiring-guru.s3-website-us-west-2.amazonaws.com","correct":true},{"id":"09cbf53f89e143efb0fb279e5d14b9e8","text":"s3-website-us-west-2.aspiring-guru.amazonaws.com","correct":false}]},{"id":"9c17aa9c-1337-4d5c-9e2b-c9c8c518d11c","domain":"ResilientDesign","question":"You work for a games development company who are re-architecting their production environment. They have decided to make all web servers stateless. Which of the following the AWS services will help your company achieve this goal?","explanation":"An Elastic Load Balancer can help you deliver stateful services, but not stateless. Elastic Map Reduce is a data-analysis service and is not related to servicing web traffic.","links":[{"url":"https://d0.awsstatic.com/whitepapers/managing-your-aws-infrastructure-at-scale.pdf","title":"Managing your Infrastructure at Scale"}],"answers":[{"id":"8d4c0b2cef256d21ab680366c8b1c6bf","text":"EMR","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":true},{"id":"1e96c51293fadd6f988e139c54e7b754","text":"ELB","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":true}]},{"id":"6e46373a-f81d-4469-8ad0-7251ab8aedc8","domain":"Performant","question":"You have an active NoSQL database which is hosted in DynamoDB. The DynamoDB table is queried by a Lambda function which is responding to requests made by individual users via API-Gateway. Your application peaks at 4pm each day with literally 100,000’s of requests per second. During this time your application becomes sluggish. Which step below may help to improve your applications performance.","explanation":"DAX is an obvious solution if the queries are hitting the same data frequently and the total set of re-read data does not exceed the size of the DAX. Re platforming is possible but will add complication. The Aurora answer refers to the 'cluster endpoint'. This would focus all traffic on the single Write node not the multiple Read replicas.","links":[{"url":"https://aws.amazon.com/dynamodb/dax/","title":"DynamoDB Accelerator (DAX)"},{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/Aurora.Overview.Endpoints.html#Aurora.Overview.Endpoints.Types","title":"Types of Aurora Endpoints"}],"answers":[{"id":"8966ac7acedbe0ee7b1f05790a1cf747","text":"Enable DynamoDB Accelerator to deliver an in memory cache to increase performance.","correct":true},{"id":"cfa63e0907a36062a7762af5c7808fb7","text":"Migrate the database from DynamoDB to Amazon Aurora and provision 15 read replicas. Update the application to send all read traffic to the cluster endpoint.","correct":false},{"id":"5b96dd7f94ff3a1e6a339b7d4bfc8322","text":"Re-architect the application to use a Network Load Balancer and a 3 EC2 instances in 3 different Availability Zones.","correct":false},{"id":"8b119eee795f3c32a2d1f9ebff37bae9","text":"Host the web front end on S3 using static website hosting. Use a combination of CloudFront and Elasticache to help distribute the load.","correct":false}]},{"id":"e768ecaa-8e40-4cd8-b6ae-9a344d560c70","domain":"CostOptimized","question":"An organization which runs critical services in AWS has a requirement to store backups in another account.  One application uses S3 as its back-end data store.  The backups should be as automated as possible but resilient and cost-effective.  How would you satisfy backup requirements for this application's S3 objects?","explanation":"The organization requires that backups are held in a separate accounts which means replication cannot be within the same account.  The backups must also be highly-resilient and cost-effective which means One Zone-IA is less desirable (the backups would only be stored in one Availability Zone for that region). Infrequently Accessed is the best storage type to fit these needs.  Lastly since the solution needs to be as automated as possible, it makes sense to use the build-in replication features of S3 rather than coding a custom Lambda function.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-walkthrough-2.html","title":"Configuring Replication When the Source and Destination Buckets Are Owned by Different Accounts"},{"url":"https://aws.amazon.com/s3/storage-classes/","title":"Amazon S3 Storage Classes"}],"answers":[{"id":"3c441e2bfc7b0c5824eb8df8bbf8373b","text":"Configure cross-account replication and configure the storage class for the replicated objects as S3 Standard Storage","correct":false},{"id":"1ae32621b4651accf109c1736e5feac1","text":"Configure S3 events in the source bucket to trigger cross-account copies using Lambda into the backup account to S3 Standard Storage","correct":false},{"id":"686edabc75287b4e419ece13f6eb6c64","text":"Configure cross-account replication and configure the storage class for the replicated objects as S3 One Zone-IA","correct":false},{"id":"e2bbecb893a3a44ba253e47129c3119d","text":"Configure S3 events in the source bucket to trigger same-account copies using Lambda into the backup account to S3 Infrequently Accessed","correct":false},{"id":"1cd85e1edc45929e969cd3f8a2469253","text":"Configure cross-account replication and configure the storage class for the replicated objects as S3 Infrequently Accessed","correct":true}]},{"id":"6a2430bd-d84d-4d98-948b-c1f9e4130752","domain":"Performant","question":"Which of the following protocols is not supported with an Classic Load Balancer?","explanation":"Amazon's Classic ELB supports the following protocols: HTTP, HTTPS, TCP, and SSL.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html","title":"Listeners for Your Classic Load Balancer"}],"answers":[{"id":"293c9ea246ff9985dc6f62a650f78986","text":"HTTP","correct":false},{"id":"c728a49363c9a93a43a7e7f232b5a54a","text":"FTP","correct":true},{"id":"765553e6c7ac8592c389acb9878a050a","text":"SSH","correct":true},{"id":"0e8433f9a404f1f3ba601c14b026d321","text":"HTTPS","correct":false}]},{"id":"28221b23-1edf-4afd-bf2e-0c681d53ce7d","domain":"ResilientDesign","question":"Which of the following statements about an Amazon SQS standard queue is true?","explanation":"Understand the fundamental differences between Standard and FiFo, and the volume or capacity differences.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html","title":"SQS Standard Queues"}],"answers":[{"id":"5178787674f59478ee4f9e034cbd5609","text":"SQS will deliver your message at least once, but cannot guarantee that it will not create duplicates of that message.","correct":true},{"id":"323f27bf40546901f5d6900427b43fdf","text":"SQS will deliver your message at least once, but cannot guarantee the order in which the messages will be delivered.","correct":true},{"id":"dc88f4345d4040dc97b69e420b6710f6","text":"SQS will deliver your message at least once, and guarantees that it will not create duplicates of that message.","correct":false},{"id":"3c41b0e4131dbb7da1914721523b42c0","text":"SQS will deliver your message at least once in FIFO order.","correct":false}]},{"id":"e05cb926-bcab-4cab-8a18-08f38bf70dfa","domain":"SecureSolutions","question":"You have an application that stores data in S3, and you need to design an integrated solution providing encryption at rest. You want Amazon to handle key management and protection using multiple layers of security. Which S3 encryption option should you use?","explanation":"SSE-S3 uses managed keys and one of the strongest block ciphers available, AES-256, to secure your data at rest.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html","title":"SSE - S3 Encryption"}],"answers":[{"id":"e17194408dc439e1658a544965724d44","text":"SSE-KMS","correct":false},{"id":"bac271f02854883c6bc665637d0a5de6","text":"Amazon S3 Encryption Client","correct":false},{"id":"472035b16201f5505380c16ec3eb8518","text":"SSE-C","correct":false},{"id":"1562bb9d2d9567740605dcb1ccab5c80","text":"SSE-S3","correct":true}]},{"id":"6cead0b9-9173-420b-bf8b-654f29866336","domain":"ResilientDesign","question":"You host a website running on EC2 instances behind an Application Load Balancer. The instances are in an AutoScaling Group in multiple Availability Zones and deliver many large image files stored on an EFS filesystem. Your company wants to improve the user experience by not serving the files from EC2 instances each time they are requested.  Which of following would help accomplishing this?","explanation":"Amazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you're serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html","title":"What is Amazon CloudFront?"}],"answers":[{"id":"83265438081640b65cfcaf2dad505d41","text":"Move the files to S3 Glacier.","correct":false},{"id":"06fa28fb7c08848c8aa0e87d08fc6597","text":"Cache static content using CloudFront.","correct":true},{"id":"8acd8869e4a5b95482224171bbd3a519","text":"Resize the files so they are smaller.","correct":false},{"id":"f1d4912f618c2ded05231140b98376d8","text":"Use Reserved EC2 Instances.","correct":false}]},{"id":"86d024c1-7027-401d-a4d2-5457b7f976a0","domain":"CostOptimized","question":"Your site uses machine learning algorithms to modify user-uploaded images in interesting ways, generating new images in under a second as a result. Both the original user image and the generated images are currently stored in S3 - but your site is currently growing with 50Gb of new content added per day, driving up your storage costs. Recent usage statistics have shown that both user uploaded and generated images are heavily accessed in the first 21 days after upload or creation, after which access sharply drops off. After 120 days they are never accessed again. You want to keep the good buzz you site has going and want to ensure that images are there when users need them, but at the same time you want to reduce storage costs to keep you site profitable. Which of the below is the best trade-off of the two?","explanation":"With a complex scenario like this, it's a good a to break it down into components. In the first 21 days, due to the high usage of the images any storage that includes retrieval costs will not be suitable - ruling out any IA storage. After 21 days as usage drops off significantly IA becomes a viable option. Taking it a step further - as your site is generating the images based on the user uploaded image, generated images are easily replaceable if lost, as long as you have the user image. This means that a reduced redundancy storage option is valid for generated images - S3-1Z-IA. Anything older than 120 days can be deleted as it is no longer needed.","links":[{"url":"https://aws.amazon.com/s3/storage-classes/","title":"S3 Storage Classes"}],"answers":[{"id":"bcfb0baa0a994f7d1fc253718a0eb14a","text":"Store all images on S3-IA in the first 21 days. After 21 days move both user uploaded and generated images to S3-1Z-IA with a lifecycle policy, then after 120 days move them to Glacier for archival purposes","correct":false},{"id":"eccefc577b666cc3968032eb19067e5b","text":"Store all images on S3 in the first 21 days. After 21 days move them both to S3-IA with a lifecycle policy. Create Lambda function that runs daily that deletes anything older than 120 days","correct":false},{"id":"afcd1b04e8899f07bdff4b5a7b6df83d","text":"Store all images on S3. After 21 days move them both user uploaded and generated images to S3-IA with a lifecycle policy, then after 120 days move them to Glacier for archival purposes","correct":false},{"id":"b3f69f81f2babbf2f17f845d1fcd4109","text":"Store all images on S3 in the first 21 days. After 21 days, move user images to S3-IA and generated images to S3-1Z-IA. Delete all content older than 120 days via lifecycle policy","correct":true}]},{"id":"0fa75b94-0aac-40ea-b312-cd38e8015b3c","domain":"SecureSolutions","question":"You need to add a route to your routing table that will allow connections to the internet from your subnet. Which of the following routes should you add?","explanation":"When setting a Custom Route Table, the destination should be 0.0.0.0/0, and the target should be the Internet gateway.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#CustomRouteTables","title":"Custom Route Tables"}],"answers":[{"id":"0bd386dbb40d5a1d0a565535fd77209e","text":"Destination: 0.0.0.0/33 --> Target: your virtual private gateway","correct":false},{"id":"c60df6d18e83ca3ad6180d0c6cbb3859","text":"Destination: 192.168.1.258/0 --> Target: your Internet gateway","correct":false},{"id":"a09fb8c63b2f9ad6d6cc5d6fa022a702","text":"Destination: 0.0.0.0/0 --> Target: your Internet gateway","correct":true},{"id":"899b7e9080653ebca0ce71d40bec7471","text":"Destination: 0.0.0.0/0 --> Target: 0.0.0.0/24","correct":false}]},{"id":"ebdeed2c-780f-4f28-ab81-0de353938dfb","domain":"ResilientDesign","question":"Your company is migrating a number of its applications to AWS. Services used will include Amazon EC2, Amazon S3, Amazon ELB Application Load Balancers, NAT Gateways, and Amazon RDS MySQL instances. You'll be using AWS's Bring Your Own IP Address (BYOIP) offering to keep all server IP addresses the same as they were on-premises. You'd also like to leverage Elastic IP Addresses for failover scenarios. Which approach will provide the most reliable IP addressing for your new AWS environment?","explanation":"You can bring your public IPv4 address ranges from your on-premises network to your AWS account with the BYOIP offering. You don't need to bring private IP address ranges. You can then create Elastic IP Addresses from your BYOIP pool and use them with AWS resources such as EC2 instances, NAT Gateways, and ELB Network Load Balancers. Elastic IP Addresses cannot be used with ELB Application Load Balancers or RDS instances.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-byoip.html","title":"Bring Your Own IP Addresses (BYOIP)"},{"url":"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-eips.html","title":"Elastic IP Addresses"}],"answers":[{"id":"d332dd2c597e20fddcdce2c0d2725e21","text":"Register your own public IP address ranges with BYOIP. Create Elastic IP Addresses from your BYOIP address pool for the EC2 instances and the NAT Gateways.","correct":true},{"id":"f719d7ed8ad37a2eac59c037e87ea416","text":"Register your own public IP address ranges with BYOIP. Create Elastic IP Addresses from your BYOIP address pool for the EC2 instances, the Application Load Balancers, and the NAT Gateways.","correct":false},{"id":"87a3a8c3c23724feef9fdbda3a8e5d50","text":"Register your own public IP address ranges with BYOIP. Create Elastic IP Addresses from your BYOIP address pool for the EC2 instances, the NAT Gateways, and the RDS MySQL instances.","correct":false},{"id":"7406ea0371eb195c45ac0db9d8c279b7","text":"Register all of your IP address ranges with BYOIP. Create Elastic IP Addresses from your BYOIP address pool for the EC2 instances and the RDS MySQL instances.","correct":false}]}]}}}}
