{"data":{"createNewExamAttempt":{"attempt":{"id":"5e8fe2e2-6fed-44aa-9c82-380b7e4b6224"},"exam":{"id":"d5ac97c3-0ce5-48a0-9aa3-f329539dd295","title":"AWS Certified Developer - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"22556a45-7db0-48f9-85cf-654ac74d729f","domain":"security","question":"When using the AWS REST API to upload an object to S3, which of the following request headers will ensure that your data must be encrypted using SSE?","explanation":"To request server-side encryption using the object creation REST APIs, provide the x-amz-server-side-encryption request header.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingServerSideEncryption.html","title":"Protecting Data Using Server-Side Encryption"}],"answers":[{"id":"f041d978ebb9256a023c1f9d263316ac","text":"amz-s3-server-side-encryption","correct":false},{"id":"63e1961675193e5c234f582f08632a28","text":"s3-amz-server-side-encryption","correct":false},{"id":"6d38512683c3cf8052e7e47d9d12a9f6","text":"x-amz-server-side-encryption","correct":true},{"id":"6d1f5944b9a6aada7e00dc385d5373bd","text":"x-s3-server-side-encryption","correct":false}]},{"id":"3cfbe3a0-1340-4fde-9a94-c1f8c88280af","domain":"development","question":"Where would you expect to find Elastic Beanstalk configuration files like healthcheckurl.config, environmentvariables.config etc?","explanation":"E/B has configuration options for before, during, and after environment creation. these files are loaded from configuration files in the .ebextensions folder at the root of the application source bundle. ","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/command-options.html","title":"Elastic Beanstalk Configuration Options"}],"answers":[{"id":"525b032d6f715f1fcf1e4b7a9a2452a8","text":"The .ebconfigurations folder","correct":false},{"id":"2045080e088be61fd27420ff9c10b0e8","text":"The .ebenvironments folder","correct":false},{"id":"2f5dad241fd1ac7fdb6396de1a2ed3c7","text":"The .ebextensions folder","correct":true},{"id":"c7a78c946f7e3bbabe6e9861292f35ac","text":"The root directory of your project folder","correct":false}]},{"id":"c6126f50-a373-47bf-8245-6037dcea0b5a","domain":"security","question":"Your e-commerce application needs to use database connection strings to access a database containing product and customer data. Which of the following is a secure and scalable way to manage this?","explanation":"Using secure string parameters in Parameter Store is an appropriate way to avoid hard coding a password in your template code. This ensures that sensitive runtime parameters are kept as secure as you keep other secrets, while also keeping them separate from your deployment code.","links":[{"url":"https://aws.amazon.com/systems-manager/features/","title":"Systems Manager - Parameter Store"},{"url":"https://aws.amazon.com/blogs/mt/using-aws-systems-manager-parameter-store-secure-string-parameters-in-aws-cloudformation-templates/","title":"Using AWS Systems Manager Parameter Store Secure String parameters"}],"answers":[{"id":"65b9be4196a653fc5de9a6427a2f168a","text":"Store the credentials in Parameter Store","correct":true},{"id":"0d2bb1f681b1226217a023c4cb989aaa","text":"Hard code the connection strings in the application code","correct":false},{"id":"7cb38c21a4fc2e2ad04aca2dfe89bb59","text":"Add encrypted IAM credentials to the application server and use an IAM role to access the database","correct":false},{"id":"62fc1a48d6c466824dfef123b5407ab3","text":"Store the encrypted credentials in an S3 bucket","correct":false},{"id":"1c2a034c75f70a59fff1e639175239dd","text":"Allow the EC2 instance to access the database using an instance role","correct":false}]},{"id":"4a098f64-6cd3-4da4-9c03-e7877d28fb80","domain":"security","question":"Your EC2 instance needs to access a number of files which have been encrypted using KMS. Which of the following must be configured in order for the EC2 instance to successfully read the files?","explanation":"Manage access to KMS keys using a key policy. In the key policy, you must specify the principal (the identity) that the permissions apply to. You can specify AWS accounts (root), IAM users, IAM roles, and some AWS services as principals in a key policy. You can use IAM policies in combination with key policies to control access to your customer master keys (CMKs) in AWS KMS.","links":[{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/control-access.html","title":"KMS Developer Guide - Access Control"},{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/control-access-overview.html","title":"Managing Access to Your AWS KMS Resources"},{"url":"https://docs.aws.amazon.com/kms/latest/developerguide/iam-policies.html","title":"Using IAM Policies with AWS KMS"}],"answers":[{"id":"17f84c2da6e5c820c31bc9bc9b8ba783","text":"The EC2 instance must have an instance role which has permission run the decrypt operation","correct":true},{"id":"070a7d0f2bcb70c9dc90f21deecf341a","text":"The Key Policy must allow the instance role to use the CMK","correct":true},{"id":"3cb9094c5f7738a8b51960d160e7e9fe","text":"The IAM user associated with the application must have a role which has permission run the decrypt operation","correct":false},{"id":"d91e2a356c12a95b1768867410657bd4","text":"The Key Policy must allow the IAM user to use the CMK","correct":false}]},{"id":"d069e7a2-ff20-46e7-9fd8-64d3fc2e0c8d","domain":"development","question":"You have a load balancer configuration that you use for most of your CloudFormation stacks. This load balancer always sits in front of your application running on EC2 as it has the important function of forwarding HTTPS requests on port 443 to HTTP requests on port 80 on the instance. As demand for the application grows you need to reuse this load balancer configuration in multiple other deployments of the application and you need to use CloudFormation to do this in an automated way. What is the most efficient way to deploy the load balancer configuration?","explanation":"Nested stacks are stacks created as part of other stacks. You create a nested stack within another stack by using the AWS::CloudFormation::Stack resource. For example, assume that you have a load balancer configuration that you use for most of your stacks. Instead of copying and pasting the same configurations into your templates, you can create a dedicated template for the load balancer. Then, you just use the resource to reference that template from within other templates. Lambda would not be able to deploy infrastructure resources as efficiently as CloudFormation nested stacks. AWS CloudFormation provides two methods for updating stacks: direct update or creating and executing change sets. When you directly update a stack, you submit changes and AWS CloudFormation immediately deploys them. Use direct updates when you want to quickly deploy your updates. With change sets, you can preview the changes AWS CloudFormation will make to your stack, and then decide whether to apply those changes.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-nested-stacks.html","title":"Working with Nested Stacks"}],"answers":[{"id":"54ac82e3cb0e853af8ce69674edafd64","text":"Instead of CloudFormation, use Lambda. Let the load balancer trigger a Lambda function that has the infrastructure code embedded to deploy the configuration when prompted.","correct":false},{"id":"97cc8d8d6d33e845e203f2c7d07e776e","text":"Use AWS CloudFormation direct updates to quickly deploy the same load balancer configuration in multiple environments.","correct":false},{"id":"d8c538a0c914101c9d913c3644dfeecd","text":"Use AWS CloudFormation change sets to change the load balancer configuration based on Region/AZ where you want to deploy a copy of the application.","correct":false},{"id":"67c3f9750fe6b5768341534dcf97ba93","text":"Use AWS CloudFormation nested stacks by creating a dedicated template for the load balancer and refer to that template within other templates.","correct":true}]},{"id":"51d0eac3-d55e-4a50-aa5b-c133add86037","domain":"refactoring","question":"A content publishing organization runs its own platform, which uses DynamoDB as its data store. A bug report has come in from the content team. They say that when two editors are working on the same content they frequently overwrite each other's changes.\n\nWhat DynamoDB feature would prevent the most number of overwrite bug reports?","explanation":"Using a condition-expression we can perform a conditional update to an item. The condition must evaluate to true; otherwise, the update operation fails. We can use this feature to make sure the content of an article has not changed since it was last read, before we update it.\n\nacid-expression is incorrect because there is no such expression.\n\nDynamoDB TTL is incorrect because it is for deleting items from DynamoDB after a given duration, not creating a lock.\n\nCalling GetItem immediately before calling UpdateItem would help mitigate the issue, but still leaves a small race condition where condition-expression does not. It is, therefore, not the best solution.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Expressions.ConditionExpressions.html","title":"Condition Expressions in DynamoDB"}],"answers":[{"id":"058706dd0f32f05aa73a515774a5dc2d","text":"Call GetItem immediately before calling UpdateItem to ensure the item has not changed.","correct":false},{"id":"9d2d53ddaae2b905e48ea3705529a19c","text":"Apply a time-limited lock to the item while an author is editing it using a DynamoDB TTL.","correct":false},{"id":"b1d92ca8c7500f89cffdf0057251aec1","text":"Include a condition-expression in the UpdateItem command.","correct":true},{"id":"ddb55880d9b1b331207bcb38cebd6dbf","text":"Include an acid-expression in the UpdateItem command.","correct":false}]},{"id":"098e4897-54dd-493d-ae35-d28374c03576","domain":"security","question":"You application can be accessed using multiple devices, for example, laptop, tablet, iPhone or Android devices. You would like to be able to identify and track when your users access your site using different devices. Which of the following AWS technologies can enable you to do this?","explanation":"Cognito enables developers to remember the devices on which end-users sign in to their application. You can see the remembered devices and associated metadata through the console. In addition, you can build custom functionality using the notion of remembered devices. For example, with a content distribution application (e.g., video streaming), you can limit the number of devices from which an end-user can stream their content.","links":[{"url":"https://aws.amazon.com/blogs/mobile/tracking-and-remembering-devices-using-amazon-cognito-your-user-pools/","title":"Tracking and Remembering Devices Using Amazon Cognito"}],"answers":[{"id":"0d6127433a099d6824bfd30c14ad4096","text":"Create a unique user ID and associate it with the device metadata","correct":false},{"id":"95e34ddc7b57bc86318fc7a45f0d2e2d","text":"Use a Lambda function to store a unique device ID in DynamoDB and associate it with the user session ID","correct":false},{"id":"5b46051451752459a684abff24663b39","text":"Store a unique session ID in ElastiCache","correct":false},{"id":"6cbb574c9488bb59fdd64fa8f509fce8","text":"Use Cognito","correct":true},{"id":"8204565cad3d39f0897a0ce85182016f","text":"Store a unique session ID in DynamoDB","correct":false}]},{"id":"d5adb3f2-4ddd-4a5e-be37-47d74da0f6d6","domain":"development","question":"You are working on a Serverless application written in Node.js. You updated the Node.js code and uploaded a new zip file containing your code to Lambda. Your application references the function using the alias \"Prod\", however it not seem to be using the new code. Which of the following is likely to fix this?","explanation":"The problem is that the application is referencing the function using an alias pointing to a previous version of the code. When you use versioning in AWS Lambda, you can publish one or more versions of your function. So that you can use different variations of your Lambda function in your development workflow such as development, beta, and production. Lambda also supports creating aliases for each of your Lambda function versions. Conceptually, an AWS Lambda alias is a pointer to a specific Lambda function version. You can update aliases to point to different versions of functions.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda Function Versioning and Aliases"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/how-to-manage-versioning.html","title":"Lambda Versioning"}],"answers":[{"id":"1ab8bb5a6ed0944df7316a0ae848727f","text":"You need to update the alias to reference the new version of your function","correct":true},{"id":"33064ca2d30b93ce4d46769270b3e34e","text":"You need to update your application to use an unqualified ARN","correct":false},{"id":"6a4ac8c4aa2076312300dc09fa5c0f21","text":"You need to call the function using $LATEST","correct":false},{"id":"68796527ce97010c4a40777a6462b3fc","text":"You need to call version 2 of the function","correct":false}]},{"id":"f5072793-928c-4fc3-8ce0-bd18571b6765","domain":"deployment","question":"You are developing a gaming website which scores all players scores in a DynamoDB table. You are using a Partition key of user_ID and a Sort Key of game_ID as well as storing the user_score which is the user's highest score for the game and also a timestamp. You need to find a way get the top scorers for each game, who have scored over 50,000 points. Which of the following will allow to to find this information in the most efficient way?","explanation":"A scan operation would be less efficient than a query, so that is definitely not the most efficient way. The Query operation described won't help you find the top scorers for each game. A local secondary index is an index that has the same partition key as the base table, but a different sort key. A global secondary index is an index with a partition key and a sort key that can be different from those on the base table.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Queries and Scans"},{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-indexes-general.html","title":"DynamoDB Indexes"}],"answers":[{"id":"1e267d3212493fc534c9b2e9de826341","text":"Use a local secondary index with a partition key of user_ID and a sort key of user_score","correct":true},{"id":"efcb11f92c2fff3dca6935cb74653ad7","text":"Scan the table and order by score","correct":false},{"id":"eae4d20326b1ecd862aed8669ad068ca","text":"Use a global secondary index with a partition key of game_ID and a sort key of user_ID","correct":false},{"id":"7b9684c68079e7ca02fe44efb81fa0eb","text":"Query the table using a partition key of user_ID and sort by game_ID","correct":false}]},{"id":"32e6ce0f-d2ca-4d5d-a9eb-37cd15470e3e","domain":"refactoring","question":"You've created an online forum to which your users post questions and comments. The 'thread' table has many users and each user has many posts, each marked by a timestamp. Which primary key configuration would be best suited to see all posts by a particular user in chronological order?","explanation":"A composite key with UserID as the partition key and the timestamp as the sort key would be best. The other answers offer non-standard key configurations.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.CoreComponents.html#HowItWorks.CoreComponents.PrimaryKey","title":"DynamoDB Primary Key Configurations"}],"answers":[{"id":"882b516d0dbad0409c65e7c2a820d710","text":"A composite key with UserID as the partition key and the timestamp as the sort key.","correct":true},{"id":"e69c02c4712b958b2470f1da330f5b56","text":"A composite key with UserID as the sort key and timestamp as the hash key.","correct":false},{"id":"283e1fc102dc542eede4dee9f921e710","text":"A composite key with UserID as the range key and timestamp as the sort key.","correct":false},{"id":"608907c754ce17f1ce80eb47c8fc1341","text":"A composite key with UserID as the sort key and timestamp as the partition key.","correct":false}]},{"id":"81a4f6d3-34ae-4753-8498-823bede20afe","domain":"deployment","question":"Your team is considering deploying an application on AWS Elastic Beanstalk. Your manager needs to know what infrastructure requirements are needed for the team, specifically in regards to maintenance, patching, and managing security. How would you explain what AWS is responsible for and what the team is responsible for to your manager?","explanation":"AWS and its customers share responsibility for achieving a high level of software component security and compliance. This shared model reduces customers' operational burden. AWS Elastic Beanstalk helps you perform your side of the shared responsibility model by providing a managed update feature. This feature automatically applies patches and minor updates for an Elastic Beanstalk supported platform version. Elastic Beanstalk publishes its platform support policy and retirement schedule for the coming 12 months. You (the customer) are responsible for the security of your application, your data, and any components that your application requires and that you downloaded. Be sure to review the Shared Responsibility Model in the URL provided.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/platforms-shared-responsibility.html","title":"Shared Responsibility Model for Elastic Beanstalk Platform Maintenance"}],"answers":[{"id":"f1e49a967c2ae8dc1525d208a8170996","text":"AWS is responsible for the security of your application, your data, and any components that your application requires and that you downloaded.","correct":false},{"id":"7086eb1de01b03376ee097977ba7cd94","text":"You are responsible for runtime, application server, and web server components if you opt into Elastic Beanstalk managed updates.","correct":false},{"id":"9fafdcf1a8a7c82b9e94d6080c00a245","text":"AWS is responsible for patches, minor, and major updates of operating system on its supported platform versions.","correct":true},{"id":"8fc7a262705a2a78a08dbc0ea667db64","text":"You are responsible for publishing Elastic Beanstalk's platform support policy and retirement schedule.","correct":false},{"id":"9d22ad24853ac3a47fe7c0e7eb2585e3","text":"You are responsible for the security of your application, your data, and any components that your application requires and that you downloaded.","correct":true}]},{"id":"c90384c4-a4e3-44cd-909d-9c75fd296455","domain":"security","question":"You are running an application on an EC2 instance. The application needs to be able to access an S3 bucket to read and write data. Which of the following is the best approach to enabling the EC2 instance to access your bucket?","explanation":"Storing credentials in EC2, in the code or in databases is not recommended. Using an IAM role with the requisite permissions and associating that with your EC2 instance is the recommended approach.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html","title":"Using an IAM Role To Allow EC2 Access To S3"}],"answers":[{"id":"9a58eab1d5aec409abbb6212545b5d45","text":"Store AWS credentials within the application code","correct":false},{"id":"2e9ca3aed8c9e4854687f9556f8e5b1a","text":"Store AWS credentials locally on the EC2 instance","correct":false},{"id":"53f6cd0aebbfa4fcbc2c8102ece8c9d8","text":"Store an access key and secret access key in a DynamoDB table","correct":false},{"id":"cae4292072ddb87ec39678934d1edc5d","text":"Use an IAM role with permissions to read and write to the bucket","correct":true}]},{"id":"952d36e5-535a-4b3c-a107-e834a2126477","domain":"development","question":"You have developed a web application running on a number of EC2 instances running Tomcat, you are using an S3 bucket to store product data, with customer transaction data held in an RDS database. You anticipate that the number of connections into your website will grow considerably over the next year and you want to configure a scalable place to store session state data so that multiple web servers can share the session state. Which of the following are suitable options for this application?","explanation":"DynamoDB and ElastiCache are both great options for storing session data. Both are scalable and resilient. RDS is more suited to relational data, whereas DynamoDB is far more flexible and better suited to storing session state data. Storing the data on the EC2 instances is not scalable or resilient. Lambda cannot store session state.","links":[{"url":"http://docs.amazonaws.cn/sdk-for-java/v1/developer-guide/java-dg-tomcat-session-manager.html","title":"Storing Web Server Session State in DynamoDB"},{"url":"https://aws.amazon.com/caching/session-management/","title":"Session management in AWS"}],"answers":[{"id":"690b4209ea43175d9fb511ffba4d6e52","text":"Store the session state data inside a Lambda function","correct":false},{"id":"be80d5651d3ee2a3c4e8736eb5082177","text":"Store session state locally on each EC2 instance","correct":false},{"id":"bc7071d9896321da24f137567ef7e97c","text":"Store the session state data in a DynamoDB table","correct":true},{"id":"87bdddfb8d5f7cc0273d9b48a667d260","text":"Store the data in the same RDS database used for customer transactions","correct":false},{"id":"ba003a66972966fcb9cc5503341c8a59","text":"Use ElastiCache to store session state","correct":true}]},{"id":"031bc6f7-17b3-47aa-b449-a97b2ae63aa6","domain":"deployment","question":"Which section of the AWS Serverless Application Model template would you use to describe the configuration of a Lambda function and an API Gateway endpoint, if you were deploying your application using AWS SAM?","explanation":"Use the Transform section to describe your Serverless functions when using the serverless application model. Under the Transform section, you define the resources you want to deploy.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/appendix-appendix-sam-templates-and-cf-templates.html","title":"CloudFormation Resources"},{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-template-basics.html","title":"AWS SAM Template Concepts"}],"answers":[{"id":"2ff4148554480a37f85efd299df04850","text":"Transform","correct":true},{"id":"ba0e0cde1bf72c28d435c89a66afc61a","text":"Sam","correct":false},{"id":"e93acb146e114b5dfa6ce2d12dcb96e4","text":"Functions","correct":false},{"id":"7df96b18c230f90ada0a9e2307226338","text":"Templates","correct":false}]},{"id":"87896ba2-d675-4fce-97b9-f144f05d42f1","domain":"security","question":"You are building an S3 hosted website and your website is accessing javascript and image files located in another S3 bucket. How can you enable this? ","explanation":"Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html","title":"Cross-Origin Resource Sharing (CORS)"}],"answers":[{"id":"bef5f130edd0f036b2ca659d3295d5c7","text":"IAM roles","correct":false},{"id":"be48e3ddc7b57744c693982774a47dad","text":"S3 ACLs","correct":false},{"id":"39e38061c46bfab6a44c6c8b5482763f","text":"Cross Origin Resource Sharing (CORS)","correct":true},{"id":"0e0c1a7e0b6fe582226b82afc8eec89b","text":"S3 bucket policies","correct":false}]},{"id":"ebcc48d0-3f87-4ad4-b2b9-e623ea736c5e","domain":"mon-trb","question":"You are attempting to upload a number of objects to S3, however you keep seeing the following error message: \"AmazonS3Exception: Internal Error; Service: Amazon S3;\" Which of the following is the best explanation for this kind of error?","explanation":"This is an Internal Error which indicates that Amazon S3 is unable to handle the request at that time. Internal errors or server-side errors have a 5xx status code, whereas client-side errors have a 4xx status code.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/http-5xx-errors-s3/","title":"S3 5XX Errors"},{"url":"https://docs.aws.amazon.com/systems-manager/latest/APIReference/CommonErrors.html","title":"Common Errors and Status Codes"}],"answers":[{"id":"a529f4cb171bbd153acf7a4c3f3116a0","text":"This is a 500 type error, which is a server-side error","correct":true},{"id":"a78bc5137bd856fc7bf93d66a03b40ca","text":"This is a 400 type error, which is a server-side error","correct":false},{"id":"f87b00b2711524f15807d3bd5811122e","text":"This is a 400 type error, which is a client-side error","correct":false},{"id":"f55fb827446b5745d21641748b94a97c","text":"This is a 500 type error, which is a client-side error","correct":false}]},{"id":"75298fe2-86e7-4945-b359-fa66efa511a5","domain":"deployment","question":"Your application is running on Docker in an Elastic Beanstalk. You have been asked to deploy a new version of the application code. What is the process for doing this?","explanation":"When you use the AWS Elastic Beanstalk console to deploy a new application or an application version, you'll need to upload a source bundle. Your source bundle must consist of a single ZIP file or WAR file which does not exceed 512 MB.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html","title":"Create an Application Source Bundle"}],"answers":[{"id":"ef19372b909be8f395f79dce7fd549c0","text":"Use the Elastic Beanstalk console to upload and deploy the new version of your application using a zip file containing your code","correct":true},{"id":"cb68a9fcd34702aca58b9c8e1ca910e9","text":"Log in to the underlying EC2 instance and replace the existing Docker image with the new code","correct":false},{"id":"f63680af566b899e62b6b0110b5677d7","text":"Log in to the EC2 instance, update the dockerfile and restart the container","correct":false},{"id":"349146001f426f05effeb7bf24d3d9e3","text":"Delete your environment and redeploy using the new code","correct":false}]},{"id":"064a1ca2-3ce2-483d-9e44-f0381416aa53","domain":"development","question":"You are developing a CloudFormation template and need to retrieve a string value containing the DNS name of the load balancer from an earlier section of the template. How would to refer to this string value in the most efficient and automated fashion?","explanation":"The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. This is the best choice per documentation and eliminates the need to hardcode values to be able to automate future renditions of the template rather than having to manually change every hard-coded value. The Fn::GetAtt intrinsic function returns the value of an attribute from a resource in the template. The intrinsic function Fn::FindInMap returns the value corresponding to keys in a two-level map that is declared in the Mappings section.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getatt.html","title":"Fn::GetAtt"}],"answers":[{"id":"d07c84be22b2e436b377f48b647e144a","text":"Use the condition function Fn::FindInMap to return the value corresponding to the key.","correct":false},{"id":"f9121262138f8b6c85cca08c00b4b4f5","text":"Use the condition function Fn::GetAtt to return the value of the attribute","correct":true},{"id":"a458b06d7d68a0755776d692742aebe5","text":"Hardcode the string value by checking the DNS name number ELBs in the Console and insert the value in the template.","correct":false},{"id":"597e06174b5664dffc6d5fa8752fc74b","text":"Use the condition function Fn::Select to return the value of the string.","correct":false}]},{"id":"d32ba0f0-1563-4a30-9e61-b5edf82d628e","domain":"security","question":"You are developing a legacy application which handles confidential healthcare data. The application runs on two EC2 instances behind an Application Load Balancer. Because of the age of the application, you cannot perform TLS encryption on the EC2 instances themselves. What is the least complex way you can ensure data is encrypted in transit between your VPC, and the customer who will be accessing it?","explanation":"Handling the TLS termination process within each EC2 instance adds to the computational load on the instance as well as the operational overhead of installing an X.509 certificate on each instance. You can easily arrange for the entire HTTPS encryption and decryption process, generally known as TLS termination to be handled by an Elastic Load Balancer. Your users can benefit from encrypted communication with very little operational overhead or administrative complexity.","links":[{"url":"https://aws.amazon.com/blogs/aws/elastic-load-balancer-support-for-ssl-termination/","title":"AWS Elastic Load Balancing: Support for SSL Termination"}],"answers":[{"id":"18c056fd0ece19fd238f6d245fe85321","text":"Upgrade the application to support TLS on the EC2 Instances","correct":false},{"id":"4567a70530701c962bab095e279dfb3b","text":"Perform TLS termination using Lambda","correct":false},{"id":"ef68b9b0058c7aa4c84143939156e93b","text":"Perform TLS termination on the ALB","correct":true},{"id":"f81774e2c858b52c0321762e8489f624","text":"Require customers to connect through a VPN to a virtual private gateway","correct":false}]},{"id":"8ee26b88-194a-4069-85a1-e28a48bcca27","domain":"security","question":"An organization has mandated that all data within its DynamoDB tables must be encrypted at rest using an AWS owned key. What must a developer do to ensure this?","explanation":"All DynamoDB tables are encrypted at rest using an AWS owned CMK by default. Non-encrypted DynamoDB tables are no longer supported in AWS. You have the option to pick an alternative AWS or Customer Managed KMS key if required.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/EncryptionAtRest.html","title":"DynamoDB Encryption at Rest"}],"answers":[{"id":"852abdb4878eba09a03ca6e37eb1dd16","text":"Enable DynamoDB encryption and select AWS managed CMK.","correct":false},{"id":"5744856c94411674b105aff56f20a6a3","text":"There's no need to do anything; all DynamoDB tables are encrypted at rest with an AWS owned key by default.","correct":true},{"id":"92c03c315e7b990388532214f2a73c62","text":"Enable DynamoDB encryption and select AWS owned CMK.","correct":false},{"id":"2a13575a2661e32db0bdf9ad7b95ffee","text":"This cannot be done; DynamoDB does not support encryption at rest.","correct":false}]},{"id":"00544151-fdaf-446d-ade3-7d6988c9133d","domain":"deployment","question":"You are building a distributed application, which is made up of a number of Docker instances running on an ECS cluster. You would like to configure your application to send data to X-Ray. Where should you install the X-Ray daemon?","explanation":"In Amazon ECS, create a Docker image that runs the X-Ray daemon, upload it to a Docker image repository, and then deploy it to your Amazon ECS cluster. X-Ray provides an official Docker container image that you can deploy alongside your application.","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon-ecs.html","title":"Running the X-Ray daemon on Amazon ECS"}],"answers":[{"id":"5844e2a52b5fd5bfeeab3e714e68ba83","text":"Update the Docker image to include the X-Ray daemon and provision the new version of the application.","correct":false},{"id":"63a693207215523784e22cf504e4579b","text":"Install the X-Ray daemon on the same Docker container where the application code is running.","correct":false},{"id":"bfdfc3a1dc6179ede8ebcc926faacd94","text":"Install the X-Ray daemon on the EC2 instance where your Docker containers are running.","correct":false},{"id":"981d352ae2b571b99295e2880457f235","text":"Create a separate Docker image to run the X-Ray daemon.","correct":true}]},{"id":"dc3e7895-b954-4fa8-8d4f-faffeca401d2","domain":"security","question":"Which of the following methods will allow you to *securely* upload/download your data to the S3 service? Pick all that apply.","explanation":"You can securely upload/download your data to Amazon S3 via SSL endpoints using the HTTPS protocol.","links":[{"url":"https://aws.amazon.com/s3/faqs/#security","title":"S3 Security"}],"answers":[{"id":"937a8b8e84ad5481f1983a1842154e18","text":"HTTP endpoints using HTTP protocol","correct":false},{"id":"1019a747b087f11f97ef6a2bf46a1978","text":"HTTP endpoints using HTTPS protocol","correct":true},{"id":"d7ad40729fa333427d4d8c3032d43fdf","text":"SSL endpoints using HTTP protocol","correct":false},{"id":"2b716d646634dd42d3d1ab628b210081","text":"SSL endpoints using the HTTPS protocol","correct":true}]},{"id":"b41da940-4b4e-11ea-b77f-2e728ce88125","domain":"mon-trb","question":"You created a CloudFormation template that launched a web application in us-west-1. However, you are experiencing a problem creating a development stack in us-east-1 to serve clients in another geographical location. What should you do to solve the problem?","explanation":"An Amazon Machine Image, or AMI, is used to launch an EC2 instance in a specified region. So, to use it in another region, you will have to copy it to the region of your choice. Recreating the resources is unnecessary since you only need to copy the AMI. And the IAM role is irrelevant to the question, since IAM roles are valid across the entire AWS account.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"6971fa728cde2ee82b21faac08aeb60a","text":"Copy your IAM role to us-east-1 region so that you have permissions to deploy CloudFormation stacks in that region.","correct":false},{"id":"b5a9be3c7b03258224fb637458459b99","text":"Recreate the AWS resources used for the application in us-west-1.","correct":false},{"id":"e3bebd36eb37842d75a71b0a69c37abe","text":"Copy the AMI in the template from us-west-1 to us-east-1.","correct":true},{"id":"e72b5dc8983df71bdc1fa0c5b4985e4f","text":"Copy the AMI in the template from us-east-1 to us-west-1.","correct":false}]},{"id":"e629622d-44a7-4083-a9a7-fb3fdc722794","domain":"development","question":"An organization wishes to use CodeDeploy to automate its application deployments. The organization has asked a developer to advise on which of their services can integrate with CodeDeploy.\n\nWhich of the following services can the developer advise are compatible with CodeDeploy managed deployments?","explanation":"CodeDeploy supports EC2, ECS (both EC2 and Fargate), Lambda, and on-premise servers.","links":[{"url":"https://docs.aws.amazon.com/codedeploy/latest/userguide/primary-components.html","title":"CodeDeploy - supported compute platforms"}],"answers":[{"id":"43928686738b0bda305045d0551f9eb4","text":"S3 Static website hosting","correct":false},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":true},{"id":"1c94a6d4d0c7d6eb4ba63ba083edaab5","text":"Elastic Kubernetes Service pods","correct":false},{"id":"a6cf28d340be2c50ea43df2e6e98d2d1","text":"Fargate","correct":true},{"id":"8f852744b4deb867329697cf35ef908a","text":"On-premises servers","correct":true}]},{"id":"89d61903-935c-4301-b05d-ed8268a9831d","domain":"deployment","question":"An organization has adopted a new policy that all services should be built using AWS Serverless technology.\n\nWhich of the following AWS services could the organization use under this new policy?","explanation":"AWS consider S3, DynamoDB, and Fargate to be serverless services.","links":[{"url":"https://aws.amazon.com/serverless/","title":"The AWS serverless platform"}],"answers":[{"id":"a6cf28d340be2c50ea43df2e6e98d2d1","text":"Fargate","correct":true},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"81b22456f78954c460ce2f531b5e048f","text":"EC2","correct":false},{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":false},{"id":"0f41d6f36f8eaee87ea08d9f4b1159e2","text":"RDS","correct":false}]},{"id":"b419a913-a5f1-4ad2-8c06-3b579643d073","domain":"development","question":"Upon creating your code repository, you remember that you want to receive recommendations on improving the quality of the Java code for all pull requests in the repository. Which of the following services provide this ability?","explanation":"When creating your repository, you have the option of enabling 'Amazon CodeGuru Reviewer for Java.' This will automate reviews of your code to spot problems that can be hard for you to detect, in addition to the recommendations to fix the code. CodeGuru Reviewer would have been the correct answer, but it’s not specific to the type of code (always look for the *most* correct answer in exams.) Creating the repository itself requires the use of CodeCommit, which includes the 'Amazon CodeGuru Reviewer for Java' option; that’s why CodeCommit is the wrong answer. Finally, CodeBuild is for building code, rather than improving it.","links":[{"url":"https://docs.aws.amazon.com/codecommit/latest/userguide/pull-requests.html","title":"Working with Pull Requests in AWS CodeCommit Repositories"}],"answers":[{"id":"b9a2b9145e469fee4b348e257067e441","text":"CodeGuru Reviewer for Java","correct":true},{"id":"f8d1a2a80933c71d9a65e3d825976bda","text":"CodeBuild","correct":false},{"id":"f7f128d00b13b324ebd29c42f1037cf8","text":"CodeGuru Reviewer","correct":false},{"id":"56c20df941e069e1a35a1871f662298a","text":"CodeCommit","correct":false}]},{"id":"9822dfa6-67ab-47c1-9ee6-16f567e8f9ae","domain":"development","question":"You have created a DynamoDB table for your application with one partition key and no local secondary index. The table will include the following attributes: \nAccountID (partition key)\nAccountName\nReportingPeriod\nTotalRevenue\n You have an application running on EC2 that displays revenue data as a dashboard for your sales organization. The dashboard requires a view of total revenue over multiple reporting periods by customer name as a readable format. What secondary index will you need to add to your table?","explanation":"The requirement is for a particular CustomerName as it would be difficult for a reader to identity customers by their ID. We need a Global Secondary Index for a different partition key because a local secondary index must be created at the time you create a table. To retrieve only the time of interest, the ReportingPeriod must be the sort key. Finally, projecting TotalRevenue into the index will provide the necessary data to fulfill the requirement.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/SecondaryIndexes.html","title":"Improving Data Access with Secondary Indexes"}],"answers":[{"id":"5a18172e710f5f6e062e96ddfedb6f9b","text":"Global secondary index with a partition key of CustomerName and sort key of ReportingPeriod; project the TotalRevenue attribute","correct":true},{"id":"c923b638655c852ecf536b4a089fc8b3","text":"Local secondary index with a partition key of CustomerName and sort key of ReportingPeriod; project the TotalRevenue attribute","correct":false},{"id":"54b2fc130eec92721970eedc9f515ad9","text":"Global secondary index with a partition key of ReportingPeriod and sort key of CustomerName; project the TotalRevenue attribute","correct":false},{"id":"ce82afc52e016682dd4eb59cdcc0d6dd","text":"Local secondary index with a partition key of ReportingPeriod and sort key of CustomerName; project the TotalRevenue attribute","correct":false}]},{"id":"d38a2534-f7bb-4cc2-9b9a-0c50dfb7707b","domain":"security","question":"You are attempting to analyse the CloudWatch metrics for a number of your application servers, however when you try to view the metrics you cannot access them, however one of your colleagues is able to access them without any issues. What could be the problem?","explanation":"Access to Amazon CloudWatch Logs requires credentials that AWS can use to authenticate your requests. Those credentials must have permissions to access AWS resources, such as to retrieve CloudWatch Logs data about your cloud resources.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/auth-and-access-control-cw.html","title":"CloudWatch Access Control"}],"answers":[{"id":"691a929a32273fce2328658fc4c41fa6","text":"Your EC2 instance role does not have permission to push the metrics to CloudWatch","correct":false},{"id":"a0ff1e54243f914c3324d8826543cdd2","text":"Your IAM user doesn't have permission to view CloudWatch metrics","correct":true},{"id":"2578745b37e7d610c9f6227f920c4cb5","text":"CloudWatch doesn't have permission to collect the metrics","correct":false},{"id":"dcd1178c83830f41078c6b19fcd33f05","text":"The CloudWatch agent has stopped running","correct":false}]},{"id":"bfec04c8-32f9-42df-b7de-1ba954709dff","domain":"refactoring","question":"Using the AWS console, you are trying to Scale DynamoDB past its pre-configured maximums. Which service can you increase by raising a ticket to AWS support?","explanation":"Provisioned throughput limits","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html#default-limits-capacity-units-provisioned-throughput","title":"Capacity Units and Provisioned Throughput"}],"answers":[{"id":"3c11d73c8083e3aae0a758891afe3a0a","text":"Item Sizes","correct":false},{"id":"1ed115474e3650b86e2a64fa03839943","text":"Global Secondary Indexes","correct":false},{"id":"657289d6192c6cf5d405aa8b4596bd21","text":"Provisioned throughput limits","correct":true},{"id":"eb1167f3583beb42c4f2e414033c5ae6","text":"Local Secondary Indexes","correct":false}]},{"id":"c11f4354-0409-46a1-a058-1e377939c655","domain":"development","question":"You are in a development team working on a popular serverless web application which allows users to book late availability flights and hotels at a significant discount. You occasionally receive complaints that the website is running slowly. After some investigation, you notice that at the time of the complaints, DynamoDB reported a ProvisionedThroughputExceeded error. Which of the following approaches is a recommended way to handle this error?","explanation":"Increasing Lambda capacity will not fix the issue because the problem is with DynamoDB. As the error only appears occasionally, the first thing to do is to ensure that the application is using Exponential Backoff to improve flow control. Increasing the capacity on the DynamoDB table could be considered but only if the problem persists.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html#Programming.Errors.RetryAndBackoff","title":"DynamoDB Error Handling"}],"answers":[{"id":"528fd1044e587b850c48dc8d209cfe11","text":"Increase the read/write capacity of the DynamoDB table","correct":false},{"id":"e7668448048601413de55468a4091b5d","text":"Increase the RAM capacity of the Lambda function","correct":false},{"id":"cbf47ddd16d15ef42c8c335fe895c69f","text":"Increase the CPU capacity of the Lambda function","correct":false},{"id":"7f6f787080ee787e0f7554f770e0c693","text":"Ensure your application is using Exponential Backoff","correct":true}]},{"id":"52d02968-6d43-434e-8d41-eaa3d8e69b68","domain":"mon-trb","question":"You are trying to diagnose a performance problem with your serverless application, which uses Lambda, API Gateway, S3 and DynamoDB. Your DynamoDB table is performing well and you suspect that your Lambda function is taking too long to execute. Which of the following could you use to investigate the source of the issue?","explanation":"AWS X-Ray can be used to display a histogram showing the latency of your Lambda function. Latency is the amount of time between when a request starts and when it completes. API Gateway Integration Latency in the time between when API Gateway relays a request to the backend and when it receives a response from the backend. API Gateway Latency is the time between when API Gateway receives a request from a client and when it returns a response to the client. The latency includes the integration latency and other API Gateway overhead. Lambda Invocations Sum measures the number of times a function is invoked in response to an event or invocation API call.","links":[{"url":"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-metrics-and-dimensions.html","title":"API Gateway CloudWatch Metrics"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-metrics.html","title":"Lambda CloudWatch Metrics"},{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"},{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-console-histograms.html","title":"Using Latency Histograms in the AWS X-Ray Console"}],"answers":[{"id":"90099b94810e3f14b68c4739eb4c456c","text":"API Gateway Integration Latency metric in CloudWatch","correct":true},{"id":"3dc993924bceb799c7009d281aa91408","text":"AWS X-Ray","correct":true},{"id":"c464cce256f4ab986973ddae5e8fdf34","text":"Lambda Invocations Sum metric in CloudWatch","correct":false},{"id":"a8d172dc1d7797b755f243837a74be36","text":"API Gateway Latency metric in CloudWatch","correct":false}]},{"id":"ea9dc476-332a-424f-a806-8a535a8b516e","domain":"deployment","question":"You want to quickly deploy and manage an application in the AWS Cloud without having to learn about the infrastructure that runs the application. Elastic Beanstalk is the first service that comes to mind. You have written you application with C#. How would you launch your application on Elastic Beanstalk in the most efficient manner?","explanation":"AWS Elastic Beanstalk supports custom platforms which lets you develop an entire new platform from scratch, customizing the operating system, additional software, and scripts that Elastic Beanstalk runs on platform instances. This flexibility enables you to build a platform for an application that uses a language or other infrastructure software, for which Elastic Beanstalk doesn't provide a managed platform. In addition, with custom platforms you use an automated, scripted way to create and maintain your customization, whereas with custom images you make the changes manually over a running instance. Rewriting your application would not be the most efficient way if you can create your own platform. Launching an EC2 instance would still require you to manage your own infrastructure. OpsWorks manages infrastructure deployment by organizing applications into layers to provision EC2 instances and resources for an application.","links":[{"url":"https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/custom-platforms.html","title":"Elastic Beanstalk Custom Platforms"}],"answers":[{"id":"5d283fee57c43b00226df6388edd5bb7","text":"Use EC2 instance. Launch the application on an EC2 instance and use CloudFormation to automate infrastructure provisioning.","correct":false},{"id":"15978d42b93994c5fa1bdaaa66df8564","text":"Use AWS OpWorks instead to launch your application that will help automate deployment and configurations for your application.","correct":false},{"id":"0993d2ef16ec086413357c635d131d1c","text":"Create your own Elastic Beanstalk platform using Packer. Use this platform for your application.","correct":true},{"id":"a55638d3d79efef4debfe4f43fcf4c40","text":"Rewrite your application in Python as C# is not a supported programming language.","correct":false}]},{"id":"339adcf9-1e4b-4680-89d7-c123c6b2c310","domain":"deployment","question":"Which DynamoDB feature allows you to set an expiry on table items so that they can automatically be deleted to reduce storage costs?","explanation":"Time To Live (TTL) for DynamoDB allows you to define when items in a table expire so that they can be automatically deleted from the database. TTL is provided at no extra cost as a way to reduce storage usage and reduce the cost of storing irrelevant data without using provisioned throughput. With TTL enabled on a table, you can set a timestamp for deletion on a per-item basis, allowing you to limit storage usage to only those records that are relevant.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html","title":"DynamoDB TTL"}],"answers":[{"id":"23b12446c9410404041f4de88841a9c3","text":"DynamoDB Provisioned Throughput","correct":false},{"id":"1f60690ba7c488a02416a7bf195f900b","text":"DynamoDB Streams","correct":false},{"id":"52d5592ad24a2cda379ce38e9c218d65","text":"DynamoDB TTL","correct":true},{"id":"61cc6306baa4c0f3c5fe422a835c2455","text":"DynamoDB AutoDelete","correct":false}]},{"id":"9548796c-789c-42ea-9e90-3da3a9252c1b","domain":"security","question":"Your Security team have recently reviewed the security standards across your entire AWS environment. They have identified that a number of EC2 instances in your development environment have read and write access to an S3 bucket containing highly confidential production data. You have been asked to help investigate and suggest a way to remedy this. Which of the following can you use to find out what is going on so that you can suggest a solution?","explanation":"With the IAM policy simulator, you can test and troubleshoot IAM and resource-based policies attached to IAM users, groups, or roles in your AWS account. You can test which actions are allowed or denied by the selected policies for specific resources.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_testing-policies.html","title":"Testing IAM Policies with the IAM Policy Simulator"}],"answers":[{"id":"aac02aded2357ef60d7cc0b8f32df947","text":"Use CloudTrail and Athena to identify which role or policy is granting access","correct":false},{"id":"5bc514eb754ea13140481ed2afc68d45","text":"Use the VPC flow logs to identify which EC2 instances are attempting to access the bucket","correct":false},{"id":"17d9101067c49b2ec4b35087e24ce8eb","text":"Use the IAM Policy Simulator to identify which role or policy is granting access","correct":true},{"id":"58f20da8b31f9e9da2e5a374608338ef","text":"Use the CLI or console to check the public access permissions of the S3 bucket","correct":false}]},{"id":"096903dc-fa87-479f-a185-59f1128dffc4","domain":"refactoring","question":"You are developing a new application which allows users to search for parking spots in their local area. Your application is based on Lambda and uses API Gateway to connect to third party parking lot companies to access information about parking tariffs and availability. Your application stores session data in a DynamoDB table, however you want to keep costs to a minimum and would like to automatically delete the session data from the table once the user session has expired and the data is no longer relevant. How can you most easily achieve this?","explanation":"Time To Live (TTL) for DynamoDB allows you to define when items in a table expire so that they can be automatically deleted from the database. TTL is provided at no extra cost as a way to reduce storage usage and reduce the cost of storing irrelevant data without using provisioned throughput. With TTL enabled on a table, you can set a timestamp for deletion on a per-item basis, allowing you to limit storage usage to only those records that are relevant.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/TTL.html","title":"DynamoDB TTL"}],"answers":[{"id":"368bfaa4732707e475d4a566a7bfa0e0","text":"Use DynamoDB Streams to prune the table and remove any unwanted data","correct":false},{"id":"8a52edb7329e1e89781f22df0aa3c585","text":"Configure a TTL based on the session expiry time","correct":true},{"id":"02e9893b7f2e8c6dfa3bc682a2079313","text":"Write a Lambda function to continually poll the table to check if the session data has expired and then delete the item from the table","correct":false},{"id":"ebd2e6b8cdc90d9f3f3d2f1552acbe9b","text":"Use SNS to send a notification when the session data expires, then configure API Gateway to remove the unwanted data","correct":false}]},{"id":"51600664-99f9-48f5-97cc-ec860d378f89","domain":"development","question":"Which AWS service allows you to build and model your serverless application as a visual workflow consisting of a series of steps where the output of one stage can be input into another?","explanation":"Step Functions provide this functionality","links":[{"url":"https://aws.amazon.com/step-functions/faqs/","title":"Step Functions FAQ"}],"answers":[{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"1f4072738a4917bea022b11256fb46a4","text":"Simple Workflow Service","correct":false},{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":false},{"id":"42816db0ecfffdf3baff90b7f2545874","text":"Step Functions","correct":true}]},{"id":"5cd0d201-9b93-42f0-9ae7-585263307009","domain":"development","question":"You've been asked to create a Web application with an endpoint that can handle thousands of REST calls a minute.  What AWS service can be used in front of an application to assist in achieving this?","explanation":"Questions containing 'REST' are usually related to APIs, so API Gateway looks the best answer.  Elastic Beanstalk is a service which allows you to run applications without understanding the infrastructure and can be discounted, as can Global Accelerator which is a networking service that improves the availability and performance of applications.  CloudFront can be used in conjunction with API Gateway to assist in geographically disparate calls, but won't process calls by itself.","links":[{"url":"https://aws.amazon.com/api-gateway/faqs/","title":"Amazon API Gateway FAQs"}],"answers":[{"id":"3d6cbd7db2a4fa389808ea6f4a5fc1bc","text":"Elastic Beanstalk","correct":false},{"id":"9ce65e2b30ed635c84bef82218a94fdf","text":"Global Accelerator","correct":false},{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"2ef9dd82927a3196ca2df3fc0cdf2e0b","text":"API Gateway","correct":true}]},{"id":"aef3c172-a47c-4705-8241-936c06d9bb7c","domain":"development","question":"You have configured your CI/CD process using CodePipeline, however you want to introduce a manual sign-off and approval process which needs to be completed before a new version of your application is deployed to Production. How can you achieve this?","explanation":"With CodePipeline, you can add an approval action to a stage in a pipeline at the point where you want the pipeline execution to stop so that someone with the required AWS Identity and Access Management permissions can approve or reject the action.","links":[{"url":"https://docs.aws.amazon.com/codepipeline/latest/userguide/approvals.html","title":"Manual Approvals in CodePipeline"}],"answers":[{"id":"5c0749c1409b05011fac6531c17f2cf8","text":"Configure two pipelines, one to handle code build and test, and one to handle automated deployment. Use SNS and Lambda to trigger the Deployment Pipeline following notification of successful completion of the Build and Test Pipeline","correct":false},{"id":"dc965161695cb07b80f56150a5a689f1","text":"Use CodePipeline to handle build, compile, test and packaging activities, then manually start a CodeDeploy job to run an automated deployment of successfully tested code","correct":false},{"id":"fbfc1e99b3679cb29f80f55cf63c4a8d","text":"Use the CodePipeline Manual Approvals feature","correct":true},{"id":"e53c0ca92d915920a376534f6d7a4e99","text":"Configure MFA for CodeDeploy deployments","correct":false}]},{"id":"730a845f-ecf8-44f3-aedd-063e6c82f952","domain":"development","question":"A company is developing its first lambda function. The function needs access to their existing EC2 instances, which are all hosted in private subnets within their VPC.\n\nWhat must the company do to ensure their lambda can access the EC2 instances?","explanation":"To configure a lambda to connect to a VPC, one or more subnets into which it can connect must be defined.\n\nThe lambda function creates an Elastic Network Interface in one of the given subnets. It, therefore, needs an execution policy that allows it permissions to do so. The specific permissions required are in the attached AWS documentation link.\n\nThe Elastic Network Interface through which the lambda connects should then be associated with one or more security groups that allow network communication to the desired destinations, over the desired ports.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html","title":"Configuring a Lambda Function to Access Resources in a VPC"}],"answers":[{"id":"48e1378bc6d56c11575da9eaf6e585a1","text":"Configure lambda's execution role to have permissions for managing an ENI within the VPC.","correct":true},{"id":"3c5b22594c1609c3eb107b6bb74dd18a","text":"Configure the lambda function to connect the private subnets used by the EC2 instances.","correct":true},{"id":"58f3dd590a2af5106b444d3ba4135b92","text":"Configure the lambda's function policy to allow EC2 to involve the function.","correct":false},{"id":"dff8a08528259b15e8eaa21fd941b858","text":"Configure lambda's security group, so it has access to the EC2 instances.","correct":true},{"id":"b83e0ff6499487c14dfb5578bbd8f3d2","text":"Configure the lambda's execution role to match the role applied to your EC2 instances.","correct":false}]},{"id":"868cb94f-ce60-4590-bfd2-60e8295cc413","domain":"security","question":"You are developing a online-banking website which will be accessed by a global customer base. You are planning to use CloudFront to ensure users experience good performance regardless of their location. The Security Architect working on the project asks you to ensure that all requests to CloudFront are encrypted using HTTPS. How can you configure this?","explanation":"Viewer Protocol Policy defines the protocols which can be used to access CloudFront content","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-https-viewers-to-cloudfront.html","title":"Requiring HTTPS for Communication Between Viewers and CloudFront"}],"answers":[{"id":"ae41866f6b2df14a344847e9629076db","text":"Set the User Protocol Policy to redirect HTTP to HTTPS","correct":false},{"id":"659099387a57b1f316abf3c6afac459d","text":"Set the Session Protocol Policy to redirect HTTP to HTTPS","correct":false},{"id":"c40022183e6d5dd97e4c778332064ed2","text":"Set the Viewer Protocol Policy to redirect HTTP to HTTPS","correct":true},{"id":"052066815497ced9f9852e55d66c6782","text":"Set the Request Protocol Policy to redirect HTTP to HTTPS","correct":false}]},{"id":"f89a5f8e-ae8f-4ee6-842e-02f3101c7c60","domain":"development","question":"An application uses DynamoDB table as its backend data store. Each item has size of 10KB.  The application needs to perform 100 strongly consistent read operations per second, and 50 write operations per second.  What is the provisioned RCU value required to meet these requirements?","explanation":"1 RCU is equivalent to one strongly consistent read per second of an item up to 4KB in size.  Thus, to calculate the required RCU in this scenario we need to: 1) Round up the item size to the nearest 4KB (12KB). 2) Divide by 4KB to calculate number of strongly consistent read units (12/4 = 3). 3) Multiple by operations per second to get the total RCU required (3*100 = 300 RCU).","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html#HowItWorks.ProvisionedThroughput.Manual","title":"Provisioned Mode"}],"answers":[{"id":"7ef605fc8dba5425d6965fbd4c8fbe1f","text":"150","correct":false},{"id":"94f6d7e04a4d452035300f18b984988c","text":"300","correct":true},{"id":"cee631121c2ec9232f3a2f028ad5c89b","text":"500","correct":false},{"id":"a9b7ba70783b617e9998dc4dd82eb3c5","text":"1000","correct":false}]},{"id":"0c35721a-5f70-44fa-b450-3a734cffe32d","domain":"development","question":"You are working on an application which runs inside a Docker container. All your images are stored in a repository named mydockerrepo AWS ECR. Which of the following commands could you use to pull the Docker image to your local workstation?","explanation":"If you would like to run a Docker image that is available in Amazon ECR, you can pull it to your local environment with the docker pull command.","links":[{"url":"https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-pull-ecr-image.html","title":"Pulling an Image From ECR To Your Local Machine"}],"answers":[{"id":"d2b7e2822cfd2c34e140e5a2b38a8844","text":"docker clone aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":false},{"id":"3de38211ddfad5912196a8d85b693d6b","text":"docker push aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":false},{"id":"90dc63a057ad01f414275df9fe070ea1","text":"docker get aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":false},{"id":"2adf07d0af0f83b4c0e540b293950cae","text":"docker pull aws_account_id.dkr.ecr.us-west-2.amazonaws.com/mydockerrepo:latest","correct":true}]},{"id":"e2661600-6bfa-446a-8ff9-b760c629b0eb","domain":"deployment","question":"You need to push a docker image to your Amazon ECR repository called my-repository located in us-east-1. Which of the following commands do you need to run in order to achieve this?","explanation":"The aws ecr get-login command provides an authorization token that is valid for 12 hours. You need to run the command which was returned by the ecr get-login command to authorize you to push images to the ECR repository. For a full list of the steps, see the link below.","links":[{"url":"https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-basics.html","title":"Docker Basics for Amazon ECR"}],"answers":[{"id":"22f8f304a6f997cf4d1f481dab61b497","text":"Run: aws ecr get-login --no-include-email --region us-east-1 \r\r Then run: docker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-repository","correct":false},{"id":"b252c8c39c36e240388f79fe234c3fef","text":"Run: aws ecr get-login --no-include-email --region us-east-1 \r\r Run the docker login command that was returned in the previous step. \r\r Then run: docker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-repository","correct":true},{"id":"014712b54a814d72bd175deae6bdb942","text":"Run: docker push -i my-image -r 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-repository","correct":false},{"id":"6d72d9334d7aba24d31008dc69bcacb1","text":"Run: docker tag -i my-image latest \r\r Then run: docker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-repository","correct":true}]},{"id":"2988d8a0-c66e-434f-948b-acee623892fc","domain":"mon-trb","question":"You work for an electric car company that has its front-end website on EC2. Company policy dictates that you must retain a history of all EC2 API calls made on your account for security analysis and operational troubleshooting purposes. Which AWS service should you use to do this?","explanation":"CloudTrail is a web service that records AWS API calls for your AWS account and delivers log files to an Amazon S3 bucket. The recorded information includes the identity of the user, the start time of the AWS API call, the source IP address, the request parameters, and the response elements returned by the service.","links":[{"url":"https://aws.amazon.com/documentation/cloudtrail/","title":"CloudTrail Overview"}],"answers":[{"id":"a907a7338c1fb3821fbe8ed113c64b33","text":"CloudHSM","correct":false},{"id":"bef6cb89241de238f082cb243307ad1b","text":"CloudFront","correct":false},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true}]},{"id":"4750f3bd-de92-4efb-ad08-06c9ea71eccb","domain":"refactoring","question":"Kinesis allows consumer applications to consume records in which order?","explanation":"Kinesis gives you the ability to consume records according to a sequence number applied when data is written to the Kinesis shard","links":[{"url":"https://aws.amazon.com/kinesis/data-streams/faqs/","title":"Kinesis FAQ"}],"answers":[{"id":"689f6f887e0c13fb07b437de23303cac","text":"Last In First Out","correct":false},{"id":"e71e8f5a50819b4773c68991d0c9f602","text":"Records are processed in no particular order","correct":false},{"id":"cb1ab21304b72197113dbe18c491e9c2","text":"According a sequence number assigned when the record is written to the stream","correct":true},{"id":"b1e05f0db70da1b8dee8592d942ed2e1","text":"According to the timestamp assigned when the record is written to the stream","correct":false}]},{"id":"1256624a-ca55-4279-94ef-95dd891413b0","domain":"development","question":"Which of the following AWS services would you recommend using to store session state data for a scalable web application?","explanation":"Storing session state locally is not a good idea for a scalable application, so it doesn't make sense to store the session state on the EC2 instance. Lambda is generally for short-lived functions which do not persist, so is not suitable for managing session state. Glacier is designed for archiving infrequently used data so is not suitable for session data which could be frequently used for the lifetime of the session and then no longer required. In order to address scalability and to provide a shared data storage for sessions that can be accessed from any individual web server, you can abstract the HTTP sessions from the web servers themselves. A common solution to for this is to leverage an In-Memory Key/Value store such as Redis and Memcached, and in AWS the service to use is ElastiCache.","links":[{"url":"https://aws.amazon.com/caching/session-management/","title":"Session Management"}],"answers":[{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":true},{"id":"04f055bdce7b135b43773f720d011d7c","text":"EC2 instance memory","correct":false},{"id":"4def2a084469f97f6372bfaf0823941b","text":"Glacier","correct":false},{"id":"04a7da3c5b04cad85da1eebb92315b8b","text":"Lambda","correct":false},{"id":"18a293ade3b7503fb165b9b2805ed819","text":"EC2 instance EBS volume","correct":false}]},{"id":"568cf3e4-6a2b-45ba-b757-85c86ce73d28","domain":"security","question":"You have developed a Lambda function that is triggered by an application running on EC2. The Lambda function currently has an execution role that allows read/write access to EC2, and also has the AWSLambdaBasicExecutionRole managed policy attached. After some architectural changes in your environment, the Lambda now needs to access some data stored in S3. What changes are required for your Lambda function to fulfill this new task of accessing data in S3?","explanation":"An AWS Lambda function's execution role grants it permission to access AWS services and resources. You provide this role when you create a function, and Lambda assumes the role when your function is invoked. You can update (add or remove) the permissions of a function's execution role at any time, or configure your function to use a different role. Add permissions for any services that your function calls with the AWS SDK, and for services that Lambda uses to enable optional features. The AWSLambdaBasicExecutionRole AWS managed policy grants Lambda the permissions to upload logs to CloudWatch. This policy alone will not grant it access to S3. You do not need to create a new function as you can add or remove permissions to an execution role at any time. Resource-based policies let you grant usage permission to other accounts on a per-resource basis, and allow an AWS service to invoke your function, so this is not a valid way to grant S3 permissions to the existing Lambda function.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/lambda-intro-execution-role.html","title":"AWS Lambda Execution Role"}],"answers":[{"id":"dae063c524a98eabfaeaa70e40596b81","text":"Add permissions to the function's execution role to grant it the necessary access to S3 in IAM.","correct":true},{"id":"1a1fe1fdb3d8e50808815f68b78e639b","text":"Create a new Lambda function with the an execution role allowing read/write access to EC2 and S3 since you cannot add permissions to a function's execution role.","correct":false},{"id":"1e059c60ffc293b2a874fa9361fc289d","text":"No changes are required. The function has all the permissions it needs to access S3.","correct":false},{"id":"a8765dde924111c8a27595676fc0cfac","text":"Attach a resource-based policy to the Lambda function that will allow it to access the S3 bucket resource.","correct":false}]},{"id":"cd7c8d61-2ce7-401a-956f-c01c33305ae2","domain":"deployment","question":"Which of the following statements is correct?","explanation":"EBS-backed instances can be stopped and restarted without losing the data on the volume.","links":[{"url":"https://aws.amazon.com/premiumsupport/knowledge-center/instance-store-vs-ebs/","title":"Differences between EBS and Instance Store"}],"answers":[{"id":"91fff5146ee33778a9158bd16a8ba469","text":"An Amazon VPC requires that instances be backed with EBS.","correct":false},{"id":"b335920b9f6cd5d6425a787a6183b378","text":"If you want to use auto-scaling, you must use an EBS-backed instance.","correct":false},{"id":"36e118d467e9fcf94627a5fa1bc11446","text":"Instance-store backed instances can be stopped and restarted.","correct":false},{"id":"18eb677e835b4b7214b432d085e121fb","text":"An EBS backed instance can be stopped and restarted.","correct":true}]},{"id":"322048b9-4d49-4c64-8aca-c7479619982a","domain":"mon-trb","question":"Your company is reaching the end of the financial year and the Finance team are running a lot of large database queries and scans against your DynamoDB tables. The database queries and scans are taking much longer to complete than expected, how can you make them more efficient?","explanation":"Reducing page size for queries and running scans in parallel are both recommended approaches for making DynamoDB operations more efficient. DynamoDB uses eventually consistent reads by default and filtering the results will not improve efficiency","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-query-scan.html","title":"Best Practices for Querying and Scanning Data"}],"answers":[{"id":"60e26c5aacc3bba5083560f51b354c87","text":"Reduce the page size to return fewer items per results page","correct":true},{"id":"c6c36956db297a402f3fef1bf83c4c7e","text":"Filter your results based on the Primary Key and Sort Key","correct":false},{"id":"867b7b3ff3ddfb076ff319ce80e543c5","text":"Run parallel scans","correct":true},{"id":"e131078f81b76b76be2718610cc739a9","text":"Set your queries to be eventually consistent","correct":false}]},{"id":"c1fc5f56-f74e-405f-a974-d9bb2e2c57e6","domain":"deployment","question":"You have deployed a new version of your Lambda function, however during testing, you notice that  your application is not behaving as expected. How can you roll back to the previous version of your code?","explanation":"Remapping the PROD alias to the previous version will allow you to quickly roll back","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda versioning and Aliases"}],"answers":[{"id":"aa97bfdc9437ce44352de51699501c4d","text":"Make a new version of your function using the original Lambda code","correct":false},{"id":"60682da7d7f6df421c71e7e42cf4b227","text":"Redeploy your original code to $LATEST","correct":false},{"id":"28ab809ddc3a2aee352db2592bca020a","text":"Remap the PROD alias to point to the previous version of your function","correct":true},{"id":"1ba636d1ad4c4e2a9239fc75d17ffc41","text":"Update the $LATEST alias to point to the previous version of your function","correct":false}]},{"id":"0f02f4b2-9d11-4efb-b467-19bc558ef33d","domain":"security","question":"Your application on EC2 must write to an Aurora cluster to store user and purchasing data. Your CISO implements a new company-wide policy that requires all AWS credentials are encrypted and rotated monthly. How would you fulfill the new security policy with minimum administrative burden?","explanation":"AWS designed IAM roles so that your applications can securely make API requests from your instances, without requiring you to manage the security credentials that the applications use. IAM roles are based on temporary security tokens, so they are rotated automatically. Credentials embedded in source code cannot be rotated without it being an administrative burden, and is a bad practice. It’s impossible to retrieve credentials from an S3 bucket if you don’t already have credentials for that bucket. IAM users cannot be associated with resources, and Active Directory authorization will not grant access to AWS resources.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html","title":"IAM Roles for Amazon EC2"}],"answers":[{"id":"c3e276ad3302f173e7d92b40534f2074","text":"Allow the application to fetch the credentials from an S3 bucket with SSE-S3. Upload new credentials monthly.","correct":false},{"id":"fc14a6fe77ae1367c0f776ae96c7379c","text":"Attach an IAM role to the instance with proper credentials.","correct":true},{"id":"5fa27e0170ca1f467557d0d8db5502ff","text":"Encrypt the Aurora clusters' credentials using SHA-256 hash function in the application code, and schedule a CRON job to rotate monthly.","correct":false},{"id":"05a57da8fa8c802639a4f49ed0d59116","text":"Associate an IAM user with the application. Enroll that user with your Active Directory domain to use AD authorization.","correct":false}]},{"id":"b6e02165-99c1-465f-b270-e95ed7b282c6","domain":"deployment","question":"Your distributed application sends and receives a number of large SQS messages, each of which can be up to 2GB in size. You are finding that the messages in one particular queue are getting processed a few seconds faster than expected which is causing problems in your application. The application architect has asked you to introduce a sleep period of 5 seconds which should apply to all the messages in the queue and you have also been asked to avoid storing large amounts of data in SQS. Which of the following changes do you recommend?","explanation":"Delay queues let you postpone the delivery of new messages to a queue for a number of seconds. If you create a delay queue, any messages that you send to the queue remain invisible to consumers for the duration of the delay period. You can use Amazon S3 and the Amazon SQS Extended Client Library for Java to manage Amazon SQS messages. This is especially useful for storing and consuming messages up to 2 GB in size. Unless your application requires repeatedly creating queues and leaving them inactive or storing large amounts of data in your queue, consider using Amazon S3 for storing your data.","links":[{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-delay-queues.html","title":"SQS Delay Queues"},{"url":"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html","title":"Managing Large Amazon SQS Messages Using Amazon S3"}],"answers":[{"id":"3b29dadac2fdd775f1294d12bdccec11","text":"Store the large messages in a separate queue","correct":false},{"id":"a41630268ea2c21362c11173dd3e5ff1","text":"Store the large messages in DynamoDB","correct":false},{"id":"afb12b79c99a2eeace3a062cd3ad4cd6","text":"Use a FIFO queue to postpone the delivery of SQS messages by 5 seconds","correct":false},{"id":"1f11b5e76705a7428ff631dfaae81308","text":"Store the large messages on S3","correct":true},{"id":"64c850e3b6d5e1a54696ff59341cffc2","text":"Use an SQS delay queue to let you postpone the delivery of SQS messages by 5 seconds","correct":true}]},{"id":"c793570e-264f-4352-8ba9-2c2f3cf6a7e0","domain":"refactoring","question":"A enterprise company is migrating their ERP system from on-premise to AWS.  The ERP system comprises of a stateful web application operating over HTTP. Various components of the system are being implemented as microservices utilizing Docker. What load balancer configuration would be a suitable solution for the ERP system migration to AWS?","explanation":"AWS Application Load Balancer receives incoming traffic and distributes the requests across targets based on evaluation of listener rules. As such, it serves as a load balancer service in AWS. More specifically, AWS Application Load Balancer works at layer 7 of the OSI model, and supports HTTP traffic. Additionally, it provides path based routing thus enabling forwarding of requests based on URL. This functionality supports microservices architecture proposed in the question. Lastly, AWS Application Load Balancer supports sticky sessions, enabling stateful applications. This meets all the requirements specified in the question scenario. Classic Load Balancer supports traffic at layer 7 (HTTP) and sticky sessions. However, it does not provide path based routing ability necessary for a microservices application design. Network load balancer operates at layer 4 of the OSI model, and thus is not appropriate for this scenario. Route53 is used to distribute traffic across geographical regions and so it is not suitable solution in this case.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html","title":"What Is an Application Load Balancer?"}],"answers":[{"id":"c92cf9cdebc4be47d4192cffa30a533d","text":"Classic Load Balancer with sticky sessions.","correct":false},{"id":"9bc634e1e1185d8d1e5b96383c28b28a","text":"Application Load Balancer with sticky sessions.","correct":true},{"id":"2c25600a1df6a32f15194f6fa7c5d056","text":"Network Load Balancer with an Elastic IP.","correct":false},{"id":"fca383fefad22bd3ef8d6ac8a24503c8","text":"Route53 with a CNAME and a CloudFront distribution.","correct":false}]},{"id":"08861bdf-6813-43f1-9def-4255492b4533","domain":"mon-trb","question":"Your application is using SQS to send and receive messages, your application needs to receive the messages as soon as they arrive and you need to ensure the architecture is as cost efficient as possible. Which of the following approaches will optimise the cost and performance of the application?","explanation":"In almost all cases, Amazon SQS long polling is preferable to short polling and results in higher performance and reduced cost in the majority of use cases.","links":[{"url":"https://aws.amazon.com/sqs/faqs/","title":"SQS FAQs"}],"answers":[{"id":"33e24a8e438593d0ed4994ce9ea68ccd","text":"Enable Long Polling","correct":true},{"id":"9ef993bf7e61fa02b5f6ac0fc8da6b18","text":"Enable Short Polling","correct":false},{"id":"8757c7e091bc29e7b9225334f00531ac","text":"Reduce the total number of message queues","correct":false},{"id":"64dab6674843dc03406bdc90b1c5b21d","text":"Lower the message Visibility Timeout","correct":false}]},{"id":"58b4c9fa-13b1-4ecf-ad3b-27db3cf299f6","domain":"mon-trb","question":"Which service can you use to analyze and debug distributed applications, identify issues and locate performance bottlenecks?","explanation":"X-Ray allows you to debug distributed, Serverless and micro-services based applications. CloudTrail is used for auditing activity in your AWS account, CloudWatch and Systems Manager do not give an end-to-end view of your application.","links":[{"url":"https://aws.amazon.com/xray/faqs/","title":"X-Ray FAQs"}],"answers":[{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"0863526e514d88cd2d00b39f8dda0920","text":"X-Ray","correct":true},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"8e75b153e61c22a8ea4e14aadc7cb4ee","text":"Systems Manager","correct":false}]},{"id":"18db8cf0-407c-4547-a64f-eabdcbf3566a","domain":"development","question":"Which of the following DynamoDB features allows Items to be automatically deleted at a given date and time?","explanation":"DynamoDB TTL allows each Item to include a date and time at which DynamoDB will automatically delete the Item.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/howitworks-ttl.html","title":"Time to Live: How It Works"}],"answers":[{"id":"fdce91249547ab22d875d26aad3493bd","text":"DynamoDB auto-delete","correct":false},{"id":"f15851a368334eb82668e066053bb738","text":"DynamoDB Timeout","correct":false},{"id":"52d5592ad24a2cda379ce38e9c218d65","text":"DynamoDB TTL","correct":true},{"id":"b0d30a23fde41c669e0592b4be4d6093","text":"DynamoDB Exponential Backoff","correct":false}]},{"id":"25cc389e-1ceb-4b17-b717-9458a1b8e133","domain":"security","question":"One of your junior developers has never had AWS Access before and needs access to an Elastic Load Balancer in your custom VPC. This is the first and only time she will need access. Which of the following choices is the most secure way to grant this access?","explanation":"It's always best practice to grant users access via IAM roles and groups. In this case, we would *not* assign the junior Dev to an existing group, as most Dev groups will have *more* access than is required for this Dev to perform the single task she has been asked to accomplish. Remember - always grant the *fewest* privileges possible.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege","title":"Least Privilege"}],"answers":[{"id":"965dceca3b86aea95ef5de037128780c","text":"None of these.","correct":false},{"id":"2a067a28bf5990259e24ae36fff49ad3","text":"Let her log in with Admin credentials and change the Admin password when she is finished.","correct":false},{"id":"89c57f09d4cfd1c434b46868a4f3e488","text":"Add that developer to a Group with the requisite access (although that group may have *more* permissions than are needed for the Dev to do her job).","correct":false},{"id":"f204900100e4e11c7582843062170feb","text":"Create a new IAM user with *only* the required credentials and delete that IAM user after the developer has finished her work.","correct":true}]},{"id":"fe61a353-eb18-40dc-9e65-30f7106d3e6e","domain":"mon-trb","question":"Your application is running on EC2 and on Linux virtual machines in your own data center. You would like to configure your application to send data to X-Ray for troubleshooting and performance analysis. Which of the following steps will you need to complete?","explanation":"You need the X-Ray SDK and the X-Ray daemon on your EC2 instances and on-premises systems, you then need to instrument your application to send the required data to X-Ray","links":[{"url":"https://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html","title":"X-Ray Developer Guide"}],"answers":[{"id":"da1eaa5b340d64b20d5b526dc0de4b85","text":"Install the X-Ray SDK and the X-Ray daemon, then instrument your application to send data to X-Ray.","correct":true},{"id":"998a1f353d1923ec24b66b6ae427d343","text":"Install the X-Ray daemon, then instrument your application to send data to X-Ray.","correct":false},{"id":"ff31ac1442cb9f28ad8f65a358816a25","text":"Install the AWS SDK and the X-Ray CLI, then instrument your application to send data to X-Ray.","correct":false},{"id":"6ffb986aa2b49eb856b38668f9a44fc2","text":"Install the AWS CLI, then instrument your application to send data to X-Ray.","correct":false}]},{"id":"e475aa36-e8a9-4d0d-81db-abf30a055ef5","domain":"mon-trb","question":"How can you configure CodeBuild to notify the DevOps team of a failure in the build process?","explanation":"CodeBuild natively supports CloudWatch Events, SNS is a subscription based notification service which integrates with CloudWatch.","links":[{"url":"https://docs.aws.amazon.com/codebuild/latest/userguide/sample-build-notifications.html","title":"Build Notifications"}],"answers":[{"id":"1448724d0c2de970718ae2bfe3159256","text":"Use CloudWatch Events and SES notifications to send an email to the DevOps team","correct":false},{"id":"4a31b4240a14801eefb085b05f7985a6","text":"Use CloudWatch Events and an SNS topic to notify subscribers of build events","correct":true},{"id":"d6c5ab1abdce3cd74b1ebe325b88d27e","text":"Use the CodePipeline dashboard to view the CodeBuild events log","correct":false},{"id":"571ab39fe2270d1c1193587ccfd234f1","text":"Add the name of the email group to the notifications section of the CodeBuild console","correct":false}]},{"id":"0d9472d0-587b-4961-9457-e37e75979b7c","domain":"development","question":"You are working on a Serverless application written in Python and running in Lambda. You have uploaded multiple versions of your code to Lambda, but would like to make sure your test environment always utilizes the latest version. How can you configure this?","explanation":"When you create a Lambda function, there is only one version: $LATEST. You can refer to the function using its Amazon Resource Name (ARN). There are two ARNs associated with this initial version, the qualified ARN which is the function ARN plus a version suffix e.g. $LATEST. Or the unqualified ARN which is the function ARN without the version suffix. The function version for an unqualified function always maps to $LATEST, so you can access the latest version using either the qualified ARN with $LATEST, or the unqualified function ARN. Lambda also supports creating aliases for each of your Lambda function versions. An alias is a pointer to a specific Lambda function version, aliases will not be updated automatically when a new version of the function becomes available.","links":[{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-intro.html","title":"Introduction To Lambda Function Versioning"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html","title":"Lambda Function Versioning and Aliases"},{"url":"https://docs.aws.amazon.com/lambda/latest/dg/how-to-manage-versioning.html","title":"Lambda Versioning"}],"answers":[{"id":"0311fc386b14ce5afd0843ecf4a6ff16","text":"Create another function to automatically update your function alias to point to the latest version of the code every time it is updated","correct":false},{"id":"cc67dedc36d230ab3574dc07b41b7443","text":"Configure the alias to automatically update to point to the latest version of the code every time it is updated","correct":false},{"id":"02f663ae252fea90c711171a5572d211","text":"Reference the function using a qualified ARN and the $LATEST suffix","correct":true},{"id":"d483464867986a2d830ac23858944891","text":"Create an alias to point to the correct version of your code","correct":false},{"id":"07c1095b47175c42406ba59e91205281","text":"Reference the function using an unqualified ARN","correct":true}]},{"id":"3eb49e2e-25b6-4fe6-8bbe-e3ccedcd1efd","domain":"security","question":"A developer is looking to implement a load balancing solution for web-based service oriented application deployed in AWS EC2. The solution must support path based routing and all communication to the users must be encrypted. What is the most performant method to achieve these requirement?","explanation":"The application requirement states support for path based routing. This means that we must use an Application Load Balancer as Network Load Balancer does not have this feature. It is best practice to deploy the SSL certificates on the Load Balancer. This implements SSL termination on the load balancer and off-loads this task from the application, thus reducing the load on EC2 instances. Additionally, it removes the requirement of distributing the certificate to all target EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html","title":"Create an HTTPS Listener for Your Application Load Balancer"}],"answers":[{"id":"a5a020608230cb06058ddd6291c7886a","text":"Use Application Load Balancer. Deploy SSL certificates on the EC2 instances.","correct":false},{"id":"b97b895cbdc513c48c5bfb7564a38aa7","text":"Use Network Load Balancer. Deploy SSL certificates on the EC2 instances.","correct":false},{"id":"206131d0e41aa9e13214ac701d6f08e2","text":"Use Application Load Balancer. Deploy SSL certificate on the Application Load Balancer.","correct":true},{"id":"7ebcbebf7f00c8f17f377813b31cc76e","text":"Use Network Load Balancer. Deploy SSL certificates on the Network Load Balancer.","correct":false}]},{"id":"d33e682c-89d2-4932-9b6d-a8095809bd88","domain":"deployment","question":"You are using CloudFormation to automate the build of several application servers in your test environment. Which of the following are valid sections that can be used in your CloudFormation template?","explanation":"Parameters, Resources and Outputs are all valid. It is worth learning the CloudFormation template anatomy and understanding how each section relates.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"}],"answers":[{"id":"ee611c8b9dfbbc792a9318c9837b2bcd","text":"Inputs","correct":false},{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":true},{"id":"e4ba47693cf74a797e63f4557d4b88f4","text":"Transformations","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":true}]},{"id":"9abb4110-4b7b-11ea-b77f-2e728ce88125","domain":"development","question":"You want to add a cross-origin resource sharing (CORS) configuration to one of your S3 buckets. Which of the following tabs should you choose to do so?","explanation":"To add a CORS configuration to your S3 bucket, you have to click the 'Permissions' tab and choose 'CORS configuration'. The 'Properties' tab is for configuring object settings such as versioning, transfer acceleration, and logging. The 'Management' tab is for managing object replication, analytics, and storage lifecycle. If you want to simplify bucket access by creating endpoints, you choose 'Access points'.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/user-guide/add-cors-configuration.html","title":"How Do I Add Cross-Domain Resource Sharing with CORS?"}],"answers":[{"id":"9fc2d28c05ed9eb1d75ba4465abf15a9","text":"Properties","correct":false},{"id":"d08ccf52b4cdd08e41cfb99ec42e0b29","text":"Permissions","correct":true},{"id":"fe4dbcab9b910577e5035e97ac068dae","text":"Management","correct":false},{"id":"902c305d02b28c2f6199601e7128ed36","text":"Access points","correct":false}]},{"id":"9382a270-2c44-45b2-95f3-79d0cf319120","domain":"mon-trb","question":"A developer has been tasked with enabling Access Logs on the Application Load Balancer that sits in-front of their web services. As part of this task, they must configure a location to which the logs are delivered.\n\nTo what AWS service can Access Logs from an Application Load Balancer be delivered?","explanation":"S3 is the only service supported by AWS for receiving ALB access logs.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html","title":"Application Load Balancer Access Logs"}],"answers":[{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":false},{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false},{"id":"594025cae6dfa6b9073dc25de93ddb56","text":"Kinesis","correct":false},{"id":"e2ab7c65b21ed8cc1c3b642b5e36429e","text":"S3","correct":true}]},{"id":"0dfd155c-e9fa-4a85-baba-ba51ae43d152","domain":"deployment","question":"As a developer you have built a WordPress site. Traffic to the site has increased and you have improved the site's functionality to meet the demand of your viewers since launch. Changes are coming frequently, and you are considering using AWS CloudFormation to automate the process of building test stacks, creating a change set, and executing the change set. How would you streamline this process in AWS most efficiently?","explanation":"Continuous delivery is a release practice in which code changes are automatically built, tested, and prepared for release to production. With AWS CloudFormation and CodePipeline, you can use continuous delivery to automatically build and test changes to your AWS CloudFormation templates before promoting them to production stacks. This release process lets you rapidly and reliably make changes to your AWS infrastructure. Although you can manually interact with CloudFormation to execute the various stages, this is not the most efficient method. Amazon Inspector is an automated security assessment service which evaluates the security loopholes in deployed resources specific to EC2. Config is a monitoring and governance tool that tracks changes to your AWS environment based on rules you configure.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/continuous-delivery-codepipeline-basic-walkthrough.html","title":"Walkthrough: Building a Pipeline for Test and Production Stacks"}],"answers":[{"id":"6e617dd2e008968aea6984c58b17c139","text":"Use Amazon Inspector to monitor your CloudFormation environment that will send an SNS notification to Lambda when a pipeline stage is complete. Subscribe the Lambda function to the SNS topic.","correct":false},{"id":"87149b0d9dbfaac4e8ba219e908d57a1","text":"Build your test stack, create a change set, and then execute the change set by manually interacting with AWS CloudFormation.","correct":false},{"id":"1498c0d02e9c619808313a425479642f","text":"Create a CodePipeline separated by three stages. For each stage organize actions in a pipeline. Have CodePipeline complete all actions in a stage before the stage processes new artifacts.","correct":true},{"id":"4b808c56dbbec61b1137c70708faf855","text":"Create a Config rule that will look for changes within your CloudFormation stack that will trigger Lambda functions to execute actions based on the pipeline.","correct":false}]}]}}}}
