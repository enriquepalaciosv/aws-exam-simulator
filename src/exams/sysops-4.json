{"data":{"createNewExamAttempt":{"attempt":{"id":"784bf870-0117-4a20-9b9f-e2f283de01c5"},"exam":{"id":"3ec03e92-073e-458d-a039-55597182e628","title":"AWS Certified SysOps Administrator - Associate Exam","duration":7800,"totalQuestions":65,"questions":[{"id":"9c6bdf99-3728-43be-9772-59500b1f2276","domain":"dep-prov","question":"A team of developers plans to migrate their GraphQL-powered web application to AWS and the development lead has been instructed to use managed services whenever possible. How can the team accomplish this?","explanation":"API Gateway is used for RESTful applications. AWS AppSync is used for GraphQL powered applications. RDS and DynamoDB are managed database services but Amazon EC2 is not a managed service.","links":[{"url":"https://docs.aws.amazon.com/appsync/latest/devguide/designing-a-graphql-api.html","title":"Designing a GraphQL API"}],"answers":[{"id":"6f76fbab4996d8c8cb993a9c4569275b","text":"Use API Gateway for the GraphQL API. Use DynamoDB for the managed database service.","correct":false},{"id":"13017b9feb28c5d8fdda19e3c79df90d","text":"Use AppSync for the GraphQL API. Use DynamoDB for the managed database service.","correct":true},{"id":"58fa18d14ef959d0d59e88ef26f8c391","text":"Use Amazon EC2 for the GraphQL API. Use RDS for the managed database service.","correct":false},{"id":"4481f8f19e1b5f28da2b0f396643167b","text":"Use Lambda for the GraphQL API. Use RDS for the managed database service.","correct":false}]},{"id":"44eb75dc-1cf8-47bc-a6c4-7eb3551d39ad","domain":"dep-prov","question":"Your team uses Docker to build and install a new application. You need to deploy it with Amazon Elastic Container Service (Amazon ECS). You create an Auto Scaling group using an ECS optimized AMI as the ECS cluster. You also define a task definition and specify the number of tasks that will run on the cluster. Which of the following is responsible for starting and stopping tasks when it receives a request from Amazon ECS?","explanation":"The ECS optimized AMI has the ECS container agent installed and it communicates with the ECS service. It sends information about the current running tasks to Amazon ECS, and schedules tasks whenever receiving requests from Amazon ECS. ECS task definition does not schedule tasks. Fargate agent is used for Fargate instead of ECS. Elastic Container Registry saves Docker images but does not start/stop ECS tasks.","links":[{"url":"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html","title":"ECS agent"}],"answers":[{"id":"69c4feff2c34858d768595502051dddb","text":"AWS ECS Fargate agent.","correct":false},{"id":"1f773c4abe01e9ac9ea69a8467588e92","text":"Amazon Elastic Container Registry.","correct":false},{"id":"6da0c2a81f282023e97f7cb2e6d2afde","text":"The Amazon ECS task definition.","correct":false},{"id":"77d3861f206ed0b395e521eef335a70e","text":"The ECS container agent running on ECS container instances.","correct":true}]},{"id":"43f0527f-8ffc-49c2-8dd8-f55203c05f15","domain":"data-man","question":"A company has a local data center that stores satellite images and the company plans to migrate the image files to AWS S3 or Glacier. The total amount of data is about 100TB. The local network speed is slow so it is not applicable to transfer the files over the internet. Which of the provided options is the best to migrate the data to AWS?","explanation":"AWS Snowball is a recommended data transport solution that accelerates moving terabytes to petabytes of data to AWS. AWS Transfer for SFTP uses the internet so it is eliminated. VPN also relies on the network connection and it cannot accelerate the data transfer. AWS Storage File Gateway is a storage service to integrate with on-premises server. It is not used to migrate data to AWS.","links":[{"url":"https://docs.aws.amazon.com/whitepapers/latest/aws-overview/migration-services.html#aws-snowball","title":"Migration and Transfer solutions"}],"answers":[{"id":"4713a94f713bbca5a4e46d58447eb1cf","text":"Configure the VPN direct connection from the local data center to AWS VPC. Copy over the files using the high speed intranet.","correct":false},{"id":"8ebed8f00ea6cd51a35c7bfbc4a1b000","text":"Create a high speed AWS Storage File Gateway to map all the local files to S3 or Glacier.","correct":false},{"id":"49088421573ec1c3f93f7588fb78704f","text":"Create an AWS Snowball job and transfer files to the Snowball hardware. After the device is shipped back, AWS is in charge of storing data in S3 or Glacier.","correct":true},{"id":"d21889436bedfa9ee6bd66e73efdc3f0","text":"Configure the AWS Transfer for SFTP service to seamlessly migrate files to AWS S3 or Glacier.","correct":false}]},{"id":"9de05324-9d1a-4252-a6ed-c8bc6e732afe","domain":"dep-prov","question":"You use a launch template to create an Auto Scaling group for an application. You need to ensure a number of EC2 instances are always online to meet minimum capacity requirements and also use lower priced instances when scaling up. Which of the following instance combinations would be the most cost effective solution to use in the Auto Scaling group?","explanation":"A combination of on-demand instances and spot instances should be launched to meet the target capacity that you specified in the spot fleet request. The on-demand instances ensure the minimum capacities are met and the spot instances provide extra capacity as the application scales up. The other options without the spot instances are not cost-efficient. And scheduled reserved instances do not run continuously and should not be selected.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html","title":"How spot fleet works"}],"answers":[{"id":"8f81bfbb0090b9ecba50b69be972ec7b","text":"Dedicated instances + on-demand instances","correct":false},{"id":"853ea21196f8eeabab96ee1faf8cb4bf","text":"On-demand instances + spot instances","correct":true},{"id":"eeea48d3cb7324682811fe139fd30093","text":"Scheduled reserved instances + spot instances","correct":false},{"id":"da8d4ca080444c6f36c71ed68a3c9a8f","text":"Reserved instances + on-demand instances","correct":false}]},{"id":"05d71be4-026e-433e-bd8b-eb4a3929ba63","domain":"automation","question":"A development team wants to use the latest Windows AMI whenever they launch an EC2 instance. Which service will allow them to query the AWS-managed Parameter Store namespace to retrieve the newest AMI for their CloudFormation template?","explanation":"AWS publish the latest AMI IDs for Operating Systems in AWS-managed parameters in the Parameter Store.  By using a Custom Resource in Lambda you can retrieve the relevant AMI ID and return it to the CloudFormation service, that way ensuring that your templates always use the newest AMI.","links":[{"url":"https://aws.amazon.com/blogs/mt/query-for-the-latest-windows-ami-using-systems-manager-parameter-store/","title":"Select AMI using Systems Manager Parameter Store"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources-lambda.html","title":"AWS Lambda-backed Custom Resources"}],"answers":[{"id":"dc0efa07b1be89f7cfd1ab666df2f949","text":"CloudFormation Custom Resource using Lambda","correct":true},{"id":"7eb8f6238570dc713a360eae3029648f","text":"CloudFormation Mappings","correct":false},{"id":"cdf3a2f6faa3abf891b952dde17eb469","text":"CloudFormation Template Transformation","correct":false},{"id":"8c19fb5ff9d451c3f315e96ca8563b84","text":"CloudFormation Linked Parameters","correct":false},{"id":"2751cfe1530d4333f0bdac2d7b7c21bd","text":"CloudFormation using AWS Systems Manager Parameter Store","correct":true}]},{"id":"32db26ef-70e3-4541-b3e5-7cde3ad73c9e","domain":"dep-prov","question":"In order to enable encryption at rest using EC2 and Elastic Block Store,  you must ________.","explanation":"To enable encryption, you must specify encryption when creating the EBS volume.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html","title":"About EBS Encryption"}],"answers":[{"id":"64237cc9809266ebc9fb12b6cede9aa8","text":"Configure encryption using X.509 certificates","correct":false},{"id":"aaed5dee4871b8256093659e8bbeba4a","text":"Configure encryption using the appropriate Operating Systems file system","correct":false},{"id":"d8e355c7726e173ad29951d3461865d6","text":"Configure encryption when creating the EBS volume","correct":true},{"id":"4bd8d581e477097d1396901aab8b3cf4","text":"Mount the EBS volume in to S3 and then encrypt the bucket using a bucket policy","correct":false}]},{"id":"9f4a3688-de11-407f-99a7-f332ade4066e","domain":"dep-prov","question":"You are running an EC2 instance and have created and attached an EBS volume with default settings. You notice that the volume status check for the volume has failed and the instance can no longer access the volume. How can you access the information on the volume?","explanation":"When Amazon EBS determines that a volume's data is potentially inconsistent, it disables I/O to the volume from any attached EC2 instances by default. This causes the volume status check to fail, and creates a volume status event that indicates the cause of the failure. Switching on Enable Volume IO will allow the instance to access the volume. Switching on Auto-Enabled IO will also achieve the same outcome automatically but this is disabled by default. All other options are incorrect.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html#work_volumes_impaired","title":"Working with an Impaired Volume"}],"answers":[{"id":"bf737cfd17a3b913cb405f896e5e9b7d","text":"Switch on Enable Volume IO","correct":true},{"id":"8daa3d585fbafd5057d0e3bf2af521e0","text":"The volume can no longer be accessed","correct":false},{"id":"7de363a9824728f9b2e5c0a8efd8c6c3","text":"Switch off Enable Volume IO","correct":false},{"id":"628b701156eef0c168e27dc6d58a9d15","text":"Switch off Auto-Enabled IO","correct":false}]},{"id":"c9f0e61e-627b-421e-8a57-0d04983c25c4","domain":"security-comp","question":"You are a consultant working for a company who has recently completed their migration from an on-premise data centre to AWS. Most of the migration has been for EC2 instances, which have been sized to match the specifications they were originally using on-premise (CPU, memory, etc.). They have setup a Business Support plan with AWS. The technical manager is unhappy with the high costs, and wants to find ways to reduce them. What would the simplest way be to find ways to reduce their AWS costs in the short-term?","explanation":"This is a very common scenario for businesses migrating to the cloud, and discovering the operational expenditure (OPEX) costs of AWS. AWS Trusted Advisor has a lot of simple and effective recommendations for Cost Optimization. Some may not be applicable in your case, but it is a very easy way to find potential options for reducing your costs. These features are unlocked with the AWS Support Plans of Business or Enterprise. CloudWatch metrics can be very useful for right-sizing your instances (aligning the needs of the application workload with the instance specifications), but CloudWatch will also automate this to an extent as well by finding under-utilized instances. Reducing your support plan is usually an unwise move for production workloads, despite their cost, as they can be very important when outages are experienced. Advocating for a transition to PaaS and SaaS is definitely a strategic cost-saving measure, but it forms part of a long term business strategy, since it involves significant resources, both in time and money","links":[{"url":"https://aws.amazon.com/premiumsupport/technology/trusted-advisor/","title":"AWS Trusted Advisor"},{"url":"https://d1.awsstatic.com/whitepapers/architecture/AWS-Cost-Optimization-Pillar.pdf","title":"AWS Whitepaper - Cost Optimization Pillar"}],"answers":[{"id":"52107942e028b953519341a78f6815ca","text":"Inspect the CloudWatch metrics to better right-size the instances","correct":false},{"id":"55af961ef2471aec130c45657098b110","text":"Investigate recommendations from AWS Trusted Advisor's automated checks","correct":true},{"id":"39788d9f10797f3b8c876dbe95022c0d","text":"Advocate a transition to more cost-effective PaaS and SaaS solutions","correct":false},{"id":"b4e67747b2a23a55a53554b964d1ab9b","text":"Reduce the expensive AWS Support Plan to lower costs","correct":false}]},{"id":"1ac9a5ce-d1dd-4b67-963e-c329dab20cce","domain":"dep-prov","question":"You've been tasked with the design of a disaster recovery solution that will allow a backup application in eu-west-1 to assume the duties of your main application running in eu-west-2. Which of the following processes will you need to follow first to get the backup server up-and-running in the backup region?","explanation":"To use an AMI in a region other than the one in which it was created, the AMI must be *copied* to the new region. From there, you can build a new server based on that AMI.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html#copy-amis-across-regions","title":"Cross-Region AMI Copying"}],"answers":[{"id":"b3b57590edfded4925d17c01250cd2a4","text":"Image the primary server, open its permissions to 'any region' and share the AMI with a new instance in eu-west-1; use that image as the template for your backup server.","correct":false},{"id":"52f25ffef53f0dae9b6c3ea47606a040","text":"Use cross-region replication to copy the server to the backup Region.","correct":false},{"id":"33f9cce716c72b0ee6990957bf7a55a2","text":"Image the primary server and copy its AMI from eu-west-2 to eu-west-1; use that image as the template for your backup server.","correct":true},{"id":"f5d75f5446b082c6621fe586b3b19e52","text":"Since AMIs are global, all you need to do is create a backup instance from the AMI of the original server.","correct":false}]},{"id":"0ac7251e-689e-4cd6-bfb9-992628fb3e3c","domain":"mon-rep","question":"There has been a major outage of S3 in US-East-1 where many of your company’s AWS assets are. Your boss wants to know what effect this will have on your organization. What dashboard can you use to help diagnose how this will affect your individual organisation?","explanation":"AWS Personal Health Dashboard provides alerts and remediation guidance when AWS is experiencing events that may impact you. Inspector is an automated security assessment service. AWS X-Ray helps developers analyze and debug production, distributed applications.","links":[{"url":"https://aws.amazon.com/premiumsupport/phd/","title":"AWS Personal Health Dashboard"}],"answers":[{"id":"0863526e514d88cd2d00b39f8dda0920","text":"X-Ray","correct":false},{"id":"6bd8c280d2d212f5f6338714620001a4","text":"AWS Service Dashboard","correct":false},{"id":"cf4db9f312542c8284a6ccdefcd98544","text":"Personal Health Dashboard","correct":true},{"id":"3473fa31769f9b170662878d3f67fc8c","text":"AWS Inspector Dashboard","correct":false}]},{"id":"4a4c6ce8-b38c-4905-8705-d5bbfb0ee4b2","domain":"mon-rep","question":"You have an Auto Scaling group resource in your AWS account. The desired number of instances has been changed from 2 to 0 recently and all instances were terminated because of it. You want to know when and how the resource was created and who modified the desired number. Which service can help you to quickly get the information?","explanation":"You can quickly get the configuration history in the AWS Config configuration timeline including who and when the resource was created or modified. A new CloudTrail does not help as it only records new events. Athena may work however it is not as easy as AWS Config. CloudWatch metrics cannot provide the required configuration information.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/view-manage-resource-console.html","title":"Viewing configuration details in AWS Config"}],"answers":[{"id":"25787092d8b6523e05e0155400bcc0bf","text":"Check the Auto Scaling group resource in AWS Config and inspect the configuration timeline for the resource.","correct":true},{"id":"8d084da5294ed862175582c9670af840","text":"Create a new CloudTrail and save the events to CloudWatch Logs. Search for the Auto Scaling group resource in the logs.","correct":false},{"id":"9a2b6d3211e9c6531d8bf6f6ff2e8351","text":"Save all CloudTrail events to an S3 bucket. Perform SQL queries in the bucket via Athena.","correct":false},{"id":"65d77f35794d925b20ff78961bb4c1df","text":"Check the CloudWatch metrics for the Auto Scaling group resource. CloudWatch metrics can record the data for 6 weeks.","correct":false}]},{"id":"bf96ed55-16e4-466e-af19-219458837cba","domain":"security-comp","question":"Which of the following is not a possible use case for AWS inspector","explanation":"Amazon Inspector in an agent-based service which allows you to automate security vulnerability assessments throughout your development and deployment pipeline or against static production systems. You cannot install the Inspector agent on an RDS instance.","links":[{"url":"https://aws.amazon.com/inspector/faqs/","title":"Inspector FAQs"}],"answers":[{"id":"8543a5ae6daf2a49147c11e5e7422e9f","text":"Use a CloudWatch Event to trigger AWS inspector to run an assesment","correct":false},{"id":"c0f6489b2e3fb0571e505c7a5560a3c3","text":"To scan your EC2 instances for Common Vulnerabilities and Exposures ","correct":false},{"id":"80b4d5c55b7c39f3d2aa5c485154a2a8","text":"Automate the assessment of your EC2 instance on a regular basis","correct":false},{"id":"2c7f5727b64a2fdb39bb7c27b505ad87","text":"The inspection of an RDS instance","correct":true}]},{"id":"d8712c58-e428-439d-9ab3-08ea592b2621","domain":"security-comp","question":"According to the AWS shared responsibility model, for which of the following Amazon RDS related activities is AWS responsible for? Select two.","explanation":"For abstracted services, such as Amazon RDS, AWS operates the infrastructure layer, the operating system and platforms. Customers are responsible for managing their data and configuring the service to match their use case.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"d32c7e4db37e5a49bf2a46e014c7e3e4","text":"Managing the database settings that are specific to the application.","correct":false},{"id":"40cc6a7d99253bc52a711d7d98c7cb17","text":"Modifying routing tables and networking ACLs in a VPC to ensure that the DB instance is reachable from client instances in the VPC.","correct":false},{"id":"27c7bca9cd16dba139d69e22a86058e0","text":"Installing the database software.","correct":true},{"id":"e027059be4bd1474a9b38c65eb31e483","text":"Operating system patches.","correct":true},{"id":"586f8ae0e95c353d5c1ca86956480c3b","text":"Configure networking ACLs to ensure that cross-AZ communication is possible in fail-over scenarios.","correct":false}]},{"id":"4c7fb750-0ec0-4c9f-8dc6-378122edf97a","domain":"automation","question":"The engineering team of a digital marketing company has a lot of AWS Lambda functions directly created and managed using the AWS Console. The CTO has mandated that the code and the deployments are managed using templates and the code is stored in a code repository to enable proper version control processes. How can the team achieve this?","explanation":"SAM templates and CloudFormation templates can be used to manage the Lambda function code. Out of all the options, only CodeCommit can be used directly as a managed service for a code repository. S3 buckets are not used directly as a code repository.","links":[{"url":"https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html","title":"What is SAM"}],"answers":[{"id":"f33ec453646a2074aa930a61f466fc1a","text":"Use CloudFormation templates to manage the lambda function code. Use ECR for the code repository.","correct":false},{"id":"a85a26cd33fe99adb584452fa780dce2","text":"Use CloudFormation templates to manage the lambda function code. Use S3 buckets for the code repository.","correct":false},{"id":"c5fe89ee64d944e98f26b2db3fa7cea2","text":"Use SAM templates to manage the lambda function code. Use CodeCommit for the code repository.","correct":true},{"id":"b670d764967a3aa65a1424279e37291c","text":"Use SAM templates to manage the lambda function code. Use S3 buckets for the code repository.","correct":false}]},{"id":"bbc0d4f2-a086-4cc0-95d5-0c429442f773","domain":"data-man","question":"You are an HR administrator for your company with admin access to an S3 bucket containing confidential employee information. Per direction from your head of HR, you've developed a process that removes any objects from the bucket pertaining to any employees that have left the company. That has recently been a mass exodus of employees due to a merger and the process removes a large number of objects from the bucket but when you immediately list objects in the bucket you still see the deleted objects. How would you explain the issue to the head of your HR?","explanation":"Amazon S3 achieves high availability by replicating data across multiple servers within AWS data centers. If a PUT request is successful, your data is safely stored. However, information about the changes must replicate across Amazon S3, which can take some time A process deletes an existing object and immediately lists keys within its bucket. Until the deletion is fully propagated, Amazon S3 might list the deleted object. Checking the bucket policy and IAM permissions could help troubleshoot access issues but as an admin to the bucket they would not apply in this scenario. The Personal Health Dashboard could help identify outages but given you can still list objects an outage would not apply.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Amazon S3 Data Consistency Model"}],"answers":[{"id":"20a599949f9375e6770343fef499f4c6","text":"You need to check the IAM permissions to verify you have permissions to delete objects.","correct":false},{"id":"7a6759da5716febb13eccf8d941266e9","text":"You need to check the bucket policy to to verify the bucket can delete objects.","correct":false},{"id":"d28f63e64ee7ffc9b6865d6893ea9239","text":"There is nothing to troubleshoot. The S3 bucket is operating normally.","correct":true},{"id":"a5cc883830b9ac97276a40509ded9935","text":"You need to check the Personal Health Dashboards to verify there are no outages in the AWS Region hosting the bucket.","correct":false}]},{"id":"edaeeffd-65ec-4d45-8f2d-f37d50773681","domain":"dep-prov","question":"You create an Oracle database in AWS RDS for an application. As the database instance needs to integrate with an S3 bucket, you want to configure an IAM role for the database to read and write the bucket objects. You already have an IAM role for EC2 and the EC2 instance can use the role to transfer files from and to the bucket properly. However, when you try to add the same role to the database, the role cannot be found. What is the reason and how to fix it?","explanation":"The trust entity of the IAM role must include rds.amazonaws.com for a RDS database to assume it. The existing role only contains the trust entity of ec2.amazonaws.com so it cannot be used for RDS. The resource and action parts of the role should be good as EC2 can work with S3 properly. Policies of an IAM role do not have the “principal” part.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-s3-integration.html","title":"RDS integrates with S3"}],"answers":[{"id":"d87fa6b85878f5af177443f4c2aa638f","text":"The trust entity of the role is the service of EC2 instead of RDS. You should create a new role for the RDS service to assume.","correct":true},{"id":"edb854c1df5fa32a6d19c322a736f525","text":"The permissions of the IAM role do not list the resource of the S3 bucket.","correct":false},{"id":"d0d2809faf6ff80ea9807995d483b3e0","text":"For the RDS database to assume the role, the IAM policy should allow the action of \"rds:*\".","correct":false},{"id":"9b1ce3b64821b8efb42f867e68acfbae","text":"The IAM role needs to add a principal of RDS so that any RDS instance can assume the role to integrate with S3.","correct":false}]},{"id":"745e3728-9374-48a2-b7ab-7ee0c4ad4ad6","domain":"security-comp","question":"Your AWS Organization includes multiple AWS accounts. To meet the security compliance, AWS Config should be enabled in all accounts. The data needs to be recorded in all regions as well. You prefer using a central place to view all the resource configurations and compliance data recorded in AWS Config. How would you configure it?","explanation":"An aggregator is an AWS Config resource type that collects AWS Config data across multiple accounts and multiple regions. You can easily add an AWS Organization and select all regions in the aggregator. After that, you can get an aggregated view of the configuration information of AWS resources, an overview of Config rules and their compliance state. You do not need to manually enable AWS Config in all regions and all accounts. And AWS Config cannot be enabled in the AWS Organizations panel.","links":[{"url":"https://docs.aws.amazon.com/config/latest/developerguide/setup-aggregator-console.html","title":"Setting up an aggregator in AWS Config"}],"answers":[{"id":"2317a132eeda89bc0a88eb9b628b6d06","text":"In AWS Organizations panel, enable AWS Config for all the regions. View the centralized configuration data in AWS Organizations.","correct":false},{"id":"4787f6c13efd28a83db2125402fa372b","text":"Enable AWS Config in all regions for each account. Configure AWS QuickSight to view the aggregated data.","correct":false},{"id":"6bfb56d27b2d920c4cc3001c82233f29","text":"Create an aggregator in AWS Config. Add the AWS Organization to the aggregator and select all AWS regions.","correct":true},{"id":"a856258c8005e338f9c1b40c80449899","text":"Enable AWS Config in all regions and all accounts. Select an S3 bucket to store all the configuration data.","correct":false}]},{"id":"7a800486-b78e-43ec-88ea-ffa673a94745","domain":"mon-rep","question":"A SysOps administrator has been asked to implement monitoring of an application using Elasticache to improve database response times.  Recently the application has begun to perform slowly.  They notice that the eviction rate is high for the Cluster.  What could you consider doing to rectify this issue?","explanation":"Scaling up and out is the recommended approach when the eviction rate is high on the cluster.  Elasticache is an in-memory service and therefore cannot use Provisioned IOPs for storage.  AWS does not provide an auto scaling service in Elasticache. Increasing the ConnectionOverhead value would reduce the amount of memory available for storing cache items, so is unlikely to improve the eviction rate.","links":[{"url":"https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/CacheMetrics.WhichShouldIMonitor.html#metrics-evictions","title":"Which Metrics Should I Monitor?"}],"answers":[{"id":"c8e144f5e160266566a48649def7cb74","text":"Redeploy the Elasticache cluster to use Provisioned IOPs storage","correct":false},{"id":"85688e53214b00837ac8ae9bb22e9d81","text":"Increase the ConnectionOverhead value of the cluster","correct":false},{"id":"ea661bc3f4ee7300ed230572ef878635","text":"Increase the cluster size or add more nodes to the cluster","correct":true},{"id":"0dedcafa7f1671fda48c2d4515da1fcb","text":"Enable Autoscaling on the Elasticache Cluster","correct":false}]},{"id":"414ac705-4dc4-4261-9523-5439c70ee19e","domain":"data-man","question":"You are running a relational database on a provisioned IOPS volume that is set to handle a moderate amount of traffic during the month. You know to expect a 10x spike in traffic during the final three days of each month due to month-end processing. How would you architect your storage environment to meet this expected increase in demand?","explanation":"With Elastic Volumes, you can increase volume size, adjust performance, or change the volume type while the volume is in use. You can continue to use your application while the change takes effect. Using CloudWatch alarms to automate these workflows is best practice. A reserved instance would not help in scaling to meet increased demand. Multi-AZ is for failover/disaster recovery purposes. Attaching multiple volumes is not best practice as it would increase cost and waste storage space during periods of low demand.","links":[{"url":"https://aws.amazon.com/blogs/aws/amazon-ebs-update-new-elastic-volumes-change-everything/","title":"Amazon EBS Update â€“ New Elastic Volumes Change Everything"}],"answers":[{"id":"8df9d9e9da10ed671385be6f7b1a0ffc","text":"Use a CloudWatch alarm to watch for a volume that is running at or near its IOPS limit. Initiate a workflow and approval process that could provision additional IOPS or change the type of the volume.","correct":true},{"id":"d49d9044d5ba871697b4be060e80701e","text":"Enable multi-AZ for your RDS instance to account for the increased demand and spread the load between at least two instances.","correct":false},{"id":"afe5d1141b5bb2e9227d1d7d8adeb777","text":"Attach multiple Provisioned IOPS volumes for your relational database in order to meet the expected increase in demand.","correct":false},{"id":"870c3d2a2d0fd0b784490ec327392d9e","text":"Purchase an AZ-specific reserved instance for your relational database in order to gain the benefit of reserved capacity.","correct":false}]},{"id":"27109f2b-2906-43cb-90b4-3e2bcfad7ab8","domain":"high-avail","question":"You are a consultant working for a global company. They are hosting their companies CRM web application on-premise across servers in three different countries. Amazon Route 53 is being used as their DNS Provider. When the servers in one of the countries goes down, traffic starts to drop instead of being redirected to the two working sites. Corporate policies prohibit client data being stored or transferred through a Public Cloud Provider. What would the simplest solution be to their issue?","explanation":"Multivalue Answer Routing will perform simple health checks on IP addresses before sending traffic to them. This has advantages over a simple routing, where an outage of one of the IP Addresses would result in failures to connect. Corporate policies prohibit in this scenario the storage or transfer of client data from the CRM through a Public Cloud Provider. This effectively rules out the migration to EC2, or the use of CloudFront as a CDN. Transferring DNS to an on-premise service may allow for more flexibility and abilities to write special health checks, but it would certainly not be the most simple option","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Amazon Route 53 Routing Policies"}],"answers":[{"id":"dcfd51b6eec1175ce379fb23d19ec48f","text":"Transfer their DNS Zone to on-premise DNS servers to allow administrators more power to respond to outages","correct":false},{"id":"1ed8875652253a24ebf466592454a1be","text":"Use a Multivalue Answer Routing Policy on their Route 53, including the Health Checks to detect outages","correct":true},{"id":"bad6a2c2cd6a244c640ffb67243421bd","text":"Migrate the servers to EC2 in three different regions to prevent outages in local datacentres","correct":false},{"id":"abb8f1f2096c4f271cf6c11ab4be0ab4","text":"Implement CloudFront as a CDN for their website, ensuring global fault tolerance","correct":false}]},{"id":"y895ku45-wsg2-9rye-087a-zdmu2wd7qtr8","domain":"mon-rep","question":"Which AWS service can be used to log API calls from the AWS console, the EC2 CLI, the AWS CLI, or the AWS SDKs.","explanation":"CloudTrail captures API calls and delivers the log files to an Amazon S3 bucket.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/APIReference/using-cloudtrail.html","title":"Logging API Calls Using AWS CloudTrail"}],"answers":[{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false},{"id":"a8c600be214ced26950e704d39c3ca21","text":"CloudWatch Logs","correct":false},{"id":"92fbbd5478621cf8f70624389759b44c","text":"CloudTrail","correct":true},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false}]},{"id":"17885db5-c61d-4edf-b0e3-e9d449d8e618","domain":"mon-rep","question":"Which of the following EC2 instance metrics are sent to Amazon CloudWatch by default? Select three.","explanation":"CPU utilization, disk I/O and network traffic are visible to the hypervisor running the instance and are sent to CloudWatch by default. For the others, you would need to install CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/viewing_metrics_with_cloudwatch.html","title":"Available CloudWatch Metrics for Your Instances"}],"answers":[{"id":"b4e5bb2b6842990e919682b3d6d5726c","text":"Volume of incoming and outgoing network traffic","correct":true},{"id":"ec1e54ae04652319df5c011f228c07ac","text":"Free disk space","correct":false},{"id":"613b1188dd73dfdb768f39cfad3cc9a3","text":"Memory utilization","correct":false},{"id":"c4903df1e41e0ba0b4636e753d8c7661","text":"Disk read and write operations","correct":true},{"id":"2105454033539f83d3b07265aac88d7a","text":"The amount of swap space currently in use","correct":false},{"id":"fb8326e1edbd06b1bf6ea0332e089055","text":"CPU utilization","correct":true}]},{"id":"74489755-3525-47c8-89c0-c840d59c5f54","domain":"dep-prov","question":"It is not possible to share an AMI across AWS Regions.","explanation":"You can copy an Amazon Machine Image (AMI) within or to another AWS region using the AWS Management Console, the AWS command line tools or SDKs, or the Amazon EC2 API. Copying a source AMI results in an identical but distinct target AMI with its own unique identifier.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html#copy-amis-across-regions","title":"Cross-Region AMI Copy"}],"answers":[{"id":"f8320b26d30ab433c5a54546d21f414c","text":"False","correct":false},{"id":"f827cf462f62848df37c5e1e94a4da74","text":"True","correct":false},{"id":"2a861232a02567f87d2cdbd622fbc89d","text":"False. AMIs must be copied to another region. One cannot simply share them.","correct":true},{"id":"129cfa3cabe8c0069adacf27b64e1022","text":"True, but only if you have sufficient permissions.","correct":false}]},{"id":"0e17eb91-9745-4365-8b54-5ebb2c6ffeb5","domain":"data-man","question":"A company wants to create a disaster recovery account involving creating snapshots of RDS, EC2 instances and EFS.  There are additional business and regulatory backup compliance requirements such as backups must be kept for three years but then must be destroyed.  Your manager wants to know how you could go about taking scheduled snapshots and deleting them once the retention period is expired with the lowest cost and operational overhead.","explanation":"AWS Backup is a centralised place to create backups of your EBS, RDS, and EFS resources.  There is no additional cost for setting up backup plans and retention policies, and this is a managed service so it's a perfect option to present to your manager.","links":[{"url":"https://aws.amazon.com/backup/","title":"AWS Backup"}],"answers":[{"id":"52b5e3e90161fce097eca53313efd955","text":"Use AWS Data Recovery Manager to create a storage vault and automated backup and retention rules.","correct":false},{"id":"fc24b51d19eedb53ab68e9e1569c9458","text":"Use AWS Backup to create a vault and a Backup Plan to take backups on a schedule and automatically delete them once expired.","correct":true},{"id":"8be1adb291f4f253ef46691652254d1f","text":"Browse the AWS Marketplace and purchase a backup tool which can run in your AWS account and perform the backup for you.","correct":false},{"id":"d75279ac650753a76148e6ac6c1b380e","text":"Your team should write some Lambda functions which are triggered by CloudWatch Events on a cron expression.  Create another lambda to delete snapshots once they are expired.","correct":false}]},{"id":"095bed19-081d-4865-acff-d6f9bc29eb7c","domain":"automation","question":"Which of the following is the only required component of a CloudFormation template?","explanation":"As the primary purpose of CloudFormation is to create a collection of related AWS resources, the Resources section is the only required section of a CloudFormation template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-anatomy.html","title":"CloudFormation Template Anatomy"}],"answers":[{"id":"7df96b18c230f90ada0a9e2307226338","text":"Templates","correct":false},{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":false},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":true},{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false}]},{"id":"c4f661ee-5ea1-4e69-9440-52bea0321a6a","domain":"mon-rep","question":"You have set CloudWatch billing alarms for your instances running in eu-west-2. However, when you try to access the billing information and alarms, no information is visible. Why might this be?","explanation":"Billing and Alarm data can be accessed only from the us-east-1 region.","links":[{"url":"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/free-tier-alarms.html","title":"Creating a Billing Alarm"}],"answers":[{"id":"b5ff6f2dfd759f7e70f27d7529e4462b","text":"You need to login as the account owner to see such information.","correct":false},{"id":"fb7a7d16c3f39960e7afde6babd422e1","text":"Billing and Alarm data can be accessed only from the us-east-1 region.","correct":true},{"id":"cd2c9fa4324b5861276dbbf7f4f593a8","text":"You need to login as the root user to see such information.","correct":false},{"id":"7f3a3688c3f0cddb24c07255b9d13767","text":"Billing and Alarm data can be accessed only from the us-west-1 region.","correct":false}]},{"id":"f0c47538-7997-40fc-9c82-27eea818fac2","domain":"security-comp","question":"A company has started running its e-commerce application in container workloads in AWS. The e-commerce application is running its web tier in Amazon ECS and the database tier in RDS all inside a VPC. Under the AWS shared responsibility model, which activities is AWS NOT responsible for?","explanation":"AWS takes care of the underlying software for managed services. For services such as EC2, the instance hypervisor and underlying hardware are managed and maintained by AWS. It is the customer's responsibility to monitor and manage the memory utilization of the containers in services such as ECS and EKS.","links":[{"url":"https://aws.amazon.com/compliance/shared-responsibility-model/","title":"Shared Responsibility Model"}],"answers":[{"id":"ac7ca331a57c32d9975616bf91327c82","text":"Monitoring and managing the memory utilization of the containers","correct":true},{"id":"b7a8057898c923210f320a3bcccbcbca","text":"Maintaining the underlying hardware infrastructure of the instances used by ECS","correct":false},{"id":"9abfc73643ea9090379aae3cd89400d1","text":"Patching the instance hypervisor","correct":false},{"id":"1dfb8644f2cce2dca687a152b45b7d54","text":"Patching the database instance software of RDS","correct":false}]},{"id":"3acceef5-9df8-49d6-a227-cd414a046293","domain":"networking","question":"As a SysOps Administrator you are tasked with improving the performance of a website that is serving customers in two separate Regions. There are customers in us-west-2, and customers in ap-southeast-1. There is growing demand for the website from customers in ap-southeast-1, and customers have been complaining about poor latency. How would you ensure that users are directed to the Region with the best performance?","explanation":"If your application is hosted in multiple AWS Regions, you can improve performance for your users by serving their requests from the AWS Region that provides the lowest latency. To use latency-based routing, you create latency records for your resources in multiple AWS Regions. When Route 53 receives a DNS query for your domain or subdomain (example.com or acme.example.com), it determines which AWS Regions you've created latency records for, determines which region gives the user the lowest latency, and then selects a latency record for that region. Geolocation may sound like the right answer but it may trick you thinking that the closest Region assumes the lowest latency, but this is not the case. There is no need to separate the website into two Regions as this is an administrative burden. An ALB with HTTP path routing has nothing to do with improving latency.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-latency","title":"Choosing a Routing Policy"}],"answers":[{"id":"eb8c189707a52253445f78cd5791eb37","text":"Use Amazon Route 53 geolocation routing to direct customers.","correct":false},{"id":"4a2ab96fd93984723a369708f83fec95","text":"Configure an Application Load Balancer in front of your website. Use the HTTP path routing to direct the customer to the best performing website.","correct":false},{"id":"57eb7a3ea4c9eabfca928f3ce81be0b7","text":"Use Amazon Route 53 latency-based routing to direct customers.","correct":true},{"id":"20977b79538e17806537e17b503fb602","text":"Separate your website into two websites -- one in us-west-2, and one in ap-southeast-1. Routinely log into both Regions to maintain both websites.","correct":false}]},{"id":"b63a9012-82a9-4a3f-9c32-2766b7adbdf6","domain":"networking","question":"You are a SysOps Administrator setting up a VPN connection between your on-premises data center and with AWS. You currently have an Amazon VPC setup with a Virtual Private Gateway. You have installed a customer gateway to your on-prem data center and router for your on-premises network is showing status OK. When you try to connect the EC2 instance in your Amazon VPC to a virtual machine in your data center it does not work. How should you set up the route table in the Amazon VPC?","explanation":"To enable instances in your VPC to reach your customer gateway, you must configure your route table to include the routes used by your Site-to-Site VPN connection and point them to your virtual private gateway. You can enable route propagation for your route table to automatically propagate those routes to the table for you.","links":[{"url":"https://docs.aws.amazon.com/vpn/latest/s2svpn/SetUpVPNConnections.html","title":"AWS Site-to-Site VPN"}],"answers":[{"id":"7607506e7811e80615e897ab0057315b","text":"Configure a route to the customer gateway.","correct":false},{"id":"39e27dda89073759c58b8260fe34ffb8","text":"Configure a route to the internet gateway.","correct":false},{"id":"06625c579c97e66a67f1dda1fb750f64","text":"Configure a route to the NAT gateway.","correct":false},{"id":"92b30688af3ba53d2f0a13cd249bd865","text":"Configure a route to the virtual private gateway.","correct":true}]},{"id":"6eb6dee0-9456-492e-afc7-b7c860b04c92","domain":"mon-rep","question":"You have a fleet of EC2 webservers behind an application load balancer. Your web application had some down time which involved some 5XX errors during a very important time in your business 1 week ago. Although you maintain application logs on individual EC2 instances, you do not store these logs anywhere central and unfortunately the EC2 instances that experienced the downtime have since been terminated. How could you review this log data?","explanation":"Elastic Load Balancing provides access logs that capture detailed information about requests sent to your load balancer. Each log contains information such as the time the request was received, the client's IP address, latencies, request paths, and server responses. These logs are encrypted and stored in S3.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-access-logs.html","title":"Application Load Balancer Access Logs"}],"answers":[{"id":"ae59c599efa75d438daecb43cc08ad41","text":"Use AWS X-ray to restore the logs from the terminated EC2 instances","correct":false},{"id":"d53665e5cde1c8f661130ca2882d789a","text":"Open the AWS artifact service. Create a new artifact job and point the AWS artifact agents at the terminated EC2 instances. Download the metrics and review in CloudWatch.","correct":false},{"id":"c13c66278433ebb606e21e9c9f5250fd","text":"Create a new AWS inspector job to pull the snapshots of the EC2 instances from S3 and run a report in conjuction with AWS Athena.","correct":false},{"id":"49774faac3030c4425f2aa345cb89dc0","text":"If access logs is turned on for your application load balancer you could review this data by reviewing the logs in S3.","correct":true}]},{"id":"6c456d08-f571-4a63-833d-ef8c49757ef4","domain":"automation","question":"You have an application running on several Amazon EC2 instances in an Auto Scaling group attached to an Elastic Load Balancer. You check the ELB logs in the S3 bucket and realize that instances that fail the ELB health checks are not being replaced. How would you troubleshoot this issue?","explanation":"The default health checks for an Auto Scaling group are EC2 status checks only. If an instance fails these status checks, the Auto Scaling group considers the instance unhealthy and replaces it. If you've attached one or more load balancers or target groups to your Auto Scaling group, the group does not, by default, consider an instance unhealthy and replace it if it fails the load balancer health checks. To do this, configure the Auto Scaling group to use Elastic Load Balancing health checks. The listener rules determines how your load balancer routes request traffic, and the trace ID traces request through your ELB.","links":[{"url":"https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-elb-healthcheck.html","title":"Amazon EC2 Auto Scaling"}],"answers":[{"id":"9283050a2c9b87649381de2f1f54a3e7","text":"Configure request tracing on the load balancer to update the X-Amzn-Trace-Id header before sending the request to the Auto Scaling group.","correct":false},{"id":"9bc372b00a1c40e68b34b0d3e9f6edc3","text":"Update the listener rules on the load balancer to allow for health checks on the ELB.","correct":false},{"id":"e5f3d2525407af983596253361c1af26","text":"Configure the Auto Scaling group to use ELB health checks to have the Auto Scaling group replace the instance.","correct":true},{"id":"ba4ba5112eec0a2ca6312a45f8834c76","text":"Check the access logs permissions. Adjust the log permissions to allow ELB to write logs to the S3 logs bucket.","correct":false}]},{"id":"2bd13304-db2d-4120-9487-7e13d7008a63","domain":"dep-prov","question":"EC2 instances are launched from Amazon Machine Images (AMIs). A given public AMI:","explanation":"An AMI cannot be launched into another region. To launch an AMI into a region other that the one in which it was created, the AMI must be copied to that other region first.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html","title":"Copying an AMI"}],"answers":[{"id":"9ba6ee29e152b251b8fc17d5d2aca126","text":"Can be used to launch EC2 instances in any AWS region.","correct":false},{"id":"3b690d9883c0bbec853ffdc3be150208","text":"Can only be used to launch EC2 instances in the same AWS country as the AMI is stored.","correct":false},{"id":"5a70861f841598d574b8ebd61e20cfc1","text":"Can only be used to launch EC2 instances in the same AWS Availability Zone (AZ) as the AMI is stored.","correct":false},{"id":"7096f3da806d7b3014ab808eb74d213a","text":"Can only be used to launch EC2 instances in the same AWS region as the AMI is stored.","correct":true}]},{"id":"cf072a65-cda4-492e-b42a-7ee7305bb9b6","domain":"high-avail","question":"You have a web application with the front end hosted on EC2 and the database hosted on RDS in a single Availability Zone. You notice that when backups are taken from your RDS instance, your applications performance is severely degraded. Your boss asks you to fix the issue. What should you do?","explanation":"You should create a multi-AZ RDS instance and migrate your DB to it. This way, when the backups are taken, they will be taken from the secondary -- not the primary.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html","title":"Multi-AZ RDS"}],"answers":[{"id":"ff7e77cc465d1a0285e8ea4c236bee2c","text":"Turn off backups for RDS. This will fix the performance issue immediately.","correct":false},{"id":"531a46711a70d61a60f10cf29f31171b","text":"Move your RDS instance to an in-house SQL server that has Netbackup installed.","correct":false},{"id":"ebcb098cff009244307167ae9489e2b1","text":"Create a multi-AZ RDS instance and migrate your DB to it. This way, when the backups are taken, they will be taken from the secondary -- not the primary.","correct":true},{"id":"82ca3fd61d44001c088391d1a6af1442","text":"Upgrade your RDS instance to an instance that has better disk IO. This way, the IO suspension from the back up will be \"equaled out\" by the increase in the new IO from the upgraded instance.","correct":false}]},{"id":"a8d6d4f3-6877-4e89-9e7c-c6f83b83e1de","domain":"automation","question":"A small business has a monolithic application utilizing several EC2 instances. The technology consultant has suggested to the engineering team of the business that the application is containerized to improve the deployment and scaling processes of the team. The engineering team processes both critical and non-critical workloads within the application. Given the size of the application and the number of transactions being processed by the system, the CFO has instructed the engineering team to ensure that the setup must be as cost-effective as possible without introducing the risk of data loss for critical workloads. How can the engineering team accomplish this?","explanation":"On-demand EC2 instances should be used for critical workloads and spot instances can be used for non-critical workloads. ECR (Elastic Container Registry) is not used to run container processes. Instead, it is used to store container images. For containerization requirements, ECS (Elastic Container Service) is used to manage container workloads. Step Functions is used for orchestrating different processes and can not be used by itself to manage the workloads.","links":[{"url":"https://aws.amazon.com/blogs/compute/running-high-scale-web-on-spot-instances/","title":"Running High-Scale Web Applications on Spot Instances"}],"answers":[{"id":"47e42a6e665f0a913236e5580553e3ad","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECS and spot EC2 instances for non-critical workloads.","correct":true},{"id":"1d3682fdb0beec13b13a37502cfb3108","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use Step Functions and on-demand EC2 instances for non-critical workloads.","correct":false},{"id":"b8864524b96a467a8f1023b5a2c9f003","text":"Use Step Functions and on-demand EC2 instances for the critical workloads. Use Step Functions and spot EC2 instances for non-critical workloads.","correct":false},{"id":"ddf2c2e29f2118061f6a160054593338","text":"Use ECS and on-demand EC2 instances for the critical workloads. Use ECR and spot EC2 instances for non-critical workloads.","correct":false}]},{"id":"a9a1c52d-1ddd-4c03-bbdf-0f7088844afd","domain":"networking","question":"Which of the following features only relate to Spread Placement Groups?","explanation":"Spread placement groups have a specific limitation that you can only have a maximum of 7 running instances per Availability Zone and therefore this is the only correct option.  Deploying instances in a single Availability Zone is unique to Cluster Placement Groups only and therefore is not correct.  The remaining options are common to all placement group types and so are not specific to Spread Placement Groups.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html","title":"Placement Groups"}],"answers":[{"id":"1d682b1a96356cb1692b672d49901726","text":"The name of your placement group must be unique within your AWS Account","correct":false},{"id":"62e7178075716f412e6f6cea59a301f5","text":"Instances must be deployed in a single Availability Zone","correct":false},{"id":"fde221f3ce615a530b477c7f48067e81","text":"There is no charge for creating a placement group","correct":false},{"id":"fd53e2976a7600365c406c0580e67862","text":"The placement group can only have 7 running instances per Availability Zone","correct":true}]},{"id":"05e4d4e8-28e3-4373-bbbd-06c207454310","domain":"data-man","question":"What is the first thing you should do to prevent your users from accidentally deleting objects in an S3 bucket?","explanation":"When a user performs a DELETE operation on an object, subsequent simple (un-versioned) requests will no longer retrieve the object. However, all versions of that object will continue to be preserved in your Amazon S3 bucket and can be retrieved or restored. Only the owner of an Amazon S3 bucket can permanently delete a version. You can set Lifecycle rules to manage the lifetime and the cost of storing multiple versions of your objects.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html","title":"Using Versioning"}],"answers":[{"id":"534876320349a72fec1b677bbcc87c53","text":"Change all users' IAM permissions so they can only s3:Get*, s3:List* and s3:Put*.","correct":false},{"id":"4640422acdab41a13ddc95492dc9c60d","text":"Distribute objects via CloudFront.","correct":false},{"id":"7ce4f0314f67bee93968904b2ab51ac3","text":"Allow objects to be accessed only with signed URLs.","correct":false},{"id":"0b291595e5f35c7ba8fed39ca7464577","text":"Enable Versioning on the bucket.","correct":true}]},{"id":"739bcd50-ad59-4cbe-a911-17cff575b80d","domain":"security-comp","question":"You have been asked by your company's CISO to create and manage an S3 bucket with highly confidential company information. Only two business-critical individuals within the company should have read and write access to the bucket. All other personnel should not have access. How would you go about ensuring the security and confidentiality of the bucket in the most efficient manner?","explanation":"Bucket policies provide centralized access control to buckets and objects based on a variety of conditions, including Amazon S3 operations, requestors, resources, and aspects of the request (for example, IP address). The policies are expressed in the access policy language and enable centralized management of permissions. The permissions attached to a bucket apply to all of the objects in that bucket. AWS Config would only report on if buckets are in compliance to any rules set. An explicitly deny for all IAM users would work but it isn't the most efficient solution. Bucket access control lists apply to bucket objects, not the bucket itself.","links":[{"url":"https://docs.aws.amazon.com/AmazonS3/latest/dev/Introduction.html","title":"Bucket Policies"}],"answers":[{"id":"ebf041183040a34a7220734ce5497478","text":"Create an IAM policy for all non-business-critical individuals that explicitly denies access to the bucket.","correct":false},{"id":"fdadf86a8030fc5cbfd2cdb0b16b95f6","text":"Create a bucket policy explicitly granting access to the two principals.","correct":true},{"id":"06899090182266f944ef7ff8a34750ed","text":"Create an AWS Config rule that denies access to the S3 bucket except for the business-critical users. Set an alarm whenever someone attempts to access the bucket.","correct":false},{"id":"48f34a3e8e8a95fcbe3abee586e0f775","text":"Create a bucket access control list to explicitly grant access to the two individuals.","correct":false}]},{"id":"17b1cb9e-6c30-4cb5-8122-ac0799b51470","domain":"mon-rep","question":"Your team uses a CloudFormation template to configure a CloudWatch dashboard. The dashboard includes metrics of a classic load balancer such as HTTPCode_Backend_5XX and HTTPCode_ELB_5XX. The development team changes the type of the load balancer to network load balancer. However, after you recreate the CloudFormation stack, the metrics in the CloudWatch dashboard do not report any data. What is the cause of it?","explanation":"CloudFormation uses the resource type AWS::CloudWatch::Dashboard to create a CloudWatch dashboard. And the resource configures the metrics names in the DashboardBody. Metrics: HTTPCode_Backend_5XX and HTTPCode_ELB_5XX are valid only for the Classic Load Balancer, and are not supported in the Network Load Balancer (NLB), since NLBs operate in layer 4. The DashboardBody in the template needs to be modified to include the appropriate NLB metrics.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-cloudwatch-metrics.html","title":"CloudWatch Metrics for network load balancer"}],"answers":[{"id":"fee717ce407145a9caf9135e8b046e55","text":"Network load balancers do not support reporting metrics to CloudWatch dashboard. Only Classic load balancers do.","correct":false},{"id":"fb1a3d94cf187bb86bd85a8a4d584c4d","text":"It takes longer time for the network load balancer to send metrics data to the CloudWatch dashboard. Wait at least half an hour.","correct":false},{"id":"0c719bf2f29ec9b673c0092df8426d3c","text":"The target groups of the network load balancer are unhealthy so that they do not report any data.","correct":false},{"id":"959ff1c7a797aea82688e7a5b2468b64","text":"The selected metrics: HTTPCode_Backend_5XX and HTTPCode_ELB_5XX are not supported in a network load balancer.","correct":true}]},{"id":"5dddbe8f-a62f-4692-b8a5-61e1ff70f722","domain":"high-avail","question":"You run a popular desktop application which is hosted on a fleet of EC2 instances behind an autoscaling group. After three years you are about to release version 9, which millions of people have been waiting for with excitement. When you released version 8, 8 years ago your website crashed from the demand. You need to prevent this from happening on this release. What AWS service could you use to assist with this?","explanation":"CloudFront works together with your website and speeds up delivery of your content by caching it at Edge Locations local to your users","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/HowCloudFrontWorks.html","title":"CloudFront"}],"answers":[{"id":"52c99d94be86aed6ff572f5dd85fc5c9","text":"Use AWS Shield to protect the software update from too many users attempting to download it at once","correct":false},{"id":"e5e2e10e37ff47a42272a2c0335fca65","text":"Use Cloudfront to cache the software update at Edge Locations so as to keep up with the demand","correct":true},{"id":"e994c20e96f7f92075129815a13774c3","text":"Host the update in AWS Aurora and turn on Aurora Accelerator to keep pace with the demand","correct":false},{"id":"3ea178bab502b44ed89d0a22b2fcfa78","text":" Host the update on a single T2 nano instance on EC2 and publish the public IP address to your customers to download","correct":false}]},{"id":"3a6ecc9f-2e62-4807-b2f7-0d4f0e032cc3","domain":"networking","question":"You're configuring an Elastic Load Balancer. What can you do to ensure that a user request always goes to the same server?","explanation":"You can use the sticky session feature (also known as session affinity) to enable the load balancer to bind a user's session to a specific instance. This ensures that all requests from the user during the session are sent to the same instance.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html","title":"Sticky Sessions for Your Classic Load Balancer"}],"answers":[{"id":"4ff5c8a41331ce8a8718cf02c632ff5d","text":"Enable sticky sessions","correct":true},{"id":"6586c5993a69b3d3955cc5bf228a0792","text":"Enable Connection Draining","correct":false},{"id":"55c493073aa412bee5b26fa084e13092","text":"Enable Zonal Failover","correct":false},{"id":"fe11d265f3c285c0d795d272a9eff45a","text":"Use Multi-Zone Load Balancing","correct":false}]},{"id":"983c6fbc-20eb-4389-a91f-491d1f1e230b","domain":"networking","question":"You have a simple VPC with a single public subnet and a security group that allows access from source 0.0.0.0/0. Although you have both an Internet Gateway and Elastic IP specified for your instance, you are still unable to reach the instance via SSH. What have you forgotten to do?","explanation":"For the outside world to be able to communicate with your instance, you must allow inbound traffic on both the Security Group and the Route Table.","links":[{"url":"https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html#AddRemoveRoutes","title":"Adding and Removing Routes from a Route Table"}],"answers":[{"id":"cb7394a526c29652c88dc22d58ad386a","text":"You have failed to associate the Internet Gateway with the custom Route Table.","correct":true},{"id":"9c4da4b8220f1bcf509bc4cd3ccd943f","text":"You forgot to associate the Security Group with the Route Table.","correct":false},{"id":"1e8881ac02fb21089d364fb6f88436a7","text":"You have forgotten to associate the Elastic IP with the private IP.","correct":false},{"id":"93b61a7d33d3f54dee0f2c7dfd033254","text":"You haven't associated the Internet Gateway with the Security Group.","correct":false}]},{"id":"e9a2a106-8596-4e7c-bd0b-7a274c9b65f1","domain":"mon-rep","question":"Your organization is growing and your CISO is concerned with the increasing risk of users accessing resources they shouldn't have permissions for. What is the most effective solution to track requests for access to S3 buckets?","explanation":"To track requests for access to your bucket, you can enable access logging. Each access log record provides details about a single access request, such as the requester, bucket name, request time, request action, response status, and error code, if any. Access log information can be useful in security and access audits. AWS Config does not collect logs. AWS CloudWatch aggregates logs into one place. You could collect AWS CloudTrail logs for API calls to an S3 bucket but the most effective method is to turn on access logging for the bucket.","links":[{"url":"https://d0.awsstatic.com/whitepapers/AWS%20Storage%20Services%20Whitepaper-v9.pdf","title":"Amazon Storage Services Overview"}],"answers":[{"id":"dcd1426526e6edaa4108cf53b54f5886","text":"Turn on access logging for the bucket","correct":true},{"id":"aa39a2d244d1792f0833837683ceaba8","text":"Turn on AWS CloudWatch logs on the bucket","correct":false},{"id":"5e65dc82f972821c704a45d2cb78368e","text":"Turn on AWS CloudTrail for the bucket","correct":false},{"id":"ff1f340f3014857175b4708e7eefa686","text":"Turn on AWS Config access for the bucket","correct":false}]},{"id":"4871ce12-9da0-4e28-b1e4-373560dbdffa","domain":"automation","question":"A telecommunications company sends out monthly bills to their customers. Usage is accumulated during the month by nightly batch jobs that process call details. The company is in the process of migrating the billing system to AWS to reduce costs. What approach will provide them with the most cost effective solution for the compute portion of their nightly batch runs?","explanation":"AWS Batch provides allocation strategies to consider capacity and throughput in addition to cost when provisioning instances for jobs. This is a newer feature that provides more flexibility than the previous scheme that chose an instance that was the best fit based on vCPU, memory, and GPU requirements. Creating a pool of EC2 Reserved Instances might result in unused capacity if workload requirements change. Lambda is not currently available as a compute resource for AWS Batch.","links":[{"url":"https://aws.amazon.com/batch/","title":"AWS Batch"},{"url":"https://aws.amazon.com/blogs/compute/optimizing-for-cost-availability-and-throughput-by-selecting-your-aws-batch-allocation-strategy/","title":"Optimizing for cost, availability and throughput by selecting your AWS Batch allocation strategy"}],"answers":[{"id":"3220afaa7c6fd31e7a8d35ce1e2df1fa","text":"Configure AWS Batch to choose an instance type for each job based on vCPU, memory, and GPU requirements at the lowest cost.","correct":false},{"id":"96ef18a4d93470acb7dbd558eb666ca3","text":"Specify AWS Lambda as the compute resource for AWS Batch. Invoke the appropriate Lambda functions for each job.","correct":false},{"id":"8633cd86b6633324660fa073362c2f98","text":"Schedule jobs with AWS Batch into a pool of EC2 Reserved Instances that contains enough servers for the minimum number of jobs that will be run on any one night. Use an Auto Scaling Group to provision Spot Instances to handle any additional demand.","correct":false},{"id":"0bb4d60773589240e55a5a506ee84275","text":"Use AWS Batch allocation strategies to define capacity, throughput, and cost priorities for instance type provisioning.","correct":true}]},{"id":"f988ca16-ff44-497e-aae5-876954a55a31","domain":"security-comp","question":"You are creating a fleet of EC2 instances that will be inside an autoscaling group. These EC2 instances will need to write a custom metric to CloudWatch and will need the appropriate permissions with which to do this. What is the most secure way to enable this?","explanation":"you should create an IAM role with CloudWatch permissions and modify the autoscaling launch configuration to use EC2 instances that have been assigned the new role.","links":[{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/using-service-linked-roles.html#create-service-linked-role","title":"IAM: Creating a Service-Linked Role"}],"answers":[{"id":"29ed526af182672c01bd543082494019","text":"Create an IAM role with CloudWatch permissions and assign this to RDS. The existing EC2 instances will automatically be able to report to CloudWatch via RDS.","correct":false},{"id":"5a06900e462d7f086d273697c7a6abdc","text":"Create a unique user in IAM with CloudWatch permissions and store these credentials in GitHub. Have the EC2 instances pull these credentials when they need to log to CloudWatch.","correct":false},{"id":"5764c31d8e5f450a679416b744d2d853","text":"Create a unique user in IAM with CloudWatch permissions and modify the autoscaling group to include a boot strap script that passes the EC2 instance that users credentials.","correct":false},{"id":"abefd699f3f65202335f75e9e67df3a9","text":"Create an IAM role with CloudWatch permissions and modify the autoscaling launch configuration to use EC2 instances that have been assigned the new role.","correct":true}]},{"id":"a4edb410-e5e5-40b4-9335-1da82639c2e3","domain":"networking","question":"You work for an investment bank, supporting a mission critical stock market data processing application running on EC2 and consuming real-time data feeds from your on-premises systems. Your traders are complaining that the system is sometimes very slow to refresh the data and you suspect that this is due to fluctuations in available network bandwidth between AWS and your datacentre. What improvement can you suggest to give users a consistent experience and improve performance for users?","explanation":"AWS Direct Connect is a network service that provides an alternative to using the Internet to connect customer's on premise sites to AWS.","links":[{"url":"https://aws.amazon.com/directconnect/faqs/","title":"Direct Connect FAQs"}],"answers":[{"id":"35461a11ab55ba8f2b7eb1d3fcc15eff","text":"Scale out your application servers","correct":false},{"id":"5d5c067abd490006c21d11ff221c552a","text":"Configure a Direct Connect connection between your data center and AWS","correct":true},{"id":"a60c49fc87050d8b3c698515938d624b","text":"Configure S3 Transfer Acceleration to move the data into AWS much faster","correct":false},{"id":"3225172eff8d104a4744f0ee6f50d836","text":"Configure an additional Elastic IP for each of your application servers to increase the network bandwidth","correct":false}]},{"id":"8b30bb8d-7142-4b59-8d3c-4d5033f31a8f","domain":"mon-rep","question":"You are working for a company which is migrating all of its data into S3, the migration is underway but your Security Architect is concerned that not all buckets are secure and wants you identify all buckets which allow public read or write. Which service can you use to find out?","explanation":"AWS Config allows gives you a view of the configuration of your AWS infrastructure and compares it for compliance against rules you can define","links":[{"url":"https://aws.amazon.com/blogs/aws/aws-config-update-new-managed-rules-to-secure-s3-buckets/","title":"AWS Config Rules to Secure S3"}],"answers":[{"id":"58e3bfbabf904de43a6a22aca509b0d8","text":"CloudFormation","correct":false},{"id":"7c90c8f2a24f3a1a28525f19fb2c75ab","text":"AWS Inspector","correct":false},{"id":"2d80a80d60fea86242f99512dbac7529","text":"AWS Config","correct":true},{"id":"311bdda432aba736b8dcb987523c0c92","text":"CloudWatch","correct":false}]},{"id":"ba193bec-84c3-41de-9995-3736374c0700","domain":"security-comp","question":"You work for a car manufacturer who produces electric vehicles. These vehicles are state of the art and because of this your infosec team is extremely disciplined in what the company can and cannot do. The company has a saying “Dance Like No One's Watching. Encrypt Like Everyone Is.”. You need to choose an AWS service that will manage your Asymmetric encryption keys. Which service should you choose?","explanation":"CloudHSM supports asymmetric keys (a different key is used to encrypt and decrypt the data), whereas KMS can only manage symmetric keys (the same key is used to encrypt and decrypt the data). Inspector and Trusted Advisor are not encryption services","links":[{"url":"https://docs.aws.amazon.com/cloudhsm/latest/userguide/introduction.html","title":"CloudHSM User Guide"}],"answers":[{"id":"4a4df63c87b4f42081b846d9b9189984","text":"KMS","correct":false},{"id":"7c90c8f2a24f3a1a28525f19fb2c75ab","text":"AWS Inspector","correct":false},{"id":"739749e0ec278613ef4f8e6861efc722","text":"Trusted Advisor","correct":false},{"id":"a907a7338c1fb3821fbe8ed113c64b33","text":"CloudHSM","correct":true}]},{"id":"82163b46-cb90-4a66-b0fc-70e4be51a532","domain":"security-comp","question":"Consolidated Medical Devices runs thousands of EC2 instances for their application portfolio. The server fleet consists of many different operating systems and instance families. Their homegrown script-based server management scheme can no longer scale with their infrastructure growth. In addition to automating systems administration tasks, they need a solution that will simplify compliance tasks related to security assessments and patching. Which architecture will provide the management capabilities they need with the least amount of ongoing maintenance?","explanation":"Amazon Inspector automatically assesses systems for exposure, vulnerabilities, and deviations from best practices. Inspector can publish to an SNS topic, which can trigger a Lambda function to query the non-compliant EC2 agent IDs. A second SNS topic and Lambda function can assess the Inspector findings and invoke AWS Systems Manager Patch Manager capabilities to patch the non-compliant instances. AWS Systems Manager doesn't currently have the capability to integrate with Inspector automatically. Amazon GuardDuty is a threat detection service, and is not used for vulnerability assessments.","links":[{"url":"https://aws.amazon.com/inspector/","title":"Amazon Inspector"},{"url":"https://aws.amazon.com/systems-manager/","title":"AWS Systems Manager"},{"url":"https://aws.amazon.com/solutions/server-fleet-management-at-scale/?did=sl_card&trk=sl_card","title":"Server Fleet Management at Scale"}],"answers":[{"id":"aa2b9bb0b72691ec56685a805a9f2f8e","text":"Configure daily assessment runs in the Amazon GuardDuty management console. Have GuardDuty publish a message to an Amazon SNS topic, which triggers an AWS Lambda function. Have the Lambda function query GuardDuty for the instance IDs of non-compliant servers and publish them to a second SNS topic which triggers a second Lambda function. Configure the second Lambda function to invoke AWS Systems Manager to patch the non-compliant instances","correct":false},{"id":"3b16dc801e9751c29f18e70c557ca982","text":"Load the AWS Systems Manager agent and the Amazon GuardDuty agent on all EC2 instances. Configure daily assessment runs in the GuardDuty management console. Configure AWS Systems Manager to automatically receive the instance IDs of non-compliant servers and trigger Patch Manager to bring the instances into compliance","correct":false},{"id":"f33a28baafce146de4e99dc5e600e088","text":"Create an Amazon CloudWatch event to trigger Amazon Inspector to run daily security assessments. Have Inspector publish a message to an Amazon SNS topic, which triggers an AWS Lambda function. Have the Lambda function query Inspector for the agent IDs of non-compliant instances and publish them to a second SNS topic which triggers a second Lambda function. Configure the second Lambda function to invoke AWS Systems Manager to patch the non-compliant instances","correct":true},{"id":"82ae7c1a5ab7c1d3ac7a76b47966f852","text":"Install the AWS Systems Manager agent and the Amazon Inspector agent on all EC2 instances. Configure daily assessment runs in the Inspector management console. Configure AWS Systems Manager to automatically receive the agent IDs of non-compliant instances and trigger Patch Manager to bring the instances into compliance","correct":false}]},{"id":"5b71bc80-b7ef-4fde-86f0-1a73d1d63e4c","domain":"high-avail","question":"You are an AWS administrator and have set up an Elastic Load Balancer inside a VPC. The ELB spans several Availability Zones. The ELB sits in front of a web application running on Amazon EC2. You notice that incoming traffic is not being evenly distributed across the AZs. How would you solve this issue?","explanation":"Traffic not evenly distributed across the instances in multiple AZs means the traffic is going to only specific EC2 instances. This happens when either the instances which are not receiving the traffic are unhealthy, or the instances that are receiving the traffic are holding on to the session. Since there is no mention of unhealthy instances, disabling sticky sessions on the ELB is the best answer. Increasing the number of subnets and/or instances will not solve the problem as users will remain stuck to the original instance. Increasing the frequency of health checks will have no impact to force even distribution of traffic.","links":[{"url":"https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html","title":"Configure Sticky Sessions for Your Classic Load Balancer"}],"answers":[{"id":"d532ac3048a69a5902a79b51bc219bd3","text":"Increase the number of EC2 instances behind the ELB.","correct":false},{"id":"e23eea1cecbc63f7423de00e65f29614","text":"Increase the frequency of the health checks to the EC2 instances running your application.","correct":false},{"id":"b7116d2a43d8462c83e8b93fda085c71","text":"Disable sticky sessions on the ELB.","correct":true},{"id":"c0d9e44a3e92d6d91864058257e9922c","text":"Add additional subnets within your ELB and configure your ELB to span the new subnets.","correct":false}]},{"id":"1a37a76e-3c69-4ae6-8ae3-5b0db850807c","domain":"mon-rep","question":"You need to monitor memory utilization of an EC2 instance. How could you achieve this?","explanation":"Monitoring memory utilization requires the installation of the CloudWatch Agent on the instance.","links":[{"url":"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Install-CloudWatch-Agent.html","title":"Collecting Metrics and Logs from Amazon EC2 Instances and On-Premises Servers with the CloudWatch Agent"}],"answers":[{"id":"e1771db5f560892163019427b6f3742c","text":"From the CloudWatch console, enable memory ulitization metric for the instance.","correct":false},{"id":"c5d4aec73235f6dc0fda6738ef7c93f9","text":"Install CloudWatch Agent on the instance and have it collect memory utilization metrics.","correct":true},{"id":"30041d2fc11ea9b43497c2fe847b6461","text":"From the EC2 console, enable memory ulitization metric for the instance.","correct":false},{"id":"8b901f2e0a6136525aaf5ffcb881b223","text":"EC2 instance memory utilization is monitored by default.","correct":false}]},{"id":"1982b211-0620-43ed-9a88-f5237a42eae2","domain":"automation","question":"You're using CloudFormation templates to build out staging environments. Which section of the template would you edit in order to allow the user to specify the SSH key-name at start time?","explanation":"The parameters property type in CloudFormation allows you to accept user input when starting the template, allowing you to reference the user input as variable throughout your cloud formation template.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html","title":"About CloudFormation Parameters"}],"answers":[{"id":"3225a10b07f1580f10dee4abc3779e6c","text":"Parameters","correct":true},{"id":"ddcf50c29294d4414f3f7c1bbc892cb5","text":"Resources","correct":false},{"id":"bf3324c66080c0b764136797d841a2bc","text":"Outputs","correct":false},{"id":"5f71daa4813d3bca5d795bc163a67eba","text":"Mappings","correct":false}]},{"id":"eb2317bb-3bd4-4593-b217-e0610e79e106","domain":"mon-rep","question":"A critical application which runs on an EC2 instance behind an ELB is experiencing occasional outages. Associated with the outages are Windows event log entries. How can you detect these events and alert your team?","explanation":"CloudWatch Logs let you to stream logs from your EC2 instances to the CloudWatch service. A log filter on a Log Group allows you to detect occurrences of a key word or phrase. SNS can then deliver alerts for these alarms. ELB logs would not contain the keyword/phrase, nor would CloudTrail or the Autoscaling activity history.","links":[{"url":"https://docs.aws.amazon.com/en_pv/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html","title":"What Is Amazon CloudWatch Logs?"},{"url":"https://docs.aws.amazon.com/en_pv/AmazonCloudWatch/latest/logs/CountOccurrencesExample.html","title":"Example: Count Occurrences of a Term"}],"answers":[{"id":"a325e8469dc87698c1ba13863e512af5","text":"Use Autoscaling activity logs and message the team using SNS","correct":false},{"id":"33e9387fac100300d7d2d03d2561f1f4","text":"Use ELB logs and a filter to alarm on the event then message the team using SNS","correct":false},{"id":"cff2a2162045687c91304445129e482d","text":"Use CloudWatch logs with a log filter to alarm on an occurrence of the event then message the team using SNS","correct":true},{"id":"d0520b3777e34e62b94d0046d78ec3b3","text":"Use CloudTrail logs and message the team using SNS","correct":false}]},{"id":"c3455562-2ff1-472f-bf2c-1fbeddfdbe17","domain":"data-man","question":"You are a SysOps Administrator tasked with finding a storage solution as your organization moves data from you on-prem data center to AWS. The storage solution requirements are: needs to be able to scale, have a hierarchical directory structure, and have control access with POSIX permissions. What AWS storage solution would you recommend?","explanation":"Amazon EFS fulfills all these requirements. S3 An on-premises storage appliance that integrates with cloud storage. Amazon EBS is a service that provides block storage volumes for EC2 instances. S3 does not provide access control with POSIX permissions.","links":[{"url":"https://aws.amazon.com/efs/","title":"Amazon Elastic File System"}],"answers":[{"id":"516729a7c0562425406a22cfe6a2c163","text":"Amazon EBS","correct":false},{"id":"4975185c02158da3ee3dd512c1f3238a","text":"Amazon Storage Gateway","correct":false},{"id":"f7b96044a16becafecad63df1725e9c8","text":"Amazon EFS","correct":true},{"id":"270fcb785810d0206945029bb05f4e97","text":"Amazon S3","correct":false}]},{"id":"5bc4279d-2c7a-43fb-a69b-e7055d2e30e5","domain":"high-avail","question":"You have been hired by a large online store to help optimize their web application. There are 3 webservers behind an elastic load balancer and each connects to the same RDS instance. This RDS instance started out as a small memory optimized instance. However, as the traffic increased, the company has moved to a larger instance type. The current instance is already the largest RDS instance currently available and it is beginning to run out of memory. You need to find a way to further scale the web application. What should you do?","explanation":"You should add a couple of read replicas and adjust the application so that read-only traffic is diverted to these instances. Write traffic will remain with the main DB server.","links":[{"url":"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html#USER_ReadRepl.Overview","title":"Overview: Read Replicas"}],"answers":[{"id":"5677b50f46d6dbd051a4229783209657","text":"Advise the company to swap their EC2 instances for larger ones and then contact Amazon to pre-warm the Elastic Load Balancer.","correct":false},{"id":"3007d193799f9cf824fb25d828aba2c0","text":"Advise your customer that their application has grown beyond the capabilities of AWS and should be migrated back to an on-premise solution.","correct":false},{"id":"447ef3eaa17197e0fee43bf9bf881f14","text":"Increase the number of EC2 web instances so you can have even more connections to the RDS instance.","correct":false},{"id":"012be8822c0ab4df608d90fadaf5b557","text":"Add a couple of read replicas and adjust the application so that read-only traffic is diverted to these instances. Write traffic will remain with the main DB server.","correct":true}]},{"id":"b4e4d4f8-b9af-47da-9f90-2b63cab25ddf","domain":"automation","question":"As a SysOps Administrator you are managing your company's infrastructure as code. You have a number of CloudFormation templates that automate the provisioning of AWS resources for disaster recovery purposes. Your CISO have asked you for additional insights into the changes that teams are making to the CloudFormation templates in order to see when templates are updated with what changes. How would you build a solution that fulfills the CISO's ask?","explanation":"Change sets allow you to preview how proposed changes to a stack might impact your running resources. For example, whether your changes will delete or replace any critical resources, AWS CloudFormation makes the changes to your stack only when you decide to execute the change set, allowing you to decide whether to proceed with your proposed changes or explore other changes by creating another change set. Config and Lambda would be complicated to configure and unnecessary as you would be able to directly do this using change sets. Amazon Inspector is used for EC2 instances.","links":[{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html","title":"Updating Stacks Using Change Sets"}],"answers":[{"id":"a374362c79930669cc8b737ca45f03cb","text":"Create a Lambda function that parses through CloudWatch logs for any changes made to a CloudFormation stack. Ensure CloudFormation has a role assigned that sends logs to CloudWatch.","correct":false},{"id":"00c32ce29ae8b3d7291d321ea5a8c6ba","text":"Run Amazon Inspector report periodically to identify changes made to a CloudFormation stack. Forward these reports to your CISO.","correct":false},{"id":"a4e164938d62b8c500a3c3bc4680f546","text":"Create a change set by submitting changes against the stack you want to update.","correct":true},{"id":"44fab4e192c83f7e36b2143702b9958e","text":"Configure an AWS Config rule to detect changes to a CloudFormation stack. Send an SNS notification to the CISO for any changes.","correct":false}]},{"id":"f43c1eae-280e-4f5b-bd96-0620dcf7ad48","domain":"data-man","question":"A company has a new Internet of Things project. You need to create a database in AWS to store customer data for further analysis. The database does not require a relational model and the data could be served using a key-value pair. You wish to quickly configure a fast and high performing database without worrying about hardware provisioning, setup and configuration, software patching or scaling. Which of the following database types would you choose?","explanation":"As the database does not require a relational model, NoSQL databases such as DynamoDB should be considered. DynamoDB offloads the administrative burdens and AWS helps to manage the DynamoDB table including provisioning, configuration, patching, etc. Amazon Aurora and QLDB do not belong to NoSQL databases. ElastiCache is a caching solution for high throughput and low latency which are not required in this scenario.","links":[{"url":"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html","title":"Amazon DynamoDB introduction"}],"answers":[{"id":"69670a9d53817d1ec89e685997343ce2","text":"Amazon Aurora","correct":false},{"id":"6ebb7423072c5943f52c11274fd71b0b","text":"DynamoDB","correct":true},{"id":"a9d83c7f8f0b0f2a8f67b7097ee73e3a","text":"Amazon QLDB","correct":false},{"id":"50848259480914860b338e7baf94c29a","text":"ElastiCache","correct":false}]},{"id":"85c8beb3-4040-4c16-80a2-28699caea7f7","domain":"mon-rep","question":"Your company is running dozens of EC2 instances. What kind of a solution would give near real-time visualizations of multiple EC2 instance metrics at once?","explanation":"You can gather the necessary metrics together in CloudWatch Dashboards for complete operational visibility.","links":[{"url":"https://aws.amazon.com/cloudwatch/","title":"CloudWatch"}],"answers":[{"id":"eaa240abb4f0731fca4c2e20cbbbfefe","text":"Add the metrics into a CloudWatch Dashboard.","correct":true},{"id":"af39109a1cd1a96dc8fc03cad521e886","text":"Visualize the metrics with QuickSight.","correct":false},{"id":"beef56bb880b285559c0254491f4d5c9","text":"Organize the metrics into a CloudFront panel.","correct":false},{"id":"1ac4cde26a39fcabf5405c352b7bdff9","text":"Send the metrics to S3 and visualize them with S3 analytics.","correct":false}]},{"id":"a633d884-fccf-4ab0-bdff-72974f6fe06c","domain":"networking","question":"You have launched an EC2 instance into the public subnet of your custom VPC. The VPC's internet gateway is properly specified in the default route table and the instance's security group allows SSH traffic over port 22. However, you are still unable to SSH into your instance. Which of the following could explain this?","explanation":"To communicate with your instance, it must have either a public IP or an Elastic IP.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html","title":"AWS Elastic IP"}],"answers":[{"id":"3376ac0efb861775fb39e3946d485331","text":"The security group isn't properly connected to the Internet Gateway.","correct":false},{"id":"780a0b2b6809da8bfafa8cc49a2d62e3","text":"Your instance doesn't have an Elastic IP.","correct":true},{"id":"0111365d729d1d299458b0a3069b9a25","text":"Your EC2 instance doesn't have a public IP address.","correct":true},{"id":"62c19bb64f03bcc2aa277034eca8fa21","text":"You have the Internet Gatweway specified as the destination in the Route Table.","correct":false}]},{"id":"0cd21180-3ac0-45e5-859c-8a439c58b4fc","domain":"networking","question":"An organization runs a website on an Autoscaling Group behind an Application Load Balancer (ALB). During deployments the application team creates a new ASG and Load Balancer. Which DNS service can you use to route 10% of users to your new environment and the remaining 90% to your existing servers?","explanation":"Route53 allows various routing policies to direct users to one or more resources.  In this case for every ten users querying our DNS we want to send nine users to the existing infrastructure and one of the ten to our new servers. Route53 weighted routing allows us to do this by setting a weight of 1 for the new load balancer and 9 for the existing load balancer.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-weighted","title":"Amazon Route 53 Weighted Routing"}],"answers":[{"id":"ebeefbe1e321377375eb3065b4a2fc20","text":"Use Route53 failover routing","correct":false},{"id":"816c21d5068061f198f8df28aaf61e0d","text":"Use Route53 multi-answer routing","correct":false},{"id":"3299777a46e7aa18ad281b2a40bf2894","text":"Use Route53 simple routing","correct":false},{"id":"b2900db4eb2c71497f4b1817819797bc","text":"Use Route53 weighted routing","correct":true}]},{"id":"524af9a6-94c5-4c0b-a6d1-8c29011045df","domain":"automation","question":"Which AWS service allows you to consolidate billing across multiple AWS accounts, automate account creation and control access to AWS services?","explanation":"AWS Organizations offers policy-based management for multiple AWS accounts as well as consolidated billing. Personal Health Dashboard provides alerts when AWS is experiencing outages and other events that may impact you. Inspector is used for vulnerability scanning of applications running on EC2. IAM is used for policy based access control for users under a single AWS account","links":[{"url":"https://aws.amazon.com/organizations/","title":"AWS Organizations"}],"answers":[{"id":"cf4db9f312542c8284a6ccdefcd98544","text":"Personal Health Dashboard","correct":false},{"id":"9deb03cd21d41a691cdc24bfaab2820c","text":"Inspector","correct":false},{"id":"41dff7155cc7aeb11c06434f6a450bb3","text":"IAM","correct":false},{"id":"b1820ee1cf68e2e65f263ff7bb207626","text":"AWS Organizations","correct":true}]},{"id":"daea596c-77ce-4763-bc26-c7eabbeb3fed","domain":"automation","question":"The CTO of an e-commerce company has mandated the use of Infrastructure as Code (IaC) services and tools to manage the application resources and processes. The engineering team has divided the resources into two groups: application resources and network (VPC) resources. The engineering team lead has been instructed to transform the configuration of these resources into templates that can easily be configured to prepare different environments. How can the engineering team lead accomplish this?","explanation":"CloudFormation can be used for the IaC requirements in provisioning and managing AWS resources including VPC resources and other managed services. Out of all the options, only OpsWorks can be used as a Configuration Management service for the management application level processes and workloads inside EC2 instances. OpsWorks is not used for provisioning network resources. Amazon EKS is for managing and orchestrating containers using Kubernetes.","links":[{"url":"https://docs.aws.amazon.com/opsworks/latest/userguide/welcome.html","title":"OpsWorks"},{"url":"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc.html","title":"EC2 VPC"}],"answers":[{"id":"9328d9954617430931d24f7812f5d613","text":"Use Amazon EKS for the network resources. Use OpsWorks for the application resources.","correct":false},{"id":"1148de578466f53ad53ec6613254366b","text":"Use CloudFormation for the network resources. Use OpsWorks for the application resources.","correct":true},{"id":"450822349ee2cf9d667ee39de6b39f39","text":"Use CloudFormation for the network resources. Use AppSync for the application resources.","correct":false},{"id":"17ad6545a81ec8297ada8e103fe040f9","text":"Use OpsWorks for the network resources. Use CloudFormation for the application resources.","correct":false}]},{"id":"cc89c061-ab6b-4cb4-8809-12daecdbc5b4","domain":"networking","question":"A SaaS company has an existing web application set up in the AWS Singapore Region. The company created a new web application setup in the Tokyo Region. The company decided to host an active-active setup with the traffic evenly distributed between the Singapore region setup and the Tokyo region setup. The company currently uses Route 53 to manage the routing policies. How can the company accomplish this?","explanation":"Route 53 Weighted Routing Policy can distribute traffic evenly between two application environments. The Failover routing policy is only used for routing requirements involving a primary setup and a backup / failover setup. Creating and adding load balancers in the architecture will not solve the problem.","links":[{"url":"https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html","title":"Route 53 - Routing Policy"}],"answers":[{"id":"c6c1e82d29d79462db966c3f61ab6b84","text":"Use the Route 53 Failover Routing Policy","correct":false},{"id":"b050fdf9ffd82093c1a184237e0849ca","text":"Create a Network Load Balancer in the Singapore Region. Register the two web application environments in the Network Load Balancer. Point the Route 53 record set to the Network Load Balancer.","correct":false},{"id":"ad3851f2c1fb167d0adcff683b66ac90","text":"Use the Route 53 Weighted Routing Policy","correct":true},{"id":"71053c311ca592ed50fdc7ec6c5a98f5","text":"Create an Application Load Balancer in the Singapore Region. Register the two web application environments in the Application Load Balancer. Point the Route 53 record set to the Application Load Balancer.","correct":false}]},{"id":"2fa2b143-f088-4fa7-ae76-77e2cc20c508","domain":"security-comp","question":"Your company has a web application running on an EC2 instance. The instance needs to periodically access files stored in an S3 bucket in the same Region. The application will process the files and return the files into the same S3 bucket with an added prefix to the file. The instance is currently running and as a mission-critical application, it cannot be stopped or terminated. As a SysOps Administrator how would you allow the EC2 instance to access and PUT objects into the S3 bucket?","explanation":"Amazon EC2 uses an instance profile as a container for an IAM role. When you create an IAM role using the IAM console, the console creates an instance profile automatically and gives it the same name as the role to which it corresponds. If you use the Amazon EC2 console to launch an instance with an IAM role or to attach an IAM role to an instance, you choose the role based on a list of instance profile names. After you've created an IAM role, you can launch an instance, and associate that role with the instance during launch. To attach an IAM role to an instance that has no role, the instance can be in the stopped or running state. Since the application needs to be running it eliminates answer choices that require stopping the instance. It is never a good idea to embed any kind of credentials to EC2.","links":[{"url":"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide//iam-roles-for-amazon-ec2.html","title":"IAM Roles for Amazon EC2"}],"answers":[{"id":"5f35c65338be6202d5400e7df2877852","text":"Use the curl command in the running EC2 instance to embed the access key ID and secret access key with programmatic access to the S3 bucket.","correct":false},{"id":"55bf0913ab807c5d7dd8860c14a3a862","text":"Create an IAM role that has full access to the S3 bucket. Attach the role to the EC2 instance in its running state.","correct":true},{"id":"81a560d2f940bf67d58c96d5e8e284ae","text":"Create a new instance and attach an in-line policy to the instance with full access to the S3 bucket. Copy the code running in the application from the existing EC2 instance into the user data script before launching.","correct":false},{"id":"829ebe6f821bf0bc095eaed744a4ff38","text":"Create an IAM role that has full access to the S3 bucket. Copy the AMI of the instance. Launch a new instance and attach the role you created to the instance before launch. Terminate the existing running instance.","correct":false}]},{"id":"5d1249a6-960b-4540-8631-50875e04850d","domain":"mon-rep","question":"A company is using a site-to-site AWS VPN connection with static routing to allow connectivity between its corporate office and a VPC in AWS. The SysOps Administrator wants to get notified if the connection goes down. What’s the most effective way to accomplish this?","explanation":"AWS support won't do this for you. The other options would work, however, creating a CloudWatch alarm is the simplest option.","links":[{"url":"https://docs.aws.amazon.com/vpn/latest/s2svpn/monitoring-cloudwatch-vpn.html","title":"Monitoring VPN Tunnels Using Amazon CloudWatch"}],"answers":[{"id":"a05514224184194909112ecdabb8b939","text":"Write a Lambda function to check the TunnelState metric every minute and send an SNS notification if necessary.","correct":false},{"id":"4ca2750b50a6661dbeff47ae8524ff24","text":"Set up a cron job in an EC2 instance to confirm the TunnelState metric every minute and send an SNS notification if necessary.","correct":false},{"id":"b9f0b72860ab9c76417cf3f4c3ec6c98","text":"Ask AWS support to monitor the connection and send an SNS notification if necessary.","correct":false},{"id":"759ca4c838619fc5548932dc516de2cf","text":"Create a CloudWatch alarm to track the TunnelState metric and send an SNS notification if necessary.","correct":true}]},{"id":"cecf0320-a724-4341-a1c2-597f1f45ee50","domain":"security-comp","question":"A development company has been given the task of designing and building a mobile application along with a backend server for a charity event. The photos taken using the mobile application need to be directly uploaded to S3. The appropriate security controls must be implemented, in that the photos can only be accessed by the users who uploaded them. In addition to this, the charity event is expected to host hundreds of users who will use the mobile application. The engineering manager has mandated that the designed solution must be as secure and scalable as possible. How can the development company accomplish this?","explanation":"AWS STS is used to request temporary credentials for IAM entities such as IAM roles. It does not create IAM users as the operations available focus on assuming the role. When the AssumeRole operation is used with an IAM role with the appropriate permissions, a set of temporary credentials is available to be used to perform the needed operations.","links":[{"url":"https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html","title":"API Assume Role"},{"url":"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_use-resources.html","title":"ID Credential Temporary Use Resources"}],"answers":[{"id":"5e96ca666fbc203287ba81688806b0a7","text":"Create an IAM user using AWS STS for each user with the appropriate permissions to the S3 bucket. Store the user's information and generated credentials in AWS ElastiCache. Upon using the mobile application, load the credentials mapped to the corresponding IAM user in order to access S3.","correct":false},{"id":"81bf4204e57252aea98b18f2d2eef4a8","text":"Store the user's information in DynamoDB. Create an IAM role for each user with the appropriate permissions to the S3 bucket. Upon using the mobile application, generate temporary credentials using AWS STS's AssumeRole operation in order to access S3. Generate new credentials every time the application is used.","correct":false},{"id":"341595f8a8029ec2428a765f8afe97d8","text":"Create an IAM user using AWS STS for each user with the appropriate permissions to the S3 bucket. Store the user's information and generated credentials in DynamoDB. Upon using the mobile application, load the credentials mapped to the corresponding IAM user in order to access S3. Generate new credentials every time the application is used.","correct":true},{"id":"5fb28fa0a1ba63fdc85716ab1b6d0e10","text":"Generate long-term credentials using AWS STS for each user. Store the user's information and generated credentials in DynamoDB. Upon using the mobile application, load the credentials mapped to the corresponding user in order to access S3.","correct":false}]}]}}}}
